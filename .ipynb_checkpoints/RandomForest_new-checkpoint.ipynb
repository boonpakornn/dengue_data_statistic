{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest Regressor</h1>\n",
    "<h2>Import</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SMAPE calculation</h2><br>\n",
    "@param<br>\n",
    "y_true = array of actual values<br>\n",
    "y_pred = array of predicted values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smape_fast(y_true, y_pred):\n",
    "    out = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a = y_true[i]\n",
    "        b = y_pred[i]\n",
    "        c = a+b\n",
    "        if c == 0:\n",
    "            continue\n",
    "        out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 1</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "Arrays of evaluation values for MA2, MA3 and MA4 respectively.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is MA2 DFma_1 which are MA2 without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is MA2 DFma_2.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is MA2 DFma_6.<br>\n",
    "Index 19 - 21 is MA3 DFma_1.<br>\n",
    "...<br><br>\n",
    "Each MA has 3 values in each type of evaluation.<br>\n",
    "Each set of DF has 18 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 1]</h4>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 2]</h4>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation_print(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' DFma_' + str(i + 1)])\n",
    "        for j in range (3):\n",
    "            eval_arr = np.append(eval_arr, [eval_values[3 * i + 18 * j + 1], \n",
    "                                            eval_values[3 * i + 18 * j + 2], \n",
    "                                            eval_values[3 * i + 18 * j + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 2</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "Instead of having multiple MAs, we have only 1 dataset for each DF.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is DF_1 which are without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is DF_2.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is DF_6.<br><br>\n",
    "Each set of DF has 3 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 1]</h4>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 2]</h4>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation_print_original(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' DF_' + str(i + 1)])\n",
    "        eval_arr = np.append(eval_arr, [eval_values[3 * i + 1], \n",
    "                                        eval_values[3 * i + 2], \n",
    "                                        eval_values[3 * i + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 3</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "This format is for modified lags which the response variable is always DFma_1 for MA or DF_1 for without smoothing dataset.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is time horizon 1 week ahead which are without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is time horizon 2 weeks ahead.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is time horizon 6 weeks ahead.<br><br>\n",
    "Each set of time horizon has 9 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 1]</h4>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 2]</h4>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation_print_modified_lag(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' ' + str(i + 1) + '-week ahead'])\n",
    "        for j in range (3):\n",
    "            eval_arr = np.append(eval_arr, [eval_values[3 * i + 18 * j + 1], \n",
    "                                            eval_values[3 * i + 18 * j + 2], \n",
    "                                            eval_values[3 * i + 18 * j + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation_print_modified_lag_original(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' ' + str(i + 1) + '-week ahead'])\n",
    "        eval_arr = np.append(eval_arr, [eval_values[3 * i + 1], \n",
    "                                        eval_values[3 * i + 2], \n",
    "                                        eval_values[3 * i + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variables that you need to change before running the code</h2>\n",
    "<b>province</b> = 'NST' or 'Krabi'<br>\n",
    "<b>number of leaves</b> = 10<br>\n",
    "<b>data set destination</b> = '...nakhon...' or '...krabi...'<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "province1 = 'Bangkok'\n",
    "province2 = 'bangkok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal Lags</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict DFma_1 to DFma_6<br>\n",
    "- Predict DF_1 to DF_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>District level</h2>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # features: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21], \n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        train_features_withCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        test_features_withCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 to DFma_6 (col 19 -> col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_' + str(j + 1)])\n",
    "        test_labels = np.array(df_test_dist['DFma_' + str(j + 1)])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (Without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_total_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin_pop9s [col 26],\n",
    "    # bowl_pop9s [col 27],\n",
    "    # bucket_pop9s [col 28],\n",
    "    # misc_short_pop9s [col 29],\n",
    "    # jar_pop9s [col 30],\n",
    "    # pottedplant_pop9s [col 31],\n",
    "    # tire_pop9s [col 32],\n",
    "    # misc_tall_pop9s [col 33],\n",
    "    # and total_pop9s [col 34]\n",
    "    \n",
    "    train_features_withoutCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    train_features_withCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "    test_features_withoutCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    test_features_withCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_' + str(i + 1)])\n",
    "    test_labels = np.array(df_test_dist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                               + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                            + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (Normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # features: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21], \n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        train_features_withCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        test_features_withCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 to DFma_6 (col 19 -> col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_' + str(j + 1)])\n",
    "        test_labels = np.array(df_test_dist['DFma_' + str(j + 1)])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_dist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' \n",
    "                                               + str(i) + '/RF_' + province2 + '_dist_MA' + str(i) \n",
    "                                               + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' \n",
    "                                        + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_cd_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin [col 26],\n",
    "    # bowl [col 27],\n",
    "    # bucket [col 28],\n",
    "    # misc_short [col 29],\n",
    "    # jar [col 30],\n",
    "    # pottedplant [col 31],\n",
    "    # tire [col 32],\n",
    "    # misc_tall [col 33],\n",
    "    # and total [col 34]\n",
    "    \n",
    "    train_features_withoutCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    train_features_withCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "    test_features_withoutCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    test_features_withCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_' + str(i + 1)])\n",
    "    test_labels = np.array(df_test_dist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                               + province2 + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                            + province2 + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                    encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                                + province2 + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sub-district level</h1>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # features: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21], \n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 to DFma_6 (col 19 -> col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_' + str(j + 1)])\n",
    "        test_labels = np.array(df_test_subdist['DFma_' + str(j + 1)])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) + '_DFma_' \n",
    "                                           + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF1 to DF6 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_total_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin_pop9s [col 26],\n",
    "    # bowl_pop9s [col 27],\n",
    "    # bucket_pop9s [col 28],\n",
    "    # misc_short_pop9s [col 29],\n",
    "    # jar_pop9s [col 30],\n",
    "    # pottedplant_pop9s [col 31],\n",
    "    # tire_pop9s [col 32],\n",
    "    # misc_tall_pop9s [col 33],\n",
    "    # and total_pop9s [col 34]\n",
    "    \n",
    "    train_features_withoutCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    train_features_withCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "    test_features_withoutCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    test_features_withCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_' + str(i + 1)])\n",
    "    test_labels = np.array(df_test_subdist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', \n",
    "                                       header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Normal Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # features: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21], \n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 to DFma_6 (col 19 -> col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_' + str(j + 1)])\n",
    "        test_labels = np.array(df_test_subdist['DFma_' + str(j + 1)])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) \n",
    "                                           + '_DFma_' + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin_pop9s [col 26],\n",
    "    # bowl_pop9s [col 27],\n",
    "    # bucket_pop9s [col 28],\n",
    "    # misc_short_pop9s [col 29],\n",
    "    # jar_pop9s [col 30],\n",
    "    # pottedplant_pop9s [col 31],\n",
    "    # tire_pop9s [col 32],\n",
    "    # misc_tall_pop9s [col 33],\n",
    "    # and total_pop9s [col 34]\n",
    "    \n",
    "    train_features_withoutCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    train_features_withCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "    test_features_withoutCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    test_features_withCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_' + str(i + 1)])\n",
    "    test_labels = np.array(df_test_subdist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Normal Lags/Normal CD/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                       encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Normal Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modified Lags</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict DFma_1 as the target<br>\n",
    "- Predict DF_1 as the target<br>\n",
    "But adjust the independent variables <b>according to the different time horizons</b><br>\n",
    " - 1 week ahead = independent variables are DFma_0, DFma_wm1, DFma_wm2, ..., and DFma_wm6<br>\n",
    " - 2 weeks ahead = independent variables are DFma_wm1, DFma_wm2, DFma_wm3, ..., and DFma_wm6<br>\n",
    " - 3 weeks ahead = independent variables are DFma_wm2, DFma_wm3, DFma_wm4, ..., and DFma_wm6<br>\n",
    "Maximum time horizon = 6 weeks ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>District level</h2>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_1'])\n",
    "        test_labels = np.array(df_test_dist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE 1-week to R squared 6-week\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_total_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i):12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i):12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 31]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_1'])\n",
    "    test_labels = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                               + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                            + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # labels: response (target) variables DFma_1 (col 12)\n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_1'])\n",
    "        test_labels = np.array(df_test_dist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_dist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' \n",
    "                                               + str(i) + '/RF_' + province2 + '_dist_MA' + str(i) \n",
    "                                               + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' \n",
    "                                        + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_cd_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i):12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i):12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 31]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_1'])\n",
    "    test_labels = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                               + province2 + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                            + province2 + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                    encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                                + province2 + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sub-district level</h2>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # labels: response (target) variables DFma_1(col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_1'])\n",
    "        test_labels = np.array(df_test_subdist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) + '_DFma_' \n",
    "                                           + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_total_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 31]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_1'])\n",
    "    test_labels = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Adjusted CD/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', \n",
    "                                       header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Modified Lags/Adjusted CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # labels: response (target) variables DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_1'])\n",
    "        test_labels = np.array(df_test_subdist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) \n",
    "                                           + '_DFma_' + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 31]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_1'])\n",
    "    test_labels = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified Lags/Normal CD/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                       encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Modified Lags/Normal CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Combined CD (Modified Lags)</h1>\n",
    "<h2>District level</h2>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_dist_combined_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_dist_combined_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # and total [col 39]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_dist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_dist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_1'])\n",
    "        test_labels = np.array(df_test_dist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE 1-week to R squared 6-week\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Combined CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_dist_combined_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_dist_combined_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # and total [col 39]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i): 12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 40]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i): 12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 40]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_1'])\n",
    "    test_labels = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                               + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                            + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sub-district level</h2>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_subdist_combined_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_subdist_combined_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # and total [col 39]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        # labels: response (target) variables DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_1'])\n",
    "        test_labels = np.array(df_test_subdist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Combined CD/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Combined CD/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Combined CD/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) + '_DFma_' \n",
    "                                           + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Combined CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_subdist_combined_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_subdist_combined_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # and total [col 39]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 40]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 40]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_1'])\n",
    "    test_labels = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Combined CD/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Combined CD/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                       encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Combined CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modified IA</h1>\n",
    "<h2>District level</h2>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified IA/train_' + province2 + '_dist_IA_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified IA/test_' + province2 + '_dist_IA_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # total [col 39]\n",
    "        # and image/area [col 40]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_dist.iloc[:, (13 + j): 41]\n",
    "        \n",
    "        test_features_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_dist.iloc[:, (13 + j): 41]\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_1'])\n",
    "        test_labels = np.array(df_test_dist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE 1-week to R squared 6-week\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified IA/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Modified IA/train_' + province2 + '_dist_IA_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified IA/test_' + province2 + '_dist_IA_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # total [col 39]\n",
    "    # and image/area [col 40]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i): 12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 41]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i): 12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 41]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_1'])\n",
    "    test_labels = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                               + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                            + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sub-district level</h2>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified IA/train_' + province2 + '_subdist_IA_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified IA/test_' + province2 + '_subdist_IA_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # and total [col 39]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        train_features_withCD = df_train_subdist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        test_features_withCD = df_test_subdist.iloc[:, (13 + j): 40]\n",
    "        \n",
    "        # labels: response (target) variables DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_1'])\n",
    "        test_labels = np.array(df_test_subdist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Modified IA/MA' \n",
    "                                                     + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                     + '_DFma_' + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Modified IA/MA' \n",
    "                                                  + str(i) + '/RF_' + province2 + '_subdist_MA' + str(i) \n",
    "                                                  + '_DFma_' + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified IA/MA' + str(i) \n",
    "                                           + '/RF_' + province2 + '_BySubDistrict_MA' + str(i) + '_DFma_' \n",
    "                                           + str(j + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Modified IA/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Modified IA/train_' + province2 + '_subdist_IA_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified IA/test_' + province2 + '_subdist_IA_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # and total [col 39]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 40]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 40]\n",
    "        \n",
    "    train_features_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    train_features_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    test_features_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    test_features_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables DF_1 (col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_1'])\n",
    "    test_labels = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                                 + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                                 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/Original DF_0/RF_' \n",
    "                               + province2 + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 + '/Modified IA/Original DF_0/RF_' \n",
    "                            + province2 + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Modified IA/Original DF_0/RF_' \n",
    "                                       + province2 + '_BySubDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, \n",
    "                                       encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Modified IA/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2 Top rank CD</h1>\n",
    "Use the dataset from combined CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>District level</h2>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_dist_combined_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_dist_combined_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # and total [col 39]\n",
    "        \n",
    "        train_features_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        test_features_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        \n",
    "        if province1 == 'NST':\n",
    "            train_CD1 = df_train_dist.iloc[:, [26]]\n",
    "            train_CD2 = df_train_dist.iloc[:, [22]]\n",
    "            test_CD1 = df_test_dist.iloc[:, [26]]\n",
    "            test_CD2 = df_test_dist.iloc[:, [22]]\n",
    "        elif province1 == 'Krabi':\n",
    "            train_CD1 = df_train_dist.iloc[:, [35]]\n",
    "            train_CD2 = df_train_dist.iloc[:, [33]]\n",
    "            test_CD1 = df_test_dist.iloc[:, [35]]\n",
    "            test_CD2 = df_test_dist.iloc[:, [33]]\n",
    "        elif province1 == 'Bangkok':\n",
    "            train_CD1 = df_train_dist.iloc[:, [26]]\n",
    "            train_CD2 = df_train_dist.iloc[:, [33]]\n",
    "            test_CD1 = df_test_dist.iloc[:, [26]]\n",
    "            test_CD2 = df_test_dist.iloc[:, [33]]\n",
    "        \n",
    "        train_CD_attr = pd.concat([train_CD1, train_CD2], axis = 1)\n",
    "        test_CD_attr = pd.concat([test_CD1, test_CD2], axis = 1)\n",
    "        train_features_withCD = pd.concat([train_features_withoutCD, train_CD_attr], axis = 1)\n",
    "        test_features_withCD = pd.concat([test_features_withoutCD, test_CD_attr], axis = 1)\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_dist['DFma_1'])\n",
    "        test_labels = np.array(df_test_dist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE 1-week to R squared 6-week\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Selected CD/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_dist_combined_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_dist_combined_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # and total [col 39]\n",
    "    \n",
    "    # DF incidence\n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i): 12]\n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i): 12]\n",
    "    \n",
    "    # Rainfall and LST\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    \n",
    "    # Combine DF and RF and lST first\n",
    "    train_features_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    test_features_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "\n",
    "    if province1 == 'NST':\n",
    "        train_CD1 = df_train_dist.iloc[:, [26]]\n",
    "        train_CD2 = df_train_dist.iloc[:, [22]]\n",
    "        test_CD1 = df_test_dist.iloc[:, [26]]\n",
    "        test_CD2 = df_test_dist.iloc[:, [22]]\n",
    "    elif province1 == 'Krabi':\n",
    "        train_CD1 = df_train_dist.iloc[:, [35]]\n",
    "        train_CD2 = df_train_dist.iloc[:, [33]]\n",
    "        test_CD1 = df_test_dist.iloc[:, [35]]\n",
    "        test_CD2 = df_test_dist.iloc[:, [33]]\n",
    "    elif province1 == 'Bangkok':\n",
    "        train_CD1 = df_train_dist.iloc[:, [26]]\n",
    "        train_CD2 = df_train_dist.iloc[:, [33]]\n",
    "        test_CD1 = df_test_dist.iloc[:, [26]]\n",
    "        test_CD2 = df_test_dist.iloc[:, [33]]\n",
    "        \n",
    "    train_CD_attr = pd.concat([train_CD1, train_CD2], axis = 1)\n",
    "    test_CD_attr = pd.concat([test_CD1, test_CD2], axis = 1)\n",
    "    \n",
    "    train_features_withCD = pd.concat([train_features_withoutCD, train_CD_attr], axis = 1)\n",
    "    test_features_withCD = pd.concat([test_features_withoutCD, test_CD_attr], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_dist['DF_1'])\n",
    "    test_labels = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                               + '_dist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                            + '_dist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_ByDistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                + '_dist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sub-district level</h1>\n",
    "For MAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_subdist_combined_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_subdist_combined_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "    \n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin_pop9s [col 22],\n",
    "        # bowl_pop9s [col 23],\n",
    "        # bucket_pop9s [col 24],\n",
    "        # misc_short_pop9s [col 25],\n",
    "        # jar_pop9s [col 26],\n",
    "        # pottedplant_pop9s [col 27],\n",
    "        # tire_pop9s [col 28],\n",
    "        # misc_tall_pop9s [col 29],\n",
    "        # total_pop9s [col 30]\n",
    "        # bin [col 31],\n",
    "        # bowl [col 32],\n",
    "        # bucket [col 33],\n",
    "        # misc_short [col 34],\n",
    "        # jar [col 35],\n",
    "        # pottedplant [col 36],\n",
    "        # tire [col 37],\n",
    "        # misc_tall [col 38],\n",
    "        # and total [col 39]\n",
    "        \n",
    "        train_features_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        test_features_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        \n",
    "        if province1 == 'NST':\n",
    "            train_CD1 = df_train_subdist.iloc[:, [22]]\n",
    "            train_CD2 = df_train_subdist.iloc[:, [24]]\n",
    "            test_CD1 = df_test_subdist.iloc[:, [22]]\n",
    "            test_CD2 = df_test_subdist.iloc[:, [24]]\n",
    "        elif province1 == 'Krabi':\n",
    "            train_CD1 = df_train_subdist.iloc[:, [22]]\n",
    "            train_CD2 = df_train_subdist.iloc[:, [28]]\n",
    "            test_CD1 = df_test_subdist.iloc[:, [22]]\n",
    "            test_CD2 = df_test_subdist.iloc[:, [28]]\n",
    "        elif province1 == 'Bangkok':\n",
    "            train_CD1 = df_train_subdist.iloc[:, [23]]\n",
    "            train_CD2 = df_train_subdist.iloc[:, [34]]\n",
    "            test_CD1 = df_test_subdist.iloc[:, [23]]\n",
    "            test_CD2 = df_test_subdist.iloc[:, [34]]\n",
    "        \n",
    "        train_CD_attr = pd.concat([train_CD1, train_CD2], axis = 1)\n",
    "        test_CD_attr = pd.concat([test_CD1, test_CD2], axis = 1)\n",
    "        train_features_withCD = pd.concat([train_features_withoutCD, train_CD_attr], axis = 1)\n",
    "        test_features_withCD = pd.concat([test_features_withoutCD, test_CD_attr], axis = 1)\n",
    "        \n",
    "        # labels: response (target) variables from DFma_1 (col 14)      \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        train_labels = np.array(df_train_subdist['DFma_1'])\n",
    "        test_labels = np.array(df_test_subdist['DFma_1'])\n",
    "\n",
    "        # Instantiate model with 10 decision trees\n",
    "        rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "        rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "        # Train the model on training data\n",
    "        rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "        rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "        predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "        \n",
    "        df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "        df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                                  + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' \n",
    "                                                  + str(j + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                               + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' \n",
    "                                               + str(j + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "        # Calculate the evaluation values\n",
    "        #print('MA' + str(i) + ' and DFma_' + str(j + 1))\n",
    "        rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "        r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "        smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "        r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "        smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                   + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_10.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                + '/RF_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_10.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each subdistrict\n",
    "        for k in subdist_code:\n",
    "\n",
    "            # Get the subset of actual and predicted values according to the subdistrict code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(subdist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 + '/Selected CD/MA' + str(i) \n",
    "                                        + '/RF_' + province2 + '_BySubdistrict_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                        + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE 1-week to R squared 6-week\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 + '/Selected CD/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1), \n",
    "# MAE (DF_1), \n",
    "# SMAPE (DF_1), \n",
    "# R-squared (DF_1)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "train_file_dir = 'Data/' + province1 + '/Combined CD/train_' + province2 + '_subdist_combined_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Combined CD/test_' + province2 + '_subdist_combined_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# Get the input var from CSV file\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # total_pop9s [col 30]\n",
    "    # bin [col 31],\n",
    "    # bowl [col 32],\n",
    "    # bucket [col 33],\n",
    "    # misc_short [col 34],\n",
    "    # jar [col 35],\n",
    "    # pottedplant [col 36],\n",
    "    # tire [col 37],\n",
    "    # misc_tall [col 38],\n",
    "    # and total [col 39]\n",
    "    \n",
    "    # DF incidence\n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i): 12]\n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i): 12]\n",
    "    \n",
    "    # Rainfall and LST\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    \n",
    "    # Combine DF and RF and lST first\n",
    "    train_features_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    test_features_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "\n",
    "    if province1 == 'NST':\n",
    "        train_CD1 = df_train_subdist.iloc[:, [22]]\n",
    "        train_CD2 = df_train_subdist.iloc[:, [24]]\n",
    "        test_CD1 = df_test_subdist.iloc[:, [22]]\n",
    "        test_CD2 = df_test_subdist.iloc[:, [24]]\n",
    "    elif province1 == 'Krabi':\n",
    "        train_CD1 = df_train_subdist.iloc[:, [22]]\n",
    "        train_CD2 = df_train_subdist.iloc[:, [28]]\n",
    "        test_CD1 = df_test_subdist.iloc[:, [22]]\n",
    "        test_CD2 = df_test_subdist.iloc[:, [28]]\n",
    "    elif province1 == 'Bangkok':\n",
    "        train_CD1 = df_train_subdist.iloc[:, [23]]\n",
    "        train_CD2 = df_train_subdist.iloc[:, [34]]\n",
    "        test_CD1 = df_test_subdist.iloc[:, [23]]\n",
    "        test_CD2 = df_test_subdist.iloc[:, [34]]\n",
    "        \n",
    "    train_CD_attr = pd.concat([train_CD1, train_CD2], axis = 1)\n",
    "    test_CD_attr = pd.concat([test_CD1, test_CD2], axis = 1)\n",
    "    \n",
    "    train_features_withCD = pd.concat([train_features_withoutCD, train_CD_attr], axis = 1)\n",
    "    test_features_withCD = pd.concat([test_features_withoutCD, test_CD_attr], axis = 1)\n",
    "    \n",
    "    # labels: response (target) variables from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    train_labels = np.array(df_train_subdist['DF_1'])\n",
    "    test_labels = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Instantiate model with 10 decision trees\n",
    "    rf_withoutCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf_withCD = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf_withoutCD.fit(train_features_withoutCD, train_labels);\n",
    "    rf_withCD.fit(train_features_withCD, train_labels);\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_withoutCD = rf_withoutCD.predict(test_features_withoutCD)\n",
    "    predictions_withCD = rf_withCD.predict(test_features_withCD)\n",
    "    \n",
    "    df_pred_withoutCD = pd.DataFrame(predictions_withoutCD, columns = ['predicted'])\n",
    "    df_pred_withCD = pd.DataFrame(predictions_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('Random Forest/' + province1 \n",
    "                                              + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                              + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('Random Forest/' + province1 \n",
    "                                           + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                           + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', encoding = 'utf-8')\n",
    "\n",
    "    # Calculate the evaluation values\n",
    "    rmse_withoutCD = mean_squared_error(test_labels, predictions_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(test_labels, predictions_withoutCD)\n",
    "    r2_withoutCD = r2_score(test_labels, predictions_withoutCD)\n",
    "    smape_withoutCD = smape_fast(test_labels, predictions_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(test_labels, predictions_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(test_labels, predictions_withCD)\n",
    "    r2_withCD = r2_score(test_labels, predictions_withCD)\n",
    "    smape_withCD = smape_fast(test_labels, predictions_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    df_withoutCD = pd.read_csv('Random Forest/' + province1 \n",
    "                               + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                               + '_subdist_DF_' + str(i + 1) + '_withoutCD_10.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('Random Forest/' + province1 \n",
    "                            + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                            + '_subdist_DF_' + str(i + 1) + '_withCD_10.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "    # For each subdistrict\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the subdistrict code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(subdist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('Random Forest/' + province1 \n",
    "                                    + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                    + '_BySubdistrict_DF_' + str(i + 1) + '_eval_10.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('Random Forest/' + province1 \n",
    "                                + '/Selected CD/Original DF_0/RF_' + province2 \n",
    "                                + '_subdist_eval_10.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF_wm5</th>\n",
       "      <th>DF_wm6</th>\n",
       "      <th>RF_wm6</th>\n",
       "      <th>LST_wm4</th>\n",
       "      <th>bowl_pop9s</th>\n",
       "      <th>misc_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>4.406998</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074986</td>\n",
       "      <td>4.343433</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.396857</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841729</td>\n",
       "      <td>4.582279</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.838580</td>\n",
       "      <td>4.686003</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DF_wm5  DF_wm6    RF_wm6   LST_wm4  bowl_pop9s  misc_short\n",
       "0     0.0     0.0  0.011162  4.406998    0.018843       7.796\n",
       "1     0.0     0.0  0.074986  4.343433    0.018843       7.796\n",
       "2     0.0     0.0  0.000000  4.396857    0.018843       7.796\n",
       "3     0.0     0.0  0.841729  4.582279    0.018843       7.796\n",
       "4     0.0     0.0  2.838580  4.686003    0.018843       7.796"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_withCD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
