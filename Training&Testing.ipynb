{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014-2016 [Training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_Bangkok.csv'))\n",
    "df_rain = df_rain.drop('Unnamed: 0', axis =1 )\n",
    "df_rain['addrcode'] = df_rain['addrcode'].astype(str)\n",
    "df_rain = df_rain.loc[df_rain['addrcode'].str[:2] == '10']\n",
    "df_lst_2014 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2014.csv'))\n",
    "df_lst_2014 = df_lst_2014.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2014['addrcode'] = df_lst_2014['addrcode'].astype(str)\n",
    "df_lst_2014['Year'] = df_lst_2014['Year'].astype(str)\n",
    "df_lst_2015 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2015.csv'))\n",
    "df_lst_2015 = df_lst_2015.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2015['addrcode'] = df_lst_2015['addrcode'].astype(str)\n",
    "df_lst_2015['Year'] = df_lst_2015['Year'].astype(str)\n",
    "df_lst_2016 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2016.csv'))\n",
    "df_lst_2016 = df_lst_2016.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2016['addrcode'] = df_lst_2016['addrcode'].astype(str)\n",
    "df_lst_2016['Year'] = df_lst_2016['Year'].astype(str)\n",
    "df_df10000pop = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','Subdistrict','DF_10000Population_details.csv'))\n",
    "df_df10000pop['addrcode'] = df_df10000pop['addrcode'].astype(str)\n",
    "df_df10000pop = df_df10000pop.loc[df_df10000pop['addrcode'].str[:2] == '10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = df_rain.loc[df_rain['Year'] < 2017]\n",
    "df_rain = df_rain.sort_values(['Week','Year','addrcode'])\n",
    "df_rain = df_rain[['Week','Year','addrcode','rainfall']]\n",
    "df_rain['Year'] = df_rain['Year'].astype(str)\n",
    "len(df_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_2014 = df_lst_2014.loc[df_lst_2014['Week'] > 8]\n",
    "df_lst_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = [df_lst_2014, df_lst_2015, df_lst_2016]\n",
    "df_lst = pd.concat(frame)\n",
    "df_lst['addrcode'] = df_lst['addrcode'].astype(str)\n",
    "len(df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst = pd.merge(df_rain,df_lst, how = 'inner', on = ['Week','Year','addrcode'])\n",
    "df_rain_lst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','Subdistrict','DF_10000Population_details.csv'))\n",
    "df_df = df_df.drop(['Unnamed: 0','NumberCases','population'], axis = 1)\n",
    "df_df.columns = ['addrcode','Year','Week','DFp10000Pop']\n",
    "df_df['addrcode'] = df_df['addrcode'].astype(str)\n",
    "df_df['Year'] = df_df['Year'].astype(str)\n",
    "df_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df = pd.merge(df_rain_lst, df_df, how = 'inner', on = ['Year','Week','addrcode'])\n",
    "df_rain_lst_df = df_rain_lst_df[['addrcode','Week','Year','rainfall','temperature','DFp10000Pop']]\n",
    "df_rain_lst_df = df_rain_lst_df.sort_values(['Year','addrcode']).reset_index().drop('index', axis =1)\n",
    "df_rain_lst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_subdist_original.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_Bangkok.csv'))\n",
    "df_rain = df_rain.drop('Unnamed: 0', axis =1 )\n",
    "df_rain['addrcode'] = df_rain['addrcode'].astype(str)\n",
    "df_rain = df_rain.loc[df_rain['addrcode'].str[:2] == '10']\n",
    "df_lst_2014 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2014.csv'))\n",
    "df_lst_2014 = df_lst_2014.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2014['addrcode'] = df_lst_2014['addrcode'].astype(str)\n",
    "df_lst_2014['Year'] = df_lst_2014['Year'].astype(str)\n",
    "df_lst_2015 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2015.csv'))\n",
    "df_lst_2015 = df_lst_2015.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2015['addrcode'] = df_lst_2015['addrcode'].astype(str)\n",
    "df_lst_2015['Year'] = df_lst_2015['Year'].astype(str)\n",
    "df_lst_2016 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2016.csv'))\n",
    "df_lst_2016 = df_lst_2016.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2016['addrcode'] = df_lst_2016['addrcode'].astype(str)\n",
    "df_lst_2016['Year'] = df_lst_2016['Year'].astype(str)\n",
    "df_df10000pop_dist = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','District','DF_10000Population_dist_details.csv'))\n",
    "df_df10000pop_dist = df_df10000pop_dist.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = df_rain.loc[df_rain['Year'] < 2017]\n",
    "df_rain = df_rain.sort_values(['Week','Year','addrcode'])\n",
    "df_rain = df_rain[['Week','Year','addrcode','rainfall']]\n",
    "df_rain['Year'] = df_rain['Year'].astype(str)\n",
    "df_lst_2014 = df_lst_2014.loc[df_lst_2014['Week'] > 8]\n",
    "frame = [df_lst_2014, df_lst_2015, df_lst_2016]\n",
    "df_lst = pd.concat(frame)\n",
    "df_lst['addrcode'] = df_lst['addrcode'].astype(str)\n",
    "df_rain_lst = pd.merge(df_rain,df_lst, how = 'inner', on = ['Week','Year','addrcode'])\n",
    "df_rain_lst['addrcode'] = df_rain_lst['addrcode'].astype(str)\n",
    "df_rain_lst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_function = {'rainfall' : 'sum', 'temperature' : 'mean'}\n",
    "df_rain_lst_dist = df_rain_lst.groupby([df_rain_lst['addrcode'].str[:4],df_rain_lst['Week'],df_rain_lst['Year']]).aggregate(aggregation_function).reset_index()\n",
    "df_rain_lst_dist['addrcode'] = df_rain_lst_dist['addrcode'].astype(str)\n",
    "df_rain_lst_dist['Week'] = df_rain_lst_dist['Week'].astype(str)\n",
    "df_rain_lst_dist['Year'] = df_rain_lst_dist['Year'].astype(str)\n",
    "df_rain_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df10000pop_dist = df_df10000pop_dist.drop(['NumberCases','population'], axis =1)\n",
    "df_df10000pop_dist.columns = ['addrcode','Year','Week','DFp10000Pop']\n",
    "df_df10000pop_dist['addrcode'] = df_df10000pop_dist['addrcode'].astype(str)\n",
    "df_df10000pop_dist['Week'] = df_df10000pop_dist['Week'].astype(str)\n",
    "df_df10000pop_dist['Year'] = df_df10000pop_dist['Year'].astype(str)\n",
    "df_df10000pop_dist = df_df10000pop_dist[['addrcode','Week','Year','DFp10000Pop']]\n",
    "df_df10000pop_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df_dist = pd.merge(df_rain_lst_dist, df_df10000pop_dist, how = 'inner', on = ['addrcode','Week','Year'])\n",
    "df_rain_lst_df_dist = df_rain_lst_df_dist.sort_values(['Year','addrcode']).reset_index()\n",
    "df_rain_lst_df_dist = df_rain_lst_df_dist.drop('index', axis = 1)\n",
    "df_rain_lst_df_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_dist_original.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 [Testing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subdistrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_Bangkok.csv'))\n",
    "df_rain = df_rain.drop('Unnamed: 0', axis =1 )\n",
    "df_rain['addrcode'] = df_rain['addrcode'].astype(str)\n",
    "df_rain = df_rain.loc[df_rain['addrcode'].str[:2] == '10']\n",
    "df_lst_2017 = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2017.csv'))\n",
    "df_lst_2017 = df_lst_2017.drop('Unnamed: 0', axis =1 )\n",
    "df_lst_2017['addrcode'] = df_lst_2017['addrcode'].astype(str)\n",
    "df_lst_2017['Year'] = df_lst_2017['Year'].astype(str)\n",
    "df_df10000pop = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','Subdistrict','DF_10000Population_details.csv'))\n",
    "df_df10000pop['addrcode'] = df_df10000pop['addrcode'].astype(str)\n",
    "df_df10000pop = df_df10000pop.loc[df_df10000pop['addrcode'].str[:2] == '10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = df_rain.loc[df_rain['Year'] == 2017]\n",
    "df_rain = df_rain.sort_values(['Week','Year','addrcode'])\n",
    "df_rain = df_rain[['Week','Year','addrcode','rainfall']]\n",
    "df_rain['Year'] = df_rain['Year'].astype(str)\n",
    "len(df_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst = pd.merge(df_rain,df_lst_2017, how = 'inner', on = ['Week','Year','addrcode'])\n",
    "df_rain_lst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','Subdistrict','DF_10000Population_details.csv'))\n",
    "df_df = df_df.drop(['Unnamed: 0','NumberCases','population'], axis = 1)\n",
    "df_df.columns = ['addrcode','Year','Week','DFp10000Pop']\n",
    "df_df['addrcode'] = df_df['addrcode'].astype(str)\n",
    "df_df['Year'] = df_df['Year'].astype(str)\n",
    "df_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df = pd.merge(df_rain_lst, df_df, how = 'inner', on = ['Year','Week','addrcode'])\n",
    "df_rain_lst_df = df_rain_lst_df[['addrcode','Week','Year','rainfall','temperature','DFp10000Pop']]\n",
    "df_rain_lst_df = df_rain_lst_df.sort_values(['Year','addrcode']).reset_index().drop('index', axis =1)\n",
    "df_rain_lst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_subdist_original.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_Bangkok.csv'))\n",
    "df_rain = df_rain.drop('Unnamed: 0', axis =1 )\n",
    "df_rain['addrcode'] = df_rain['addrcode'].astype(str)\n",
    "df_rain = df_rain.loc[df_rain['addrcode'].str[:2] == '10']\n",
    "df_lst = pd.read_csv(os.path.join('Data','Climatic Data','Sub Result','LST_weekly_Bangkok_2017.csv'))\n",
    "df_lst = df_lst.drop('Unnamed: 0', axis =1 )\n",
    "df_lst['addrcode'] = df_lst['addrcode'].astype(str)\n",
    "df_lst['Year'] = df_lst['Year'].astype(str)\n",
    "df_df10000pop_dist = pd.read_csv(os.path.join('Data','Dengue-cases','Dengue fever data','Manipulated','District','DF_10000Population_dist_details.csv'))\n",
    "df_df10000pop_dist = df_df10000pop_dist.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = df_rain.loc[df_rain['Year'] == 2017]\n",
    "df_rain = df_rain.sort_values(['Week','Year','addrcode'])\n",
    "df_rain = df_rain[['Week','Year','addrcode','rainfall']]\n",
    "df_rain['Year'] = df_rain['Year'].astype(str)\n",
    "df_rain_lst = pd.merge(df_rain,df_lst, how = 'inner', on = ['Week','Year','addrcode'])\n",
    "df_rain_lst['addrcode'] = df_rain_lst['addrcode'].astype(str)\n",
    "df_rain_lst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_function = {'rainfall' : 'sum', 'temperature' : 'mean'}\n",
    "df_rain_lst_dist = df_rain_lst.groupby([df_rain_lst['addrcode'].str[:4],df_rain_lst['Week'],df_rain_lst['Year']]).aggregate(aggregation_function).reset_index()\n",
    "df_rain_lst_dist['addrcode'] = df_rain_lst_dist['addrcode'].astype(str)\n",
    "df_rain_lst_dist['Week'] = df_rain_lst_dist['Week'].astype(str)\n",
    "df_rain_lst_dist['Year'] = df_rain_lst_dist['Year'].astype(str)\n",
    "df_rain_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df10000pop_dist = df_df10000pop_dist.drop(['NumberCases','population'], axis =1)\n",
    "df_df10000pop_dist.columns = ['addrcode','Year','Week','DFp10000Pop']\n",
    "df_df10000pop_dist['addrcode'] = df_df10000pop_dist['addrcode'].astype(str)\n",
    "df_df10000pop_dist['Week'] = df_df10000pop_dist['Week'].astype(str)\n",
    "df_df10000pop_dist['Year'] = df_df10000pop_dist['Year'].astype(str)\n",
    "df_df10000pop_dist = df_df10000pop_dist[['addrcode','Week','Year','DFp10000Pop']]\n",
    "df_df10000pop_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_lst_df_dist = pd.merge(df_rain_lst_dist, df_df10000pop_dist, how = 'inner', on = ['addrcode','Week','Year'])\n",
    "df_rain_lst_df_dist = df_rain_lst_df_dist.sort_values(['Year','addrcode']).reset_index()\n",
    "df_rain_lst_df_dist = df_rain_lst_df_dist.drop('index', axis = 1)\n",
    "df_rain_lst_df_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_dist_original.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted Container Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area_pop = pd.read_csv(os.path.join('Data','Correlation','area_pop_bangkok.csv'), encoding = 'utf-8')\n",
    "df_area_pop = df_area_pop.drop('Unnamed: 0', axis = 1)\n",
    "df_area_pop = df_area_pop.iloc[:,[0,12,13,14,15,16,17,18,19]]\n",
    "df_area_pop['addrcode'] = df_area_pop['addrcode'].astype(str)\n",
    "df_area_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area = pd.read_csv(os.path.join('Data','Area and GSV','image_coverage','image_coverage_bangkok.csv'))\n",
    "df_area = df_area.drop(['Unnamed: 0','image_coverage'], axis = 1)\n",
    "df_area['addrcode'] = df_area['addrcode'].astype(str)\n",
    "df_area['image/area'] = df_area['image_area']/ df_area['land_area']\n",
    "df_area['image/area'].loc[df_area['image/area'] > 1 ] = 1\n",
    "df_area['image/area'] = df_area['image/area'].round(2)\n",
    "df_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_total = pd.read_csv(os.path.join('Data','Population','addrcode-index','Bangkok-population.csv'))\n",
    "df_pop_total['addrcode'] = df_pop_total['addrcode'].astype(str).str[:6]\n",
    "df_pop_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area_pop_total = pd.merge(df_area,df_pop_total, how = 'inner')\n",
    "df_area_pop_total['total_s'] = df_area_pop_total['image/area'] * df_area_pop_total['Total']\n",
    "df_area_pop_total = df_area_pop_total.iloc[:,[0,5]]\n",
    "df_area_pop_total['addrcode'] = df_area_pop_total['addrcode'].astype(str)\n",
    "df_area_pop_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_s = pd.merge(df_area_pop,df_area_pop_total, how = 'inner')\n",
    "df_pop_s['addrcode'] = df_pop_s['addrcode'].astype(str)\n",
    "df_pop_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_count = pd.read_csv(os.path.join('Data','Container Density','Subdistrict Level','container_Bangkok_subdist.csv'))\n",
    "df_container_count = df_container_count.drop('Unnamed: 0', axis = 1)\n",
    "df_container_count['addrcode'] = df_container_count['addrcode'].astype(str)\n",
    "df_container_count = df_container_count.sort_values('addrcode').reset_index().drop('index', axis = 1)\n",
    "df_container_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = pd.DataFrame(df_container_count['addrcode'])\n",
    "#==========\n",
    "a = 10\n",
    "#==========\n",
    "\n",
    "df_new_cd['bin_pop1s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bin_pop2s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bin_pop3s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bin_pop4s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bin_pop5s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bin_pop6s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bin_pop7s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bin_pop8s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bin_pop9s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['bowl_pop1s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bowl_pop2s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bowl_pop3s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bowl_pop4s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bowl_pop5s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bowl_pop6s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bowl_pop7s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bowl_pop8s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bowl_pop9s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['bucket_pop1s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bucket_pop2s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bucket_pop3s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bucket_pop4s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bucket_pop5s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bucket_pop6s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bucket_pop7s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bucket_pop8s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bucket_pop9s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['misc_short_pop1s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['misc_short_pop2s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['misc_short_pop3s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['misc_short_pop4s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['misc_short_pop5s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['misc_short_pop6s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['misc_short_pop7s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['misc_short_pop8s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['misc_short_pop9s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['jar_pop1s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['jar_pop2s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['jar_pop3s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['jar_pop4s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['jar_pop5s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['jar_pop6s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['jar_pop7s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['jar_pop8s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['jar_pop9s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['pottedplant_pop1s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['pottedplant_pop2s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['pottedplant_pop3s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['pottedplant_pop4s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['pottedplant_pop5s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['pottedplant_pop6s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['pottedplant_pop7s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['pottedplant_pop8s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['pottedplant_pop9s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['tire_pop1s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['tire_pop2s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['tire_pop3s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['tire_pop4s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['tire_pop5s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['tire_pop6s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['tire_pop7s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['tire_pop8s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['tire_pop9s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['misc_tall_pop1s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['misc_tall_pop2s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['misc_tall_pop3s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['misc_tall_pop4s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['misc_tall_pop5s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['misc_tall_pop6s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['misc_tall_pop7s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['misc_tall_pop8s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['misc_tall_pop9s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['total_pop1s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['total_pop2s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['total_pop3s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['total_pop4s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['total_pop5s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['total_pop6s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['total_pop7s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['total_pop8s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['total_pop9s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd = df_new_cd.sort_values('addrcode')\n",
    "df_new_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = df_new_cd.replace([np.inf, -np.inf], np.nan)\n",
    "df_new_cd.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = df_new_cd.fillna(0)\n",
    "df_new_cd.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Krabi/Normal Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('train_krabi_subdist'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-12] +'total'+ filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "    df_frame = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_frame['addrcode'] = df_frame['addrcode'].astype(str).str[:6]\n",
    "    # Normal Lags\n",
    "    df_frame = df_frame.iloc[:,0:25]\n",
    "    df_frame = pd.merge(df_frame, df_new_cd, how = 'inner')\n",
    "    df_frame = df_frame.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,33,42,51,60,69,78,87,96,105]]\n",
    "    # Modified Lags\n",
    "    #df_frame = df_frame.iloc[:,0:21]\n",
    "    #df_frame = pd.merge(df_frame, df_new_cd, how = 'inner')\n",
    "    #df_frame = df_frame.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,29,38,47,56,65,74,83,92,101]]\n",
    "    df_frame.to_csv(path + filename[:-12]+'total'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','Bangkok','Original','train_bangkok_subdist_original.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "df_train['addrcode'] = df_train['addrcode'].astype(str)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new = pd.merge(df_train,df_new_cd, how = 'inner')\n",
    "df_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new['rainfall'] = (df_train_new['rainfall'] / max(df_train_new['rainfall'])) * 5\n",
    "df_train_new['temperature'] = (df_train_new['temperature'] / max(df_train_new['temperature'])) * 5\n",
    "df_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_subdist_all.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new = df_train_new.iloc[:,[0,1,2,3,4,5,14,23,32,41,50,59,68,77,86]]\n",
    "df_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_new.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_subdist_total.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','Bangkok','Original','test_bangkok_subdist_original.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "df_test['addrcode'] = df_test['addrcode'].astype(str)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = pd.merge(df_test,df_new_cd, how = 'inner')\n",
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['rainfall'] = (df_test_new['rainfall'] / max(df_test_new['rainfall'])) * 5\n",
    "df_test_new['temperature'] = (df_test_new['temperature'] / max(df_test_new['temperature'])) * 5\n",
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_subdist_all.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = df_test_new.iloc[:,[0,1,2,3,4,5,14,23,32,41,50,59,68,77,86]]\n",
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_subdist_total.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area_pop = pd.read_csv(os.path.join('Data','Correlation','area_pop_bangkok_dist.csv'), encoding = 'utf-8')\n",
    "df_area_pop = df_area_pop.drop('Unnamed: 0', axis = 1)\n",
    "df_area_pop = df_area_pop.iloc[:,[0,12,13,14,15,16,17,18,19]]\n",
    "df_area_pop['addrcode'] = df_area_pop['addrcode'].astype(str)\n",
    "df_area_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area = pd.read_csv(os.path.join('Data','Area and GSV','image_coverage','image_coverage_Bangkok.csv'))\n",
    "df_area = df_area.drop(['Unnamed: 0','image_coverage'], axis = 1)\n",
    "df_area['addrcode'] = df_area['addrcode'].astype(str)\n",
    "df_area = df_area.groupby(df_area['addrcode'].str[:4]).sum().reset_index()\n",
    "df_area['image/area'] = df_area['image_area']/ df_area['land_area']\n",
    "df_area['image/area'].loc[df_area['image/area'] > 1 ] = 1\n",
    "df_area['image/area'] = df_area['image/area'].round(2)\n",
    "df_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_total = pd.read_csv(os.path.join('Data','Population','addrcode-index','NST-population.csv'))\n",
    "df_pop_total['addrcode'] = df_pop_total['addrcode'].astype(str).str[:6]\n",
    "df_pop_total = df_pop_total.groupby(df_pop_total['addrcode'].str[:4]).sum().reset_index()\n",
    "df_pop_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area_pop_total = pd.merge(df_area,df_pop_total, how = 'inner')\n",
    "df_area_pop_total['total_s'] = df_area_pop_total['image/area'] * df_area_pop_total['Total']\n",
    "df_area_pop_total = df_area_pop_total.iloc[:,[0,5]]\n",
    "df_area_pop_total['addrcode'] = df_area_pop_total['addrcode'].astype(str)\n",
    "df_area_pop_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_s = pd.merge(df_area_pop,df_area_pop_total, how = 'inner')\n",
    "df_pop_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_count = pd.read_csv(os.path.join('Data','Container Density','District Level','container_Bangkok_dist.csv'))\n",
    "df_container_count = df_container_count.drop('Unnamed: 0', axis = 1)\n",
    "df_container_count = df_container_count.sort_values('addrcode').reset_index().drop('index', axis = 1)\n",
    "df_container_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = pd.DataFrame(df_container_count['addrcode'])\n",
    "#==========\n",
    "a = 10\n",
    "#==========\n",
    "\n",
    "df_new_cd['bin_pop1s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bin_pop2s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bin_pop3s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bin_pop4s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bin_pop5s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bin_pop6s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bin_pop7s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bin_pop8s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bin_pop9s'] = a * df_container_count.iloc[:,1]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['bowl_pop1s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bowl_pop2s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bowl_pop3s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bowl_pop4s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bowl_pop5s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bowl_pop6s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bowl_pop7s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bowl_pop8s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bowl_pop9s'] = a * df_container_count.iloc[:,2]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['bucket_pop1s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['bucket_pop2s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['bucket_pop3s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['bucket_pop4s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['bucket_pop5s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['bucket_pop6s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['bucket_pop7s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['bucket_pop8s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['bucket_pop9s'] = a * df_container_count.iloc[:,3]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['misc_short_pop1s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['misc_short_pop2s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['misc_short_pop3s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['misc_short_pop4s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['misc_short_pop5s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['misc_short_pop6s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['misc_short_pop7s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['misc_short_pop8s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['misc_short_pop9s'] = a * df_container_count.iloc[:,4]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['jar_pop1s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['jar_pop2s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['jar_pop3s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['jar_pop4s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['jar_pop5s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['jar_pop6s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['jar_pop7s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['jar_pop8s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['jar_pop9s'] = a * df_container_count.iloc[:,5]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['pottedplant_pop1s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['pottedplant_pop2s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['pottedplant_pop3s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['pottedplant_pop4s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['pottedplant_pop5s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['pottedplant_pop6s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['pottedplant_pop7s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['pottedplant_pop8s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['pottedplant_pop9s'] = a * df_container_count.iloc[:,6]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['tire_pop1s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['tire_pop2s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['tire_pop3s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['tire_pop4s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['tire_pop5s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['tire_pop6s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['tire_pop7s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['tire_pop8s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['tire_pop9s'] = a * df_container_count.iloc[:,7]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['misc_tall_pop1s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['misc_tall_pop2s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['misc_tall_pop3s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['misc_tall_pop4s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['misc_tall_pop5s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['misc_tall_pop6s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['misc_tall_pop7s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['misc_tall_pop8s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['misc_tall_pop9s'] = a * df_container_count.iloc[:,8]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['total_pop1s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,1]\n",
    "df_new_cd['total_pop2s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,2]\n",
    "df_new_cd['total_pop3s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,3]\n",
    "df_new_cd['total_pop4s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,4]\n",
    "df_new_cd['total_pop5s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,5]\n",
    "df_new_cd['total_pop6s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,6]\n",
    "df_new_cd['total_pop7s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,7]\n",
    "df_new_cd['total_pop8s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,8]\n",
    "df_new_cd['total_pop9s'] = a * df_container_count.iloc[:,9]/df_pop_s.iloc[:,9]\n",
    "\n",
    "df_new_cd['addrcode'] = df_new_cd['addrcode'].astype(str)\n",
    "df_new_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = df_new_cd.replace([np.inf, -np.inf], np.nan)\n",
    "df_new_cd.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cd = df_new_cd.fillna(0)\n",
    "df_new_cd.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Krabi/Modified Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('train_krabi_dist'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-12] + 'total' + filename [0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "    df_frame = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_frame['addrcode'] = df_frame['addrcode'].astype(str).str[:6]\n",
    "    # Normal Lags\n",
    "    #df_frame = df_frame.iloc[:,0:25]\n",
    "    #df_frame = pd.merge(df_frame, df_new_cd, how = 'inner')\n",
    "    #df_frame = df_frame.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,33,42,51,60,69,78,87,96,105]]\n",
    "    # Modified Lags\n",
    "    df_frame = df_frame.iloc[:,0:21]\n",
    "    df_frame = pd.merge(df_frame, df_new_cd, how = 'inner')\n",
    "    df_frame = df_frame.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,29,38,47,56,65,74,83,92,101]]\n",
    "    df_frame.to_csv(path + filename[:-12]+'total'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','Bangkok','Original','train_bangkok_dist_original.csv'), header=0, skiprows=0)\n",
    "df_train_dist = df_train_dist.drop('Unnamed: 0', axis = 1)\n",
    "df_train_dist['addrcode'] = df_train_dist['addrcode'].astype(str)\n",
    "df_train_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist = pd.merge(df_train_dist, df_new_cd, how ='inner')\n",
    "df_train_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist['rainfall'] = (df_train_dist['rainfall'] / max(df_train_dist['rainfall'])) * 5\n",
    "df_train_dist['temperature'] = (df_train_dist['temperature'] / max(df_train_dist['temperature'])) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_dist_all.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist = df_train_dist.iloc[:,[0,1,2,3,4,5,14,23,32,41,50,59,68,77,86]]\n",
    "df_train_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/train_bangkok_dist_total.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Bangkok/Normal Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('train_bangkok'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_train_lag = pd.read_csv(os.path.join(path+filename))\n",
    "    df_train_lag = df_train_lag.drop('Unnamed: 0', axis = 1)\n",
    "    df_train_lag['WeekYear'] = df_train_lag[['Week','Year']].astype(str).sum(axis=1)\n",
    "    df_train_lag['WeekYear'] = df_train_lag['WeekYear'].astype(str).str[:-2]\n",
    "    df_train_lag.head()\n",
    "    #Normal Lags\n",
    "    list = ['92014','102014','112014','122014','132014','142014','472016','482016','492016','502016','512016','522016']\n",
    "    #Modified Lags\n",
    "    #list = ['92014','102014','112014','122014','132014','142014','522016']\n",
    "\n",
    "    for i in range(len(list)):\n",
    "         df_train_lag = df_train_lag[df_train_lag.WeekYear != list[i]]\n",
    "\n",
    "    df_train_lag.to_csv(path+filename , encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','Bangkok','Original','test_bangkok_dist_original.csv'), header=0, skiprows=0)\n",
    "df_test_dist = df_test_dist.drop('Unnamed: 0', axis = 1)\n",
    "df_test_dist['addrcode'] = df_test_dist['addrcode'].astype(str)\n",
    "df_test_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist = pd.merge(df_test_dist, df_new_cd, how ='inner')\n",
    "df_test_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist['rainfall'] = (df_test_dist['rainfall'] / max(df_test_dist['rainfall'])) * 5\n",
    "df_test_dist['temperature'] = (df_test_dist['temperature'] / max(df_test_dist['temperature'])) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_dist_all.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist = df_test_dist.iloc[:,[0,1,2,3,4,5,14,23,32,41,50,59,68,77,86]]\n",
    "df_test_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist.to_csv('Data/Modeling/Training&Testing/Bangkok/Original/test_bangkok_dist_total.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Bangkok/Modified Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_bangkok'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_test_lag = pd.read_csv(os.path.join(path+filename))\n",
    "    df_test_lag = df_test_lag.drop('Unnamed: 0', axis = 1)\n",
    "    df_test_lag['WeekYear'] = df_test_lag[['Week','Year']].astype(str).sum(axis=1)\n",
    "    df_test_lag['WeekYear'] = df_test_lag['WeekYear'].astype(str).str[:-2]\n",
    "    df_test_lag.head()\n",
    "    #Normal Lags\n",
    "    #list = ['12017','22017','32017','42017','52017','62017','472017','482017','492017','502017','512017','522017']\n",
    "    #Modified Lags\n",
    "    list = ['12017','22017','32017','42017','52017','62017','522017']\n",
    "\n",
    "    for i in range(len(list)):\n",
    "         df_test_lag = df_test_lag[df_test_lag.WeekYear != list[i]]\n",
    "        \n",
    "    df_test_lag.to_csv(path+filename, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Container Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_nst = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_NST_subdist.csv'))\n",
    "df_container_nst = df_container_nst.drop('Unnamed: 0', axis = 1)\n",
    "df_container_nst['addrcode'] = df_container_nst['addrcode'].astype(str)\n",
    "df_container_krabi = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_krabi_subdist.csv'))\n",
    "df_container_krabi = df_container_krabi.drop('Unnamed: 0', axis = 1)\n",
    "df_container_krabi['addrcode'] = df_container_krabi['addrcode'].astype(str)\n",
    "df_container_bangkok = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_Bangkok_subdist.csv'))\n",
    "df_container_bangkok = df_container_bangkok.drop('Unnamed: 0', axis = 1)\n",
    "df_container_bangkok['addrcode'] = df_container_bangkok['addrcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Bangkok/Normal Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_bangkok_sub'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-15]+'cd'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    # Normal Lags\n",
    "    df_train = df_train.iloc[:,0:25]\n",
    "    # Modified Lags\n",
    "    #df_train = df_train.iloc[:,0:21]\n",
    "    df_train = pd.merge(df_train, df_container_bangkok, how = 'inner')\n",
    "    df_train.to_csv(path + filename[:-15]+'cd'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_nst = pd.read_csv(os.path.join('Data','Container Density','District level','CD_NST_dist.csv'))\n",
    "df_container_nst = df_container_nst.drop('Unnamed: 0', axis = 1)\n",
    "df_container_nst['addrcode'] = df_container_nst['addrcode'].astype(str)\n",
    "df_container_krabi = pd.read_csv(os.path.join('Data','Container Density','District level','CD_krabi_dist.csv'))\n",
    "df_container_krabi = df_container_krabi.drop('Unnamed: 0', axis = 1)\n",
    "df_container_krabi['addrcode'] = df_container_krabi['addrcode'].astype(str)\n",
    "df_container_bangkok = pd.read_csv(os.path.join('Data','Container Density','District level','CD_bangkok_dist.csv'))\n",
    "df_container_bangkok = df_container_bangkok.drop('Unnamed: 0', axis = 1)\n",
    "df_container_bangkok['addrcode'] = df_container_bangkok['addrcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Bangkok/Normal Lags/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_bangkok_dist'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-15]+'cd'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    # Normal Lags\n",
    "    df_train = df_train.iloc[:,0:25]\n",
    "    # Modified Lags\n",
    "    #df_train = df_train.iloc[:,0:21]\n",
    "    df_train = pd.merge(df_train, df_container_bangkok, how = 'inner')\n",
    "    df_train.to_csv(path + filename[:-15]+'cd'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Container Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_nst = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_NST_subdist.csv'))\n",
    "df_container_nst = df_container_nst.drop('Unnamed: 0', axis = 1)\n",
    "df_container_nst['addrcode'] = df_container_nst['addrcode'].astype(str)\n",
    "df_container_krabi = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_krabi_subdist.csv'))\n",
    "df_container_krabi = df_container_krabi.drop('Unnamed: 0', axis = 1)\n",
    "df_container_krabi['addrcode'] = df_container_krabi['addrcode'].astype(str)\n",
    "df_container_bangkok = pd.read_csv(os.path.join('Data','Container Density','Subdistrict level','CD_Bangkok_subdist.csv'))\n",
    "df_container_bangkok = df_container_bangkok.drop('Unnamed: 0', axis = 1)\n",
    "df_container_bangkok['addrcode'] = df_container_bangkok['addrcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Nakhon/Modified Lags/'\n",
    "des = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Nakhon/Combined CD/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('train_nakhon_subdist_total'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-15]+'combined'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    df_train = df_train.iloc[:,0:30]\n",
    "    df_train = pd.merge(df_train, df_container_nst, how = 'inner')\n",
    "    df_train.to_csv(des + filename[:-15]+'combined'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_container_nst = pd.read_csv(os.path.join('Data','Container Density','District level','CD_NST_dist.csv'))\n",
    "df_container_nst = df_container_nst.drop('Unnamed: 0', axis = 1)\n",
    "df_container_nst['addrcode'] = df_container_nst['addrcode'].astype(str)\n",
    "df_container_krabi = pd.read_csv(os.path.join('Data','Container Density','District level','CD_krabi_dist.csv'))\n",
    "df_container_krabi = df_container_krabi.drop('Unnamed: 0', axis = 1)\n",
    "df_container_krabi['addrcode'] = df_container_krabi['addrcode'].astype(str)\n",
    "df_container_bangkok = pd.read_csv(os.path.join('Data','Container Density','District level','CD_bangkok_dist.csv'))\n",
    "df_container_bangkok = df_container_bangkok.drop('Unnamed: 0', axis = 1)\n",
    "df_container_bangkok['addrcode'] = df_container_bangkok['addrcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Nakhon/Modified Lags/'\n",
    "des = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Nakhon/Combined CD/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_nakhon_dist_total'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[0][:-15]+'combined'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    df_train = df_train.iloc[:,0:30]\n",
    "    df_train = pd.merge(df_train, df_container_nst, how = 'inner')\n",
    "    df_train.to_csv(des + filename[:-15]+'combined'+filename[-10:], encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing Modified IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addrcode</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801611</td>\n",
       "      <td>6891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800708</td>\n",
       "      <td>8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801206</td>\n",
       "      <td>5101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800301</td>\n",
       "      <td>7544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800907</td>\n",
       "      <td>10586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addrcode  Total\n",
       "0    801611   6891\n",
       "1    800708   8958\n",
       "2    801206   5101\n",
       "3    800301   7544\n",
       "4    800907  10586"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop = pd.read_csv(os.path.join('Data','Population','addrcode-index','NST-population.csv'))\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 68759.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Nakhon/Modified IA/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_nakhon_subdist_'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_nakhon_subdist_IA_mavg2.csv',\n",
       " 'test_nakhon_subdist_IA_mavg3.csv',\n",
       " 'test_nakhon_subdist_IA_mavg4.csv']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_nakhon_subdist_IA_mavg2.csv'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0][:-12]+'IA'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "    \n",
    "    a = 100\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train = pd.merge(df_train,df_pop, how = 'inner')\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    df_train['bin'] = df_train['bin']/df_train['Total'] * a\n",
    "    df_train['bowl'] = df_train['bowl']/df_train['Total'] * a\n",
    "    df_train['bucket'] = df_train['bucket']/df_train['Total'] * a\n",
    "    df_train['misc_short'] = df_train['misc_short']/df_train['Total'] * a\n",
    "    df_train['jar'] = df_train['jar']/df_train['Total'] * a\n",
    "    df_train['pottedplant'] = df_train['pottedplant']/df_train['Total'] * a\n",
    "    df_train['tire'] = df_train['tire']/df_train['Total'] * a\n",
    "    df_train['misc_tall'] = df_train['misc_tall']/df_train['Total'] * a\n",
    "    df_train['total'] = df_train['total']/df_train['Total'] * a\n",
    "    df_train['image/area'] = df_train['image/area'] * 100\n",
    "    df_train = df_train.drop('Total', axis = 1)\n",
    "    df_train.to_csv(path + filename, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv(os.path.join('Data','Population','addrcode-index','Bangkok-population.csv'))\n",
    "df_pop['addrcode'] = df_pop['addrcode'].astype(str).str[:6]\n",
    "df_pop = df_pop.groupby(df_pop['addrcode'].str[:4]).sum().reset_index()\n",
    "df_pop.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 35064.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Modeling/Training&Testing/Krabi/Modified IA/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.startswith('test_krabi_dist_'):\n",
    "        filename.append(f)\n",
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_krabi_dist_IA_mavg2.csv',\n",
       " 'test_krabi_dist_IA_mavg3.csv',\n",
       " 'test_krabi_dist_IA_mavg4.csv']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_krabi_dist_IA_mavg2.csv'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0][:-12]+'IA'+filename[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename:\n",
    "    \n",
    "    a = 100\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(path+filename), index_col = 0)\n",
    "    df_train['addrcode'] = df_train['addrcode'].astype(str).str[:6]\n",
    "    df_train = pd.merge(df_train,df_pop, how = 'inner')\n",
    "    df_train['bin'] = df_train['bin']/df_train['Total'] * a\n",
    "    df_train['bowl'] = df_train['bowl']/df_train['Total'] * a\n",
    "    df_train['bucket'] = df_train['bucket']/df_train['Total'] * a\n",
    "    df_train['misc_short'] = df_train['misc_short']/df_train['Total'] * a\n",
    "    df_train['jar'] = df_train['jar']/df_train['Total'] * a\n",
    "    df_train['pottedplant'] = df_train['pottedplant']/df_train['Total'] * a\n",
    "    df_train['tire'] = df_train['tire']/df_train['Total'] * a\n",
    "    df_train['misc_tall'] = df_train['misc_tall']/df_train['Total'] * a\n",
    "    df_train['total'] = df_train['total']/df_train['Total'] * a\n",
    "    df_train['image/area'] = df_train['image/area'] * 100\n",
    "    df_train = df_train.drop('Total', axis = 1)\n",
    "    df_train.to_csv(path + filename, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds Cross Validation Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "province = 'nakhon'\n",
    "level = 'dist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addrcode</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>DF_1</th>\n",
       "      <th>DF_0</th>\n",
       "      <th>DF_wm1</th>\n",
       "      <th>DF_wm2</th>\n",
       "      <th>DF_wm3</th>\n",
       "      <th>DF_wm4</th>\n",
       "      <th>DF_wm5</th>\n",
       "      <th>...</th>\n",
       "      <th>total_pop9s</th>\n",
       "      <th>bin</th>\n",
       "      <th>bowl</th>\n",
       "      <th>bucket</th>\n",
       "      <th>misc_short</th>\n",
       "      <th>jar</th>\n",
       "      <th>pottedplant</th>\n",
       "      <th>tire</th>\n",
       "      <th>misc_tall</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8001</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.074631</td>\n",
       "      <td>0.074631</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>...</td>\n",
       "      <td>3.715707</td>\n",
       "      <td>4.611</td>\n",
       "      <td>0.224</td>\n",
       "      <td>16.424</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.699</td>\n",
       "      <td>14.409</td>\n",
       "      <td>2.468</td>\n",
       "      <td>0.039</td>\n",
       "      <td>39.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.802246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.018643</td>\n",
       "      <td>1.297</td>\n",
       "      <td>0.053</td>\n",
       "      <td>3.674</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.049</td>\n",
       "      <td>3.679</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.009</td>\n",
       "      <td>9.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8003</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>0.244750</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>...</td>\n",
       "      <td>9.049635</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1.484</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8004</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151953</td>\n",
       "      <td>0.151953</td>\n",
       "      <td>...</td>\n",
       "      <td>9.243783</td>\n",
       "      <td>1.282</td>\n",
       "      <td>0.038</td>\n",
       "      <td>4.063</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.167</td>\n",
       "      <td>2.998</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.003</td>\n",
       "      <td>9.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8005</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.343855</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>1.031566</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>0.687711</td>\n",
       "      <td>0.343855</td>\n",
       "      <td>...</td>\n",
       "      <td>31.153291</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.029</td>\n",
       "      <td>2.060</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.071</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.016</td>\n",
       "      <td>4.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  addrcode  Week  Year      DF_1      DF_0    DF_wm1    DF_wm2    DF_wm3  \\\n",
       "0     8001    15  2014  0.111947  0.074631  0.074631  0.111947  0.111947   \n",
       "1     8002    15  2014  0.802246  0.000000  0.267415  0.000000  0.000000   \n",
       "2     8003    15  2014  0.000000  0.000000  0.000000  0.489500  0.489500   \n",
       "3     8004    15  2014  0.000000  0.151953  0.000000  0.151953  0.000000   \n",
       "4     8005    15  2014  0.343855  0.687711  0.687711  1.031566  0.687711   \n",
       "\n",
       "     DF_wm4    DF_wm5   ...    total_pop9s    bin   bowl  bucket  misc_short  \\\n",
       "0  0.149263  0.149263   ...       3.715707  4.611  0.224  16.424       0.317   \n",
       "1  0.802246  0.000000   ...       8.018643  1.297  0.053   3.674       0.031   \n",
       "2  0.244750  0.489500   ...       9.049635  0.648  0.016   2.200       0.013   \n",
       "3  0.151953  0.151953   ...       9.243783  1.282  0.038   4.063       0.096   \n",
       "4  0.687711  0.343855   ...      31.153291  0.257  0.029   2.060       0.031   \n",
       "\n",
       "     jar  pottedplant   tire  misc_tall   total  \n",
       "0  0.699       14.409  2.468      0.039  39.191  \n",
       "1  0.049        3.679  0.533      0.009   9.325  \n",
       "2  0.099        1.484  0.238      0.003   4.701  \n",
       "3  0.167        2.998  0.581      0.003   9.228  \n",
       "4  0.071        1.310  0.244      0.016   4.017  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(os.path.join('Data','Modeling','Training&Testing',province,'10 Folds', province+'_'+level+'_combined_mavg4.csv'), index_col = 0)\n",
    "df_data['addrcode'] = df_data['addrcode'].astype(str)\n",
    "df_data = df_data.sort_values(['Year','Week']).reset_index().drop('index', axis = 1)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenf = int(np.floor(len(df_data)/10))\n",
    "lenf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/Modeling/Training&Testing/'+province+'/10 Folds/'\n",
    "df_data = pd.read_csv(path + province+'_'+level+'_combined_mavg4.csv', index_col = 0)\n",
    "df_data['addrcode'] = df_data['addrcode'].astype(str)\n",
    "df_data = df_data.sort_values(['Year','Week']).reset_index().drop('index', axis = 1)\n",
    "\n",
    "# Rounding the length of each fold\n",
    "if np.ceil(len(df_data)/10) - (len(df_data)/10) >= 0.5:\n",
    "    lenf = int(np.floor(len(df_data)/10))\n",
    "else:\n",
    "    lenf = int(np.ceil(len(df_data)/10))\n",
    "\n",
    "# For each fold\n",
    "for i in range(10):\n",
    "    # df_data_lower: the dataset that has the lower index compared to the testing dataset\n",
    "    # df_data_higher: the dataset that has the higher index compared to the testing dataset\n",
    "    \n",
    "    # First fold\n",
    "    if i == 0:\n",
    "        df_data_higher = df_data.iloc[(lenf*(i+1)):len(df_data), :].reset_index().drop('index', axis = 1)\n",
    "        df_data_train = df_data_higher\n",
    "    # Other folds\n",
    "    else:\n",
    "        df_data_lower = df_data.iloc[0:(lenf*i), :].reset_index().drop('index', axis = 1)\n",
    "        df_data_higher = df_data.iloc[(lenf*(i+1)):len(df_data), :].reset_index().drop('index', axis = 1)\n",
    "        df_data_train = pd.concat([df_data_lower, df_data_higher])\n",
    "    df_data_train.to_csv(path + 'train_' + province2 + '_' + level + '_combined_mavg4_F' + str(i + 1) + '.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/Modeling/Training&Testing/'+province+'/10 Folds/'\n",
    "df_data = pd.read_csv(path + province+'_'+level+'_combined_mavg4.csv', index_col = 0)\n",
    "df_data['addrcode'] = df_data['addrcode'].astype(str)\n",
    "df_data = df_data.sort_values(['Year','Week']).reset_index().drop('index', axis = 1)\n",
    "\n",
    "# Rounding the length of each fold\n",
    "if np.ceil(len(df_data)/10) - (len(df_data)/10) >= 0.5:\n",
    "    lenf = int(np.floor(len(df_data)/10))\n",
    "else:\n",
    "    lenf = int(np.ceil(len(df_data)/10))\n",
    "    \n",
    "# For each fold\n",
    "for i in range(10): \n",
    "    # Select the data from row [lenf * num_fold] up to row [lenf * (num_fold + 1)] to be the testing data\n",
    "    df_data_test = df_data.iloc[(lenf*i):(lenf*(i+1)), :].reset_index().drop('index', axis = 1)\n",
    "    df_data_test.to_csv(path + 'test_' + province2 + '_' + level + '_combined_mavg4_F' + str(i + 1) + '.csv', \n",
    "                        encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
