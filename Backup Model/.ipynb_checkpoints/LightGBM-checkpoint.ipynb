{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Without CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_subdist.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_subdist.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]\n",
    "\n",
    "# Importing the dataset\n",
    "X_train = df_train.iloc[:,[6,12,18,19,20,21,22,23,24,25,26]]\n",
    "y_train = df_train.iloc[:,[3]]\n",
    "X_test = df_test.iloc[:,[6,12,18,19,20,21,22,23,24,25,26]]\n",
    "y_test = df_test.iloc[:,[3]]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.738732\tvalid_0's l1: 0.516486\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 0.738056\tvalid_0's l1: 0.516336\n",
      "[3]\tvalid_0's l2: 0.736778\tvalid_0's l1: 0.515487\n",
      "[4]\tvalid_0's l2: 0.7357\tvalid_0's l1: 0.514884\n",
      "[5]\tvalid_0's l2: 0.734812\tvalid_0's l1: 0.514011\n",
      "[6]\tvalid_0's l2: 0.734041\tvalid_0's l1: 0.513223\n",
      "[7]\tvalid_0's l2: 0.733705\tvalid_0's l1: 0.51245\n",
      "[8]\tvalid_0's l2: 0.732998\tvalid_0's l1: 0.511504\n",
      "[9]\tvalid_0's l2: 0.732626\tvalid_0's l1: 0.510584\n",
      "[10]\tvalid_0's l2: 0.732474\tvalid_0's l1: 0.50997\n",
      "[11]\tvalid_0's l2: 0.732451\tvalid_0's l1: 0.509705\n",
      "[12]\tvalid_0's l2: 0.732674\tvalid_0's l1: 0.509366\n",
      "[13]\tvalid_0's l2: 0.732718\tvalid_0's l1: 0.508932\n",
      "[14]\tvalid_0's l2: 0.733235\tvalid_0's l1: 0.508865\n",
      "[15]\tvalid_0's l2: 0.733874\tvalid_0's l1: 0.508788\n",
      "[16]\tvalid_0's l2: 0.734309\tvalid_0's l1: 0.508222\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l2: 0.732451\tvalid_0's l1: 0.509705\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "#print('Saving model...')\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The RMSE of prediction is: 0.8558334449512031\n",
      "The MAE of prediction is: 0.5097053791891465\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "df_y_pred = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "df_compare_addrcode = pd.concat([df_test_week_addrcode, df_y_pred], axis = 1)\n",
    "df_compare_addrcode.columns = [['Week','Year','addrcode','actual','predicted']]\n",
    "df_compare_addrcode.to_csv('LGBM_subdist_withoutCD.csv', encoding = 'utf-8')\n",
    "# eval\n",
    "print('The RMSE of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The MAE of prediction is:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>addrcode</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>3.434223</td>\n",
       "      <td>0.418336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.384151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.686845</td>\n",
       "      <td>0.384151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.686845</td>\n",
       "      <td>0.530001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.312388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.286441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.144741</td>\n",
       "      <td>0.286441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.307667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.291069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.517168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.256299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.144741</td>\n",
       "      <td>0.384151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.418336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.686845</td>\n",
       "      <td>0.306426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.602637</td>\n",
       "      <td>0.461838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.831586</td>\n",
       "      <td>0.284869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.379313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.602637</td>\n",
       "      <td>0.423283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.144741</td>\n",
       "      <td>0.670786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.418336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.423283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.418336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.309137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.602637</td>\n",
       "      <td>0.306097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.289840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.298125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.373689</td>\n",
       "      <td>0.461838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.686845</td>\n",
       "      <td>0.418336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>0.457896</td>\n",
       "      <td>0.304416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36</td>\n",
       "      <td>2017</td>\n",
       "      <td>800101</td>\n",
       "      <td>1.144741</td>\n",
       "      <td>0.419524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>1.153137</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7824</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>32</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>33</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>1.153137</td>\n",
       "      <td>0.301023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>34</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>35</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>36</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832</th>\n",
       "      <td>37</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>38</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>40</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>1.153137</td>\n",
       "      <td>0.296883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>41</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>42</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>43</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>1.153137</td>\n",
       "      <td>0.419890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>44</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>45</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>46</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>47</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>48</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>49</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7845</th>\n",
       "      <td>50</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>51</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>52</td>\n",
       "      <td>2017</td>\n",
       "      <td>802304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7848 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Week  Year addrcode    actual predicted\n",
       "0       7  2017   800101  3.434223  0.418336\n",
       "1       8  2017   800101  0.457896  0.384151\n",
       "2       9  2017   800101  0.686845  0.384151\n",
       "3      10  2017   800101  0.686845  0.530001\n",
       "4      11  2017   800101  0.228948  0.312388\n",
       "5      12  2017   800101  1.373689  0.286441\n",
       "6      13  2017   800101  1.144741  0.286441\n",
       "7      14  2017   800101  0.457896  0.307667\n",
       "8      15  2017   800101  1.373689  0.291069\n",
       "9      16  2017   800101  1.373689  0.517168\n",
       "10     17  2017   800101  0.228948  0.256299\n",
       "11     18  2017   800101  1.144741  0.384151\n",
       "12     19  2017   800101  1.373689  0.418336\n",
       "13     20  2017   800101  0.686845  0.306426\n",
       "14     21  2017   800101  1.602637  0.461838\n",
       "15     22  2017   800101  1.831586  0.284869\n",
       "16     23  2017   800101  1.373689  0.379313\n",
       "17     24  2017   800101  1.602637  0.423283\n",
       "18     25  2017   800101  1.144741  0.670786\n",
       "19     26  2017   800101  0.457896  0.418336\n",
       "20     27  2017   800101  0.457896  0.423283\n",
       "21     28  2017   800101  0.228948  0.418336\n",
       "22     29  2017   800101  0.228948  0.309137\n",
       "23     30  2017   800101  1.602637  0.306097\n",
       "24     31  2017   800101  1.373689  0.289840\n",
       "25     32  2017   800101  0.228948  0.298125\n",
       "26     33  2017   800101  1.373689  0.461838\n",
       "27     34  2017   800101  0.686845  0.418336\n",
       "28     35  2017   800101  0.457896  0.304416\n",
       "29     36  2017   800101  1.144741  0.419524\n",
       "...   ...   ...      ...       ...       ...\n",
       "7818   23  2017   802304  0.000000  0.304674\n",
       "7819   24  2017   802304  1.153137  0.304274\n",
       "7820   25  2017   802304  0.000000  0.304274\n",
       "7821   26  2017   802304  0.000000  0.304274\n",
       "7822   27  2017   802304  0.000000  0.419890\n",
       "7823   28  2017   802304  0.000000  0.304274\n",
       "7824   29  2017   802304  0.000000  0.304274\n",
       "7825   30  2017   802304  0.000000  0.303033\n",
       "7826   31  2017   802304  0.000000  0.297984\n",
       "7827   32  2017   802304  0.000000  0.297984\n",
       "7828   33  2017   802304  1.153137  0.301023\n",
       "7829   34  2017   802304  0.000000  0.296483\n",
       "7830   35  2017   802304  0.000000  0.301423\n",
       "7831   36  2017   802304  0.000000  0.419524\n",
       "7832   37  2017   802304  0.000000  0.304274\n",
       "7833   38  2017   802304  0.000000  0.304274\n",
       "7834   39  2017   802304  0.000000  0.296883\n",
       "7835   40  2017   802304  1.153137  0.296883\n",
       "7836   41  2017   802304  0.000000  0.304274\n",
       "7837   42  2017   802304  0.000000  0.304274\n",
       "7838   43  2017   802304  1.153137  0.419890\n",
       "7839   44  2017   802304  0.000000  0.301023\n",
       "7840   45  2017   802304  0.000000  0.304274\n",
       "7841   46  2017   802304  0.000000  0.419890\n",
       "7842   47  2017   802304  0.000000  0.304674\n",
       "7843   48  2017   802304  0.000000  0.304274\n",
       "7844   49  2017   802304  0.000000  0.304674\n",
       "7845   50  2017   802304  0.000000  0.304674\n",
       "7846   51  2017   802304  0.000000  0.304674\n",
       "7847   52  2017   802304  0.000000  0.304674\n",
       "\n",
       "[7848 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_addrcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [With CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_subdist.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_subdist.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]\n",
    "\n",
    "# Importing the dataset\n",
    "X_train = df_train.iloc[:,[6,12,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]]\n",
    "y_train = df_train.iloc[:,[3]]\n",
    "X_test = df_test.iloc[:,[6,12,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]]\n",
    "y_test = df_test.iloc[:,[3]]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.516062\tvalid_0's l2: 0.738482\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l1: 0.515167\tvalid_0's l2: 0.736851\n",
      "[3]\tvalid_0's l1: 0.514037\tvalid_0's l2: 0.735482\n",
      "[4]\tvalid_0's l1: 0.513525\tvalid_0's l2: 0.73457\n",
      "[5]\tvalid_0's l1: 0.512624\tvalid_0's l2: 0.733468\n",
      "[6]\tvalid_0's l1: 0.512263\tvalid_0's l2: 0.733072\n",
      "[7]\tvalid_0's l1: 0.511783\tvalid_0's l2: 0.732915\n",
      "[8]\tvalid_0's l1: 0.511177\tvalid_0's l2: 0.732875\n",
      "[9]\tvalid_0's l1: 0.510546\tvalid_0's l2: 0.73291\n",
      "[10]\tvalid_0's l1: 0.510378\tvalid_0's l2: 0.732559\n",
      "[11]\tvalid_0's l1: 0.509976\tvalid_0's l2: 0.732669\n",
      "[12]\tvalid_0's l1: 0.509589\tvalid_0's l2: 0.7329\n",
      "[13]\tvalid_0's l1: 0.509913\tvalid_0's l2: 0.733239\n",
      "[14]\tvalid_0's l1: 0.510281\tvalid_0's l2: 0.73331\n",
      "[15]\tvalid_0's l1: 0.509998\tvalid_0's l2: 0.733721\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.510378\tvalid_0's l2: 0.732559\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "#print('Saving model...')\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The rmse of prediction is: 0.8558967769119842\n",
      "The MAE of prediction is: 0.5103778142879005\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "df_y_pred = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "df_compare_addrcode = pd.concat([df_test_week_addrcode, df_y_pred], axis = 1)\n",
    "df_compare_addrcode.columns = [['Week','Year','addrcode','actual','predicted']]\n",
    "df_compare_addrcode.to_csv('LGBM_subdist_withCD.csv', encoding = 'utf-8')\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The MAE of prediction is:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Without CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_dist.csv'), header=0, skiprows=0)\n",
    "df_test_dist = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_dist.csv'), header=0, skiprows=0)\n",
    "df_test_week_addrcode_dist = df_test_dist.iloc[:,[0,1,2,3]]\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "X_train = df_train_dist.iloc[:,[6,12,18,19,20,21,22,23,24,25,26]]\n",
    "y_train = df_train_dist.iloc[:,[3]]\n",
    "X_test = df_test_dist.iloc[:,[6,12,18,19,20,21,22,23,24,25,26]]\n",
    "y_test = df_test_dist.iloc[:,[3]]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 2.11377\tvalid_0's l2: 8.94474\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l1: 2.09762\tvalid_0's l2: 8.82329\n",
      "[3]\tvalid_0's l1: 2.0695\tvalid_0's l2: 8.60186\n",
      "[4]\tvalid_0's l1: 2.04186\tvalid_0's l2: 8.40561\n",
      "[5]\tvalid_0's l1: 2.01816\tvalid_0's l2: 8.23596\n",
      "[6]\tvalid_0's l1: 1.99697\tvalid_0's l2: 8.09747\n",
      "[7]\tvalid_0's l1: 1.97866\tvalid_0's l2: 7.97903\n",
      "[8]\tvalid_0's l1: 1.96218\tvalid_0's l2: 7.88557\n",
      "[9]\tvalid_0's l1: 1.94786\tvalid_0's l2: 7.79846\n",
      "[10]\tvalid_0's l1: 1.93442\tvalid_0's l2: 7.72101\n",
      "[11]\tvalid_0's l1: 1.92062\tvalid_0's l2: 7.65336\n",
      "[12]\tvalid_0's l1: 1.90493\tvalid_0's l2: 7.5758\n",
      "[13]\tvalid_0's l1: 1.89093\tvalid_0's l2: 7.51346\n",
      "[14]\tvalid_0's l1: 1.87941\tvalid_0's l2: 7.46801\n",
      "[15]\tvalid_0's l1: 1.8688\tvalid_0's l2: 7.42238\n",
      "[16]\tvalid_0's l1: 1.85665\tvalid_0's l2: 7.36171\n",
      "[17]\tvalid_0's l1: 1.84547\tvalid_0's l2: 7.30782\n",
      "[18]\tvalid_0's l1: 1.8374\tvalid_0's l2: 7.27209\n",
      "[19]\tvalid_0's l1: 1.82927\tvalid_0's l2: 7.23666\n",
      "[20]\tvalid_0's l1: 1.82043\tvalid_0's l2: 7.19844\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 1.82043\tvalid_0's l2: 7.19844\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "#print('Saving model...')\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The rmse of prediction is: 2.6829901896725614\n",
      "The MAE of prediction is: 1.8204314754903421\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "df_y_pred = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "df_compare_addrcode_dist = pd.concat([df_test_week_addrcode_dist, df_y_pred], axis = 1)\n",
    "df_compare_addrcode_dist.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "df_compare_addrcode_dist.to_csv('LGBM_dist_withoutCD.csv', encoding = 'utf-8')\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The MAE of prediction is:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [With CD] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_dist.csv'), header=0, skiprows=0)\n",
    "df_test_dist = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_dist.csv'), header=0, skiprows=0)\n",
    "df_test_week_addrcode_dist = df_test_dist.iloc[:,[0,1,2,3]]\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "X_train = df_train_dist.iloc[:,[6,12,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]]\n",
    "y_train = df_train_dist.iloc[:,[3]]\n",
    "X_test = df_test_dist.iloc[:,[6,12,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]]\n",
    "y_test = df_test_dist.iloc[:,[3]]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 2.11413\tvalid_0's l2: 8.95521\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l1: 2.08308\tvalid_0's l2: 8.7218\n",
      "[3]\tvalid_0's l1: 2.05456\tvalid_0's l2: 8.50653\n",
      "[4]\tvalid_0's l1: 2.02999\tvalid_0's l2: 8.33145\n",
      "[5]\tvalid_0's l1: 2.00821\tvalid_0's l2: 8.17647\n",
      "[6]\tvalid_0's l1: 1.98509\tvalid_0's l2: 8.02517\n",
      "[7]\tvalid_0's l1: 1.96631\tvalid_0's l2: 7.91188\n",
      "[8]\tvalid_0's l1: 1.94942\tvalid_0's l2: 7.81759\n",
      "[9]\tvalid_0's l1: 1.93375\tvalid_0's l2: 7.72639\n",
      "[10]\tvalid_0's l1: 1.92161\tvalid_0's l2: 7.65936\n",
      "[11]\tvalid_0's l1: 1.90695\tvalid_0's l2: 7.57794\n",
      "[12]\tvalid_0's l1: 1.89394\tvalid_0's l2: 7.5104\n",
      "[13]\tvalid_0's l1: 1.88428\tvalid_0's l2: 7.46009\n",
      "[14]\tvalid_0's l1: 1.87687\tvalid_0's l2: 7.42399\n",
      "[15]\tvalid_0's l1: 1.86488\tvalid_0's l2: 7.36719\n",
      "[16]\tvalid_0's l1: 1.85091\tvalid_0's l2: 7.29717\n",
      "[17]\tvalid_0's l1: 1.83886\tvalid_0's l2: 7.23428\n",
      "[18]\tvalid_0's l1: 1.8294\tvalid_0's l2: 7.191\n",
      "[19]\tvalid_0's l1: 1.81876\tvalid_0's l2: 7.14161\n",
      "[20]\tvalid_0's l1: 1.81114\tvalid_0's l2: 7.10883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 1.81114\tvalid_0's l2: 7.10883\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "#print('Saving model...')\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The rmse of prediction is: 2.666239481217889\n",
      "The MAE of prediction is: 1.8111404261879975\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "df_y_pred = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "df_compare_addrcode_dist = pd.concat([df_test_week_addrcode_dist, df_y_pred], axis = 1)\n",
    "df_compare_addrcode_dist.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "df_compare_addrcode_dist.to_csv('LGBM_dist_withCD.csv', encoding = 'utf-8')\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The MAE of prediction is:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Subdistrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Modeling/Light GBM/Province/Subdistrict/LGBM_subdist_withoutCD.csv',\n",
       " 'Data/Modeling/Light GBM/Province/Subdistrict/LGBM_subdist_withCD.csv']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sub = glob.glob(os.path.join('Data','Modeling','Light GBM','Province','Subdistrict','*'))\n",
    "list_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_subdist_withoutCD'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sub[0][:-4][45:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available = pd.read_csv(os.path.join('Data','Data Statistics','available_addrcode_subdistrict.csv'))\n",
    "df_available['addrcode'] = df_available['addrcode'].astype(str)\n",
    "addrcode_list = df_available['addrcode']\n",
    "addrcode_nakhon_sub = []\n",
    "\n",
    "for i in range(len(addrcode_list)):\n",
    "    if addrcode_list[i].startswith('80'):\n",
    "        addrcode_nakhon_sub.append(addrcode_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_sub)):\n",
    "    for j in range(len(addrcode_nakhon_sub)):\n",
    "        df_result = pd.read_csv(list_sub[i])\n",
    "        df_result['addrcode'] = df_result['addrcode'].astype(str)\n",
    "        df_result = df_result.drop('Unnamed: 0', axis =1 )\n",
    "        df_result = df_result.loc[df_result['addrcode'] == addrcode_nakhon_sub[j]]\n",
    "        df_result = df_result.reset_index()\n",
    "        df_result = df_result.drop('index', axis = 1)\n",
    "        df_result.to_csv(list_sub[i][:-4][45:]+'_'+addrcode_nakhon_sub[j]+'.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Modeling/Light GBM/Province/District/LGBM_dist_withCD.csv',\n",
       " 'Data/Modeling/Light GBM/Province/District/LGBM_dist_withoutCD.csv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dist = glob.glob(os.path.join('Data','Modeling','Light GBM','Province','District','*'))\n",
    "list_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_dist_withCD'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dist[0][:-4][42:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrcode_nakhon_dist = []\n",
    "\n",
    "for i in range(len(addrcode_nakhon_sub)):\n",
    "    addrcode_nakhon_sub[i] = addrcode_nakhon_sub[i][:-2]\n",
    "    addrcode_nakhon_dist.append(addrcode_nakhon_sub[i]) \n",
    "    \n",
    "addrcode_nakhon_dist = list(set(addrcode_nakhon_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_dist)):\n",
    "    for j in range(len(addrcode_nakhon_dist)):\n",
    "        df_result = pd.read_csv(list_dist[i])\n",
    "        df_result['addrcode'] = df_result['addrcode'].astype(str)\n",
    "        df_result = df_result.drop('Unnamed: 0', axis =1 )\n",
    "        df_result = df_result.loc[df_result['addrcode'] == addrcode_nakhon_dist[j]]\n",
    "        df_result = df_result.reset_index()\n",
    "        df_result = df_result.drop('index', axis = 1)\n",
    "        df_result.to_csv(list_dist[i][:-4][42:]+'_'+addrcode_nakhon_dist[j]+'.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Different and MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperated Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Subdistrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sub = glob.glob(os.path.join('Data','Modeling','Light GBM','Separated','Subdistrict','*'))\n",
    "len(file_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_subdist_withoutCD_801607.csv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sub[0][46:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_sub)):\n",
    "    df_diff = pd.read_csv(file_sub[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',None,None,None,None,df_diff['different'].sum()/len(df_diff)]\n",
    "    df_diff.to_csv(file_sub[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dist = glob.glob(os.path.join('Data','Modeling','Light GBM','Separated','District','*'))\n",
    "len(file_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_dist_withoutCD_8018.csv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dist[0][43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_dist)):\n",
    "    df_diff = pd.read_csv(file_dist[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',None,None,None,None,df_diff['different'].sum()/len(df_diff)]\n",
    "    df_diff.to_csv(file_dist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Province Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Subdistrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_sub = glob.glob(os.path.join('Data','Modeling','Light GBM','Province','Subdistrict','*'))\n",
    "len(file_pro_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_subdist_withoutCD'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_sub[0][45:][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_pro_sub)):\n",
    "    df_diff = pd.read_csv(file_pro_sub[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',None,None,None,None,df_diff['different'].sum()/len(df_diff)]\n",
    "    df_diff.to_csv(file_pro_sub[i][45:][:-4]+'_diff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_dist = glob.glob(os.path.join('Data','Modeling','Light GBM','Province','District','*'))\n",
    "len(file_pro_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM_dist_withCD'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_dist[0][42:][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_pro_dist)):\n",
    "    df_diff = pd.read_csv(file_pro_dist[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',None,None,None,None,df_diff['different'].sum()/len(df_diff)]\n",
    "    df_diff.to_csv(file_pro_dist[i][42:][:-4]+'_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
