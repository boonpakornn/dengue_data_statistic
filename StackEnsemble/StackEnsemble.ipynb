{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzgGq7XY6FUN"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#province = 'krabi'\n",
    "#province = 'bangkok'\n",
    "province = 'nakhon'\n",
    "#setting = 'DFMet'\n",
    "setting = 'DFMetCD'\n",
    "#setting = 'DFCD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DFma_wm5</th>\n",
       "      <th>DFma_wm6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130605</td>\n",
       "      <td>0.111947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130605</td>\n",
       "      <td>0.130605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.130605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093289</td>\n",
       "      <td>0.111947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093289</td>\n",
       "      <td>0.093289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DFma_wm5  DFma_wm6\n",
       "0  0.130605  0.111947\n",
       "1  0.130605  0.130605\n",
       "2  0.111947  0.130605\n",
       "3  0.093289  0.111947\n",
       "4  0.093289  0.093289"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "  \n",
    "\n",
    "# Data Preparation\n",
    "\n",
    "df_train = pd.read_csv('./Data/train_'+province+'_dist_combined_mavg4.csv')\n",
    "df_test = pd.read_csv('./Data/test_'+province+'_dist_combined_mavg4.csv')\n",
    "attr_train = df_train.iloc[:,np.r_[18, 19]]\n",
    "attr_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22397,
     "status": "ok",
     "timestamp": 1549589542450,
     "user": {
      "displayName": "Krittiya Champangta",
      "photoUrl": "https://lh4.googleusercontent.com/-mOOtSQJZgYE/AAAAAAAAAAI/AAAAAAAAACc/HRdPIc5RVHA/s64/photo.jpg",
      "userId": "04670264686861320734"
     },
     "user_tz": -420
    },
    "id": "jNosP59i6FUY",
    "outputId": "2f67f2c8-609c-4f25-8c7d-0613216f7cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF6 without\n",
      "DF6 with\n",
      "DF6 without\n",
      "DF6 with\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "\n",
    "df_train = pd.read_csv('./Data/train_krabi_dist_combined_mavg4.csv')\n",
    "df_test = pd.read_csv('./Data/test_krabi_dist_combined_mavg4.csv')\n",
    "head = df_test.iloc[:,1:4]\n",
    "\n",
    "#for i in range (6):\n",
    "i=5\n",
    "################################ DF ONLY ###################################\n",
    "\n",
    "attr_train = df_train.iloc[:,np.r_[18, 19]]\n",
    "X_train = pd.concat([attr_train], axis=1)\n",
    "y_train = df_train.iloc[:,12]\n",
    "\n",
    "attr_test = df_test.iloc[:,np.r_[18, 19]]\n",
    "X_test = pd.concat([attr_test], axis=1)\n",
    "y_test = df_test.iloc[:,12]\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=30, random_state=0, n_estimators=10)\n",
    "svr_lin = SVR(kernel='linear')\n",
    "#svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[rf, rf], meta_regressor=svr_lin)\n",
    "\n",
    "ensembles = stregr.fit(X_train, y_train)\n",
    "y_hat = ensembles.predict(X_test)\n",
    "\n",
    "y = pd.DataFrame(y_hat, columns = ['predicted'])\n",
    "file = pd.concat([head, y_test,y], axis = 1)\n",
    "file.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "file.to_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_withoutST_DF%d.csv'%(i+1), encoding = 'utf-8')\n",
    "print(\"DF%d without\"%(i+1))\n",
    "\n",
    "################################ WITH SETTING ###################################\n",
    "# NST District JarPop9s, BinPop9s, Misc_tallPop9s 22, 26, 29\n",
    "# bangkok District JarPop9s, Bucket, TirePop9s 26, 33, 28 \n",
    "# Krabi District Jar, Bucket, Bin 33, 35, 31  \n",
    "\n",
    "attr_train = df_train.iloc[:,np.r_[18, 19]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21]]\n",
    "# last_train = df_train.iloc[:,np.r_[22, 26, 29]]\n",
    "# last_train = df_train.iloc[:,np.r_[26, 33, 28]]\n",
    "# last_train = df_train.iloc[:,np.r_[33, 35, 31]]\n",
    "last_train = df_train.iloc[:,np.r_[20, 21, 22, 26, 29]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21, 26, 33, 28]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21, 33, 35, 31]]\n",
    "X_train = pd.concat([attr_train,last_train], axis=1)\n",
    "y_train = df_train.iloc[:,12]\n",
    "\n",
    "attr_test = df_test.iloc[:,np.r_[18, 19]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21]]\n",
    "# last_test = df_test.iloc[:,np.r_[22, 26, 29]]\n",
    "# last_test = df_test.iloc[:,np.r_[26, 33, 28]]\n",
    "# last_test = df_test.iloc[:,np.r_[33, 35, 31]]\n",
    "last_test = df_test.iloc[:,np.r_[20, 21, 22, 26, 29]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21, 26, 33, 28]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21, 33, 35, 31]]\n",
    "X_test = pd.concat([attr_test,last_test], axis=1)\n",
    "y_test = df_test.iloc[:,12]\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=30, random_state=0, n_estimators=10)\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[rf, rf], meta_regressor=svr_lin)\n",
    "\n",
    "ensembles = stregr.fit(X_train, y_train)\n",
    "y_hat = ensembles.predict(X_test)\n",
    "\n",
    "y = pd.DataFrame(y_hat, columns = ['predicted'])\n",
    "file = pd.concat([head, y_test,y], axis = 1)\n",
    "file.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "file.to_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_withST_DF%d.csv'%(i+1), encoding = 'utf-8')\n",
    "print(\"DF%d with\"%(i+1))\n",
    "\n",
    "### **RF**\n",
    "\n",
    "available_addr = pd.read_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_withST_DF6.csv')\n",
    "a = available_addr['addrcode'].unique()\n",
    "\n",
    "#for i in range (6):\n",
    "i=5\n",
    "addr = []\n",
    "rmse_a = []\n",
    "rmse_n = []\n",
    "mae_a =[]\n",
    "mae_n = []\n",
    "smape_a = []\n",
    "smape_n = []\n",
    "im_mae=[]\n",
    "im_rmse=[]\n",
    "im_smape=[]\n",
    "\n",
    "for j in range (len(a)):\n",
    "    add = a[j]\n",
    "    addr.append(add)\n",
    "\n",
    "    #ADJUSTED CD\n",
    "    adjustedCD = pd.read_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_withoutST_DF%d.csv'%(i+1))\n",
    "    subset_ad =  adjustedCD.loc[adjustedCD['addrcode'] == add]\n",
    "    predicted = subset_ad['predicted']\n",
    "    actual = subset_ad['actual']\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(predicted, actual))\n",
    "    rmse_a.append(rmse)\n",
    "\n",
    "    # calculate MAE\n",
    "    mae = mean_absolute_error(predicted,actual)\n",
    "    mae_a.append(mae)\n",
    "\n",
    "    Smape = smape(predicted, actual)\n",
    "    smape_a.append(Smape)\n",
    "\n",
    "\n",
    "    #NORMAL CD\n",
    "    normalCD = pd.read_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_withST_DF%d.csv'%(i+1)) \n",
    "    subset_norm =  normalCD.loc[normalCD['addrcode'] == add]\n",
    "    predicted_norm = subset_norm['predicted']\n",
    "    actual_norm = subset_norm['actual']\n",
    "\n",
    "    # calculate RMSE\n",
    "    lin_mse = mean_squared_error(predicted_norm,actual_norm)\n",
    "    rmse_norm = np.sqrt(lin_mse)\n",
    "    rmse_n.append(rmse_norm)\n",
    "\n",
    "    # calculate MAE\n",
    "    mae_norm = mean_absolute_error(predicted_norm,actual_norm)\n",
    "    mae_n.append(mae_norm)\n",
    "\n",
    "    Smape_norm = smape(predicted_norm,actual_norm)\n",
    "    smape_n.append(Smape_norm)\n",
    "\n",
    "    #%improvement\n",
    "    improve_smape = (Smape - Smape_norm)/Smape\n",
    "    im_smape.append(improve_smape)\n",
    "\n",
    "    improve_rmse = (rmse - rmse_norm)/rmse\n",
    "    im_rmse.append(improve_rmse)\n",
    "\n",
    "    improve_mae = (mae - mae_norm)/mae\n",
    "    im_mae.append(improve_mae)\n",
    "\n",
    "\n",
    "    code = pd.DataFrame({'addrcode':addr})\n",
    "\n",
    "    smape_ad = pd.DataFrame({'smape_wo':smape_a})\n",
    "    smape_norm = pd.DataFrame({'smape_w':smape_n})\n",
    "\n",
    "    rmse_ad = pd.DataFrame({'rmse_wo': rmse_a})\n",
    "    rmse_norm = pd.DataFrame({'rmse_w':rmse_n})\n",
    "\n",
    "    mae_ad = pd.DataFrame({'mae_wo':mae_a})\n",
    "    mae_norm = pd.DataFrame({'mae_w':mae_n})\n",
    "\n",
    "    percent_smape = pd.DataFrame({'ims':im_smape}) \n",
    "    percent_rmse = pd.DataFrame({'imr':im_rmse}) \n",
    "    percent_mae = pd.DataFrame({'imm':im_mae}) \n",
    "\n",
    "    file = pd.concat([code, smape_ad, smape_norm,percent_smape, rmse_ad,rmse_norm,percent_rmse,mae_ad,mae_norm, percent_mae], axis=1)\n",
    "    file.columns = [['addrcode','SMAPE without ST', 'SMAPE with ST','% improve SMAPE','RMSE without ST','RMSE with ST','% improvve RMSE','MAE without ST','MAE with ST','% improve MAE']]\n",
    "    file.to_csv('./Results/District/'+setting+'/'+province+'_Dist_Ensemble_Eva_DF%d.csv'%(i+1), encoding = 'utf-8', index=False)\n",
    "\n",
    "## **Sub district**\n",
    "\n",
    "df_train = pd.read_csv('./Data/train_'+province+'_subdist_combined_mavg4.csv')\n",
    "df_test = pd.read_csv('./Data/test_'+province+'_subdist_combined_mavg4.csv')\n",
    "head = df_test.iloc[:,1:4]\n",
    "\n",
    "#for i in range (6):\n",
    "i=5\n",
    "\n",
    "################################ DF ONLY ###################################\n",
    "attr_train = df_train.iloc[:,18:19]\n",
    "X_train = pd.concat([attr_train], axis=1)\n",
    "y_train = df_train.iloc[:,12]\n",
    "\n",
    "attr_test = df_test.iloc[:,18:19]\n",
    "X_test = pd.concat([attr_test], axis=1)\n",
    "y_test = df_test.iloc[:,12]\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=30, random_state=0, n_estimators=10)\n",
    "svr_lin = SVR(kernel='linear')\n",
    "#svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[rf, rf], meta_regressor=svr_lin)\n",
    "\n",
    "ensembles = stregr.fit(X_train, y_train)\n",
    "y_hat = ensembles.predict(X_test)\n",
    "\n",
    "y = pd.DataFrame(y_hat, columns = ['predicted'])\n",
    "file = pd.concat([head, y_test,y], axis = 1)\n",
    "file.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "file.to_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_withoutST_DF%d.csv'%(i+1), encoding = 'utf-8')\n",
    "print(\"DF%d without\"%(i+1))\n",
    "\n",
    "################################ WITH Setting ###################################\n",
    "# NST SubDistrict BinPop9s, BucketPop9s, Jar 22, 24, 35\n",
    "# bangkok SubDistrict BowlPop9s, Misc_shorts, TirePop9s 23, 34, 28\n",
    "# Krabi SubDistrict BinPop9s, TirePop9s, Misc_shortPop9s 22, 28, 25\n",
    "\n",
    "attr_train = df_train.iloc[:,np.r_[18, 19]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21]]\n",
    "# last_train = df_train.iloc[:,np.r_[22, 24, 35]]\n",
    "# last_train = df_train.iloc[:,np.r_[23, 34, 28]]\n",
    "# last_train = df_train.iloc[:,np.r_[22, 28, 25]]\n",
    "last_train = df_train.iloc[:,np.r_[20, 21, 22, 24, 35]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21, 23, 34, 28]]\n",
    "# last_train = df_train.iloc[:,np.r_[20, 21, 22, 28, 25]]\n",
    "X_train = pd.concat([attr_train,last_train], axis=1)\n",
    "y_train = df_train.iloc[:,12]\n",
    "\n",
    "attr_test = df_test.iloc[:,np.r_[18, 19]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21]]\n",
    "# last_test = df_test.iloc[:,np.r_[22, 24, 35]]\n",
    "# last_test = df_test.iloc[:,np.r_[23, 34, 28]]\n",
    "# last_test = df_test.iloc[:,np.r_[22, 28, 25]]\n",
    "last_test = df_test.iloc[:,np.r_[20, 21, 22, 24, 35]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21, 23, 34, 28]]\n",
    "# last_test = df_test.iloc[:,np.r_[20, 21, 22, 28, 25]]\n",
    "X_test = pd.concat([attr_test,last_test], axis=1)\n",
    "y_test = df_test.iloc[:,12]\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=10)\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[rf, rf], meta_regressor=svr_lin)\n",
    "\n",
    "ensembles = stregr.fit(X_train, y_train)\n",
    "y_hat = ensembles.predict(X_test)\n",
    "\n",
    "y = pd.DataFrame(y_hat, columns = ['predicted'])\n",
    "file = pd.concat([head, y_test,y], axis = 1)\n",
    "file.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "file.to_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_withST_DF%d.csv'%(i+1), encoding = 'utf-8')\n",
    "print(\"DF%d with\"%(i+1))\n",
    "\n",
    "\n",
    "### **RF**\n",
    "\n",
    "available_addr = pd.read_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_withST_DF6.csv')\n",
    "a = available_addr['addrcode'].unique()\n",
    "\n",
    "#for i in range (6):\n",
    "i=5\n",
    "addr = []\n",
    "rmse_a = []\n",
    "rmse_n = []\n",
    "mae_a =[]\n",
    "mae_n = []\n",
    "smape_a = []\n",
    "smape_n = []\n",
    "im_mae=[]\n",
    "im_rmse=[]\n",
    "im_smape=[]\n",
    "\n",
    "for j in range (len(a)):\n",
    "    add = a[j]\n",
    "    addr.append(add)\n",
    "\n",
    "    #ADJUSTED CD\n",
    "    adjustedCD = pd.read_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_withoutST_DF%d.csv'%(i+1))\n",
    "    subset_ad =  adjustedCD.loc[adjustedCD['addrcode'] == add]\n",
    "    predicted = subset_ad['predicted']\n",
    "    actual = subset_ad['actual']\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(predicted, actual))\n",
    "    rmse_a.append(rmse)\n",
    "\n",
    "    # calculate MAE\n",
    "    mae = mean_absolute_error(predicted,actual)\n",
    "    mae_a.append(mae)\n",
    "\n",
    "    Smape = smape(predicted, actual)\n",
    "    smape_a.append(Smape)\n",
    "\n",
    "\n",
    "    #NORMAL CD\n",
    "    normalCD = pd.read_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_withST_DF%d.csv'%(i+1)) \n",
    "    subset_norm =  normalCD.loc[normalCD['addrcode'] == add]\n",
    "    predicted_norm = subset_norm['predicted']\n",
    "    actual_norm = subset_norm['actual']\n",
    "\n",
    "    # calculate RMSE\n",
    "    lin_mse = mean_squared_error(predicted_norm,actual_norm)\n",
    "    rmse_norm = np.sqrt(lin_mse)\n",
    "    rmse_n.append(rmse_norm)\n",
    "\n",
    "    # calculate MAE\n",
    "    mae_norm = mean_absolute_error(predicted_norm,actual_norm)\n",
    "    mae_n.append(mae_norm)\n",
    "\n",
    "    Smape_norm = smape(predicted_norm,actual_norm)\n",
    "    smape_n.append(Smape_norm)\n",
    "\n",
    "    #%improvement\n",
    "    improve_smape = (Smape - Smape_norm)/Smape\n",
    "    im_smape.append(improve_smape)\n",
    "\n",
    "    improve_rmse = (rmse - rmse_norm)/rmse\n",
    "    im_rmse.append(improve_rmse)\n",
    "\n",
    "    improve_mae = (mae - mae_norm)/mae\n",
    "    im_mae.append(improve_mae)\n",
    "\n",
    "\n",
    "    code = pd.DataFrame({'addrcode':addr})\n",
    "\n",
    "    smape_ad = pd.DataFrame({'smape_wo':smape_a})\n",
    "    smape_norm = pd.DataFrame({'smape_w':smape_n})\n",
    "\n",
    "    rmse_ad = pd.DataFrame({'rmse_wo': rmse_a})\n",
    "    rmse_norm = pd.DataFrame({'rmse_w':rmse_n})\n",
    "\n",
    "    mae_ad = pd.DataFrame({'mae_wo':mae_a})\n",
    "    mae_norm = pd.DataFrame({'mae_w':mae_n})\n",
    "\n",
    "    percent_smape = pd.DataFrame({'ims':im_smape}) \n",
    "    percent_rmse = pd.DataFrame({'imr':im_rmse}) \n",
    "    percent_mae = pd.DataFrame({'imm':im_mae}) \n",
    "\n",
    "    file = pd.concat([code, smape_ad, smape_norm,percent_smape, rmse_ad,rmse_norm,percent_rmse,mae_ad,mae_norm, percent_mae], axis=1)\n",
    "    file.columns = [['addrcode','SMAPE without ST', 'SMAPE with ST','% improve SMAPE','RMSE without ST','RMSE with ST','% improvve RMSE','MAE without ST','MAE with ST','% improve MAE']]\n",
    "    file.to_csv('./Results/Subdistrict/'+setting+'/'+province+'_Subdist_Ensemble_Eva_DF%d.csv'%(i+1), encoding = 'utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StaclEmsemble.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
