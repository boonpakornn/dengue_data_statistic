{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting RF and LST DATA\n",
    "## Matching Latitude-Longtitude to Sub-District\n",
    "### Climatic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addrcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  addrcode\n",
       "0   801904\n",
       "1   800905\n",
       "2   801701\n",
       "3   800611\n",
       "4   801204"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_big_area_nakhon_krabi = pd.read_csv(os.path.join('Data','Climatic Data','Climatic Data Result','big_Nakhon_Krabi_LST.csv'))\n",
    "df_big_area_nakhon_krabi = pd.read_csv(os.path.join('Data','Climatic Data','Climatic Data Result','big_Nakhon_Krabi_Rainfall.csv'))\n",
    "df_big_area_nakhon_krabi['addrcode'] = df_big_area_nakhon_krabi['addrcode'].astype(str)\n",
    "df_big_area_nakhon_krabi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addrcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  addrcode\n",
       "0   100508\n",
       "1   100112\n",
       "2   104601\n",
       "3   104101\n",
       "4   100302"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_area_bangkok = pd.read_csv(os.path.join('Data','Climatic Data','Climatic Data Result','big_Bangkok_LST.csv'))\n",
    "#df_big_area_bangkok = pd.read_csv(os.path.join('Data','Climatic Data','Climatic Data Result','big_Bangkok_Rainfall.csv'))\n",
    "df_big_area_bangkok['addrcode'] = df_big_area_bangkok['addrcode'].astype(str)\n",
    "df_big_area_bangkok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_bangkok = pd.read_csv(os.path.join('Data','Climatic Data','Coordinate','BMA_LT_LST.csv'))\n",
    "#df_point_bangkok = pd.read_csv(os.path.join('Data','Climatic Data','Coordinate','BMA_LT_Rainfall.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_bangkok['X'] = df_point_bangkok['X'].astype(str)\n",
    "df_point_bangkok['Y'] = df_point_bangkok['Y'].astype(str)\n",
    "df_point_bangkok['X'] = df_point_bangkok['X'].str[:7]\n",
    "df_point_bangkok['Y'] = df_point_bangkok['Y'].str[:6]\n",
    "df_point_bangkok = df_point_bangkok.drop('BMA_CODE', axis = 1)\n",
    "df_point_bangkok.columns = ['addrcode','X','Y']\n",
    "df_point_bangkok['addrcode'] = df_point_bangkok['addrcode'].astype(str)\n",
    "df_point_bangkok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_nakhon_krabi = pd.read_csv(os.path.join('Data','Climatic Data Result','XY_Coordinate_Nakhon_Krabi.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_nakhon_krabi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_nakhon_krabi['X'] = df_point_nakhon_krabi['X'].astype(str)\n",
    "df_point_nakhon_krabi['Y'] = df_point_nakhon_krabi['Y'].astype(str)\n",
    "df_point_nakhon_krabi['X'] = df_point_nakhon_krabi['X'].str[:7]\n",
    "df_point_nakhon_krabi['Y'] = df_point_nakhon_krabi['Y'].str[:7]\n",
    "df_point_nakhon_krabi['addrcode'] = df_point_nakhon_krabi['addrcode'].astype(str)\n",
    "df_point_nakhon_krabi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bangkok LST & Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Climatic Data/Climatic Data Result/LST Result/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.endswith('Bangkok.csv'):\n",
    "        filename.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## === Small Area ===\n",
    "for filename in filename:\n",
    "    if filename.startswith('Small'):\n",
    "        df_temp = pd.read_csv(os.path.join(path+filename))\n",
    "        df_temp['X'] = df_temp['X'].astype(str)\n",
    "        df_temp['Y'] = df_temp['Y'].astype(str)\n",
    "        df_temp['X'] = df_temp['X'].str[:7]\n",
    "        df_temp['Y'] = df_temp['Y'].str[:6]\n",
    "        df_temp.head()\n",
    "\n",
    "        df_result = pd.merge(df_temp,df_point_bangkok,how = 'inner', on = ['X','Y'])\n",
    "        df_result = df_result.drop(['POINT_BANG','X','Y'],axis = 1)\n",
    "        df_result['MOD11C2_20'] = df_result['MOD11C2_20']*0.02-273.15\n",
    "        df_result['MOD11C2_20'] = df_result['MOD11C2_20'].round(2)\n",
    "        df_result = df_result[['addrcode','MOD11C2_20']]\n",
    "        df_result.columns = ['addrcode','temperature']\n",
    "        df_result['temperature'].loc[df_result['temperature'] <0 ] = 0\n",
    "\n",
    "#         df_result = pd.merge(df_temp,df_point_bangkok,how = 'inner', on = ['X','Y'])\n",
    "#         df_result = df_result.drop(['POINT_BANG','X','Y'],axis = 1)\n",
    "#         df_result.columns = ['rainfall','addrcode']\n",
    "#         df_result = df_result[['addrcode','rainfall']]\n",
    "#         df_result['rainfall'] = df_result['rainfall'].round(2)\n",
    "#         df_result['rainfall'].loc[df_result['rainfall'] < 0] = None\n",
    "#         df_result = df_result[['addrcode','rainfall']]\n",
    "\n",
    "        df_result.to_csv(path+'Code_'+filename, encoding = 'utf-8') \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## === Big Area ===\n",
    "for filename in filename:\n",
    "    \n",
    "    if filename.startswith('MOD'):\n",
    "        df_temp = pd.read_csv(os.path.join(path+filename))\n",
    "        df_temp = df_temp.drop(['ZONE_CODE','COUNT','AREA','MIN','MAX','RANGE','STD','SUM','VARIETY','MAJORITY','MINORITY','MEDIAN'], axis = 1)\n",
    "        df_temp['SCODE_BMA'] = df_temp['SCODE_BMA'].astype(str)\n",
    "        df_temp['MEAN'].loc[df_temp['MEAN'] > 7500 ] = df_temp['MEAN']*0.02-273.15\n",
    "        df_temp['MEAN'] = df_temp['MEAN'].round(2)\n",
    "        df_temp['MEAN'].loc[df_temp['MEAN'] <0 ] = 0\n",
    "        df_temp.columns = ['addrcode','temperature']\n",
    "        df_temp.head()\n",
    "        df_result = pd.merge(df_temp,df_big_area_bangkok,how = 'outer', on ='addrcode')\n",
    "        df_result = df_result.fillna(0)\n",
    "        df_result = df_result[['addrcode','temperature']]\n",
    "\n",
    "#     if filename.startswith('P_Rain'):\n",
    "#         df_temp = pd.read_csv(os.path.join(path+filename))\n",
    "#         df_temp = df_temp.drop(['ZONE_CODE','COUNT','AREA','MIN','MAX','RANGE','STD','SUM'], axis = 1)\n",
    "#         df_temp['MEAN'] = df_temp['MEAN'].round(2)\n",
    "#         df_temp.columns = ['addrcode','rainfall']\n",
    "#         df_temp['addrcode'] = df_temp['addrcode'].astype(str)\n",
    "    \n",
    "        df_result = pd.merge(df_temp,df_big_area_bangkok,how = 'outer', on ='addrcode')\n",
    "\n",
    "        df_result.to_csv(path+'Code_'+filename, encoding = 'utf-8')\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nakhon-Krabi LST & Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "#path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Climatic Data/Climatic Data Result/LST Result/'\n",
    "path = '/Users/boonpakorn/Documents/GitHub/dengue_data_statistics/Data/Climatic Data/Climatic Data Result/Rainfall Result/'\n",
    "filename = []\n",
    "filelist= listdir(path)\n",
    "for f in tqdm(filelist):\n",
    "    if f.endswith('Nakhon_Krabi.csv'):\n",
    "        filename.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## === Small Area ===\n",
    "for filename in filename:\n",
    "    if filename.startswith('Small'):\n",
    "        df_temp = pd.read_csv(os.path.join(path+filename))\n",
    "        df_temp['X'] = df_temp['X'].astype(str)\n",
    "        df_temp['Y'] = df_temp['Y'].astype(str)\n",
    "        df_temp['X'] = df_temp['X'].str[:7]\n",
    "        df_temp['Y'] = df_temp['Y'].str[:7]\n",
    "        df_temp.head()\n",
    "\n",
    "        #df_result = pd.merge(df_temp,df_point_nakhon_krabi,how = 'inner', on = ['X','Y'])\n",
    "        #df_result = df_result.drop(['POINT_NAKH','X','Y','TB_EN','OLD_TB_IDN'],axis = 1)\n",
    "        #df_result['MOD11C2_20'] = df_result['MOD11C2_20']*0.02-273.15\n",
    "        #df_result['MOD11C2_20'] = df_result['MOD11C2_20'].round(2)\n",
    "        #df_result['MOD11C2_20'].loc[df_result['MOD11C2_20'] < 0] = None\n",
    "        #df_result.columns = ['temperature','addrcode']\n",
    "        #df_result = df_result[['addrcode','temperature']]\n",
    "        \n",
    "        df_result = pd.merge(df_temp,df_point_nakhon_krabi,how = 'inner', on = ['X','Y'])\n",
    "        df_result = df_result.drop(['POINT_NAKH','X','Y','TB_EN','OLD_TB_IDN'],axis = 1)\n",
    "        df_result.columns = ['rainfall','addrcode']\n",
    "        df_result = df_result[['addrcode','rainfall']]\n",
    "        df_result['rainfall'] = df_result['rainfall'].round(2)\n",
    "        df_result['rainfall'].loc[df_result['rainfall'] < 0] = None\n",
    "        df_result = df_result[['addrcode','rainfall']]\n",
    "        \n",
    "        df_result.to_csv(path+'Code_'+filename, encoding = 'utf-8') \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## === Big Area ===\n",
    "for filename in filename:\n",
    "    #if filename.startswith('MOD'):\n",
    "    if filename.startswith('P_Rain'):\n",
    "        df_temp = pd.read_csv(os.path.join(path+filename))\n",
    "\n",
    "        #df_temp = df_temp.drop(['ZONE_CODE','COUNT','AREA','MIN','MAX','RANGE','STD','SUM','VARIETY','MAJORITY','MINORITY','MEDIAN'], axis = 1)\n",
    "        #df_temp['TB_IDN'] = df_temp['TB_IDN'].astype(str)\n",
    "        #df_temp.head()\n",
    "        #df_temp['MEAN'].loc[df_temp['MEAN'] > 7500 ] = df_temp['MEAN']*0.02-273.15\n",
    "        #df_temp['MEAN'] = df_temp['MEAN'].round(2)\n",
    "        #df_temp['MEAN'].loc[df_temp['MEAN'] <0 ] = None\n",
    "        #df_temp.columns = ['addrcode','temperature']\n",
    "        df_temp = df_temp.drop(['ZONE_CODE','COUNT','AREA','MIN','MAX','RANGE','STD','SUM'], axis = 1)\n",
    "        df_temp['MEAN'] = df_temp['MEAN'].round(2)\n",
    "        df_temp.columns = ['addrcode','rainfall']\n",
    "        df_temp['addrcode'] = df_temp['addrcode'].astype(str)\n",
    "        \n",
    "        df_result = pd.merge(df_temp,df_big_area_nakhon_krabi,how = 'outer', on ='addrcode')\n",
    "        df_result.to_csv(path+'Code_'+filename, encoding = 'utf-8')\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_path = '/Users/boonpakornnonthaleerak/Documents/GitHub/dengue_data_statistics/Data/Climatic Data/Climatic Data Result/LST Result/'\n",
    "all = []\n",
    "for filename in filename:\n",
    "    if filename.startswith('Code_'):\n",
    "        df_com = pd.read_csv(os.path.join(path+filename))\n",
    "        if filename.startswith('Code_Small_'):\n",
    "            if filename.endswith('Bangkok.csv'):\n",
    "                weekday = filename[:-12][19:] \n",
    "                day = weekday[4:]\n",
    "                year = weekday[:4]\n",
    "                df_com['Day'] = day\n",
    "                \n",
    "#                 weekday = filename[:-12][17:] \n",
    "#                 if(len(weekday) == 6): \n",
    "#                     year = weekday[2:]\n",
    "#                     week = weekday[:1]\n",
    "#                 elif(len(weekday) == 7): \n",
    "#                     year = weekday[3:]\n",
    "#                     week = weekday[:2]\n",
    "#                 df_com['Week'] = week\n",
    "                \n",
    "                \n",
    "                df_com['Year'] = year\n",
    "                all.append(df_com)\n",
    "        #elif filename.startswith('Code_P_Rain'):\n",
    "        elif filename.startswith('Code_MOD'):\n",
    "            if filename.endswith('Bangkok.csv'):\n",
    "                weekday = filename[:-12][13:] \n",
    "                year = weekday[:4]\n",
    "                day = weekday[4:]\n",
    "                df_com['Day'] = day\n",
    "                \n",
    "#                 weekday = filename[:-12][11:] \n",
    "#                 if(len(weekday) == 6):    \n",
    "#                     year = weekday[2:]\n",
    "#                     week = weekday[:1]\n",
    "#                 elif(len(weekday) == 7):\n",
    "#                     year = weekday[3:]\n",
    "#                     week = weekday[:2]\n",
    "#                 df_com['Week'] = week\n",
    "                \n",
    "                df_com['Year'] = year\n",
    "                all.append(df_com)\n",
    "\n",
    "    \n",
    "big_frame = pd.concat(all, ignore_index=True)\n",
    "big_frame = big_frame.drop('Unnamed: 0', axis = 1)\n",
    "big_frame = big_frame[['Day','Year','addrcode','temperature']]\n",
    "big_frame['temperature'].loc[big_frame['temperature'] == 0 ]  = None\n",
    "\n",
    "# big_frame = pd.concat(all, ignore_index=True)\n",
    "# big_frame = big_frame.drop('Unnamed: 0', axis = 1)\n",
    "# big_frame = big_frame[['Week','Year','addrcode','rainfall']]\n",
    "\n",
    "big_frame.to_csv('LST_Bangkok.csv', encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat all Climatic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data file names\n",
    "path ='LST Interpolation/Results/'\n",
    "filenames = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "big_frame = pd.concat(dfs, ignore_index=True)\n",
    "big_frame = big_frame.drop('Unnamed: 0', axis = 1)\n",
    "big_frame.to_csv(path +'LST_subdist.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist = pd.read_csv(path+'LST_subdist.csv', index_col =0)\n",
    "df_lst_dist['addrcode'] = df_lst_dist['addrcode'].astype(str)\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist = df_lst_dist.groupby([df_lst_dist['addrcode'].str[:4],df_lst_dist['Year'],df_lst_dist['Week']]).mean().reset_index()\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist.to_csv(path+'LST_dist.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_dist = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_subdist.csv'))\n",
    "df_rain_dist['addrcode'] = df_rain_dist['addrcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_dist = df_rain_dist.groupby([df_rain_dist['addrcode'].str[:4],df_rain_dist['Year'],df_rain_dist['Week']]).mean().reset_index()\n",
    "df_rain_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_dist.to_csv('Data/Climatic Data/Rainfall_dist.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly to Monthly Climatic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist = pd.read_csv(os.path.join('Data','Climatic Data','Rainfall_subdist.csv'))\n",
    "df_lst_dist['Week'] = df_lst_dist['Week'].astype(str)\n",
    "df_lst_dist['Year'] = df_lst_dist['Year'].astype(str)\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekyear = []\n",
    "for i in range(len(df_lst_dist)):\n",
    "    if len(df_lst_dist['Week'][i]) == 1:\n",
    "        weekyear.append(df_lst_dist['Year'][i] + '0' + df_lst_dist['Week'][i])\n",
    "    elif len(df_lst_dist['Week'][i]) == 2:\n",
    "        weekyear.append(df_lst_dist['Year'][i] + df_lst_dist['Week'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist['WeekYear'] = weekyear\n",
    "df_lst_dist['WeekYear'] = df_lst_dist['WeekYear'].astype(int)\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist['LastDayWeek'] = pd.to_datetime((df_lst_dist['WeekYear']-1).astype(str) + \"6\", format=\"%Y%U%w\")\n",
    "df_lst_dist['Month'] = pd.DatetimeIndex(df_lst_dist['LastDayWeek']).month\n",
    "df_lst_dist = df_lst_dist.drop(['LastDayWeek','WeekYear'], axis =1)\n",
    "#df_lst_dist = df_lst_dist[['addrcode','Year','Month','Week','temperature']]\n",
    "df_lst_dist = df_lst_dist[['addrcode','Year','Month','Week','rainfall']]\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist = df_lst_dist.groupby([df_lst_dist['addrcode'],df_lst_dist['Year'],df_lst_dist['Month']]).mean().reset_index()\n",
    "df_lst_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist = df_lst_dist[df_lst_dist.Year != '2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_dist.to_csv('Data/Climatic Data/Rainfall_subdist_monthly.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly to Yearly Climatic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli = pd.read_csv(os.path.join('Data','Climatic Data','LST_subdist_monthly.csv'), index_col = 0)\n",
    "df_cli['addrcode']  = df_cli['addrcode'].astype(str)\n",
    "df_cli['Month'] = df_cli['Month'].astype(str)\n",
    "df_cli['Year'] = df_cli['Year'].astype(str)\n",
    "df_cli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli = df_cli.groupby([df_cli['addrcode'],df_cli['Year']]).mean().reset_index()\n",
    "df_cli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cli.to_csv('Data/Climatic Data/LST_subdist_yearly.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
