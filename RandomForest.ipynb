{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import glob\n",
    "from numba import jit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_fast(y_true, y_pred):\n",
    "    out = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a = y_true[i]\n",
    "        b = y_pred[i]\n",
    "        c = a+b\n",
    "        if c == 0:\n",
    "            continue\n",
    "        out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdistrict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Without CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_subdist_total.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "#df_train = df_train.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_subdist_total.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "#df_test = df_test.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "train_labels = np.array(df_train['DF_4'])\n",
    "test_labels = np.array(df_test['DF_4'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "train_features= df_train.iloc[:,[9,10,11,12,13,14]]\n",
    "test_features= df_test.iloc[:,[9,10,11,12,13,14]]\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_train.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF_0</th>\n",
       "      <th>DF_wm1</th>\n",
       "      <th>DF_wm2</th>\n",
       "      <th>DF_wm3</th>\n",
       "      <th>RF_wm6</th>\n",
       "      <th>LST_wm4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.051964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.622857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.353750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>33.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>33.605000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DF_0    DF_wm1  DF_wm2  DF_wm3  RF_wm6    LST_wm4\n",
       "0  0.000000  0.000000     0.0     0.0    0.00  34.051964\n",
       "1  0.000000  0.000000     0.0     0.0    0.00  34.622857\n",
       "2  0.000000  0.000000     0.0     0.0    0.00  34.353750\n",
       "3  0.228948  0.000000     0.0     0.0    1.75  33.910000\n",
       "4  0.000000  0.228948     0.0     0.0    0.08  33.605000"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (22879, 6)\n",
      "Training Labels Shape: (22879,)\n",
      "Testing Features Shape: (6680, 6)\n",
      "Testing Labels Shape: (6680,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 30, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.53758 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.83376524606356"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape = smape_fast(test_labels,predictions)\n",
    "smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(predictions, columns = ['predicted'])\n",
    "df_compare_addrcode = pd.concat([df_test_week_addrcode, df_predicted], axis = 1)\n",
    "df_compare_addrcode.columns = [['Week','Year','addrcode','actual','predicted']]\n",
    "df_compare_addrcode.loc[len(df_predicted)] = ['SMAPE',smape,None,None,None]\n",
    "df_compare_addrcode.to_csv('Data/Modeling/Random Forest/DF_4/Province/Subdistrict/RF_DFw4_subdist_withoutCD.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [With CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_subdist_total.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "#df_train = df_train.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_subdist_total.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "#df_test = df_test.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "train_labels = np.array(df_train['DF_4'])\n",
    "test_labels = np.array(df_test['DF_4'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "#train_features= df_train.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,71,82,83,84,85,86,87,88,89,90,91,92,93,94]]\n",
    "#test_features= df_test.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,71,82,83,84,85,86,87,88,89,90,91,92,93,94]]\n",
    "train_features= df_train.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "test_features= df_test.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_train.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF_0</th>\n",
       "      <th>DF_wm1</th>\n",
       "      <th>DF_wm2</th>\n",
       "      <th>DF_wm3</th>\n",
       "      <th>RF_wm6</th>\n",
       "      <th>LST_wm4</th>\n",
       "      <th>bin_pop9s</th>\n",
       "      <th>bowl_pop9s</th>\n",
       "      <th>bucket_pop9s</th>\n",
       "      <th>misc_short_pop9s</th>\n",
       "      <th>jar_pop9s</th>\n",
       "      <th>pottedplant_pop9s</th>\n",
       "      <th>tire_pop9s</th>\n",
       "      <th>misc_tall_pop9s</th>\n",
       "      <th>total_pop9s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.051964</td>\n",
       "      <td>23.32913</td>\n",
       "      <td>1.765448</td>\n",
       "      <td>59.773014</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>1.450189</td>\n",
       "      <td>81.778058</td>\n",
       "      <td>10.340479</td>\n",
       "      <td>0.315259</td>\n",
       "      <td>179.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.622857</td>\n",
       "      <td>23.32913</td>\n",
       "      <td>1.765448</td>\n",
       "      <td>59.773014</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>1.450189</td>\n",
       "      <td>81.778058</td>\n",
       "      <td>10.340479</td>\n",
       "      <td>0.315259</td>\n",
       "      <td>179.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.353750</td>\n",
       "      <td>23.32913</td>\n",
       "      <td>1.765448</td>\n",
       "      <td>59.773014</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>1.450189</td>\n",
       "      <td>81.778058</td>\n",
       "      <td>10.340479</td>\n",
       "      <td>0.315259</td>\n",
       "      <td>179.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>23.32913</td>\n",
       "      <td>1.765448</td>\n",
       "      <td>59.773014</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>1.450189</td>\n",
       "      <td>81.778058</td>\n",
       "      <td>10.340479</td>\n",
       "      <td>0.315259</td>\n",
       "      <td>179.760404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>33.605000</td>\n",
       "      <td>23.32913</td>\n",
       "      <td>1.765448</td>\n",
       "      <td>59.773014</td>\n",
       "      <td>1.008827</td>\n",
       "      <td>1.450189</td>\n",
       "      <td>81.778058</td>\n",
       "      <td>10.340479</td>\n",
       "      <td>0.315259</td>\n",
       "      <td>179.760404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DF_0    DF_wm1  DF_wm2  DF_wm3  RF_wm6    LST_wm4  bin_pop9s  \\\n",
       "0  0.000000  0.000000     0.0     0.0    0.00  34.051964   23.32913   \n",
       "1  0.000000  0.000000     0.0     0.0    0.00  34.622857   23.32913   \n",
       "2  0.000000  0.000000     0.0     0.0    0.00  34.353750   23.32913   \n",
       "3  0.228948  0.000000     0.0     0.0    1.75  33.910000   23.32913   \n",
       "4  0.000000  0.228948     0.0     0.0    0.08  33.605000   23.32913   \n",
       "\n",
       "   bowl_pop9s  bucket_pop9s  misc_short_pop9s  jar_pop9s  pottedplant_pop9s  \\\n",
       "0    1.765448     59.773014          1.008827   1.450189          81.778058   \n",
       "1    1.765448     59.773014          1.008827   1.450189          81.778058   \n",
       "2    1.765448     59.773014          1.008827   1.450189          81.778058   \n",
       "3    1.765448     59.773014          1.008827   1.450189          81.778058   \n",
       "4    1.765448     59.773014          1.008827   1.450189          81.778058   \n",
       "\n",
       "   tire_pop9s  misc_tall_pop9s  total_pop9s  \n",
       "0   10.340479         0.315259   179.760404  \n",
       "1   10.340479         0.315259   179.760404  \n",
       "2   10.340479         0.315259   179.760404  \n",
       "3   10.340479         0.315259   179.760404  \n",
       "4   10.340479         0.315259   179.760404  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (22879, 15)\n",
      "Training Labels Shape: (22879,)\n",
      "Testing Features Shape: (6680, 15)\n",
      "Testing Labels Shape: (6680,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 30, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.53356 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.86752241178323"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape = smape_fast(test_labels,predictions)\n",
    "smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(predictions, columns = ['predicted'])\n",
    "df_compare_addrcode = pd.concat([df_test_week_addrcode, df_predicted], axis = 1)\n",
    "df_compare_addrcode.columns = [['Week','Year','addrcode','actual','predicted']]\n",
    "df_compare_addrcode.loc[len(df_predicted)] = ['SMAPE',smape,None,None,None]\n",
    "df_compare_addrcode.to_csv('Data/Modeling/Random Forest/DF_4/Province/Subdistrict/RF_DFw4_subdist_withCD.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Without CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_dist_total.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "#df_train = df_train.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_dist_total.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "#df_test = df_test.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "train_labels = np.array(df_train['DF_4'])\n",
    "test_labels = np.array(df_test['DF_4'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "train_features= df_train.iloc[:,[9,10,11,12,13,14]]\n",
    "test_features= df_test.iloc[:,[9,10,11,12,13,14]]\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_train.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (3151, 6)\n",
      "Training Labels Shape: (3151,)\n",
      "Testing Features Shape: (920, 6)\n",
      "Testing Labels Shape: (920,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 6, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.30164 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.13102104119007"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape = smape_fast(test_labels,predictions)\n",
    "smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(predictions, columns = ['predicted'])\n",
    "df_compare_addrcode_dist = pd.concat([df_test_week_addrcode_dist, df_predicted], axis = 1)\n",
    "df_compare_addrcode_dist.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "df_compare_addrcode_dist.loc[len(df_predicted)] = ['SMAPE',smape,None,None,None]\n",
    "df_compare_addrcode_dist.to_csv('Data/Modeling/Random Forest/DF_1/Province/District/RF_DFw1_dist_withoutCD.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [With CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =  pd.read_csv(os.path.join('Data','Modeling','Training&Testing','train_dist_total.csv'), header=0, skiprows=0)\n",
    "df_train = df_train.drop('Unnamed: 0', axis = 1)\n",
    "#df_train = df_train.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test = pd.read_csv(os.path.join('Data','Modeling','Training&Testing','test_dist_total.csv'), header=0, skiprows=0)\n",
    "df_test = df_test.drop('Unnamed: 0', axis = 1)\n",
    "#df_test = df_test.drop(['bin','bowl','bucket','misc_short','jar','pottedplant','tire','misc_tall'], axis = 1)\n",
    "df_test_week_addrcode = df_test.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "train_labels = np.array(df_train['DF_4'])\n",
    "test_labels = np.array(df_test['DF_4'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "train_features= df_train.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "test_features= df_test.iloc[:,[9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_train.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (3151, 15)\n",
      "Training Labels Shape: (3151,)\n",
      "Testing Features Shape: (920, 15)\n",
      "Testing Labels Shape: (920,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 6, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.30888 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.98826952102227"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape = smape_fast(test_labels,predictions)\n",
    "smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(predictions, columns = ['predicted'])\n",
    "df_compare_addrcode_dist = pd.concat([df_test_week_addrcode_dist, df_predicted], axis = 1)\n",
    "df_compare_addrcode_dist.columns = [['addrcode','Week','Year','actual','predicted']]\n",
    "df_compare_addrcode_dist.loc[len(df_predicted)] = ['SMAPE',smape,None,None,None]\n",
    "df_compare_addrcode_dist.to_csv('Data/Modeling/Random Forest/DF_1/Province/District/RF_DFw1_dist_withCD.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Subdistrict] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Modeling/Random Forest/DF_1/Province/Subdistrict/RF_DFw1_subdist_withoutCD.csv',\n",
       " 'Data/Modeling/Random Forest/DF_1/Province/Subdistrict/RF_DFw1_subdist_withCD.csv']"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sub = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_1','Province','Subdistrict','*'))\n",
    "list_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw1_subdist_withoutCD'"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sub[0][:-4][54:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available = pd.read_csv(os.path.join('Data','Data Statistics','available_addrcode_subdistrict.csv'))\n",
    "df_available['addrcode'] = df_available['addrcode'].astype(str)\n",
    "addrcode_list = df_available['addrcode']\n",
    "addrcode_nakhon_sub = []\n",
    "\n",
    "for i in range(len(addrcode_list)):\n",
    "    if addrcode_list[i].startswith('80'):\n",
    "        addrcode_nakhon_sub.append(addrcode_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_sub)):\n",
    "    for j in range(len(addrcode_nakhon_sub)):\n",
    "        df_result = pd.read_csv(list_sub[i])\n",
    "        df_result['addrcode'] = df_result['addrcode'].astype(str).str[:6]\n",
    "        df_result = df_result.drop('Unnamed: 0', axis =1 )\n",
    "        df_result = df_result.loc[df_result['addrcode'] == addrcode_nakhon_sub[j]]\n",
    "        df_result = df_result.reset_index()\n",
    "        df_result = df_result.drop('index', axis = 1)\n",
    "        smape = smape_fast(df_result['actual'],df_result['predicted'])\n",
    "        df_result.loc[len(df_result)] = ['SMAPE',smape,None,None,None]\n",
    "        df_result.to_csv('Data/Modeling/Random Forest/DF_1/Separated/Subdistrict/'+list_sub[i][:-4][54:]+'_'+addrcode_nakhon_sub[j]+'.csv', encoding = 'utf-8')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Modeling/Random Forest/DF_1/Province/District/RF_DFw1_dist_withoutCD.csv',\n",
       " 'Data/Modeling/Random Forest/DF_1/Province/District/RF_DFw1_dist_withCD.csv']"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dist = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_1','Province','District','*'))\n",
    "list_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw1_dist_withoutCD'"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dist[0][:-4][51:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrcode_nakhon_dist = []\n",
    "\n",
    "for i in range(len(addrcode_nakhon_sub)):\n",
    "    addrcode_nakhon_sub[i] = addrcode_nakhon_sub[i][:-2]\n",
    "    addrcode_nakhon_dist.append(addrcode_nakhon_sub[i]) \n",
    "    \n",
    "addrcode_nakhon_dist = list(set(addrcode_nakhon_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_dist)):\n",
    "    for j in range(len(addrcode_nakhon_dist)):\n",
    "        df_result = pd.read_csv(list_dist[i])\n",
    "        df_result['addrcode'] = df_result['addrcode'].astype(str).str[:6]\n",
    "        df_result = df_result.drop('Unnamed: 0', axis =1 )\n",
    "        df_result = df_result.loc[df_result['addrcode'] == addrcode_nakhon_dist[j]]\n",
    "        df_result = df_result.reset_index()\n",
    "        df_result = df_result.drop('index', axis = 1)\n",
    "        smape = smape_fast(df_result['actual'],df_result['predicted'])\n",
    "        df_result.loc[len(df_result)] = ['SMAPE',smape,None,None,None]\n",
    "        df_result.to_csv('Data/Modeling/Random Forest/DF_1/Separated/District/'+list_dist[i][:-4][51:]+'_'+addrcode_nakhon_dist[j]+'.csv', encoding = 'utf-8')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Different and MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperated Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Subdistrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sub = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_1','Separated','Subdistrict','*'))\n",
    "len(file_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw1_subdist_withoutCD_802102.csv'"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sub[0][55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_sub)):\n",
    "    df_diff = pd.read_csv(file_sub[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',df_diff['different'].sum()/len(df_diff),None,None,None,None]\n",
    "    df_diff.to_csv(file_sub[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dist = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_1','Separated','District','*'))\n",
    "len(file_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw1_dist_withoutCD_8007.csv'"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dist[0][52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_dist)):\n",
    "    df_diff = pd.read_csv(file_dist[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',df_diff['different'].sum()/len(df_diff),None,None,None,None]\n",
    "    df_diff.to_csv(file_dist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Province Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Subdistrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_sub = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_6','Province','Subdistrict','*'))\n",
    "len(file_pro_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw6_subdist_withCD'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_sub[0][54:][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_pro_sub)):\n",
    "    df_diff = pd.read_csv(file_pro_sub[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',df_diff['different'].sum()/len(df_diff),None,None,None,None]\n",
    "    df_diff.to_csv('Data/Modeling/Random Forest/DF_6/Province/Subdistrict/'+file_pro_sub[i][54:][:-4]+'_diff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [District]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_dist = glob.glob(os.path.join('Data','Modeling','Random Forest','DF_1','Province','District','*'))\n",
    "len(file_pro_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF_DFw1_dist_withoutCD'"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_dist[0][51:][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/Modeling/Random Forest/DF_1/Province/District/RF_DFw1_dist_withoutCD.csv'"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pro_dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_pro_dist)):\n",
    "    df_diff = pd.read_csv(file_pro_dist[i])\n",
    "    df_diff = df_diff.drop('Unnamed: 0', axis = 1)\n",
    "    df_diff['different'] = df_diff['predicted'] - df_diff['actual']\n",
    "    df_diff['different'] = df_diff['different'].abs()\n",
    "    df_diff.loc[len(df_diff)] = ['MAE',df_diff['different'].sum()/len(df_diff),None,None,None,None]\n",
    "    df_diff.to_csv('Data/Modeling/Random Forest/DF_1/Province/District/'+file_pro_dist[i][51:][:-4]+'_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
