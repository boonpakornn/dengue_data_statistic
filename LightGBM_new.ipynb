{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Light GBM</h1>\n",
    "<h2>Import</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import lightgbm as lgb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SMAPE calculation</h2><br>\n",
    "@param<br>\n",
    "y_true = array of actual values<br>\n",
    "y_pred = array of predicted values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_fast(y_true, y_pred):\n",
    "    out = 0\n",
    "    # shape[0] = number of rows (data)\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a = y_true[i]\n",
    "        b = y_pred[i]\n",
    "        c = a + b\n",
    "        if c == 0:\n",
    "            continue\n",
    "        out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 1</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "Arrays of evaluation values for MA2, MA3 and MA4 respectively.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is MA2 DFma_1 which are MA2 without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is MA2 DFma_2.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is MA2 DFma_6.<br>\n",
    "Index 19 - 21 is MA3 DFma_1.<br>\n",
    "...<br><br>\n",
    "Each MA has 3 values in each type of evaluation.<br>\n",
    "Each set of DF has 18 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 1]</h4>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 2]</h4>\n",
    "<h4>array[3 * (which DFma_X in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_print(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' DFma_' + str(i + 1)])\n",
    "        for j in range (3):\n",
    "            eval_arr = np.append(eval_arr, [eval_values[3 * i + 18 * j + 1], \n",
    "                                            eval_values[3 * i + 18 * j + 2], \n",
    "                                            eval_values[3 * i + 18 * j + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 2</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "Instead of having multiple MAs, we have only 1 dataset for each DF.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is DF_1 which are without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is DF_2.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is DF_6.<br><br>\n",
    "Each set of DF has 3 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 1]</h4>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 2]</h4>\n",
    "<h4>array[3 * (which DF_X in range [0, 5]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_print_original(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' DF_' + str(i + 1)])\n",
    "        eval_arr = np.append(eval_arr, [eval_values[3 * i + 1], \n",
    "                                        eval_values[3 * i + 2], \n",
    "                                        eval_values[3 * i + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation printing format 3</h2><br>\n",
    "@param<br>\n",
    "array = target array to append<br>\n",
    "type_eval = string of evaluation type<br>\n",
    "eval_values = array of evaluation values<br><br>\n",
    "This format is for modified lags which the response variable is always DFma_1 for MA or DF_1 for without smoothing dataset.<br>\n",
    "Index 0 is 0 in all array because of the initialisation.<br>\n",
    "Index 1 - 3 is time horizon 1 week ahead which are without CD, with CD, and % improved respectively.<br>\n",
    "Index 4 - 6 is time horizon 2 weeks ahead.<br>\n",
    "...<br>\n",
    "Index 16 - 18 is time horizon 6 weeks ahead.<br><br>\n",
    "Each set of time horizon has 9 values in total.\n",
    "<h3>Thus,</h3>the formula for calculating the index to get the correct value is:<br>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 1]</h4>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 2]</h4>\n",
    "<h4>array[3 * (which time horizon is in range [0, 5]) + 18 * (which MA_X in range [0, 2]) + 3]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_print_modified_lag(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' ' + str(i + 1) + '-week ahead'])\n",
    "        for j in range (3):\n",
    "            eval_arr = np.append(eval_arr, [eval_values[3 * i + 18 * j + 1], \n",
    "                                            eval_values[3 * i + 18 * j + 2], \n",
    "                                            eval_values[3 * i + 18 * j + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_print_modified_lag_original(array, type_eval, eval_values):\n",
    "    for i in range (6):\n",
    "        eval_arr = np.asarray([type_eval + ' ' + str(i + 1) + '-week ahead'])\n",
    "        eval_arr = np.append(eval_arr, [eval_values[3 * i + 1], \n",
    "                                        eval_values[3 * i + 2], \n",
    "                                        eval_values[3 * i + 3]])\n",
    "        array = np.append(array, [eval_arr], axis = 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variables that you need to change before running the code</h2>\n",
    "<b>province</b> = 'Bangkok', 'NST' or 'Krabi'<br>\n",
    "<b>number of leaves</b> = 25, 31 or 70<br>\n",
    "<b>data set destination</b> = '...bangkok...', '...nakhon...' or '...krabi...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves = 70\n",
    "province1 = 'Bangkok'\n",
    "province2 = 'bangkok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normal Lags</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict DFma_1 to DFma_6<br>\n",
    "- Predict DF_1 to DF_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>District level</h2>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.294086\tvalid_0's l2: 0.116316\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.28157\tvalid_0's l2: 0.106822\n",
      "[3]\tvalid_0's l1: 0.26954\tvalid_0's l2: 0.0980169\n",
      "[4]\tvalid_0's l1: 0.258517\tvalid_0's l2: 0.0903174\n",
      "[5]\tvalid_0's l1: 0.247967\tvalid_0's l2: 0.0832162\n",
      "[6]\tvalid_0's l1: 0.238166\tvalid_0's l2: 0.0768718\n",
      "[7]\tvalid_0's l1: 0.230261\tvalid_0's l2: 0.0721112\n",
      "[8]\tvalid_0's l1: 0.221453\tvalid_0's l2: 0.0668732\n",
      "[9]\tvalid_0's l1: 0.213312\tvalid_0's l2: 0.0622892\n",
      "[10]\tvalid_0's l1: 0.205632\tvalid_0's l2: 0.0580527\n",
      "[11]\tvalid_0's l1: 0.198283\tvalid_0's l2: 0.0541466\n",
      "[12]\tvalid_0's l1: 0.191429\tvalid_0's l2: 0.0506908\n",
      "[13]\tvalid_0's l1: 0.185257\tvalid_0's l2: 0.0477157\n",
      "[14]\tvalid_0's l1: 0.179455\tvalid_0's l2: 0.0449754\n",
      "[15]\tvalid_0's l1: 0.174003\tvalid_0's l2: 0.0425092\n",
      "[16]\tvalid_0's l1: 0.168961\tvalid_0's l2: 0.040294\n",
      "[17]\tvalid_0's l1: 0.165328\tvalid_0's l2: 0.0388748\n",
      "[18]\tvalid_0's l1: 0.161159\tvalid_0's l2: 0.0372112\n",
      "[19]\tvalid_0's l1: 0.156984\tvalid_0's l2: 0.035598\n",
      "[20]\tvalid_0's l1: 0.153313\tvalid_0's l2: 0.0342374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.153313\tvalid_0's l2: 0.0342374\n",
      "[1]\tvalid_0's l1: 0.294065\tvalid_0's l2: 0.11634\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.281344\tvalid_0's l2: 0.106651\n",
      "[3]\tvalid_0's l1: 0.269324\tvalid_0's l2: 0.097842\n",
      "[4]\tvalid_0's l1: 0.257957\tvalid_0's l2: 0.0898696\n",
      "[5]\tvalid_0's l1: 0.247433\tvalid_0's l2: 0.0828562\n",
      "[6]\tvalid_0's l1: 0.237596\tvalid_0's l2: 0.0765537\n",
      "[7]\tvalid_0's l1: 0.228397\tvalid_0's l2: 0.0708903\n",
      "[8]\tvalid_0's l1: 0.219711\tvalid_0's l2: 0.0657515\n",
      "[9]\tvalid_0's l1: 0.212844\tvalid_0's l2: 0.0619873\n",
      "[10]\tvalid_0's l1: 0.205288\tvalid_0's l2: 0.0578478\n",
      "[11]\tvalid_0's l1: 0.198122\tvalid_0's l2: 0.0540565\n",
      "[12]\tvalid_0's l1: 0.191435\tvalid_0's l2: 0.0506374\n",
      "[13]\tvalid_0's l1: 0.185302\tvalid_0's l2: 0.0476386\n",
      "[14]\tvalid_0's l1: 0.179505\tvalid_0's l2: 0.0449051\n",
      "[15]\tvalid_0's l1: 0.174144\tvalid_0's l2: 0.0425096\n",
      "[16]\tvalid_0's l1: 0.169074\tvalid_0's l2: 0.0403133\n",
      "[17]\tvalid_0's l1: 0.164405\tvalid_0's l2: 0.0383856\n",
      "[18]\tvalid_0's l1: 0.160185\tvalid_0's l2: 0.0367216\n",
      "[19]\tvalid_0's l1: 0.15709\tvalid_0's l2: 0.0356777\n",
      "[20]\tvalid_0's l1: 0.153449\tvalid_0's l2: 0.034339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.153449\tvalid_0's l2: 0.034339\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.292318\tvalid_0's l2: 0.11665\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.281687\tvalid_0's l2: 0.108692\n",
      "[3]\tvalid_0's l1: 0.271889\tvalid_0's l2: 0.101587\n",
      "[4]\tvalid_0's l1: 0.262996\tvalid_0's l2: 0.0954091\n",
      "[5]\tvalid_0's l1: 0.254824\tvalid_0's l2: 0.089837\n",
      "[6]\tvalid_0's l1: 0.247363\tvalid_0's l2: 0.0848732\n",
      "[7]\tvalid_0's l1: 0.240835\tvalid_0's l2: 0.0807458\n",
      "[8]\tvalid_0's l1: 0.234422\tvalid_0's l2: 0.0768712\n",
      "[9]\tvalid_0's l1: 0.228687\tvalid_0's l2: 0.0734897\n",
      "[10]\tvalid_0's l1: 0.22339\tvalid_0's l2: 0.0705472\n",
      "[11]\tvalid_0's l1: 0.218497\tvalid_0's l2: 0.0679621\n",
      "[12]\tvalid_0's l1: 0.214068\tvalid_0's l2: 0.0657583\n",
      "[13]\tvalid_0's l1: 0.210151\tvalid_0's l2: 0.0639331\n",
      "[14]\tvalid_0's l1: 0.206494\tvalid_0's l2: 0.0623553\n",
      "[15]\tvalid_0's l1: 0.203004\tvalid_0's l2: 0.060861\n",
      "[16]\tvalid_0's l1: 0.199889\tvalid_0's l2: 0.0596492\n",
      "[17]\tvalid_0's l1: 0.197481\tvalid_0's l2: 0.0587164\n",
      "[18]\tvalid_0's l1: 0.194987\tvalid_0's l2: 0.0578699\n",
      "[19]\tvalid_0's l1: 0.192793\tvalid_0's l2: 0.0572727\n",
      "[20]\tvalid_0's l1: 0.190709\tvalid_0's l2: 0.0567247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.190709\tvalid_0's l2: 0.0567247\n",
      "[1]\tvalid_0's l1: 0.292309\tvalid_0's l2: 0.116548\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.28179\tvalid_0's l2: 0.108615\n",
      "[3]\tvalid_0's l1: 0.272098\tvalid_0's l2: 0.101494\n",
      "[4]\tvalid_0's l1: 0.26311\tvalid_0's l2: 0.0951839\n",
      "[5]\tvalid_0's l1: 0.255267\tvalid_0's l2: 0.0897982\n",
      "[6]\tvalid_0's l1: 0.247809\tvalid_0's l2: 0.0850481\n",
      "[7]\tvalid_0's l1: 0.240848\tvalid_0's l2: 0.0808419\n",
      "[8]\tvalid_0's l1: 0.234985\tvalid_0's l2: 0.0772564\n",
      "[9]\tvalid_0's l1: 0.229364\tvalid_0's l2: 0.0738531\n",
      "[10]\tvalid_0's l1: 0.224236\tvalid_0's l2: 0.0709262\n",
      "[11]\tvalid_0's l1: 0.219525\tvalid_0's l2: 0.0685809\n",
      "[12]\tvalid_0's l1: 0.214987\tvalid_0's l2: 0.0663937\n",
      "[13]\tvalid_0's l1: 0.211172\tvalid_0's l2: 0.0647291\n",
      "[14]\tvalid_0's l1: 0.20783\tvalid_0's l2: 0.0633799\n",
      "[15]\tvalid_0's l1: 0.204476\tvalid_0's l2: 0.061935\n",
      "[16]\tvalid_0's l1: 0.201613\tvalid_0's l2: 0.0608141\n",
      "[17]\tvalid_0's l1: 0.198923\tvalid_0's l2: 0.059877\n",
      "[18]\tvalid_0's l1: 0.196612\tvalid_0's l2: 0.0591959\n",
      "[19]\tvalid_0's l1: 0.194661\tvalid_0's l2: 0.0587876\n",
      "[20]\tvalid_0's l1: 0.192652\tvalid_0's l2: 0.0583053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192652\tvalid_0's l2: 0.0583053\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.288787\tvalid_0's l2: 0.114889\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27862\tvalid_0's l2: 0.107247\n",
      "[3]\tvalid_0's l1: 0.269581\tvalid_0's l2: 0.10068\n",
      "[4]\tvalid_0's l1: 0.261372\tvalid_0's l2: 0.0950185\n",
      "[5]\tvalid_0's l1: 0.25398\tvalid_0's l2: 0.0900792\n",
      "[6]\tvalid_0's l1: 0.247457\tvalid_0's l2: 0.0858903\n",
      "[7]\tvalid_0's l1: 0.242132\tvalid_0's l2: 0.082511\n",
      "[8]\tvalid_0's l1: 0.236844\tvalid_0's l2: 0.0793207\n",
      "[9]\tvalid_0's l1: 0.232134\tvalid_0's l2: 0.0767547\n",
      "[10]\tvalid_0's l1: 0.227896\tvalid_0's l2: 0.0745646\n",
      "[11]\tvalid_0's l1: 0.224004\tvalid_0's l2: 0.0725999\n",
      "[12]\tvalid_0's l1: 0.220472\tvalid_0's l2: 0.0709728\n",
      "[13]\tvalid_0's l1: 0.217596\tvalid_0's l2: 0.0698626\n",
      "[14]\tvalid_0's l1: 0.214821\tvalid_0's l2: 0.0688858\n",
      "[15]\tvalid_0's l1: 0.212347\tvalid_0's l2: 0.0681003\n",
      "[16]\tvalid_0's l1: 0.210088\tvalid_0's l2: 0.0675468\n",
      "[17]\tvalid_0's l1: 0.208558\tvalid_0's l2: 0.0675539\n",
      "[18]\tvalid_0's l1: 0.207123\tvalid_0's l2: 0.0674963\n",
      "[19]\tvalid_0's l1: 0.205522\tvalid_0's l2: 0.0673689\n",
      "[20]\tvalid_0's l1: 0.204273\tvalid_0's l2: 0.0675303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.204273\tvalid_0's l2: 0.0675303\n",
      "[1]\tvalid_0's l1: 0.28872\tvalid_0's l2: 0.115014\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.278697\tvalid_0's l2: 0.107558\n",
      "[3]\tvalid_0's l1: 0.269825\tvalid_0's l2: 0.101235\n",
      "[4]\tvalid_0's l1: 0.261452\tvalid_0's l2: 0.0954816\n",
      "[5]\tvalid_0's l1: 0.254334\tvalid_0's l2: 0.0906402\n",
      "[6]\tvalid_0's l1: 0.247738\tvalid_0's l2: 0.0864154\n",
      "[7]\tvalid_0's l1: 0.24145\tvalid_0's l2: 0.0826115\n",
      "[8]\tvalid_0's l1: 0.236023\tvalid_0's l2: 0.0793245\n",
      "[9]\tvalid_0's l1: 0.231749\tvalid_0's l2: 0.0767334\n",
      "[10]\tvalid_0's l1: 0.227592\tvalid_0's l2: 0.0745391\n",
      "[11]\tvalid_0's l1: 0.223915\tvalid_0's l2: 0.0727486\n",
      "[12]\tvalid_0's l1: 0.2206\tvalid_0's l2: 0.0712579\n",
      "[13]\tvalid_0's l1: 0.217692\tvalid_0's l2: 0.0701399\n",
      "[14]\tvalid_0's l1: 0.215224\tvalid_0's l2: 0.0692591\n",
      "[15]\tvalid_0's l1: 0.212792\tvalid_0's l2: 0.0685581\n",
      "[16]\tvalid_0's l1: 0.21093\tvalid_0's l2: 0.0680631\n",
      "[17]\tvalid_0's l1: 0.209145\tvalid_0's l2: 0.0677114\n",
      "[18]\tvalid_0's l1: 0.207735\tvalid_0's l2: 0.0676042\n",
      "[19]\tvalid_0's l1: 0.206921\tvalid_0's l2: 0.0679256\n",
      "[20]\tvalid_0's l1: 0.205933\tvalid_0's l2: 0.0682575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.205933\tvalid_0's l2: 0.0682575\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285212\tvalid_0's l2: 0.113366\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275828\tvalid_0's l2: 0.106276\n",
      "[3]\tvalid_0's l1: 0.267622\tvalid_0's l2: 0.100077\n",
      "[4]\tvalid_0's l1: 0.260591\tvalid_0's l2: 0.0950878\n",
      "[5]\tvalid_0's l1: 0.254337\tvalid_0's l2: 0.0907984\n",
      "[6]\tvalid_0's l1: 0.249122\tvalid_0's l2: 0.0873672\n",
      "[7]\tvalid_0's l1: 0.24537\tvalid_0's l2: 0.0847931\n",
      "[8]\tvalid_0's l1: 0.241502\tvalid_0's l2: 0.0825918\n",
      "[9]\tvalid_0's l1: 0.237938\tvalid_0's l2: 0.0809156\n",
      "[10]\tvalid_0's l1: 0.234467\tvalid_0's l2: 0.079386\n",
      "[11]\tvalid_0's l1: 0.23136\tvalid_0's l2: 0.0782148\n",
      "[12]\tvalid_0's l1: 0.228685\tvalid_0's l2: 0.0773801\n",
      "[13]\tvalid_0's l1: 0.226412\tvalid_0's l2: 0.0768929\n",
      "[14]\tvalid_0's l1: 0.224589\tvalid_0's l2: 0.0767203\n",
      "[15]\tvalid_0's l1: 0.223082\tvalid_0's l2: 0.0766633\n",
      "[16]\tvalid_0's l1: 0.222043\tvalid_0's l2: 0.0771975\n",
      "[17]\tvalid_0's l1: 0.221355\tvalid_0's l2: 0.078024\n",
      "[18]\tvalid_0's l1: 0.220697\tvalid_0's l2: 0.0788106\n",
      "[19]\tvalid_0's l1: 0.220123\tvalid_0's l2: 0.0798407\n",
      "[20]\tvalid_0's l1: 0.219554\tvalid_0's l2: 0.0807202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.219554\tvalid_0's l2: 0.0807202\n",
      "[1]\tvalid_0's l1: 0.285124\tvalid_0's l2: 0.113408\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275652\tvalid_0's l2: 0.106246\n",
      "[3]\tvalid_0's l1: 0.267415\tvalid_0's l2: 0.100129\n",
      "[4]\tvalid_0's l1: 0.260192\tvalid_0's l2: 0.0950426\n",
      "[5]\tvalid_0's l1: 0.254093\tvalid_0's l2: 0.0908049\n",
      "[6]\tvalid_0's l1: 0.24913\tvalid_0's l2: 0.0875415\n",
      "[7]\tvalid_0's l1: 0.244883\tvalid_0's l2: 0.0849453\n",
      "[8]\tvalid_0's l1: 0.240852\tvalid_0's l2: 0.0826584\n",
      "[9]\tvalid_0's l1: 0.237906\tvalid_0's l2: 0.0811964\n",
      "[10]\tvalid_0's l1: 0.235146\tvalid_0's l2: 0.080029\n",
      "[11]\tvalid_0's l1: 0.232535\tvalid_0's l2: 0.0790433\n",
      "[12]\tvalid_0's l1: 0.230247\tvalid_0's l2: 0.0783675\n",
      "[13]\tvalid_0's l1: 0.228793\tvalid_0's l2: 0.0784199\n",
      "[14]\tvalid_0's l1: 0.227498\tvalid_0's l2: 0.0786638\n",
      "[15]\tvalid_0's l1: 0.226149\tvalid_0's l2: 0.0789836\n",
      "[16]\tvalid_0's l1: 0.225395\tvalid_0's l2: 0.0795973\n",
      "[17]\tvalid_0's l1: 0.224468\tvalid_0's l2: 0.0802795\n",
      "[18]\tvalid_0's l1: 0.223583\tvalid_0's l2: 0.080877\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.230247\tvalid_0's l2: 0.0783675\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.28241\tvalid_0's l2: 0.112094\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27411\tvalid_0's l2: 0.105892\n",
      "[3]\tvalid_0's l1: 0.267041\tvalid_0's l2: 0.100624\n",
      "[4]\tvalid_0's l1: 0.261373\tvalid_0's l2: 0.0966179\n",
      "[5]\tvalid_0's l1: 0.256436\tvalid_0's l2: 0.0934745\n",
      "[6]\tvalid_0's l1: 0.252469\tvalid_0's l2: 0.0910145\n",
      "[7]\tvalid_0's l1: 0.249984\tvalid_0's l2: 0.0896444\n",
      "[8]\tvalid_0's l1: 0.24768\tvalid_0's l2: 0.088581\n",
      "[9]\tvalid_0's l1: 0.245823\tvalid_0's l2: 0.0880672\n",
      "[10]\tvalid_0's l1: 0.243943\tvalid_0's l2: 0.0878685\n",
      "[11]\tvalid_0's l1: 0.242087\tvalid_0's l2: 0.0877056\n",
      "[12]\tvalid_0's l1: 0.240234\tvalid_0's l2: 0.0877367\n",
      "[13]\tvalid_0's l1: 0.239256\tvalid_0's l2: 0.0883811\n",
      "[14]\tvalid_0's l1: 0.238541\tvalid_0's l2: 0.0894472\n",
      "[15]\tvalid_0's l1: 0.238036\tvalid_0's l2: 0.0907084\n",
      "[16]\tvalid_0's l1: 0.23793\tvalid_0's l2: 0.0925221\n",
      "[17]\tvalid_0's l1: 0.238338\tvalid_0's l2: 0.0947761\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.242087\tvalid_0's l2: 0.0877056\n",
      "[1]\tvalid_0's l1: 0.282432\tvalid_0's l2: 0.112108\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.274219\tvalid_0's l2: 0.105828\n",
      "[3]\tvalid_0's l1: 0.267083\tvalid_0's l2: 0.100753\n",
      "[4]\tvalid_0's l1: 0.261108\tvalid_0's l2: 0.0968003\n",
      "[5]\tvalid_0's l1: 0.256539\tvalid_0's l2: 0.0937632\n",
      "[6]\tvalid_0's l1: 0.25273\tvalid_0's l2: 0.0912677\n",
      "[7]\tvalid_0's l1: 0.249388\tvalid_0's l2: 0.0895083\n",
      "[8]\tvalid_0's l1: 0.247138\tvalid_0's l2: 0.0883842\n",
      "[9]\tvalid_0's l1: 0.245534\tvalid_0's l2: 0.0881788\n",
      "[10]\tvalid_0's l1: 0.244002\tvalid_0's l2: 0.0881842\n",
      "[11]\tvalid_0's l1: 0.242712\tvalid_0's l2: 0.0884228\n",
      "[12]\tvalid_0's l1: 0.241522\tvalid_0's l2: 0.0888874\n",
      "[13]\tvalid_0's l1: 0.240945\tvalid_0's l2: 0.0901825\n",
      "[14]\tvalid_0's l1: 0.2405\tvalid_0's l2: 0.0915253\n",
      "[15]\tvalid_0's l1: 0.240182\tvalid_0's l2: 0.0933542\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.245534\tvalid_0's l2: 0.0881788\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.281498\tvalid_0's l2: 0.111533\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.274766\tvalid_0's l2: 0.106647\n",
      "[3]\tvalid_0's l1: 0.269732\tvalid_0's l2: 0.103009\n",
      "[4]\tvalid_0's l1: 0.265502\tvalid_0's l2: 0.100305\n",
      "[5]\tvalid_0's l1: 0.262918\tvalid_0's l2: 0.0989023\n",
      "[6]\tvalid_0's l1: 0.260628\tvalid_0's l2: 0.098025\n",
      "[7]\tvalid_0's l1: 0.259423\tvalid_0's l2: 0.0979203\n",
      "[8]\tvalid_0's l1: 0.258393\tvalid_0's l2: 0.0984661\n",
      "[9]\tvalid_0's l1: 0.257336\tvalid_0's l2: 0.0992061\n",
      "[10]\tvalid_0's l1: 0.257095\tvalid_0's l2: 0.100901\n",
      "[11]\tvalid_0's l1: 0.256517\tvalid_0's l2: 0.102287\n",
      "[12]\tvalid_0's l1: 0.256163\tvalid_0's l2: 0.104127\n",
      "[13]\tvalid_0's l1: 0.256139\tvalid_0's l2: 0.10649\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.259423\tvalid_0's l2: 0.0979203\n",
      "[1]\tvalid_0's l1: 0.281506\tvalid_0's l2: 0.11151\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27479\tvalid_0's l2: 0.10662\n",
      "[3]\tvalid_0's l1: 0.270114\tvalid_0's l2: 0.103231\n",
      "[4]\tvalid_0's l1: 0.266165\tvalid_0's l2: 0.100802\n",
      "[5]\tvalid_0's l1: 0.263638\tvalid_0's l2: 0.0996277\n",
      "[6]\tvalid_0's l1: 0.261175\tvalid_0's l2: 0.0983637\n",
      "[7]\tvalid_0's l1: 0.259781\tvalid_0's l2: 0.0981567\n",
      "[8]\tvalid_0's l1: 0.258519\tvalid_0's l2: 0.098449\n",
      "[9]\tvalid_0's l1: 0.25826\tvalid_0's l2: 0.0996325\n",
      "[10]\tvalid_0's l1: 0.257774\tvalid_0's l2: 0.100978\n",
      "[11]\tvalid_0's l1: 0.257713\tvalid_0's l2: 0.102961\n",
      "[12]\tvalid_0's l1: 0.258134\tvalid_0's l2: 0.105585\n",
      "[13]\tvalid_0's l1: 0.258468\tvalid_0's l2: 0.10857\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.259781\tvalid_0's l2: 0.0981567\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.28235\tvalid_0's l2: 0.106335\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.268861\tvalid_0's l2: 0.0966252\n",
      "[3]\tvalid_0's l1: 0.256397\tvalid_0's l2: 0.0879825\n",
      "[4]\tvalid_0's l1: 0.244448\tvalid_0's l2: 0.0801429\n",
      "[5]\tvalid_0's l1: 0.233351\tvalid_0's l2: 0.0731236\n",
      "[6]\tvalid_0's l1: 0.222901\tvalid_0's l2: 0.066824\n",
      "[7]\tvalid_0's l1: 0.21363\tvalid_0's l2: 0.061487\n",
      "[8]\tvalid_0's l1: 0.204122\tvalid_0's l2: 0.0562772\n",
      "[9]\tvalid_0's l1: 0.195184\tvalid_0's l2: 0.0516123\n",
      "[10]\tvalid_0's l1: 0.186807\tvalid_0's l2: 0.0474237\n",
      "[11]\tvalid_0's l1: 0.179011\tvalid_0's l2: 0.0437318\n",
      "[12]\tvalid_0's l1: 0.1715\tvalid_0's l2: 0.0403251\n",
      "[13]\tvalid_0's l1: 0.1645\tvalid_0's l2: 0.0372847\n",
      "[14]\tvalid_0's l1: 0.157998\tvalid_0's l2: 0.0345879\n",
      "[15]\tvalid_0's l1: 0.151904\tvalid_0's l2: 0.0321769\n",
      "[16]\tvalid_0's l1: 0.146318\tvalid_0's l2: 0.0300301\n",
      "[17]\tvalid_0's l1: 0.141427\tvalid_0's l2: 0.0282034\n",
      "[18]\tvalid_0's l1: 0.136617\tvalid_0's l2: 0.0264744\n",
      "[19]\tvalid_0's l1: 0.132086\tvalid_0's l2: 0.0249065\n",
      "[20]\tvalid_0's l1: 0.127921\tvalid_0's l2: 0.0235078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.127921\tvalid_0's l2: 0.0235078\n",
      "[1]\tvalid_0's l1: 0.28229\tvalid_0's l2: 0.106303\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.268973\tvalid_0's l2: 0.0966848\n",
      "[3]\tvalid_0's l1: 0.256492\tvalid_0's l2: 0.0880292\n",
      "[4]\tvalid_0's l1: 0.244555\tvalid_0's l2: 0.0802197\n",
      "[5]\tvalid_0's l1: 0.233404\tvalid_0's l2: 0.0731942\n",
      "[6]\tvalid_0's l1: 0.222775\tvalid_0's l2: 0.0668181\n",
      "[7]\tvalid_0's l1: 0.212779\tvalid_0's l2: 0.061127\n",
      "[8]\tvalid_0's l1: 0.203398\tvalid_0's l2: 0.0559638\n",
      "[9]\tvalid_0's l1: 0.194907\tvalid_0's l2: 0.051495\n",
      "[10]\tvalid_0's l1: 0.186543\tvalid_0's l2: 0.0473337\n",
      "[11]\tvalid_0's l1: 0.178751\tvalid_0's l2: 0.043658\n",
      "[12]\tvalid_0's l1: 0.171408\tvalid_0's l2: 0.0403014\n",
      "[13]\tvalid_0's l1: 0.164592\tvalid_0's l2: 0.0373202\n",
      "[14]\tvalid_0's l1: 0.158134\tvalid_0's l2: 0.0346467\n",
      "[15]\tvalid_0's l1: 0.152051\tvalid_0's l2: 0.0322485\n",
      "[16]\tvalid_0's l1: 0.146471\tvalid_0's l2: 0.0300974\n",
      "[17]\tvalid_0's l1: 0.141274\tvalid_0's l2: 0.0281876\n",
      "[18]\tvalid_0's l1: 0.136358\tvalid_0's l2: 0.0264396\n",
      "[19]\tvalid_0's l1: 0.13223\tvalid_0's l2: 0.0250164\n",
      "[20]\tvalid_0's l1: 0.128041\tvalid_0's l2: 0.0236452\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.128041\tvalid_0's l2: 0.0236452\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.279314\tvalid_0's l2: 0.105271\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267296\tvalid_0's l2: 0.0964699\n",
      "[3]\tvalid_0's l1: 0.255837\tvalid_0's l2: 0.088469\n",
      "[4]\tvalid_0's l1: 0.245261\tvalid_0's l2: 0.0814041\n",
      "[5]\tvalid_0's l1: 0.235433\tvalid_0's l2: 0.0752233\n",
      "[6]\tvalid_0's l1: 0.226176\tvalid_0's l2: 0.0695847\n",
      "[7]\tvalid_0's l1: 0.218701\tvalid_0's l2: 0.0652842\n",
      "[8]\tvalid_0's l1: 0.210905\tvalid_0's l2: 0.0609225\n",
      "[9]\tvalid_0's l1: 0.203771\tvalid_0's l2: 0.0569894\n",
      "[10]\tvalid_0's l1: 0.196935\tvalid_0's l2: 0.0534466\n",
      "[11]\tvalid_0's l1: 0.190763\tvalid_0's l2: 0.0503637\n",
      "[12]\tvalid_0's l1: 0.185051\tvalid_0's l2: 0.0476234\n",
      "[13]\tvalid_0's l1: 0.179902\tvalid_0's l2: 0.0452546\n",
      "[14]\tvalid_0's l1: 0.175065\tvalid_0's l2: 0.0430954\n",
      "[15]\tvalid_0's l1: 0.170647\tvalid_0's l2: 0.0411926\n",
      "[16]\tvalid_0's l1: 0.166514\tvalid_0's l2: 0.0395164\n",
      "[17]\tvalid_0's l1: 0.16381\tvalid_0's l2: 0.0384354\n",
      "[18]\tvalid_0's l1: 0.160327\tvalid_0's l2: 0.0371005\n",
      "[19]\tvalid_0's l1: 0.157104\tvalid_0's l2: 0.0359728\n",
      "[20]\tvalid_0's l1: 0.15408\tvalid_0's l2: 0.0348721\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.15408\tvalid_0's l2: 0.0348721\n",
      "[1]\tvalid_0's l1: 0.279353\tvalid_0's l2: 0.105222\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267048\tvalid_0's l2: 0.0962339\n",
      "[3]\tvalid_0's l1: 0.255488\tvalid_0's l2: 0.0881716\n",
      "[4]\tvalid_0's l1: 0.244811\tvalid_0's l2: 0.0810841\n",
      "[5]\tvalid_0's l1: 0.234765\tvalid_0's l2: 0.0748318\n",
      "[6]\tvalid_0's l1: 0.225431\tvalid_0's l2: 0.0692472\n",
      "[7]\tvalid_0's l1: 0.216594\tvalid_0's l2: 0.0641864\n",
      "[8]\tvalid_0's l1: 0.208632\tvalid_0's l2: 0.0597562\n",
      "[9]\tvalid_0's l1: 0.202335\tvalid_0's l2: 0.0564061\n",
      "[10]\tvalid_0's l1: 0.195668\tvalid_0's l2: 0.0529858\n",
      "[11]\tvalid_0's l1: 0.189646\tvalid_0's l2: 0.0499615\n",
      "[12]\tvalid_0's l1: 0.183926\tvalid_0's l2: 0.047169\n",
      "[13]\tvalid_0's l1: 0.17894\tvalid_0's l2: 0.04481\n",
      "[14]\tvalid_0's l1: 0.174364\tvalid_0's l2: 0.0427626\n",
      "[15]\tvalid_0's l1: 0.17026\tvalid_0's l2: 0.0409511\n",
      "[16]\tvalid_0's l1: 0.166304\tvalid_0's l2: 0.0393328\n",
      "[17]\tvalid_0's l1: 0.162794\tvalid_0's l2: 0.0379127\n",
      "[18]\tvalid_0's l1: 0.159552\tvalid_0's l2: 0.0367216\n",
      "[19]\tvalid_0's l1: 0.157256\tvalid_0's l2: 0.0359378\n",
      "[20]\tvalid_0's l1: 0.154476\tvalid_0's l2: 0.0349873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.154476\tvalid_0's l2: 0.0349873\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.276051\tvalid_0's l2: 0.104113\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265441\tvalid_0's l2: 0.09648\n",
      "[3]\tvalid_0's l1: 0.255547\tvalid_0's l2: 0.0895576\n",
      "[4]\tvalid_0's l1: 0.246969\tvalid_0's l2: 0.0838434\n",
      "[5]\tvalid_0's l1: 0.239014\tvalid_0's l2: 0.078639\n",
      "[6]\tvalid_0's l1: 0.231922\tvalid_0's l2: 0.0741559\n",
      "[7]\tvalid_0's l1: 0.226127\tvalid_0's l2: 0.0706941\n",
      "[8]\tvalid_0's l1: 0.220363\tvalid_0's l2: 0.0673972\n",
      "[9]\tvalid_0's l1: 0.215419\tvalid_0's l2: 0.0645717\n",
      "[10]\tvalid_0's l1: 0.210945\tvalid_0's l2: 0.0621735\n",
      "[11]\tvalid_0's l1: 0.206506\tvalid_0's l2: 0.0599668\n",
      "[12]\tvalid_0's l1: 0.202572\tvalid_0's l2: 0.0581569\n",
      "[13]\tvalid_0's l1: 0.199189\tvalid_0's l2: 0.0566948\n",
      "[14]\tvalid_0's l1: 0.195986\tvalid_0's l2: 0.0553803\n",
      "[15]\tvalid_0's l1: 0.193091\tvalid_0's l2: 0.0543385\n",
      "[16]\tvalid_0's l1: 0.190639\tvalid_0's l2: 0.0535618\n",
      "[17]\tvalid_0's l1: 0.188778\tvalid_0's l2: 0.0532112\n",
      "[18]\tvalid_0's l1: 0.187093\tvalid_0's l2: 0.0529409\n",
      "[19]\tvalid_0's l1: 0.185293\tvalid_0's l2: 0.0526087\n",
      "[20]\tvalid_0's l1: 0.184061\tvalid_0's l2: 0.0526331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.184061\tvalid_0's l2: 0.0526331\n",
      "[1]\tvalid_0's l1: 0.275874\tvalid_0's l2: 0.103922\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.26534\tvalid_0's l2: 0.0962463\n",
      "[3]\tvalid_0's l1: 0.255373\tvalid_0's l2: 0.0893777\n",
      "[4]\tvalid_0's l1: 0.246303\tvalid_0's l2: 0.0834536\n",
      "[5]\tvalid_0's l1: 0.23829\tvalid_0's l2: 0.0782434\n",
      "[6]\tvalid_0's l1: 0.231218\tvalid_0's l2: 0.0738294\n",
      "[7]\tvalid_0's l1: 0.224635\tvalid_0's l2: 0.0698987\n",
      "[8]\tvalid_0's l1: 0.219\tvalid_0's l2: 0.066626\n",
      "[9]\tvalid_0's l1: 0.214156\tvalid_0's l2: 0.064049\n",
      "[10]\tvalid_0's l1: 0.209729\tvalid_0's l2: 0.0616818\n",
      "[11]\tvalid_0's l1: 0.205989\tvalid_0's l2: 0.059761\n",
      "[12]\tvalid_0's l1: 0.202642\tvalid_0's l2: 0.0581915\n",
      "[13]\tvalid_0's l1: 0.199682\tvalid_0's l2: 0.056974\n",
      "[14]\tvalid_0's l1: 0.197077\tvalid_0's l2: 0.0560008\n",
      "[15]\tvalid_0's l1: 0.194641\tvalid_0's l2: 0.0552673\n",
      "[16]\tvalid_0's l1: 0.192148\tvalid_0's l2: 0.0545009\n",
      "[17]\tvalid_0's l1: 0.19011\tvalid_0's l2: 0.0540295\n",
      "[18]\tvalid_0's l1: 0.188413\tvalid_0's l2: 0.0538362\n",
      "[19]\tvalid_0's l1: 0.18722\tvalid_0's l2: 0.0539377\n",
      "[20]\tvalid_0's l1: 0.185702\tvalid_0's l2: 0.0538817\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.185702\tvalid_0's l2: 0.0538817\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.271792\tvalid_0's l2: 0.101897\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.261436\tvalid_0's l2: 0.0945204\n",
      "[3]\tvalid_0's l1: 0.252669\tvalid_0's l2: 0.0883785\n",
      "[4]\tvalid_0's l1: 0.244716\tvalid_0's l2: 0.0830711\n",
      "[5]\tvalid_0's l1: 0.237866\tvalid_0's l2: 0.078738\n",
      "[6]\tvalid_0's l1: 0.231959\tvalid_0's l2: 0.0751806\n",
      "[7]\tvalid_0's l1: 0.227324\tvalid_0's l2: 0.0724602\n",
      "[8]\tvalid_0's l1: 0.222922\tvalid_0's l2: 0.070115\n",
      "[9]\tvalid_0's l1: 0.219379\tvalid_0's l2: 0.0682723\n",
      "[10]\tvalid_0's l1: 0.21648\tvalid_0's l2: 0.0668936\n",
      "[11]\tvalid_0's l1: 0.213422\tvalid_0's l2: 0.0655686\n",
      "[12]\tvalid_0's l1: 0.210883\tvalid_0's l2: 0.0645794\n",
      "[13]\tvalid_0's l1: 0.208695\tvalid_0's l2: 0.0638662\n",
      "[14]\tvalid_0's l1: 0.20681\tvalid_0's l2: 0.0635104\n",
      "[15]\tvalid_0's l1: 0.205194\tvalid_0's l2: 0.0631698\n",
      "[16]\tvalid_0's l1: 0.204027\tvalid_0's l2: 0.0633686\n",
      "[17]\tvalid_0's l1: 0.203453\tvalid_0's l2: 0.0640219\n",
      "[18]\tvalid_0's l1: 0.202623\tvalid_0's l2: 0.0645878\n",
      "[19]\tvalid_0's l1: 0.202125\tvalid_0's l2: 0.0653926\n",
      "[20]\tvalid_0's l1: 0.20168\tvalid_0's l2: 0.0662381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.20168\tvalid_0's l2: 0.0662381\n",
      "[1]\tvalid_0's l1: 0.271433\tvalid_0's l2: 0.101752\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260746\tvalid_0's l2: 0.0941543\n",
      "[3]\tvalid_0's l1: 0.251621\tvalid_0's l2: 0.0878797\n",
      "[4]\tvalid_0's l1: 0.243881\tvalid_0's l2: 0.0827321\n",
      "[5]\tvalid_0's l1: 0.236919\tvalid_0's l2: 0.0782906\n",
      "[6]\tvalid_0's l1: 0.231366\tvalid_0's l2: 0.0747711\n",
      "[7]\tvalid_0's l1: 0.226171\tvalid_0's l2: 0.0716758\n",
      "[8]\tvalid_0's l1: 0.221797\tvalid_0's l2: 0.0691587\n",
      "[9]\tvalid_0's l1: 0.218813\tvalid_0's l2: 0.0675164\n",
      "[10]\tvalid_0's l1: 0.215953\tvalid_0's l2: 0.0661188\n",
      "[11]\tvalid_0's l1: 0.213306\tvalid_0's l2: 0.0650379\n",
      "[12]\tvalid_0's l1: 0.211148\tvalid_0's l2: 0.0643031\n",
      "[13]\tvalid_0's l1: 0.209551\tvalid_0's l2: 0.0639253\n",
      "[14]\tvalid_0's l1: 0.207954\tvalid_0's l2: 0.0635797\n",
      "[15]\tvalid_0's l1: 0.206434\tvalid_0's l2: 0.0635024\n",
      "[16]\tvalid_0's l1: 0.205123\tvalid_0's l2: 0.0637121\n",
      "[17]\tvalid_0's l1: 0.2045\tvalid_0's l2: 0.0643341\n",
      "[18]\tvalid_0's l1: 0.203876\tvalid_0's l2: 0.0649687\n",
      "[19]\tvalid_0's l1: 0.204133\tvalid_0's l2: 0.0662986\n",
      "[20]\tvalid_0's l1: 0.203749\tvalid_0's l2: 0.067344\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.203749\tvalid_0's l2: 0.067344\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.269199\tvalid_0's l2: 0.101025\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260055\tvalid_0's l2: 0.0947383\n",
      "[3]\tvalid_0's l1: 0.252461\tvalid_0's l2: 0.0896761\n",
      "[4]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.0855705\n",
      "[5]\tvalid_0's l1: 0.241743\tvalid_0's l2: 0.0821948\n",
      "[6]\tvalid_0's l1: 0.237963\tvalid_0's l2: 0.0796513\n",
      "[7]\tvalid_0's l1: 0.235397\tvalid_0's l2: 0.0780643\n",
      "[8]\tvalid_0's l1: 0.232833\tvalid_0's l2: 0.0767813\n",
      "[9]\tvalid_0's l1: 0.230629\tvalid_0's l2: 0.0760909\n",
      "[10]\tvalid_0's l1: 0.228993\tvalid_0's l2: 0.0759022\n",
      "[11]\tvalid_0's l1: 0.227348\tvalid_0's l2: 0.0758192\n",
      "[12]\tvalid_0's l1: 0.226034\tvalid_0's l2: 0.0760462\n",
      "[13]\tvalid_0's l1: 0.22519\tvalid_0's l2: 0.0768668\n",
      "[14]\tvalid_0's l1: 0.224472\tvalid_0's l2: 0.0777934\n",
      "[15]\tvalid_0's l1: 0.22395\tvalid_0's l2: 0.0789986\n",
      "[16]\tvalid_0's l1: 0.223361\tvalid_0's l2: 0.0802061\n",
      "[17]\tvalid_0's l1: 0.223612\tvalid_0's l2: 0.0820581\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.227348\tvalid_0's l2: 0.0758192\n",
      "[1]\tvalid_0's l1: 0.269374\tvalid_0's l2: 0.101191\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260831\tvalid_0's l2: 0.0951729\n",
      "[3]\tvalid_0's l1: 0.253696\tvalid_0's l2: 0.0902622\n",
      "[4]\tvalid_0's l1: 0.247845\tvalid_0's l2: 0.0863348\n",
      "[5]\tvalid_0's l1: 0.242861\tvalid_0's l2: 0.0828171\n",
      "[6]\tvalid_0's l1: 0.239464\tvalid_0's l2: 0.0803605\n",
      "[7]\tvalid_0's l1: 0.236253\tvalid_0's l2: 0.0786275\n",
      "[8]\tvalid_0's l1: 0.233636\tvalid_0's l2: 0.0773055\n",
      "[9]\tvalid_0's l1: 0.232153\tvalid_0's l2: 0.0769073\n",
      "[10]\tvalid_0's l1: 0.230687\tvalid_0's l2: 0.0767521\n",
      "[11]\tvalid_0's l1: 0.229565\tvalid_0's l2: 0.0771225\n",
      "[12]\tvalid_0's l1: 0.228603\tvalid_0's l2: 0.0776964\n",
      "[13]\tvalid_0's l1: 0.227685\tvalid_0's l2: 0.0785885\n",
      "[14]\tvalid_0's l1: 0.227289\tvalid_0's l2: 0.0796639\n",
      "[15]\tvalid_0's l1: 0.227269\tvalid_0's l2: 0.081296\n",
      "[16]\tvalid_0's l1: 0.226823\tvalid_0's l2: 0.0827386\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.230687\tvalid_0's l2: 0.0767521\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.268071\tvalid_0's l2: 0.100228\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260835\tvalid_0's l2: 0.0951111\n",
      "[3]\tvalid_0's l1: 0.255158\tvalid_0's l2: 0.0911672\n",
      "[4]\tvalid_0's l1: 0.251363\tvalid_0's l2: 0.0883783\n",
      "[5]\tvalid_0's l1: 0.248459\tvalid_0's l2: 0.0864471\n",
      "[6]\tvalid_0's l1: 0.246301\tvalid_0's l2: 0.0852823\n",
      "[7]\tvalid_0's l1: 0.244797\tvalid_0's l2: 0.0848116\n",
      "[8]\tvalid_0's l1: 0.243546\tvalid_0's l2: 0.0850199\n",
      "[9]\tvalid_0's l1: 0.242615\tvalid_0's l2: 0.0857066\n",
      "[10]\tvalid_0's l1: 0.242274\tvalid_0's l2: 0.0870817\n",
      "[11]\tvalid_0's l1: 0.241543\tvalid_0's l2: 0.0881003\n",
      "[12]\tvalid_0's l1: 0.24098\tvalid_0's l2: 0.0893867\n",
      "[13]\tvalid_0's l1: 0.241003\tvalid_0's l2: 0.0913785\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.244797\tvalid_0's l2: 0.0848116\n",
      "[1]\tvalid_0's l1: 0.26735\tvalid_0's l2: 0.0997703\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.259345\tvalid_0's l2: 0.0941689\n",
      "[3]\tvalid_0's l1: 0.253943\tvalid_0's l2: 0.0905068\n",
      "[4]\tvalid_0's l1: 0.250102\tvalid_0's l2: 0.087708\n",
      "[5]\tvalid_0's l1: 0.247146\tvalid_0's l2: 0.0856115\n",
      "[6]\tvalid_0's l1: 0.245429\tvalid_0's l2: 0.0845338\n",
      "[7]\tvalid_0's l1: 0.24372\tvalid_0's l2: 0.0838762\n",
      "[8]\tvalid_0's l1: 0.24272\tvalid_0's l2: 0.0840236\n",
      "[9]\tvalid_0's l1: 0.242724\tvalid_0's l2: 0.0852684\n",
      "[10]\tvalid_0's l1: 0.24239\tvalid_0's l2: 0.086515\n",
      "[11]\tvalid_0's l1: 0.242491\tvalid_0's l2: 0.0882164\n",
      "[12]\tvalid_0's l1: 0.242976\tvalid_0's l2: 0.0905882\n",
      "[13]\tvalid_0's l1: 0.243049\tvalid_0's l2: 0.0927248\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.24372\tvalid_0's l2: 0.0838762\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273515\tvalid_0's l2: 0.100029\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260147\tvalid_0's l2: 0.0904881\n",
      "[3]\tvalid_0's l1: 0.247561\tvalid_0's l2: 0.0819568\n",
      "[4]\tvalid_0's l1: 0.235636\tvalid_0's l2: 0.074271\n",
      "[5]\tvalid_0's l1: 0.224397\tvalid_0's l2: 0.0673593\n",
      "[6]\tvalid_0's l1: 0.213699\tvalid_0's l2: 0.0611097\n",
      "[7]\tvalid_0's l1: 0.203991\tvalid_0's l2: 0.0557182\n",
      "[8]\tvalid_0's l1: 0.194553\tvalid_0's l2: 0.0507126\n",
      "[9]\tvalid_0's l1: 0.185557\tvalid_0's l2: 0.046144\n",
      "[10]\tvalid_0's l1: 0.177198\tvalid_0's l2: 0.042106\n",
      "[11]\tvalid_0's l1: 0.169249\tvalid_0's l2: 0.0384473\n",
      "[12]\tvalid_0's l1: 0.161792\tvalid_0's l2: 0.0351665\n",
      "[13]\tvalid_0's l1: 0.154689\tvalid_0's l2: 0.032202\n",
      "[14]\tvalid_0's l1: 0.148097\tvalid_0's l2: 0.0295824\n",
      "[15]\tvalid_0's l1: 0.141925\tvalid_0's l2: 0.0272467\n",
      "[16]\tvalid_0's l1: 0.136178\tvalid_0's l2: 0.0251524\n",
      "[17]\tvalid_0's l1: 0.130928\tvalid_0's l2: 0.0233483\n",
      "[18]\tvalid_0's l1: 0.125831\tvalid_0's l2: 0.0216351\n",
      "[19]\tvalid_0's l1: 0.121197\tvalid_0's l2: 0.0201256\n",
      "[20]\tvalid_0's l1: 0.116829\tvalid_0's l2: 0.0187499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.116829\tvalid_0's l2: 0.0187499\n",
      "[1]\tvalid_0's l1: 0.273474\tvalid_0's l2: 0.100008\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260018\tvalid_0's l2: 0.0904592\n",
      "[3]\tvalid_0's l1: 0.247395\tvalid_0's l2: 0.0819302\n",
      "[4]\tvalid_0's l1: 0.235456\tvalid_0's l2: 0.0742529\n",
      "[5]\tvalid_0's l1: 0.224194\tvalid_0's l2: 0.0673268\n",
      "[6]\tvalid_0's l1: 0.213566\tvalid_0's l2: 0.0610994\n",
      "[7]\tvalid_0's l1: 0.203306\tvalid_0's l2: 0.0554323\n",
      "[8]\tvalid_0's l1: 0.193788\tvalid_0's l2: 0.0503885\n",
      "[9]\tvalid_0's l1: 0.185179\tvalid_0's l2: 0.0460767\n",
      "[10]\tvalid_0's l1: 0.176707\tvalid_0's l2: 0.0419928\n",
      "[11]\tvalid_0's l1: 0.168794\tvalid_0's l2: 0.0383268\n",
      "[12]\tvalid_0's l1: 0.161398\tvalid_0's l2: 0.0350585\n",
      "[13]\tvalid_0's l1: 0.154434\tvalid_0's l2: 0.0321301\n",
      "[14]\tvalid_0's l1: 0.147839\tvalid_0's l2: 0.029506\n",
      "[15]\tvalid_0's l1: 0.1418\tvalid_0's l2: 0.0272008\n",
      "[16]\tvalid_0's l1: 0.135953\tvalid_0's l2: 0.0250755\n",
      "[17]\tvalid_0's l1: 0.130426\tvalid_0's l2: 0.0231462\n",
      "[18]\tvalid_0's l1: 0.125347\tvalid_0's l2: 0.0214512\n",
      "[19]\tvalid_0's l1: 0.120868\tvalid_0's l2: 0.0200155\n",
      "[20]\tvalid_0's l1: 0.116472\tvalid_0's l2: 0.0186516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.116472\tvalid_0's l2: 0.0186516\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.269663\tvalid_0's l2: 0.0983996\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256701\tvalid_0's l2: 0.0892713\n",
      "[3]\tvalid_0's l1: 0.244721\tvalid_0's l2: 0.0812725\n",
      "[4]\tvalid_0's l1: 0.23332\tvalid_0's l2: 0.0739634\n",
      "[5]\tvalid_0's l1: 0.222897\tvalid_0's l2: 0.0675839\n",
      "[6]\tvalid_0's l1: 0.213064\tvalid_0's l2: 0.0618614\n",
      "[7]\tvalid_0's l1: 0.204425\tvalid_0's l2: 0.05709\n",
      "[8]\tvalid_0's l1: 0.195981\tvalid_0's l2: 0.052604\n",
      "[9]\tvalid_0's l1: 0.188115\tvalid_0's l2: 0.0485199\n",
      "[10]\tvalid_0's l1: 0.180947\tvalid_0's l2: 0.0449675\n",
      "[11]\tvalid_0's l1: 0.17417\tvalid_0's l2: 0.0417402\n",
      "[12]\tvalid_0's l1: 0.167968\tvalid_0's l2: 0.0388902\n",
      "[13]\tvalid_0's l1: 0.162409\tvalid_0's l2: 0.0363897\n",
      "[14]\tvalid_0's l1: 0.157168\tvalid_0's l2: 0.0341182\n",
      "[15]\tvalid_0's l1: 0.152338\tvalid_0's l2: 0.0321686\n",
      "[16]\tvalid_0's l1: 0.147807\tvalid_0's l2: 0.0304243\n",
      "[17]\tvalid_0's l1: 0.144307\tvalid_0's l2: 0.0291388\n",
      "[18]\tvalid_0's l1: 0.140628\tvalid_0's l2: 0.0277918\n",
      "[19]\tvalid_0's l1: 0.137178\tvalid_0's l2: 0.0265826\n",
      "[20]\tvalid_0's l1: 0.134142\tvalid_0's l2: 0.0255674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.134142\tvalid_0's l2: 0.0255674\n",
      "[1]\tvalid_0's l1: 0.26959\tvalid_0's l2: 0.0983514\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256714\tvalid_0's l2: 0.0893915\n",
      "[3]\tvalid_0's l1: 0.244621\tvalid_0's l2: 0.0813357\n",
      "[4]\tvalid_0's l1: 0.233251\tvalid_0's l2: 0.0741231\n",
      "[5]\tvalid_0's l1: 0.222637\tvalid_0's l2: 0.0676395\n",
      "[6]\tvalid_0's l1: 0.212584\tvalid_0's l2: 0.0618461\n",
      "[7]\tvalid_0's l1: 0.203149\tvalid_0's l2: 0.0565745\n",
      "[8]\tvalid_0's l1: 0.194757\tvalid_0's l2: 0.0520755\n",
      "[9]\tvalid_0's l1: 0.187551\tvalid_0's l2: 0.0484857\n",
      "[10]\tvalid_0's l1: 0.180287\tvalid_0's l2: 0.0448871\n",
      "[11]\tvalid_0's l1: 0.173886\tvalid_0's l2: 0.041764\n",
      "[12]\tvalid_0's l1: 0.167788\tvalid_0's l2: 0.0389294\n",
      "[13]\tvalid_0's l1: 0.162322\tvalid_0's l2: 0.0364255\n",
      "[14]\tvalid_0's l1: 0.157324\tvalid_0's l2: 0.0342696\n",
      "[15]\tvalid_0's l1: 0.152652\tvalid_0's l2: 0.0323208\n",
      "[16]\tvalid_0's l1: 0.148233\tvalid_0's l2: 0.0305715\n",
      "[17]\tvalid_0's l1: 0.144412\tvalid_0's l2: 0.0290909\n",
      "[18]\tvalid_0's l1: 0.140812\tvalid_0's l2: 0.0277655\n",
      "[19]\tvalid_0's l1: 0.138202\tvalid_0's l2: 0.0269033\n",
      "[20]\tvalid_0's l1: 0.134996\tvalid_0's l2: 0.0258659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.134996\tvalid_0's l2: 0.0258659\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265989\tvalid_0's l2: 0.0968033\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254368\tvalid_0's l2: 0.0886517\n",
      "[3]\tvalid_0's l1: 0.243351\tvalid_0's l2: 0.081317\n",
      "[4]\tvalid_0's l1: 0.233436\tvalid_0's l2: 0.075037\n",
      "[5]\tvalid_0's l1: 0.224276\tvalid_0's l2: 0.0694212\n",
      "[6]\tvalid_0's l1: 0.215673\tvalid_0's l2: 0.0644472\n",
      "[7]\tvalid_0's l1: 0.2088\tvalid_0's l2: 0.0606942\n",
      "[8]\tvalid_0's l1: 0.201945\tvalid_0's l2: 0.05697\n",
      "[9]\tvalid_0's l1: 0.195874\tvalid_0's l2: 0.0537805\n",
      "[10]\tvalid_0's l1: 0.190326\tvalid_0's l2: 0.0509349\n",
      "[11]\tvalid_0's l1: 0.185128\tvalid_0's l2: 0.0483407\n",
      "[12]\tvalid_0's l1: 0.180486\tvalid_0's l2: 0.0461039\n",
      "[13]\tvalid_0's l1: 0.176609\tvalid_0's l2: 0.0443506\n",
      "[14]\tvalid_0's l1: 0.172808\tvalid_0's l2: 0.0426892\n",
      "[15]\tvalid_0's l1: 0.169527\tvalid_0's l2: 0.0413913\n",
      "[16]\tvalid_0's l1: 0.166504\tvalid_0's l2: 0.0402492\n",
      "[17]\tvalid_0's l1: 0.164812\tvalid_0's l2: 0.0397987\n",
      "[18]\tvalid_0's l1: 0.162238\tvalid_0's l2: 0.0390585\n",
      "[19]\tvalid_0's l1: 0.159879\tvalid_0's l2: 0.038402\n",
      "[20]\tvalid_0's l1: 0.157884\tvalid_0's l2: 0.0379305\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.157884\tvalid_0's l2: 0.0379305\n",
      "[1]\tvalid_0's l1: 0.265903\tvalid_0's l2: 0.0967165\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254205\tvalid_0's l2: 0.088526\n",
      "[3]\tvalid_0's l1: 0.24312\tvalid_0's l2: 0.0811612\n",
      "[4]\tvalid_0's l1: 0.232967\tvalid_0's l2: 0.0748155\n",
      "[5]\tvalid_0's l1: 0.223928\tvalid_0's l2: 0.0692877\n",
      "[6]\tvalid_0's l1: 0.215365\tvalid_0's l2: 0.0642418\n",
      "[7]\tvalid_0's l1: 0.207369\tvalid_0's l2: 0.0597827\n",
      "[8]\tvalid_0's l1: 0.200735\tvalid_0's l2: 0.0561359\n",
      "[9]\tvalid_0's l1: 0.195633\tvalid_0's l2: 0.053422\n",
      "[10]\tvalid_0's l1: 0.190396\tvalid_0's l2: 0.0507454\n",
      "[11]\tvalid_0's l1: 0.185674\tvalid_0's l2: 0.0483685\n",
      "[12]\tvalid_0's l1: 0.181574\tvalid_0's l2: 0.0463769\n",
      "[13]\tvalid_0's l1: 0.177794\tvalid_0's l2: 0.0446517\n",
      "[14]\tvalid_0's l1: 0.174366\tvalid_0's l2: 0.0432053\n",
      "[15]\tvalid_0's l1: 0.171067\tvalid_0's l2: 0.0418448\n",
      "[16]\tvalid_0's l1: 0.168309\tvalid_0's l2: 0.0408735\n",
      "[17]\tvalid_0's l1: 0.165636\tvalid_0's l2: 0.0399792\n",
      "[18]\tvalid_0's l1: 0.163349\tvalid_0's l2: 0.039337\n",
      "[19]\tvalid_0's l1: 0.16215\tvalid_0's l2: 0.0393301\n",
      "[20]\tvalid_0's l1: 0.16049\tvalid_0's l2: 0.0390256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.16049\tvalid_0's l2: 0.0390256\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.262275\tvalid_0's l2: 0.095075\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251927\tvalid_0's l2: 0.0879186\n",
      "[3]\tvalid_0's l1: 0.242532\tvalid_0's l2: 0.0817401\n",
      "[4]\tvalid_0's l1: 0.2343\tvalid_0's l2: 0.0765531\n",
      "[5]\tvalid_0's l1: 0.227692\tvalid_0's l2: 0.0723253\n",
      "[6]\tvalid_0's l1: 0.221883\tvalid_0's l2: 0.0688002\n",
      "[7]\tvalid_0's l1: 0.217365\tvalid_0's l2: 0.0661839\n",
      "[8]\tvalid_0's l1: 0.212998\tvalid_0's l2: 0.0636928\n",
      "[9]\tvalid_0's l1: 0.209462\tvalid_0's l2: 0.0617608\n",
      "[10]\tvalid_0's l1: 0.206313\tvalid_0's l2: 0.0602149\n",
      "[11]\tvalid_0's l1: 0.203304\tvalid_0's l2: 0.0589035\n",
      "[12]\tvalid_0's l1: 0.200509\tvalid_0's l2: 0.0579444\n",
      "[13]\tvalid_0's l1: 0.198278\tvalid_0's l2: 0.0572476\n",
      "[14]\tvalid_0's l1: 0.196141\tvalid_0's l2: 0.056651\n",
      "[15]\tvalid_0's l1: 0.194258\tvalid_0's l2: 0.0563203\n",
      "[16]\tvalid_0's l1: 0.192578\tvalid_0's l2: 0.0562396\n",
      "[17]\tvalid_0's l1: 0.192017\tvalid_0's l2: 0.0568549\n",
      "[18]\tvalid_0's l1: 0.190961\tvalid_0's l2: 0.0570903\n",
      "[19]\tvalid_0's l1: 0.189948\tvalid_0's l2: 0.0575601\n",
      "[20]\tvalid_0's l1: 0.189255\tvalid_0's l2: 0.0581886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189255\tvalid_0's l2: 0.0581886\n",
      "[1]\tvalid_0's l1: 0.262128\tvalid_0's l2: 0.0950715\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251745\tvalid_0's l2: 0.0879297\n",
      "[3]\tvalid_0's l1: 0.24277\tvalid_0's l2: 0.0818958\n",
      "[4]\tvalid_0's l1: 0.234724\tvalid_0's l2: 0.0767343\n",
      "[5]\tvalid_0's l1: 0.228032\tvalid_0's l2: 0.072369\n",
      "[6]\tvalid_0's l1: 0.222286\tvalid_0's l2: 0.0688517\n",
      "[7]\tvalid_0's l1: 0.217045\tvalid_0's l2: 0.0657735\n",
      "[8]\tvalid_0's l1: 0.212946\tvalid_0's l2: 0.0634417\n",
      "[9]\tvalid_0's l1: 0.209696\tvalid_0's l2: 0.0617446\n",
      "[10]\tvalid_0's l1: 0.206849\tvalid_0's l2: 0.0603838\n",
      "[11]\tvalid_0's l1: 0.204246\tvalid_0's l2: 0.0593067\n",
      "[12]\tvalid_0's l1: 0.201928\tvalid_0's l2: 0.05856\n",
      "[13]\tvalid_0's l1: 0.199853\tvalid_0's l2: 0.0581166\n",
      "[14]\tvalid_0's l1: 0.198056\tvalid_0's l2: 0.0579096\n",
      "[15]\tvalid_0's l1: 0.196728\tvalid_0's l2: 0.057908\n",
      "[16]\tvalid_0's l1: 0.195542\tvalid_0's l2: 0.0581331\n",
      "[17]\tvalid_0's l1: 0.194185\tvalid_0's l2: 0.0582365\n",
      "[18]\tvalid_0's l1: 0.193312\tvalid_0's l2: 0.0586559\n",
      "[19]\tvalid_0's l1: 0.19311\tvalid_0's l2: 0.0596451\n",
      "[20]\tvalid_0's l1: 0.192479\tvalid_0's l2: 0.060432\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192479\tvalid_0's l2: 0.060432\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.259057\tvalid_0's l2: 0.0935911\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.249615\tvalid_0's l2: 0.0872757\n",
      "[3]\tvalid_0's l1: 0.241707\tvalid_0's l2: 0.0821899\n",
      "[4]\tvalid_0's l1: 0.235676\tvalid_0's l2: 0.0781348\n",
      "[5]\tvalid_0's l1: 0.231446\tvalid_0's l2: 0.0751815\n",
      "[6]\tvalid_0's l1: 0.22808\tvalid_0's l2: 0.0729629\n",
      "[7]\tvalid_0's l1: 0.225705\tvalid_0's l2: 0.071619\n",
      "[8]\tvalid_0's l1: 0.223064\tvalid_0's l2: 0.0704577\n",
      "[9]\tvalid_0's l1: 0.221237\tvalid_0's l2: 0.0700622\n",
      "[10]\tvalid_0's l1: 0.219277\tvalid_0's l2: 0.0697912\n",
      "[11]\tvalid_0's l1: 0.217282\tvalid_0's l2: 0.0694661\n",
      "[12]\tvalid_0's l1: 0.215627\tvalid_0's l2: 0.0695672\n",
      "[13]\tvalid_0's l1: 0.214658\tvalid_0's l2: 0.0702863\n",
      "[14]\tvalid_0's l1: 0.21372\tvalid_0's l2: 0.0709396\n",
      "[15]\tvalid_0's l1: 0.21304\tvalid_0's l2: 0.0719316\n",
      "[16]\tvalid_0's l1: 0.212083\tvalid_0's l2: 0.0725901\n",
      "[17]\tvalid_0's l1: 0.212196\tvalid_0's l2: 0.0741386\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.217282\tvalid_0's l2: 0.0694661\n",
      "[1]\tvalid_0's l1: 0.259002\tvalid_0's l2: 0.0936229\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.249468\tvalid_0's l2: 0.0873343\n",
      "[3]\tvalid_0's l1: 0.242232\tvalid_0's l2: 0.0823921\n",
      "[4]\tvalid_0's l1: 0.23657\tvalid_0's l2: 0.0784662\n",
      "[5]\tvalid_0's l1: 0.231946\tvalid_0's l2: 0.0753831\n",
      "[6]\tvalid_0's l1: 0.228576\tvalid_0's l2: 0.0732745\n",
      "[7]\tvalid_0's l1: 0.22489\tvalid_0's l2: 0.0714199\n",
      "[8]\tvalid_0's l1: 0.222229\tvalid_0's l2: 0.070333\n",
      "[9]\tvalid_0's l1: 0.220946\tvalid_0's l2: 0.0702007\n",
      "[10]\tvalid_0's l1: 0.219017\tvalid_0's l2: 0.0698368\n",
      "[11]\tvalid_0's l1: 0.217775\tvalid_0's l2: 0.0701062\n",
      "[12]\tvalid_0's l1: 0.216815\tvalid_0's l2: 0.0707415\n",
      "[13]\tvalid_0's l1: 0.215659\tvalid_0's l2: 0.0713435\n",
      "[14]\tvalid_0's l1: 0.215513\tvalid_0's l2: 0.0727872\n",
      "[15]\tvalid_0's l1: 0.215098\tvalid_0's l2: 0.0741272\n",
      "[16]\tvalid_0's l1: 0.213849\tvalid_0's l2: 0.0746111\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.219017\tvalid_0's l2: 0.0698368\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.258501\tvalid_0's l2: 0.0930071\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251054\tvalid_0's l2: 0.0879611\n",
      "[3]\tvalid_0's l1: 0.245802\tvalid_0's l2: 0.0841836\n",
      "[4]\tvalid_0's l1: 0.241815\tvalid_0's l2: 0.0814183\n",
      "[5]\tvalid_0's l1: 0.238427\tvalid_0's l2: 0.0794182\n",
      "[6]\tvalid_0's l1: 0.236338\tvalid_0's l2: 0.0785063\n",
      "[7]\tvalid_0's l1: 0.235271\tvalid_0's l2: 0.0784335\n",
      "[8]\tvalid_0's l1: 0.233842\tvalid_0's l2: 0.0786098\n",
      "[9]\tvalid_0's l1: 0.233174\tvalid_0's l2: 0.0797606\n",
      "[10]\tvalid_0's l1: 0.232622\tvalid_0's l2: 0.081064\n",
      "[11]\tvalid_0's l1: 0.231805\tvalid_0's l2: 0.0821764\n",
      "[12]\tvalid_0's l1: 0.231318\tvalid_0's l2: 0.0837196\n",
      "[13]\tvalid_0's l1: 0.23119\tvalid_0's l2: 0.0856214\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.235271\tvalid_0's l2: 0.0784335\n",
      "[1]\tvalid_0's l1: 0.257848\tvalid_0's l2: 0.09286\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.249783\tvalid_0's l2: 0.0875291\n",
      "[3]\tvalid_0's l1: 0.244351\tvalid_0's l2: 0.0838562\n",
      "[4]\tvalid_0's l1: 0.240074\tvalid_0's l2: 0.0810757\n",
      "[5]\tvalid_0's l1: 0.237873\tvalid_0's l2: 0.0797027\n",
      "[6]\tvalid_0's l1: 0.235939\tvalid_0's l2: 0.0788194\n",
      "[7]\tvalid_0's l1: 0.233883\tvalid_0's l2: 0.0781689\n",
      "[8]\tvalid_0's l1: 0.233123\tvalid_0's l2: 0.078913\n",
      "[9]\tvalid_0's l1: 0.232686\tvalid_0's l2: 0.0797356\n",
      "[10]\tvalid_0's l1: 0.23258\tvalid_0's l2: 0.0812705\n",
      "[11]\tvalid_0's l1: 0.232524\tvalid_0's l2: 0.0830869\n",
      "[12]\tvalid_0's l1: 0.232533\tvalid_0's l2: 0.0850493\n",
      "[13]\tvalid_0's l1: 0.232699\tvalid_0's l2: 0.0872766\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.233883\tvalid_0's l2: 0.0781689\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin [col 26],\n",
    "        # bowl [col 27],\n",
    "        # bucket [col 28],\n",
    "        # misc_short [col 29],\n",
    "        # jar [col 30],\n",
    "        # pottedplant [col 31],\n",
    "        # tire [col 32],\n",
    "        # misc_tall [col 33],\n",
    "        # and total [col 34]\n",
    "        \n",
    "        x_train_withoutCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_train_withCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        x_test_withoutCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_test_withCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # y: response (target) variable DFma_1 to DFma_6 [col 19 -> 14]\n",
    "        y_train = df_train_dist.iloc[:, [19 - j]]\n",
    "        y_test = df_test_dist.iloc[:, [19 - j]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_dist['DFma_' + str(j + 1)])\n",
    "        y_test_true = np.array(df_test_dist['DFma_' + str(j + 1)])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                                  + str(i) + '_DFma_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                               + str(i) + '_DFma_' + str(j + 1) + '_withCD_' + str(num_leaves) + '.csv', \n",
    "                                               encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_dist_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.320476\tvalid_0's l2: 0.144048\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310479\tvalid_0's l2: 0.136154\n",
      "[3]\tvalid_0's l1: 0.3009\tvalid_0's l2: 0.128727\n",
      "[4]\tvalid_0's l1: 0.292464\tvalid_0's l2: 0.122536\n",
      "[5]\tvalid_0's l1: 0.284402\tvalid_0's l2: 0.116608\n",
      "[6]\tvalid_0's l1: 0.277052\tvalid_0's l2: 0.111426\n",
      "[7]\tvalid_0's l1: 0.270324\tvalid_0's l2: 0.106816\n",
      "[8]\tvalid_0's l1: 0.263979\tvalid_0's l2: 0.102709\n",
      "[9]\tvalid_0's l1: 0.258178\tvalid_0's l2: 0.0991075\n",
      "[10]\tvalid_0's l1: 0.252509\tvalid_0's l2: 0.0956931\n",
      "[11]\tvalid_0's l1: 0.24751\tvalid_0's l2: 0.0929538\n",
      "[12]\tvalid_0's l1: 0.242876\tvalid_0's l2: 0.0904785\n",
      "[13]\tvalid_0's l1: 0.23887\tvalid_0's l2: 0.0884331\n",
      "[14]\tvalid_0's l1: 0.234894\tvalid_0's l2: 0.0865239\n",
      "[15]\tvalid_0's l1: 0.231166\tvalid_0's l2: 0.0846408\n",
      "[16]\tvalid_0's l1: 0.227919\tvalid_0's l2: 0.083149\n",
      "[17]\tvalid_0's l1: 0.225068\tvalid_0's l2: 0.0819192\n",
      "[18]\tvalid_0's l1: 0.222278\tvalid_0's l2: 0.0807971\n",
      "[19]\tvalid_0's l1: 0.219724\tvalid_0's l2: 0.0797885\n",
      "[20]\tvalid_0's l1: 0.217521\tvalid_0's l2: 0.0789726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.217521\tvalid_0's l2: 0.0789726\n",
      "[1]\tvalid_0's l1: 0.320324\tvalid_0's l2: 0.143947\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310503\tvalid_0's l2: 0.136185\n",
      "[3]\tvalid_0's l1: 0.300948\tvalid_0's l2: 0.128769\n",
      "[4]\tvalid_0's l1: 0.292388\tvalid_0's l2: 0.122304\n",
      "[5]\tvalid_0's l1: 0.284536\tvalid_0's l2: 0.116746\n",
      "[6]\tvalid_0's l1: 0.277066\tvalid_0's l2: 0.111548\n",
      "[7]\tvalid_0's l1: 0.270012\tvalid_0's l2: 0.106899\n",
      "[8]\tvalid_0's l1: 0.263571\tvalid_0's l2: 0.102716\n",
      "[9]\tvalid_0's l1: 0.257449\tvalid_0's l2: 0.0988463\n",
      "[10]\tvalid_0's l1: 0.252094\tvalid_0's l2: 0.0956134\n",
      "[11]\tvalid_0's l1: 0.247028\tvalid_0's l2: 0.0927375\n",
      "[12]\tvalid_0's l1: 0.242538\tvalid_0's l2: 0.0903353\n",
      "[13]\tvalid_0's l1: 0.238419\tvalid_0's l2: 0.0882122\n",
      "[14]\tvalid_0's l1: 0.234682\tvalid_0's l2: 0.086396\n",
      "[15]\tvalid_0's l1: 0.231146\tvalid_0's l2: 0.0847134\n",
      "[16]\tvalid_0's l1: 0.227911\tvalid_0's l2: 0.0831763\n",
      "[17]\tvalid_0's l1: 0.224922\tvalid_0's l2: 0.0818649\n",
      "[18]\tvalid_0's l1: 0.222156\tvalid_0's l2: 0.0807649\n",
      "[19]\tvalid_0's l1: 0.21988\tvalid_0's l2: 0.0798148\n",
      "[20]\tvalid_0's l1: 0.217689\tvalid_0's l2: 0.0790724\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.217689\tvalid_0's l2: 0.0790724\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.318208\tvalid_0's l2: 0.143072\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.309152\tvalid_0's l2: 0.135674\n",
      "[3]\tvalid_0's l1: 0.300265\tvalid_0's l2: 0.128714\n",
      "[4]\tvalid_0's l1: 0.292883\tvalid_0's l2: 0.123057\n",
      "[5]\tvalid_0's l1: 0.285506\tvalid_0's l2: 0.11763\n",
      "[6]\tvalid_0's l1: 0.278979\tvalid_0's l2: 0.113052\n",
      "[7]\tvalid_0's l1: 0.273591\tvalid_0's l2: 0.109334\n",
      "[8]\tvalid_0's l1: 0.267948\tvalid_0's l2: 0.105824\n",
      "[9]\tvalid_0's l1: 0.263006\tvalid_0's l2: 0.102909\n",
      "[10]\tvalid_0's l1: 0.258331\tvalid_0's l2: 0.100235\n",
      "[11]\tvalid_0's l1: 0.25405\tvalid_0's l2: 0.0979098\n",
      "[12]\tvalid_0's l1: 0.250089\tvalid_0's l2: 0.0957941\n",
      "[13]\tvalid_0's l1: 0.246823\tvalid_0's l2: 0.0942018\n",
      "[14]\tvalid_0's l1: 0.243573\tvalid_0's l2: 0.092628\n",
      "[15]\tvalid_0's l1: 0.24051\tvalid_0's l2: 0.0913256\n",
      "[16]\tvalid_0's l1: 0.237884\tvalid_0's l2: 0.0903834\n",
      "[17]\tvalid_0's l1: 0.235694\tvalid_0's l2: 0.0896123\n",
      "[18]\tvalid_0's l1: 0.23383\tvalid_0's l2: 0.0891718\n",
      "[19]\tvalid_0's l1: 0.231975\tvalid_0's l2: 0.0886853\n",
      "[20]\tvalid_0's l1: 0.230347\tvalid_0's l2: 0.0884494\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.230347\tvalid_0's l2: 0.0884494\n",
      "[1]\tvalid_0's l1: 0.318084\tvalid_0's l2: 0.142987\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308874\tvalid_0's l2: 0.135482\n",
      "[3]\tvalid_0's l1: 0.300053\tvalid_0's l2: 0.128668\n",
      "[4]\tvalid_0's l1: 0.292075\tvalid_0's l2: 0.122531\n",
      "[5]\tvalid_0's l1: 0.285121\tvalid_0's l2: 0.117502\n",
      "[6]\tvalid_0's l1: 0.27881\tvalid_0's l2: 0.113079\n",
      "[7]\tvalid_0's l1: 0.272765\tvalid_0's l2: 0.109015\n",
      "[8]\tvalid_0's l1: 0.267268\tvalid_0's l2: 0.105539\n",
      "[9]\tvalid_0's l1: 0.262257\tvalid_0's l2: 0.102599\n",
      "[10]\tvalid_0's l1: 0.258016\tvalid_0's l2: 0.100163\n",
      "[11]\tvalid_0's l1: 0.253956\tvalid_0's l2: 0.0978548\n",
      "[12]\tvalid_0's l1: 0.250396\tvalid_0's l2: 0.0958743\n",
      "[13]\tvalid_0's l1: 0.247267\tvalid_0's l2: 0.0943522\n",
      "[14]\tvalid_0's l1: 0.24442\tvalid_0's l2: 0.0930565\n",
      "[15]\tvalid_0's l1: 0.241653\tvalid_0's l2: 0.0919527\n",
      "[16]\tvalid_0's l1: 0.239295\tvalid_0's l2: 0.0910731\n",
      "[17]\tvalid_0's l1: 0.237257\tvalid_0's l2: 0.0904092\n",
      "[18]\tvalid_0's l1: 0.235255\tvalid_0's l2: 0.0898917\n",
      "[19]\tvalid_0's l1: 0.233492\tvalid_0's l2: 0.0894489\n",
      "[20]\tvalid_0's l1: 0.232049\tvalid_0's l2: 0.0891741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.232049\tvalid_0's l2: 0.0891741\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315259\tvalid_0's l2: 0.141866\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306296\tvalid_0's l2: 0.134753\n",
      "[3]\tvalid_0's l1: 0.298531\tvalid_0's l2: 0.128434\n",
      "[4]\tvalid_0's l1: 0.291891\tvalid_0's l2: 0.1234\n",
      "[5]\tvalid_0's l1: 0.285483\tvalid_0's l2: 0.118765\n",
      "[6]\tvalid_0's l1: 0.279453\tvalid_0's l2: 0.11459\n",
      "[7]\tvalid_0's l1: 0.274585\tvalid_0's l2: 0.111244\n",
      "[8]\tvalid_0's l1: 0.270045\tvalid_0's l2: 0.108448\n",
      "[9]\tvalid_0's l1: 0.266105\tvalid_0's l2: 0.106161\n",
      "[10]\tvalid_0's l1: 0.262275\tvalid_0's l2: 0.104316\n",
      "[11]\tvalid_0's l1: 0.258751\tvalid_0's l2: 0.102566\n",
      "[12]\tvalid_0's l1: 0.255736\tvalid_0's l2: 0.101363\n",
      "[13]\tvalid_0's l1: 0.25286\tvalid_0's l2: 0.100523\n",
      "[14]\tvalid_0's l1: 0.250516\tvalid_0's l2: 0.0997441\n",
      "[15]\tvalid_0's l1: 0.248422\tvalid_0's l2: 0.0992681\n",
      "[16]\tvalid_0's l1: 0.2466\tvalid_0's l2: 0.0990372\n",
      "[17]\tvalid_0's l1: 0.245\tvalid_0's l2: 0.098879\n",
      "[18]\tvalid_0's l1: 0.243823\tvalid_0's l2: 0.0990443\n",
      "[19]\tvalid_0's l1: 0.242618\tvalid_0's l2: 0.0992765\n",
      "[20]\tvalid_0's l1: 0.241787\tvalid_0's l2: 0.0997699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.241787\tvalid_0's l2: 0.0997699\n",
      "[1]\tvalid_0's l1: 0.315109\tvalid_0's l2: 0.141812\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.30627\tvalid_0's l2: 0.134736\n",
      "[3]\tvalid_0's l1: 0.298132\tvalid_0's l2: 0.128231\n",
      "[4]\tvalid_0's l1: 0.291155\tvalid_0's l2: 0.122881\n",
      "[5]\tvalid_0's l1: 0.284746\tvalid_0's l2: 0.118231\n",
      "[6]\tvalid_0's l1: 0.278741\tvalid_0's l2: 0.114051\n",
      "[7]\tvalid_0's l1: 0.273554\tvalid_0's l2: 0.110651\n",
      "[8]\tvalid_0's l1: 0.268926\tvalid_0's l2: 0.107871\n",
      "[9]\tvalid_0's l1: 0.264779\tvalid_0's l2: 0.105262\n",
      "[10]\tvalid_0's l1: 0.261146\tvalid_0's l2: 0.103422\n",
      "[11]\tvalid_0's l1: 0.258054\tvalid_0's l2: 0.102051\n",
      "[12]\tvalid_0's l1: 0.254975\tvalid_0's l2: 0.100759\n",
      "[13]\tvalid_0's l1: 0.252359\tvalid_0's l2: 0.0998237\n",
      "[14]\tvalid_0's l1: 0.250427\tvalid_0's l2: 0.0993286\n",
      "[15]\tvalid_0's l1: 0.248486\tvalid_0's l2: 0.0990284\n",
      "[16]\tvalid_0's l1: 0.246421\tvalid_0's l2: 0.0984234\n",
      "[17]\tvalid_0's l1: 0.244797\tvalid_0's l2: 0.0981976\n",
      "[18]\tvalid_0's l1: 0.243546\tvalid_0's l2: 0.0982907\n",
      "[19]\tvalid_0's l1: 0.242144\tvalid_0's l2: 0.0981853\n",
      "[20]\tvalid_0's l1: 0.24117\tvalid_0's l2: 0.0985278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.24117\tvalid_0's l2: 0.0985278\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.314163\tvalid_0's l2: 0.141138\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306302\tvalid_0's l2: 0.134546\n",
      "[3]\tvalid_0's l1: 0.298674\tvalid_0's l2: 0.128581\n",
      "[4]\tvalid_0's l1: 0.292686\tvalid_0's l2: 0.123902\n",
      "[5]\tvalid_0's l1: 0.287256\tvalid_0's l2: 0.119929\n",
      "[6]\tvalid_0's l1: 0.282556\tvalid_0's l2: 0.116653\n",
      "[7]\tvalid_0's l1: 0.278747\tvalid_0's l2: 0.114328\n",
      "[8]\tvalid_0's l1: 0.275222\tvalid_0's l2: 0.112461\n",
      "[9]\tvalid_0's l1: 0.272318\tvalid_0's l2: 0.111284\n",
      "[10]\tvalid_0's l1: 0.269416\tvalid_0's l2: 0.11019\n",
      "[11]\tvalid_0's l1: 0.266907\tvalid_0's l2: 0.109408\n",
      "[12]\tvalid_0's l1: 0.264893\tvalid_0's l2: 0.109108\n",
      "[13]\tvalid_0's l1: 0.263116\tvalid_0's l2: 0.109017\n",
      "[14]\tvalid_0's l1: 0.261722\tvalid_0's l2: 0.109095\n",
      "[15]\tvalid_0's l1: 0.260369\tvalid_0's l2: 0.109477\n",
      "[16]\tvalid_0's l1: 0.259222\tvalid_0's l2: 0.109971\n",
      "[17]\tvalid_0's l1: 0.258435\tvalid_0's l2: 0.110694\n",
      "[18]\tvalid_0's l1: 0.257686\tvalid_0's l2: 0.11151\n",
      "[19]\tvalid_0's l1: 0.257161\tvalid_0's l2: 0.112421\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.263116\tvalid_0's l2: 0.109017\n",
      "[1]\tvalid_0's l1: 0.314199\tvalid_0's l2: 0.141174\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306639\tvalid_0's l2: 0.134764\n",
      "[3]\tvalid_0's l1: 0.299006\tvalid_0's l2: 0.128657\n",
      "[4]\tvalid_0's l1: 0.29283\tvalid_0's l2: 0.123966\n",
      "[5]\tvalid_0's l1: 0.287263\tvalid_0's l2: 0.119851\n",
      "[6]\tvalid_0's l1: 0.282644\tvalid_0's l2: 0.116784\n",
      "[7]\tvalid_0's l1: 0.278366\tvalid_0's l2: 0.114282\n",
      "[8]\tvalid_0's l1: 0.274845\tvalid_0's l2: 0.112333\n",
      "[9]\tvalid_0's l1: 0.271996\tvalid_0's l2: 0.110742\n",
      "[10]\tvalid_0's l1: 0.269555\tvalid_0's l2: 0.110008\n",
      "[11]\tvalid_0's l1: 0.267506\tvalid_0's l2: 0.109501\n",
      "[12]\tvalid_0's l1: 0.265638\tvalid_0's l2: 0.109322\n",
      "[13]\tvalid_0's l1: 0.264275\tvalid_0's l2: 0.109582\n",
      "[14]\tvalid_0's l1: 0.263154\tvalid_0's l2: 0.109972\n",
      "[15]\tvalid_0's l1: 0.26214\tvalid_0's l2: 0.110274\n",
      "[16]\tvalid_0's l1: 0.26105\tvalid_0's l2: 0.110888\n",
      "[17]\tvalid_0's l1: 0.260284\tvalid_0's l2: 0.111816\n",
      "[18]\tvalid_0's l1: 0.259582\tvalid_0's l2: 0.112586\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.265638\tvalid_0's l2: 0.109322\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.311406\tvalid_0's l2: 0.140187\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.30414\tvalid_0's l2: 0.134518\n",
      "[3]\tvalid_0's l1: 0.298473\tvalid_0's l2: 0.13\n",
      "[4]\tvalid_0's l1: 0.293904\tvalid_0's l2: 0.126715\n",
      "[5]\tvalid_0's l1: 0.289932\tvalid_0's l2: 0.124174\n",
      "[6]\tvalid_0's l1: 0.286324\tvalid_0's l2: 0.122163\n",
      "[7]\tvalid_0's l1: 0.283461\tvalid_0's l2: 0.120599\n",
      "[8]\tvalid_0's l1: 0.280807\tvalid_0's l2: 0.119602\n",
      "[9]\tvalid_0's l1: 0.278894\tvalid_0's l2: 0.11924\n",
      "[10]\tvalid_0's l1: 0.277175\tvalid_0's l2: 0.119357\n",
      "[11]\tvalid_0's l1: 0.275837\tvalid_0's l2: 0.119451\n",
      "[12]\tvalid_0's l1: 0.274886\tvalid_0's l2: 0.120214\n",
      "[13]\tvalid_0's l1: 0.274198\tvalid_0's l2: 0.120947\n",
      "[14]\tvalid_0's l1: 0.273656\tvalid_0's l2: 0.121989\n",
      "[15]\tvalid_0's l1: 0.273194\tvalid_0's l2: 0.123295\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.278894\tvalid_0's l2: 0.11924\n",
      "[1]\tvalid_0's l1: 0.311349\tvalid_0's l2: 0.140113\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.304524\tvalid_0's l2: 0.134636\n",
      "[3]\tvalid_0's l1: 0.298816\tvalid_0's l2: 0.130224\n",
      "[4]\tvalid_0's l1: 0.293826\tvalid_0's l2: 0.126507\n",
      "[5]\tvalid_0's l1: 0.28983\tvalid_0's l2: 0.12388\n",
      "[6]\tvalid_0's l1: 0.286455\tvalid_0's l2: 0.121982\n",
      "[7]\tvalid_0's l1: 0.283514\tvalid_0's l2: 0.120687\n",
      "[8]\tvalid_0's l1: 0.281313\tvalid_0's l2: 0.120112\n",
      "[9]\tvalid_0's l1: 0.279585\tvalid_0's l2: 0.119582\n",
      "[10]\tvalid_0's l1: 0.27828\tvalid_0's l2: 0.119708\n",
      "[11]\tvalid_0's l1: 0.277099\tvalid_0's l2: 0.119876\n",
      "[12]\tvalid_0's l1: 0.276177\tvalid_0's l2: 0.120705\n",
      "[13]\tvalid_0's l1: 0.275474\tvalid_0's l2: 0.121578\n",
      "[14]\tvalid_0's l1: 0.274805\tvalid_0's l2: 0.122806\n",
      "[15]\tvalid_0's l1: 0.274589\tvalid_0's l2: 0.124542\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.279585\tvalid_0's l2: 0.119582\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.313762\tvalid_0's l2: 0.141956\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308348\tvalid_0's l2: 0.137458\n",
      "[3]\tvalid_0's l1: 0.304076\tvalid_0's l2: 0.134098\n",
      "[4]\tvalid_0's l1: 0.300607\tvalid_0's l2: 0.132045\n",
      "[5]\tvalid_0's l1: 0.297674\tvalid_0's l2: 0.130636\n",
      "[6]\tvalid_0's l1: 0.295449\tvalid_0's l2: 0.129952\n",
      "[7]\tvalid_0's l1: 0.293848\tvalid_0's l2: 0.129819\n",
      "[8]\tvalid_0's l1: 0.292839\tvalid_0's l2: 0.130483\n",
      "[9]\tvalid_0's l1: 0.292291\tvalid_0's l2: 0.131719\n",
      "[10]\tvalid_0's l1: 0.292249\tvalid_0's l2: 0.133665\n",
      "[11]\tvalid_0's l1: 0.291659\tvalid_0's l2: 0.135115\n",
      "[12]\tvalid_0's l1: 0.291769\tvalid_0's l2: 0.137366\n",
      "[13]\tvalid_0's l1: 0.292223\tvalid_0's l2: 0.140156\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.293848\tvalid_0's l2: 0.129819\n",
      "[1]\tvalid_0's l1: 0.313423\tvalid_0's l2: 0.141557\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308333\tvalid_0's l2: 0.137391\n",
      "[3]\tvalid_0's l1: 0.30361\tvalid_0's l2: 0.13384\n",
      "[4]\tvalid_0's l1: 0.299992\tvalid_0's l2: 0.131191\n",
      "[5]\tvalid_0's l1: 0.297205\tvalid_0's l2: 0.129815\n",
      "[6]\tvalid_0's l1: 0.294776\tvalid_0's l2: 0.128961\n",
      "[7]\tvalid_0's l1: 0.293182\tvalid_0's l2: 0.129106\n",
      "[8]\tvalid_0's l1: 0.291815\tvalid_0's l2: 0.129419\n",
      "[9]\tvalid_0's l1: 0.29162\tvalid_0's l2: 0.130905\n",
      "[10]\tvalid_0's l1: 0.291208\tvalid_0's l2: 0.132276\n",
      "[11]\tvalid_0's l1: 0.291077\tvalid_0's l2: 0.134209\n",
      "[12]\tvalid_0's l1: 0.291188\tvalid_0's l2: 0.136626\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's l1: 0.294776\tvalid_0's l2: 0.128961\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Get the input variables from CSV file\n",
    "# Change files directory here\n",
    "rain_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_total_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin_pop9s [col 26],\n",
    "    # bowl_pop9s [col 27],\n",
    "    # bucket_pop9s [col 28],\n",
    "    # misc_short_pop9s [col 29],\n",
    "    # jar_pop9s [col 30],\n",
    "    # pottedplant_pop9s [col 31],\n",
    "    # tire_pop9s [col 32],\n",
    "    # misc_tall_pop9s [col 33],\n",
    "    # and total_pop9s [col 34]\n",
    "        \n",
    "    x_train_withoutCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_train_withCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    x_test_withoutCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_test_withCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # y: response (target) variable from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    y_train = df_train_dist.iloc[:, [9 - i]]\n",
    "    y_test = df_test_dist.iloc[:, [9 - i]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_dist['DF_' + str(i + 1)])\n",
    "    y_test_true = np.array(df_test_dist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                              + str(i + 1) + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                           + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                           + str(i + 1) + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_ByDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_dist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (Normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.294086\tvalid_0's l2: 0.116316\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.28157\tvalid_0's l2: 0.106822\n",
      "[3]\tvalid_0's l1: 0.26954\tvalid_0's l2: 0.0980169\n",
      "[4]\tvalid_0's l1: 0.258517\tvalid_0's l2: 0.0903174\n",
      "[5]\tvalid_0's l1: 0.247967\tvalid_0's l2: 0.0832162\n",
      "[6]\tvalid_0's l1: 0.238166\tvalid_0's l2: 0.0768718\n",
      "[7]\tvalid_0's l1: 0.230261\tvalid_0's l2: 0.0721112\n",
      "[8]\tvalid_0's l1: 0.221453\tvalid_0's l2: 0.0668732\n",
      "[9]\tvalid_0's l1: 0.213312\tvalid_0's l2: 0.0622892\n",
      "[10]\tvalid_0's l1: 0.205632\tvalid_0's l2: 0.0580527\n",
      "[11]\tvalid_0's l1: 0.198283\tvalid_0's l2: 0.0541466\n",
      "[12]\tvalid_0's l1: 0.191429\tvalid_0's l2: 0.0506908\n",
      "[13]\tvalid_0's l1: 0.185257\tvalid_0's l2: 0.0477157\n",
      "[14]\tvalid_0's l1: 0.179455\tvalid_0's l2: 0.0449754\n",
      "[15]\tvalid_0's l1: 0.174003\tvalid_0's l2: 0.0425092\n",
      "[16]\tvalid_0's l1: 0.168961\tvalid_0's l2: 0.040294\n",
      "[17]\tvalid_0's l1: 0.165328\tvalid_0's l2: 0.0388748\n",
      "[18]\tvalid_0's l1: 0.161159\tvalid_0's l2: 0.0372112\n",
      "[19]\tvalid_0's l1: 0.156984\tvalid_0's l2: 0.035598\n",
      "[20]\tvalid_0's l1: 0.153313\tvalid_0's l2: 0.0342374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.153313\tvalid_0's l2: 0.0342374\n",
      "[1]\tvalid_0's l1: 0.294071\tvalid_0's l2: 0.116351\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.281368\tvalid_0's l2: 0.106739\n",
      "[3]\tvalid_0's l1: 0.269434\tvalid_0's l2: 0.0979717\n",
      "[4]\tvalid_0's l1: 0.258256\tvalid_0's l2: 0.0901387\n",
      "[5]\tvalid_0's l1: 0.247629\tvalid_0's l2: 0.0830154\n",
      "[6]\tvalid_0's l1: 0.237772\tvalid_0's l2: 0.0766723\n",
      "[7]\tvalid_0's l1: 0.228449\tvalid_0's l2: 0.070909\n",
      "[8]\tvalid_0's l1: 0.219673\tvalid_0's l2: 0.0657331\n",
      "[9]\tvalid_0's l1: 0.212787\tvalid_0's l2: 0.0619721\n",
      "[10]\tvalid_0's l1: 0.205164\tvalid_0's l2: 0.0578088\n",
      "[11]\tvalid_0's l1: 0.197938\tvalid_0's l2: 0.0540188\n",
      "[12]\tvalid_0's l1: 0.191259\tvalid_0's l2: 0.0506003\n",
      "[13]\tvalid_0's l1: 0.185124\tvalid_0's l2: 0.0475653\n",
      "[14]\tvalid_0's l1: 0.179323\tvalid_0's l2: 0.044864\n",
      "[15]\tvalid_0's l1: 0.173822\tvalid_0's l2: 0.0424045\n",
      "[16]\tvalid_0's l1: 0.168809\tvalid_0's l2: 0.0402472\n",
      "[17]\tvalid_0's l1: 0.164201\tvalid_0's l2: 0.0383155\n",
      "[18]\tvalid_0's l1: 0.159916\tvalid_0's l2: 0.0366573\n",
      "[19]\tvalid_0's l1: 0.15664\tvalid_0's l2: 0.0355523\n",
      "[20]\tvalid_0's l1: 0.153037\tvalid_0's l2: 0.0342312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.153037\tvalid_0's l2: 0.0342312\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.292318\tvalid_0's l2: 0.11665\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.281687\tvalid_0's l2: 0.108692\n",
      "[3]\tvalid_0's l1: 0.271889\tvalid_0's l2: 0.101587\n",
      "[4]\tvalid_0's l1: 0.262996\tvalid_0's l2: 0.0954091\n",
      "[5]\tvalid_0's l1: 0.254824\tvalid_0's l2: 0.089837\n",
      "[6]\tvalid_0's l1: 0.247363\tvalid_0's l2: 0.0848732\n",
      "[7]\tvalid_0's l1: 0.240835\tvalid_0's l2: 0.0807458\n",
      "[8]\tvalid_0's l1: 0.234422\tvalid_0's l2: 0.0768712\n",
      "[9]\tvalid_0's l1: 0.228687\tvalid_0's l2: 0.0734897\n",
      "[10]\tvalid_0's l1: 0.22339\tvalid_0's l2: 0.0705472\n",
      "[11]\tvalid_0's l1: 0.218497\tvalid_0's l2: 0.0679621\n",
      "[12]\tvalid_0's l1: 0.214068\tvalid_0's l2: 0.0657583\n",
      "[13]\tvalid_0's l1: 0.210151\tvalid_0's l2: 0.0639331\n",
      "[14]\tvalid_0's l1: 0.206494\tvalid_0's l2: 0.0623553\n",
      "[15]\tvalid_0's l1: 0.203004\tvalid_0's l2: 0.060861\n",
      "[16]\tvalid_0's l1: 0.199889\tvalid_0's l2: 0.0596492\n",
      "[17]\tvalid_0's l1: 0.197481\tvalid_0's l2: 0.0587164\n",
      "[18]\tvalid_0's l1: 0.194987\tvalid_0's l2: 0.0578699\n",
      "[19]\tvalid_0's l1: 0.192793\tvalid_0's l2: 0.0572727\n",
      "[20]\tvalid_0's l1: 0.190709\tvalid_0's l2: 0.0567247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.190709\tvalid_0's l2: 0.0567247\n",
      "[1]\tvalid_0's l1: 0.292384\tvalid_0's l2: 0.116683\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.281808\tvalid_0's l2: 0.1088\n",
      "[3]\tvalid_0's l1: 0.272031\tvalid_0's l2: 0.101698\n",
      "[4]\tvalid_0's l1: 0.263205\tvalid_0's l2: 0.0954238\n",
      "[5]\tvalid_0's l1: 0.255052\tvalid_0's l2: 0.0898777\n",
      "[6]\tvalid_0's l1: 0.24765\tvalid_0's l2: 0.0850942\n",
      "[7]\tvalid_0's l1: 0.240822\tvalid_0's l2: 0.0808148\n",
      "[8]\tvalid_0's l1: 0.234628\tvalid_0's l2: 0.0771032\n",
      "[9]\tvalid_0's l1: 0.229253\tvalid_0's l2: 0.07388\n",
      "[10]\tvalid_0's l1: 0.224241\tvalid_0's l2: 0.0710582\n",
      "[11]\tvalid_0's l1: 0.21947\tvalid_0's l2: 0.068549\n",
      "[12]\tvalid_0's l1: 0.214944\tvalid_0's l2: 0.0663787\n",
      "[13]\tvalid_0's l1: 0.210963\tvalid_0's l2: 0.0646116\n",
      "[14]\tvalid_0's l1: 0.207233\tvalid_0's l2: 0.0629901\n",
      "[15]\tvalid_0's l1: 0.204104\tvalid_0's l2: 0.0617351\n",
      "[16]\tvalid_0's l1: 0.201315\tvalid_0's l2: 0.0606227\n",
      "[17]\tvalid_0's l1: 0.198645\tvalid_0's l2: 0.0597458\n",
      "[18]\tvalid_0's l1: 0.196382\tvalid_0's l2: 0.0591749\n",
      "[19]\tvalid_0's l1: 0.194539\tvalid_0's l2: 0.0587209\n",
      "[20]\tvalid_0's l1: 0.192589\tvalid_0's l2: 0.0584066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192589\tvalid_0's l2: 0.0584066\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.288787\tvalid_0's l2: 0.114889\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27862\tvalid_0's l2: 0.107247\n",
      "[3]\tvalid_0's l1: 0.269581\tvalid_0's l2: 0.10068\n",
      "[4]\tvalid_0's l1: 0.261372\tvalid_0's l2: 0.0950185\n",
      "[5]\tvalid_0's l1: 0.25398\tvalid_0's l2: 0.0900792\n",
      "[6]\tvalid_0's l1: 0.247457\tvalid_0's l2: 0.0858903\n",
      "[7]\tvalid_0's l1: 0.242132\tvalid_0's l2: 0.082511\n",
      "[8]\tvalid_0's l1: 0.236844\tvalid_0's l2: 0.0793207\n",
      "[9]\tvalid_0's l1: 0.232134\tvalid_0's l2: 0.0767547\n",
      "[10]\tvalid_0's l1: 0.227896\tvalid_0's l2: 0.0745646\n",
      "[11]\tvalid_0's l1: 0.224004\tvalid_0's l2: 0.0725999\n",
      "[12]\tvalid_0's l1: 0.220472\tvalid_0's l2: 0.0709728\n",
      "[13]\tvalid_0's l1: 0.217596\tvalid_0's l2: 0.0698626\n",
      "[14]\tvalid_0's l1: 0.214821\tvalid_0's l2: 0.0688858\n",
      "[15]\tvalid_0's l1: 0.212347\tvalid_0's l2: 0.0681003\n",
      "[16]\tvalid_0's l1: 0.210088\tvalid_0's l2: 0.0675468\n",
      "[17]\tvalid_0's l1: 0.208558\tvalid_0's l2: 0.0675539\n",
      "[18]\tvalid_0's l1: 0.207123\tvalid_0's l2: 0.0674963\n",
      "[19]\tvalid_0's l1: 0.205522\tvalid_0's l2: 0.0673689\n",
      "[20]\tvalid_0's l1: 0.204273\tvalid_0's l2: 0.0675303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.204273\tvalid_0's l2: 0.0675303\n",
      "[1]\tvalid_0's l1: 0.288723\tvalid_0's l2: 0.114922\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.278737\tvalid_0's l2: 0.107565\n",
      "[3]\tvalid_0's l1: 0.269643\tvalid_0's l2: 0.101019\n",
      "[4]\tvalid_0's l1: 0.26163\tvalid_0's l2: 0.0953479\n",
      "[5]\tvalid_0's l1: 0.254485\tvalid_0's l2: 0.0904553\n",
      "[6]\tvalid_0's l1: 0.247908\tvalid_0's l2: 0.0861471\n",
      "[7]\tvalid_0's l1: 0.242034\tvalid_0's l2: 0.0825379\n",
      "[8]\tvalid_0's l1: 0.236697\tvalid_0's l2: 0.0793491\n",
      "[9]\tvalid_0's l1: 0.232296\tvalid_0's l2: 0.0767292\n",
      "[10]\tvalid_0's l1: 0.228144\tvalid_0's l2: 0.0745894\n",
      "[11]\tvalid_0's l1: 0.224344\tvalid_0's l2: 0.0726685\n",
      "[12]\tvalid_0's l1: 0.220929\tvalid_0's l2: 0.071134\n",
      "[13]\tvalid_0's l1: 0.21814\tvalid_0's l2: 0.07011\n",
      "[14]\tvalid_0's l1: 0.215672\tvalid_0's l2: 0.0693905\n",
      "[15]\tvalid_0's l1: 0.213318\tvalid_0's l2: 0.0687282\n",
      "[16]\tvalid_0's l1: 0.21123\tvalid_0's l2: 0.0682639\n",
      "[17]\tvalid_0's l1: 0.209554\tvalid_0's l2: 0.0680557\n",
      "[18]\tvalid_0's l1: 0.208258\tvalid_0's l2: 0.0681449\n",
      "[19]\tvalid_0's l1: 0.207153\tvalid_0's l2: 0.0683956\n",
      "[20]\tvalid_0's l1: 0.206078\tvalid_0's l2: 0.0685557\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.206078\tvalid_0's l2: 0.0685557\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285212\tvalid_0's l2: 0.113366\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275828\tvalid_0's l2: 0.106276\n",
      "[3]\tvalid_0's l1: 0.267622\tvalid_0's l2: 0.100077\n",
      "[4]\tvalid_0's l1: 0.260591\tvalid_0's l2: 0.0950878\n",
      "[5]\tvalid_0's l1: 0.254337\tvalid_0's l2: 0.0907984\n",
      "[6]\tvalid_0's l1: 0.249122\tvalid_0's l2: 0.0873672\n",
      "[7]\tvalid_0's l1: 0.24537\tvalid_0's l2: 0.0847931\n",
      "[8]\tvalid_0's l1: 0.241502\tvalid_0's l2: 0.0825918\n",
      "[9]\tvalid_0's l1: 0.237938\tvalid_0's l2: 0.0809156\n",
      "[10]\tvalid_0's l1: 0.234467\tvalid_0's l2: 0.079386\n",
      "[11]\tvalid_0's l1: 0.23136\tvalid_0's l2: 0.0782148\n",
      "[12]\tvalid_0's l1: 0.228685\tvalid_0's l2: 0.0773801\n",
      "[13]\tvalid_0's l1: 0.226412\tvalid_0's l2: 0.0768929\n",
      "[14]\tvalid_0's l1: 0.224589\tvalid_0's l2: 0.0767203\n",
      "[15]\tvalid_0's l1: 0.223082\tvalid_0's l2: 0.0766633\n",
      "[16]\tvalid_0's l1: 0.222043\tvalid_0's l2: 0.0771975\n",
      "[17]\tvalid_0's l1: 0.221355\tvalid_0's l2: 0.078024\n",
      "[18]\tvalid_0's l1: 0.220697\tvalid_0's l2: 0.0788106\n",
      "[19]\tvalid_0's l1: 0.220123\tvalid_0's l2: 0.0798407\n",
      "[20]\tvalid_0's l1: 0.219554\tvalid_0's l2: 0.0807202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.219554\tvalid_0's l2: 0.0807202\n",
      "[1]\tvalid_0's l1: 0.285348\tvalid_0's l2: 0.113535\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.276204\tvalid_0's l2: 0.10653\n",
      "[3]\tvalid_0's l1: 0.268103\tvalid_0's l2: 0.100523\n",
      "[4]\tvalid_0's l1: 0.260783\tvalid_0's l2: 0.0952751\n",
      "[5]\tvalid_0's l1: 0.25467\tvalid_0's l2: 0.0908825\n",
      "[6]\tvalid_0's l1: 0.249687\tvalid_0's l2: 0.0875999\n",
      "[7]\tvalid_0's l1: 0.245301\tvalid_0's l2: 0.0848117\n",
      "[8]\tvalid_0's l1: 0.241511\tvalid_0's l2: 0.0826393\n",
      "[9]\tvalid_0's l1: 0.238485\tvalid_0's l2: 0.0811537\n",
      "[10]\tvalid_0's l1: 0.235062\tvalid_0's l2: 0.0796574\n",
      "[11]\tvalid_0's l1: 0.232263\tvalid_0's l2: 0.0785859\n",
      "[12]\tvalid_0's l1: 0.229731\tvalid_0's l2: 0.0778364\n",
      "[13]\tvalid_0's l1: 0.227889\tvalid_0's l2: 0.0776128\n",
      "[14]\tvalid_0's l1: 0.226223\tvalid_0's l2: 0.0776398\n",
      "[15]\tvalid_0's l1: 0.224837\tvalid_0's l2: 0.0777693\n",
      "[16]\tvalid_0's l1: 0.223653\tvalid_0's l2: 0.078341\n",
      "[17]\tvalid_0's l1: 0.222615\tvalid_0's l2: 0.0789913\n",
      "[18]\tvalid_0's l1: 0.221841\tvalid_0's l2: 0.0799342\n",
      "[19]\tvalid_0's l1: 0.22122\tvalid_0's l2: 0.0808574\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.227889\tvalid_0's l2: 0.0776128\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.28241\tvalid_0's l2: 0.112094\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27411\tvalid_0's l2: 0.105892\n",
      "[3]\tvalid_0's l1: 0.267041\tvalid_0's l2: 0.100624\n",
      "[4]\tvalid_0's l1: 0.261373\tvalid_0's l2: 0.0966179\n",
      "[5]\tvalid_0's l1: 0.256436\tvalid_0's l2: 0.0934745\n",
      "[6]\tvalid_0's l1: 0.252469\tvalid_0's l2: 0.0910145\n",
      "[7]\tvalid_0's l1: 0.249984\tvalid_0's l2: 0.0896444\n",
      "[8]\tvalid_0's l1: 0.24768\tvalid_0's l2: 0.088581\n",
      "[9]\tvalid_0's l1: 0.245823\tvalid_0's l2: 0.0880672\n",
      "[10]\tvalid_0's l1: 0.243943\tvalid_0's l2: 0.0878685\n",
      "[11]\tvalid_0's l1: 0.242087\tvalid_0's l2: 0.0877056\n",
      "[12]\tvalid_0's l1: 0.240234\tvalid_0's l2: 0.0877367\n",
      "[13]\tvalid_0's l1: 0.239256\tvalid_0's l2: 0.0883811\n",
      "[14]\tvalid_0's l1: 0.238541\tvalid_0's l2: 0.0894472\n",
      "[15]\tvalid_0's l1: 0.238036\tvalid_0's l2: 0.0907084\n",
      "[16]\tvalid_0's l1: 0.23793\tvalid_0's l2: 0.0925221\n",
      "[17]\tvalid_0's l1: 0.238338\tvalid_0's l2: 0.0947761\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.242087\tvalid_0's l2: 0.0877056\n",
      "[1]\tvalid_0's l1: 0.282305\tvalid_0's l2: 0.112093\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.274127\tvalid_0's l2: 0.105817\n",
      "[3]\tvalid_0's l1: 0.267133\tvalid_0's l2: 0.100721\n",
      "[4]\tvalid_0's l1: 0.261195\tvalid_0's l2: 0.0966106\n",
      "[5]\tvalid_0's l1: 0.256382\tvalid_0's l2: 0.0934597\n",
      "[6]\tvalid_0's l1: 0.252718\tvalid_0's l2: 0.0911443\n",
      "[7]\tvalid_0's l1: 0.249662\tvalid_0's l2: 0.0894783\n",
      "[8]\tvalid_0's l1: 0.247633\tvalid_0's l2: 0.0885258\n",
      "[9]\tvalid_0's l1: 0.246199\tvalid_0's l2: 0.0883498\n",
      "[10]\tvalid_0's l1: 0.244479\tvalid_0's l2: 0.0882436\n",
      "[11]\tvalid_0's l1: 0.243363\tvalid_0's l2: 0.0885665\n",
      "[12]\tvalid_0's l1: 0.242037\tvalid_0's l2: 0.0890034\n",
      "[13]\tvalid_0's l1: 0.241598\tvalid_0's l2: 0.0901249\n",
      "[14]\tvalid_0's l1: 0.240983\tvalid_0's l2: 0.0911864\n",
      "[15]\tvalid_0's l1: 0.240577\tvalid_0's l2: 0.0925146\n",
      "[16]\tvalid_0's l1: 0.240303\tvalid_0's l2: 0.093965\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.244479\tvalid_0's l2: 0.0882436\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.281498\tvalid_0's l2: 0.111533\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.274766\tvalid_0's l2: 0.106647\n",
      "[3]\tvalid_0's l1: 0.269732\tvalid_0's l2: 0.103009\n",
      "[4]\tvalid_0's l1: 0.265502\tvalid_0's l2: 0.100305\n",
      "[5]\tvalid_0's l1: 0.262918\tvalid_0's l2: 0.0989023\n",
      "[6]\tvalid_0's l1: 0.260628\tvalid_0's l2: 0.098025\n",
      "[7]\tvalid_0's l1: 0.259423\tvalid_0's l2: 0.0979203\n",
      "[8]\tvalid_0's l1: 0.258393\tvalid_0's l2: 0.0984661\n",
      "[9]\tvalid_0's l1: 0.257336\tvalid_0's l2: 0.0992061\n",
      "[10]\tvalid_0's l1: 0.257095\tvalid_0's l2: 0.100901\n",
      "[11]\tvalid_0's l1: 0.256517\tvalid_0's l2: 0.102287\n",
      "[12]\tvalid_0's l1: 0.256163\tvalid_0's l2: 0.104127\n",
      "[13]\tvalid_0's l1: 0.256139\tvalid_0's l2: 0.10649\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.259423\tvalid_0's l2: 0.0979203\n",
      "[1]\tvalid_0's l1: 0.281385\tvalid_0's l2: 0.111544\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27458\tvalid_0's l2: 0.106494\n",
      "[3]\tvalid_0's l1: 0.269544\tvalid_0's l2: 0.10288\n",
      "[4]\tvalid_0's l1: 0.265717\tvalid_0's l2: 0.100382\n",
      "[5]\tvalid_0's l1: 0.262751\tvalid_0's l2: 0.098809\n",
      "[6]\tvalid_0's l1: 0.260519\tvalid_0's l2: 0.0977139\n",
      "[7]\tvalid_0's l1: 0.258521\tvalid_0's l2: 0.0974214\n",
      "[8]\tvalid_0's l1: 0.257247\tvalid_0's l2: 0.0977947\n",
      "[9]\tvalid_0's l1: 0.256744\tvalid_0's l2: 0.0989171\n",
      "[10]\tvalid_0's l1: 0.256154\tvalid_0's l2: 0.100164\n",
      "[11]\tvalid_0's l1: 0.256038\tvalid_0's l2: 0.101961\n",
      "[12]\tvalid_0's l1: 0.256207\tvalid_0's l2: 0.104375\n",
      "[13]\tvalid_0's l1: 0.256148\tvalid_0's l2: 0.106509\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.258521\tvalid_0's l2: 0.0974214\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.28235\tvalid_0's l2: 0.106335\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.268861\tvalid_0's l2: 0.0966252\n",
      "[3]\tvalid_0's l1: 0.256397\tvalid_0's l2: 0.0879825\n",
      "[4]\tvalid_0's l1: 0.244448\tvalid_0's l2: 0.0801429\n",
      "[5]\tvalid_0's l1: 0.233351\tvalid_0's l2: 0.0731236\n",
      "[6]\tvalid_0's l1: 0.222901\tvalid_0's l2: 0.066824\n",
      "[7]\tvalid_0's l1: 0.21363\tvalid_0's l2: 0.061487\n",
      "[8]\tvalid_0's l1: 0.204122\tvalid_0's l2: 0.0562772\n",
      "[9]\tvalid_0's l1: 0.195184\tvalid_0's l2: 0.0516123\n",
      "[10]\tvalid_0's l1: 0.186807\tvalid_0's l2: 0.0474237\n",
      "[11]\tvalid_0's l1: 0.179011\tvalid_0's l2: 0.0437318\n",
      "[12]\tvalid_0's l1: 0.1715\tvalid_0's l2: 0.0403251\n",
      "[13]\tvalid_0's l1: 0.1645\tvalid_0's l2: 0.0372847\n",
      "[14]\tvalid_0's l1: 0.157998\tvalid_0's l2: 0.0345879\n",
      "[15]\tvalid_0's l1: 0.151904\tvalid_0's l2: 0.0321769\n",
      "[16]\tvalid_0's l1: 0.146318\tvalid_0's l2: 0.0300301\n",
      "[17]\tvalid_0's l1: 0.141427\tvalid_0's l2: 0.0282034\n",
      "[18]\tvalid_0's l1: 0.136617\tvalid_0's l2: 0.0264744\n",
      "[19]\tvalid_0's l1: 0.132086\tvalid_0's l2: 0.0249065\n",
      "[20]\tvalid_0's l1: 0.127921\tvalid_0's l2: 0.0235078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.127921\tvalid_0's l2: 0.0235078\n",
      "[1]\tvalid_0's l1: 0.282285\tvalid_0's l2: 0.106273\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.268964\tvalid_0's l2: 0.0966021\n",
      "[3]\tvalid_0's l1: 0.256425\tvalid_0's l2: 0.0879253\n",
      "[4]\tvalid_0's l1: 0.244463\tvalid_0's l2: 0.0800873\n",
      "[5]\tvalid_0's l1: 0.233404\tvalid_0's l2: 0.0731229\n",
      "[6]\tvalid_0's l1: 0.222819\tvalid_0's l2: 0.0667532\n",
      "[7]\tvalid_0's l1: 0.212853\tvalid_0's l2: 0.0610709\n",
      "[8]\tvalid_0's l1: 0.203549\tvalid_0's l2: 0.0559575\n",
      "[9]\tvalid_0's l1: 0.195259\tvalid_0's l2: 0.0515878\n",
      "[10]\tvalid_0's l1: 0.186907\tvalid_0's l2: 0.0474338\n",
      "[11]\tvalid_0's l1: 0.179024\tvalid_0's l2: 0.0437144\n",
      "[12]\tvalid_0's l1: 0.171522\tvalid_0's l2: 0.0403053\n",
      "[13]\tvalid_0's l1: 0.164636\tvalid_0's l2: 0.0372808\n",
      "[14]\tvalid_0's l1: 0.158142\tvalid_0's l2: 0.0345799\n",
      "[15]\tvalid_0's l1: 0.152038\tvalid_0's l2: 0.0321536\n",
      "[16]\tvalid_0's l1: 0.146413\tvalid_0's l2: 0.0300098\n",
      "[17]\tvalid_0's l1: 0.141092\tvalid_0's l2: 0.0280764\n",
      "[18]\tvalid_0's l1: 0.13617\tvalid_0's l2: 0.0263454\n",
      "[19]\tvalid_0's l1: 0.132091\tvalid_0's l2: 0.0249338\n",
      "[20]\tvalid_0's l1: 0.12799\tvalid_0's l2: 0.0235645\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.12799\tvalid_0's l2: 0.0235645\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.279314\tvalid_0's l2: 0.105271\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267296\tvalid_0's l2: 0.0964699\n",
      "[3]\tvalid_0's l1: 0.255837\tvalid_0's l2: 0.088469\n",
      "[4]\tvalid_0's l1: 0.245261\tvalid_0's l2: 0.0814041\n",
      "[5]\tvalid_0's l1: 0.235433\tvalid_0's l2: 0.0752233\n",
      "[6]\tvalid_0's l1: 0.226176\tvalid_0's l2: 0.0695847\n",
      "[7]\tvalid_0's l1: 0.218701\tvalid_0's l2: 0.0652842\n",
      "[8]\tvalid_0's l1: 0.210905\tvalid_0's l2: 0.0609225\n",
      "[9]\tvalid_0's l1: 0.203771\tvalid_0's l2: 0.0569894\n",
      "[10]\tvalid_0's l1: 0.196935\tvalid_0's l2: 0.0534466\n",
      "[11]\tvalid_0's l1: 0.190763\tvalid_0's l2: 0.0503637\n",
      "[12]\tvalid_0's l1: 0.185051\tvalid_0's l2: 0.0476234\n",
      "[13]\tvalid_0's l1: 0.179902\tvalid_0's l2: 0.0452546\n",
      "[14]\tvalid_0's l1: 0.175065\tvalid_0's l2: 0.0430954\n",
      "[15]\tvalid_0's l1: 0.170647\tvalid_0's l2: 0.0411926\n",
      "[16]\tvalid_0's l1: 0.166514\tvalid_0's l2: 0.0395164\n",
      "[17]\tvalid_0's l1: 0.16381\tvalid_0's l2: 0.0384354\n",
      "[18]\tvalid_0's l1: 0.160327\tvalid_0's l2: 0.0371005\n",
      "[19]\tvalid_0's l1: 0.157104\tvalid_0's l2: 0.0359728\n",
      "[20]\tvalid_0's l1: 0.15408\tvalid_0's l2: 0.0348721\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.15408\tvalid_0's l2: 0.0348721\n",
      "[1]\tvalid_0's l1: 0.279048\tvalid_0's l2: 0.105106\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.266826\tvalid_0's l2: 0.0962476\n",
      "[3]\tvalid_0's l1: 0.255297\tvalid_0's l2: 0.0882336\n",
      "[4]\tvalid_0's l1: 0.244728\tvalid_0's l2: 0.0811981\n",
      "[5]\tvalid_0's l1: 0.234807\tvalid_0's l2: 0.074857\n",
      "[6]\tvalid_0's l1: 0.225615\tvalid_0's l2: 0.0693457\n",
      "[7]\tvalid_0's l1: 0.216802\tvalid_0's l2: 0.0642803\n",
      "[8]\tvalid_0's l1: 0.209031\tvalid_0's l2: 0.0599054\n",
      "[9]\tvalid_0's l1: 0.203019\tvalid_0's l2: 0.0566185\n",
      "[10]\tvalid_0's l1: 0.196358\tvalid_0's l2: 0.0531136\n",
      "[11]\tvalid_0's l1: 0.190484\tvalid_0's l2: 0.0501375\n",
      "[12]\tvalid_0's l1: 0.18502\tvalid_0's l2: 0.0475413\n",
      "[13]\tvalid_0's l1: 0.180046\tvalid_0's l2: 0.0452608\n",
      "[14]\tvalid_0's l1: 0.175467\tvalid_0's l2: 0.0432047\n",
      "[15]\tvalid_0's l1: 0.171206\tvalid_0's l2: 0.0413792\n",
      "[16]\tvalid_0's l1: 0.167222\tvalid_0's l2: 0.0397084\n",
      "[17]\tvalid_0's l1: 0.163476\tvalid_0's l2: 0.038243\n",
      "[18]\tvalid_0's l1: 0.16007\tvalid_0's l2: 0.0369242\n",
      "[19]\tvalid_0's l1: 0.157872\tvalid_0's l2: 0.0361975\n",
      "[20]\tvalid_0's l1: 0.155019\tvalid_0's l2: 0.0352096\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.155019\tvalid_0's l2: 0.0352096\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.276051\tvalid_0's l2: 0.104113\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265441\tvalid_0's l2: 0.09648\n",
      "[3]\tvalid_0's l1: 0.255547\tvalid_0's l2: 0.0895576\n",
      "[4]\tvalid_0's l1: 0.246969\tvalid_0's l2: 0.0838434\n",
      "[5]\tvalid_0's l1: 0.239014\tvalid_0's l2: 0.078639\n",
      "[6]\tvalid_0's l1: 0.231922\tvalid_0's l2: 0.0741559\n",
      "[7]\tvalid_0's l1: 0.226127\tvalid_0's l2: 0.0706941\n",
      "[8]\tvalid_0's l1: 0.220363\tvalid_0's l2: 0.0673972\n",
      "[9]\tvalid_0's l1: 0.215419\tvalid_0's l2: 0.0645717\n",
      "[10]\tvalid_0's l1: 0.210945\tvalid_0's l2: 0.0621735\n",
      "[11]\tvalid_0's l1: 0.206506\tvalid_0's l2: 0.0599668\n",
      "[12]\tvalid_0's l1: 0.202572\tvalid_0's l2: 0.0581569\n",
      "[13]\tvalid_0's l1: 0.199189\tvalid_0's l2: 0.0566948\n",
      "[14]\tvalid_0's l1: 0.195986\tvalid_0's l2: 0.0553803\n",
      "[15]\tvalid_0's l1: 0.193091\tvalid_0's l2: 0.0543385\n",
      "[16]\tvalid_0's l1: 0.190639\tvalid_0's l2: 0.0535618\n",
      "[17]\tvalid_0's l1: 0.188778\tvalid_0's l2: 0.0532112\n",
      "[18]\tvalid_0's l1: 0.187093\tvalid_0's l2: 0.0529409\n",
      "[19]\tvalid_0's l1: 0.185293\tvalid_0's l2: 0.0526087\n",
      "[20]\tvalid_0's l1: 0.184061\tvalid_0's l2: 0.0526331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.184061\tvalid_0's l2: 0.0526331\n",
      "[1]\tvalid_0's l1: 0.27636\tvalid_0's l2: 0.104374\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265908\tvalid_0's l2: 0.0969042\n",
      "[3]\tvalid_0's l1: 0.256178\tvalid_0's l2: 0.0901861\n",
      "[4]\tvalid_0's l1: 0.247691\tvalid_0's l2: 0.0844959\n",
      "[5]\tvalid_0's l1: 0.23943\tvalid_0's l2: 0.0790831\n",
      "[6]\tvalid_0's l1: 0.232234\tvalid_0's l2: 0.0745667\n",
      "[7]\tvalid_0's l1: 0.225653\tvalid_0's l2: 0.0707244\n",
      "[8]\tvalid_0's l1: 0.219951\tvalid_0's l2: 0.0673828\n",
      "[9]\tvalid_0's l1: 0.214999\tvalid_0's l2: 0.0648103\n",
      "[10]\tvalid_0's l1: 0.210583\tvalid_0's l2: 0.0624025\n",
      "[11]\tvalid_0's l1: 0.206646\tvalid_0's l2: 0.0603899\n",
      "[12]\tvalid_0's l1: 0.203143\tvalid_0's l2: 0.0588529\n",
      "[13]\tvalid_0's l1: 0.200037\tvalid_0's l2: 0.0575972\n",
      "[14]\tvalid_0's l1: 0.197531\tvalid_0's l2: 0.0567522\n",
      "[15]\tvalid_0's l1: 0.19498\tvalid_0's l2: 0.0558471\n",
      "[16]\tvalid_0's l1: 0.192457\tvalid_0's l2: 0.055035\n",
      "[17]\tvalid_0's l1: 0.190295\tvalid_0's l2: 0.0544728\n",
      "[18]\tvalid_0's l1: 0.188463\tvalid_0's l2: 0.054134\n",
      "[19]\tvalid_0's l1: 0.187001\tvalid_0's l2: 0.0539618\n",
      "[20]\tvalid_0's l1: 0.185437\tvalid_0's l2: 0.053889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.185437\tvalid_0's l2: 0.053889\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.271792\tvalid_0's l2: 0.101897\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.261436\tvalid_0's l2: 0.0945204\n",
      "[3]\tvalid_0's l1: 0.252669\tvalid_0's l2: 0.0883785\n",
      "[4]\tvalid_0's l1: 0.244716\tvalid_0's l2: 0.0830711\n",
      "[5]\tvalid_0's l1: 0.237866\tvalid_0's l2: 0.078738\n",
      "[6]\tvalid_0's l1: 0.231959\tvalid_0's l2: 0.0751806\n",
      "[7]\tvalid_0's l1: 0.227324\tvalid_0's l2: 0.0724602\n",
      "[8]\tvalid_0's l1: 0.222922\tvalid_0's l2: 0.070115\n",
      "[9]\tvalid_0's l1: 0.219379\tvalid_0's l2: 0.0682723\n",
      "[10]\tvalid_0's l1: 0.21648\tvalid_0's l2: 0.0668936\n",
      "[11]\tvalid_0's l1: 0.213422\tvalid_0's l2: 0.0655686\n",
      "[12]\tvalid_0's l1: 0.210883\tvalid_0's l2: 0.0645794\n",
      "[13]\tvalid_0's l1: 0.208695\tvalid_0's l2: 0.0638662\n",
      "[14]\tvalid_0's l1: 0.20681\tvalid_0's l2: 0.0635104\n",
      "[15]\tvalid_0's l1: 0.205194\tvalid_0's l2: 0.0631698\n",
      "[16]\tvalid_0's l1: 0.204027\tvalid_0's l2: 0.0633686\n",
      "[17]\tvalid_0's l1: 0.203453\tvalid_0's l2: 0.0640219\n",
      "[18]\tvalid_0's l1: 0.202623\tvalid_0's l2: 0.0645878\n",
      "[19]\tvalid_0's l1: 0.202125\tvalid_0's l2: 0.0653926\n",
      "[20]\tvalid_0's l1: 0.20168\tvalid_0's l2: 0.0662381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.20168\tvalid_0's l2: 0.0662381\n",
      "[1]\tvalid_0's l1: 0.271553\tvalid_0's l2: 0.101919\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.261444\tvalid_0's l2: 0.094733\n",
      "[3]\tvalid_0's l1: 0.252506\tvalid_0's l2: 0.088621\n",
      "[4]\tvalid_0's l1: 0.244823\tvalid_0's l2: 0.0835814\n",
      "[5]\tvalid_0's l1: 0.238078\tvalid_0's l2: 0.0792443\n",
      "[6]\tvalid_0's l1: 0.232338\tvalid_0's l2: 0.0756101\n",
      "[7]\tvalid_0's l1: 0.227111\tvalid_0's l2: 0.0724557\n",
      "[8]\tvalid_0's l1: 0.222811\tvalid_0's l2: 0.0699844\n",
      "[9]\tvalid_0's l1: 0.220053\tvalid_0's l2: 0.0685203\n",
      "[10]\tvalid_0's l1: 0.217226\tvalid_0's l2: 0.0672161\n",
      "[11]\tvalid_0's l1: 0.214398\tvalid_0's l2: 0.0659974\n",
      "[12]\tvalid_0's l1: 0.212224\tvalid_0's l2: 0.0652765\n",
      "[13]\tvalid_0's l1: 0.210158\tvalid_0's l2: 0.0646049\n",
      "[14]\tvalid_0's l1: 0.208906\tvalid_0's l2: 0.0645223\n",
      "[15]\tvalid_0's l1: 0.207732\tvalid_0's l2: 0.0646146\n",
      "[16]\tvalid_0's l1: 0.206418\tvalid_0's l2: 0.0645906\n",
      "[17]\tvalid_0's l1: 0.20533\tvalid_0's l2: 0.0649119\n",
      "[18]\tvalid_0's l1: 0.204766\tvalid_0's l2: 0.065439\n",
      "[19]\tvalid_0's l1: 0.204965\tvalid_0's l2: 0.0668465\n",
      "[20]\tvalid_0's l1: 0.204596\tvalid_0's l2: 0.0677345\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.204596\tvalid_0's l2: 0.0677345\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.269199\tvalid_0's l2: 0.101025\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260055\tvalid_0's l2: 0.0947383\n",
      "[3]\tvalid_0's l1: 0.252461\tvalid_0's l2: 0.0896761\n",
      "[4]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.0855705\n",
      "[5]\tvalid_0's l1: 0.241743\tvalid_0's l2: 0.0821948\n",
      "[6]\tvalid_0's l1: 0.237963\tvalid_0's l2: 0.0796513\n",
      "[7]\tvalid_0's l1: 0.235397\tvalid_0's l2: 0.0780643\n",
      "[8]\tvalid_0's l1: 0.232833\tvalid_0's l2: 0.0767813\n",
      "[9]\tvalid_0's l1: 0.230629\tvalid_0's l2: 0.0760909\n",
      "[10]\tvalid_0's l1: 0.228993\tvalid_0's l2: 0.0759022\n",
      "[11]\tvalid_0's l1: 0.227348\tvalid_0's l2: 0.0758192\n",
      "[12]\tvalid_0's l1: 0.226034\tvalid_0's l2: 0.0760462\n",
      "[13]\tvalid_0's l1: 0.22519\tvalid_0's l2: 0.0768668\n",
      "[14]\tvalid_0's l1: 0.224472\tvalid_0's l2: 0.0777934\n",
      "[15]\tvalid_0's l1: 0.22395\tvalid_0's l2: 0.0789986\n",
      "[16]\tvalid_0's l1: 0.223361\tvalid_0's l2: 0.0802061\n",
      "[17]\tvalid_0's l1: 0.223612\tvalid_0's l2: 0.0820581\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.227348\tvalid_0's l2: 0.0758192\n",
      "[1]\tvalid_0's l1: 0.269303\tvalid_0's l2: 0.1013\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260236\tvalid_0's l2: 0.0952783\n",
      "[3]\tvalid_0's l1: 0.253446\tvalid_0's l2: 0.0905329\n",
      "[4]\tvalid_0's l1: 0.248192\tvalid_0's l2: 0.0868075\n",
      "[5]\tvalid_0's l1: 0.243569\tvalid_0's l2: 0.0835701\n",
      "[6]\tvalid_0's l1: 0.240073\tvalid_0's l2: 0.0812881\n",
      "[7]\tvalid_0's l1: 0.236392\tvalid_0's l2: 0.0792681\n",
      "[8]\tvalid_0's l1: 0.234061\tvalid_0's l2: 0.0780553\n",
      "[9]\tvalid_0's l1: 0.232621\tvalid_0's l2: 0.0777238\n",
      "[10]\tvalid_0's l1: 0.230932\tvalid_0's l2: 0.0775267\n",
      "[11]\tvalid_0's l1: 0.229942\tvalid_0's l2: 0.0778486\n",
      "[12]\tvalid_0's l1: 0.228991\tvalid_0's l2: 0.0784158\n",
      "[13]\tvalid_0's l1: 0.228586\tvalid_0's l2: 0.0794642\n",
      "[14]\tvalid_0's l1: 0.228289\tvalid_0's l2: 0.080562\n",
      "[15]\tvalid_0's l1: 0.228077\tvalid_0's l2: 0.0822444\n",
      "[16]\tvalid_0's l1: 0.227851\tvalid_0's l2: 0.0835712\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.230932\tvalid_0's l2: 0.0775267\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.268071\tvalid_0's l2: 0.100228\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260835\tvalid_0's l2: 0.0951111\n",
      "[3]\tvalid_0's l1: 0.255158\tvalid_0's l2: 0.0911672\n",
      "[4]\tvalid_0's l1: 0.251363\tvalid_0's l2: 0.0883783\n",
      "[5]\tvalid_0's l1: 0.248459\tvalid_0's l2: 0.0864471\n",
      "[6]\tvalid_0's l1: 0.246301\tvalid_0's l2: 0.0852823\n",
      "[7]\tvalid_0's l1: 0.244797\tvalid_0's l2: 0.0848116\n",
      "[8]\tvalid_0's l1: 0.243546\tvalid_0's l2: 0.0850199\n",
      "[9]\tvalid_0's l1: 0.242615\tvalid_0's l2: 0.0857066\n",
      "[10]\tvalid_0's l1: 0.242274\tvalid_0's l2: 0.0870817\n",
      "[11]\tvalid_0's l1: 0.241543\tvalid_0's l2: 0.0881003\n",
      "[12]\tvalid_0's l1: 0.24098\tvalid_0's l2: 0.0893867\n",
      "[13]\tvalid_0's l1: 0.241003\tvalid_0's l2: 0.0913785\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.244797\tvalid_0's l2: 0.0848116\n",
      "[1]\tvalid_0's l1: 0.267906\tvalid_0's l2: 0.100206\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260902\tvalid_0's l2: 0.0951968\n",
      "[3]\tvalid_0's l1: 0.255668\tvalid_0's l2: 0.0914776\n",
      "[4]\tvalid_0's l1: 0.252078\tvalid_0's l2: 0.0887666\n",
      "[5]\tvalid_0's l1: 0.249592\tvalid_0's l2: 0.0872849\n",
      "[6]\tvalid_0's l1: 0.247675\tvalid_0's l2: 0.0863093\n",
      "[7]\tvalid_0's l1: 0.245764\tvalid_0's l2: 0.0856432\n",
      "[8]\tvalid_0's l1: 0.24508\tvalid_0's l2: 0.0860232\n",
      "[9]\tvalid_0's l1: 0.245308\tvalid_0's l2: 0.0874171\n",
      "[10]\tvalid_0's l1: 0.245187\tvalid_0's l2: 0.0888732\n",
      "[11]\tvalid_0's l1: 0.245206\tvalid_0's l2: 0.0907991\n",
      "[12]\tvalid_0's l1: 0.245497\tvalid_0's l2: 0.0932626\n",
      "[13]\tvalid_0's l1: 0.245332\tvalid_0's l2: 0.0952396\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.245764\tvalid_0's l2: 0.0856432\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273515\tvalid_0's l2: 0.100029\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.260147\tvalid_0's l2: 0.0904881\n",
      "[3]\tvalid_0's l1: 0.247561\tvalid_0's l2: 0.0819568\n",
      "[4]\tvalid_0's l1: 0.235636\tvalid_0's l2: 0.074271\n",
      "[5]\tvalid_0's l1: 0.224397\tvalid_0's l2: 0.0673593\n",
      "[6]\tvalid_0's l1: 0.213699\tvalid_0's l2: 0.0611097\n",
      "[7]\tvalid_0's l1: 0.203991\tvalid_0's l2: 0.0557182\n",
      "[8]\tvalid_0's l1: 0.194553\tvalid_0's l2: 0.0507126\n",
      "[9]\tvalid_0's l1: 0.185557\tvalid_0's l2: 0.046144\n",
      "[10]\tvalid_0's l1: 0.177198\tvalid_0's l2: 0.042106\n",
      "[11]\tvalid_0's l1: 0.169249\tvalid_0's l2: 0.0384473\n",
      "[12]\tvalid_0's l1: 0.161792\tvalid_0's l2: 0.0351665\n",
      "[13]\tvalid_0's l1: 0.154689\tvalid_0's l2: 0.032202\n",
      "[14]\tvalid_0's l1: 0.148097\tvalid_0's l2: 0.0295824\n",
      "[15]\tvalid_0's l1: 0.141925\tvalid_0's l2: 0.0272467\n",
      "[16]\tvalid_0's l1: 0.136178\tvalid_0's l2: 0.0251524\n",
      "[17]\tvalid_0's l1: 0.130928\tvalid_0's l2: 0.0233483\n",
      "[18]\tvalid_0's l1: 0.125831\tvalid_0's l2: 0.0216351\n",
      "[19]\tvalid_0's l1: 0.121197\tvalid_0's l2: 0.0201256\n",
      "[20]\tvalid_0's l1: 0.116829\tvalid_0's l2: 0.0187499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.116829\tvalid_0's l2: 0.0187499\n",
      "[1]\tvalid_0's l1: 0.273509\tvalid_0's l2: 0.100073\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.26014\tvalid_0's l2: 0.0905952\n",
      "[3]\tvalid_0's l1: 0.247516\tvalid_0's l2: 0.082051\n",
      "[4]\tvalid_0's l1: 0.235598\tvalid_0's l2: 0.0743984\n",
      "[5]\tvalid_0's l1: 0.224242\tvalid_0's l2: 0.0674539\n",
      "[6]\tvalid_0's l1: 0.213583\tvalid_0's l2: 0.0612134\n",
      "[7]\tvalid_0's l1: 0.203348\tvalid_0's l2: 0.0555144\n",
      "[8]\tvalid_0's l1: 0.193846\tvalid_0's l2: 0.0504653\n",
      "[9]\tvalid_0's l1: 0.185068\tvalid_0's l2: 0.0460898\n",
      "[10]\tvalid_0's l1: 0.176541\tvalid_0's l2: 0.0419768\n",
      "[11]\tvalid_0's l1: 0.168611\tvalid_0's l2: 0.0383081\n",
      "[12]\tvalid_0's l1: 0.161243\tvalid_0's l2: 0.0350627\n",
      "[13]\tvalid_0's l1: 0.15425\tvalid_0's l2: 0.032119\n",
      "[14]\tvalid_0's l1: 0.14769\tvalid_0's l2: 0.0295086\n",
      "[15]\tvalid_0's l1: 0.141602\tvalid_0's l2: 0.0271796\n",
      "[16]\tvalid_0's l1: 0.135768\tvalid_0's l2: 0.0250658\n",
      "[17]\tvalid_0's l1: 0.13036\tvalid_0's l2: 0.0231756\n",
      "[18]\tvalid_0's l1: 0.125331\tvalid_0's l2: 0.0214841\n",
      "[19]\tvalid_0's l1: 0.120888\tvalid_0's l2: 0.0200655\n",
      "[20]\tvalid_0's l1: 0.116507\tvalid_0's l2: 0.0186856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.116507\tvalid_0's l2: 0.0186856\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.269663\tvalid_0's l2: 0.0983996\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256701\tvalid_0's l2: 0.0892713\n",
      "[3]\tvalid_0's l1: 0.244721\tvalid_0's l2: 0.0812725\n",
      "[4]\tvalid_0's l1: 0.23332\tvalid_0's l2: 0.0739634\n",
      "[5]\tvalid_0's l1: 0.222897\tvalid_0's l2: 0.0675839\n",
      "[6]\tvalid_0's l1: 0.213064\tvalid_0's l2: 0.0618614\n",
      "[7]\tvalid_0's l1: 0.204425\tvalid_0's l2: 0.05709\n",
      "[8]\tvalid_0's l1: 0.195981\tvalid_0's l2: 0.052604\n",
      "[9]\tvalid_0's l1: 0.188115\tvalid_0's l2: 0.0485199\n",
      "[10]\tvalid_0's l1: 0.180947\tvalid_0's l2: 0.0449675\n",
      "[11]\tvalid_0's l1: 0.17417\tvalid_0's l2: 0.0417402\n",
      "[12]\tvalid_0's l1: 0.167968\tvalid_0's l2: 0.0388902\n",
      "[13]\tvalid_0's l1: 0.162409\tvalid_0's l2: 0.0363897\n",
      "[14]\tvalid_0's l1: 0.157168\tvalid_0's l2: 0.0341182\n",
      "[15]\tvalid_0's l1: 0.152338\tvalid_0's l2: 0.0321686\n",
      "[16]\tvalid_0's l1: 0.147807\tvalid_0's l2: 0.0304243\n",
      "[17]\tvalid_0's l1: 0.144307\tvalid_0's l2: 0.0291388\n",
      "[18]\tvalid_0's l1: 0.140628\tvalid_0's l2: 0.0277918\n",
      "[19]\tvalid_0's l1: 0.137178\tvalid_0's l2: 0.0265826\n",
      "[20]\tvalid_0's l1: 0.134142\tvalid_0's l2: 0.0255674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.134142\tvalid_0's l2: 0.0255674\n",
      "[1]\tvalid_0's l1: 0.269507\tvalid_0's l2: 0.0983133\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256586\tvalid_0's l2: 0.0892825\n",
      "[3]\tvalid_0's l1: 0.244526\tvalid_0's l2: 0.0812249\n",
      "[4]\tvalid_0's l1: 0.233345\tvalid_0's l2: 0.074071\n",
      "[5]\tvalid_0's l1: 0.22285\tvalid_0's l2: 0.0676673\n",
      "[6]\tvalid_0's l1: 0.212968\tvalid_0's l2: 0.0619438\n",
      "[7]\tvalid_0's l1: 0.203643\tvalid_0's l2: 0.0567767\n",
      "[8]\tvalid_0's l1: 0.195123\tvalid_0's l2: 0.0522365\n",
      "[9]\tvalid_0's l1: 0.18795\tvalid_0's l2: 0.0485976\n",
      "[10]\tvalid_0's l1: 0.180802\tvalid_0's l2: 0.044997\n",
      "[11]\tvalid_0's l1: 0.174145\tvalid_0's l2: 0.0418178\n",
      "[12]\tvalid_0's l1: 0.167956\tvalid_0's l2: 0.0389576\n",
      "[13]\tvalid_0's l1: 0.162354\tvalid_0's l2: 0.0364477\n",
      "[14]\tvalid_0's l1: 0.157191\tvalid_0's l2: 0.0342676\n",
      "[15]\tvalid_0's l1: 0.15249\tvalid_0's l2: 0.0323113\n",
      "[16]\tvalid_0's l1: 0.148151\tvalid_0's l2: 0.0305567\n",
      "[17]\tvalid_0's l1: 0.144268\tvalid_0's l2: 0.0290556\n",
      "[18]\tvalid_0's l1: 0.140559\tvalid_0's l2: 0.0276847\n",
      "[19]\tvalid_0's l1: 0.137834\tvalid_0's l2: 0.0267655\n",
      "[20]\tvalid_0's l1: 0.134734\tvalid_0's l2: 0.0257556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.134734\tvalid_0's l2: 0.0257556\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265989\tvalid_0's l2: 0.0968033\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254368\tvalid_0's l2: 0.0886517\n",
      "[3]\tvalid_0's l1: 0.243351\tvalid_0's l2: 0.081317\n",
      "[4]\tvalid_0's l1: 0.233436\tvalid_0's l2: 0.075037\n",
      "[5]\tvalid_0's l1: 0.224276\tvalid_0's l2: 0.0694212\n",
      "[6]\tvalid_0's l1: 0.215673\tvalid_0's l2: 0.0644472\n",
      "[7]\tvalid_0's l1: 0.2088\tvalid_0's l2: 0.0606942\n",
      "[8]\tvalid_0's l1: 0.201945\tvalid_0's l2: 0.05697\n",
      "[9]\tvalid_0's l1: 0.195874\tvalid_0's l2: 0.0537805\n",
      "[10]\tvalid_0's l1: 0.190326\tvalid_0's l2: 0.0509349\n",
      "[11]\tvalid_0's l1: 0.185128\tvalid_0's l2: 0.0483407\n",
      "[12]\tvalid_0's l1: 0.180486\tvalid_0's l2: 0.0461039\n",
      "[13]\tvalid_0's l1: 0.176609\tvalid_0's l2: 0.0443506\n",
      "[14]\tvalid_0's l1: 0.172808\tvalid_0's l2: 0.0426892\n",
      "[15]\tvalid_0's l1: 0.169527\tvalid_0's l2: 0.0413913\n",
      "[16]\tvalid_0's l1: 0.166504\tvalid_0's l2: 0.0402492\n",
      "[17]\tvalid_0's l1: 0.164812\tvalid_0's l2: 0.0397987\n",
      "[18]\tvalid_0's l1: 0.162238\tvalid_0's l2: 0.0390585\n",
      "[19]\tvalid_0's l1: 0.159879\tvalid_0's l2: 0.038402\n",
      "[20]\tvalid_0's l1: 0.157884\tvalid_0's l2: 0.0379305\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.157884\tvalid_0's l2: 0.0379305\n",
      "[1]\tvalid_0's l1: 0.265824\tvalid_0's l2: 0.0966728\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254137\tvalid_0's l2: 0.088552\n",
      "[3]\tvalid_0's l1: 0.243052\tvalid_0's l2: 0.081255\n",
      "[4]\tvalid_0's l1: 0.233071\tvalid_0's l2: 0.0750609\n",
      "[5]\tvalid_0's l1: 0.223952\tvalid_0's l2: 0.0694815\n",
      "[6]\tvalid_0's l1: 0.215272\tvalid_0's l2: 0.0645331\n",
      "[7]\tvalid_0's l1: 0.207431\tvalid_0's l2: 0.0601655\n",
      "[8]\tvalid_0's l1: 0.200674\tvalid_0's l2: 0.0565141\n",
      "[9]\tvalid_0's l1: 0.195639\tvalid_0's l2: 0.0538401\n",
      "[10]\tvalid_0's l1: 0.190434\tvalid_0's l2: 0.0511354\n",
      "[11]\tvalid_0's l1: 0.185821\tvalid_0's l2: 0.0487413\n",
      "[12]\tvalid_0's l1: 0.18172\tvalid_0's l2: 0.0467137\n",
      "[13]\tvalid_0's l1: 0.177976\tvalid_0's l2: 0.0450146\n",
      "[14]\tvalid_0's l1: 0.17442\tvalid_0's l2: 0.0434929\n",
      "[15]\tvalid_0's l1: 0.171379\tvalid_0's l2: 0.04227\n",
      "[16]\tvalid_0's l1: 0.168427\tvalid_0's l2: 0.0411419\n",
      "[17]\tvalid_0's l1: 0.165802\tvalid_0's l2: 0.040297\n",
      "[18]\tvalid_0's l1: 0.163444\tvalid_0's l2: 0.0395944\n",
      "[19]\tvalid_0's l1: 0.162046\tvalid_0's l2: 0.0394872\n",
      "[20]\tvalid_0's l1: 0.159997\tvalid_0's l2: 0.0389566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.159997\tvalid_0's l2: 0.0389566\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.262275\tvalid_0's l2: 0.095075\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251927\tvalid_0's l2: 0.0879186\n",
      "[3]\tvalid_0's l1: 0.242532\tvalid_0's l2: 0.0817401\n",
      "[4]\tvalid_0's l1: 0.2343\tvalid_0's l2: 0.0765531\n",
      "[5]\tvalid_0's l1: 0.227692\tvalid_0's l2: 0.0723253\n",
      "[6]\tvalid_0's l1: 0.221883\tvalid_0's l2: 0.0688002\n",
      "[7]\tvalid_0's l1: 0.217365\tvalid_0's l2: 0.0661839\n",
      "[8]\tvalid_0's l1: 0.212998\tvalid_0's l2: 0.0636928\n",
      "[9]\tvalid_0's l1: 0.209462\tvalid_0's l2: 0.0617608\n",
      "[10]\tvalid_0's l1: 0.206313\tvalid_0's l2: 0.0602149\n",
      "[11]\tvalid_0's l1: 0.203304\tvalid_0's l2: 0.0589035\n",
      "[12]\tvalid_0's l1: 0.200509\tvalid_0's l2: 0.0579444\n",
      "[13]\tvalid_0's l1: 0.198278\tvalid_0's l2: 0.0572476\n",
      "[14]\tvalid_0's l1: 0.196141\tvalid_0's l2: 0.056651\n",
      "[15]\tvalid_0's l1: 0.194258\tvalid_0's l2: 0.0563203\n",
      "[16]\tvalid_0's l1: 0.192578\tvalid_0's l2: 0.0562396\n",
      "[17]\tvalid_0's l1: 0.192017\tvalid_0's l2: 0.0568549\n",
      "[18]\tvalid_0's l1: 0.190961\tvalid_0's l2: 0.0570903\n",
      "[19]\tvalid_0's l1: 0.189948\tvalid_0's l2: 0.0575601\n",
      "[20]\tvalid_0's l1: 0.189255\tvalid_0's l2: 0.0581886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189255\tvalid_0's l2: 0.0581886\n",
      "[1]\tvalid_0's l1: 0.262192\tvalid_0's l2: 0.0950461\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251732\tvalid_0's l2: 0.087886\n",
      "[3]\tvalid_0's l1: 0.242468\tvalid_0's l2: 0.0818354\n",
      "[4]\tvalid_0's l1: 0.234785\tvalid_0's l2: 0.0768452\n",
      "[5]\tvalid_0's l1: 0.22778\tvalid_0's l2: 0.0724237\n",
      "[6]\tvalid_0's l1: 0.222222\tvalid_0's l2: 0.0689632\n",
      "[7]\tvalid_0's l1: 0.216979\tvalid_0's l2: 0.0658531\n",
      "[8]\tvalid_0's l1: 0.212919\tvalid_0's l2: 0.0633983\n",
      "[9]\tvalid_0's l1: 0.2103\tvalid_0's l2: 0.0619599\n",
      "[10]\tvalid_0's l1: 0.207164\tvalid_0's l2: 0.0603743\n",
      "[11]\tvalid_0's l1: 0.204479\tvalid_0's l2: 0.0592151\n",
      "[12]\tvalid_0's l1: 0.202216\tvalid_0's l2: 0.0583611\n",
      "[13]\tvalid_0's l1: 0.200495\tvalid_0's l2: 0.0580512\n",
      "[14]\tvalid_0's l1: 0.199162\tvalid_0's l2: 0.0581731\n",
      "[15]\tvalid_0's l1: 0.197577\tvalid_0's l2: 0.057977\n",
      "[16]\tvalid_0's l1: 0.196225\tvalid_0's l2: 0.0580737\n",
      "[17]\tvalid_0's l1: 0.195078\tvalid_0's l2: 0.0583598\n",
      "[18]\tvalid_0's l1: 0.19409\tvalid_0's l2: 0.0588268\n",
      "[19]\tvalid_0's l1: 0.193643\tvalid_0's l2: 0.0595452\n",
      "[20]\tvalid_0's l1: 0.193021\tvalid_0's l2: 0.0603414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.193021\tvalid_0's l2: 0.0603414\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.259057\tvalid_0's l2: 0.0935911\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.249615\tvalid_0's l2: 0.0872757\n",
      "[3]\tvalid_0's l1: 0.241707\tvalid_0's l2: 0.0821899\n",
      "[4]\tvalid_0's l1: 0.235676\tvalid_0's l2: 0.0781348\n",
      "[5]\tvalid_0's l1: 0.231446\tvalid_0's l2: 0.0751815\n",
      "[6]\tvalid_0's l1: 0.22808\tvalid_0's l2: 0.0729629\n",
      "[7]\tvalid_0's l1: 0.225705\tvalid_0's l2: 0.071619\n",
      "[8]\tvalid_0's l1: 0.223064\tvalid_0's l2: 0.0704577\n",
      "[9]\tvalid_0's l1: 0.221237\tvalid_0's l2: 0.0700622\n",
      "[10]\tvalid_0's l1: 0.219277\tvalid_0's l2: 0.0697912\n",
      "[11]\tvalid_0's l1: 0.217282\tvalid_0's l2: 0.0694661\n",
      "[12]\tvalid_0's l1: 0.215627\tvalid_0's l2: 0.0695672\n",
      "[13]\tvalid_0's l1: 0.214658\tvalid_0's l2: 0.0702863\n",
      "[14]\tvalid_0's l1: 0.21372\tvalid_0's l2: 0.0709396\n",
      "[15]\tvalid_0's l1: 0.21304\tvalid_0's l2: 0.0719316\n",
      "[16]\tvalid_0's l1: 0.212083\tvalid_0's l2: 0.0725901\n",
      "[17]\tvalid_0's l1: 0.212196\tvalid_0's l2: 0.0741386\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.217282\tvalid_0's l2: 0.0694661\n",
      "[1]\tvalid_0's l1: 0.258909\tvalid_0's l2: 0.0936123\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.249504\tvalid_0's l2: 0.0874263\n",
      "[3]\tvalid_0's l1: 0.241964\tvalid_0's l2: 0.0824306\n",
      "[4]\tvalid_0's l1: 0.236672\tvalid_0's l2: 0.0787361\n",
      "[5]\tvalid_0's l1: 0.23205\tvalid_0's l2: 0.0756158\n",
      "[6]\tvalid_0's l1: 0.228604\tvalid_0's l2: 0.0732896\n",
      "[7]\tvalid_0's l1: 0.224744\tvalid_0's l2: 0.0711983\n",
      "[8]\tvalid_0's l1: 0.222536\tvalid_0's l2: 0.0702225\n",
      "[9]\tvalid_0's l1: 0.221443\tvalid_0's l2: 0.0702109\n",
      "[10]\tvalid_0's l1: 0.219692\tvalid_0's l2: 0.0700121\n",
      "[11]\tvalid_0's l1: 0.218541\tvalid_0's l2: 0.0703365\n",
      "[12]\tvalid_0's l1: 0.21761\tvalid_0's l2: 0.0708586\n",
      "[13]\tvalid_0's l1: 0.216838\tvalid_0's l2: 0.0716324\n",
      "[14]\tvalid_0's l1: 0.216324\tvalid_0's l2: 0.0727652\n",
      "[15]\tvalid_0's l1: 0.21568\tvalid_0's l2: 0.0738643\n",
      "[16]\tvalid_0's l1: 0.21505\tvalid_0's l2: 0.0750221\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.219692\tvalid_0's l2: 0.0700121\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.258501\tvalid_0's l2: 0.0930071\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.251054\tvalid_0's l2: 0.0879611\n",
      "[3]\tvalid_0's l1: 0.245802\tvalid_0's l2: 0.0841836\n",
      "[4]\tvalid_0's l1: 0.241815\tvalid_0's l2: 0.0814183\n",
      "[5]\tvalid_0's l1: 0.238427\tvalid_0's l2: 0.0794182\n",
      "[6]\tvalid_0's l1: 0.236338\tvalid_0's l2: 0.0785063\n",
      "[7]\tvalid_0's l1: 0.235271\tvalid_0's l2: 0.0784335\n",
      "[8]\tvalid_0's l1: 0.233842\tvalid_0's l2: 0.0786098\n",
      "[9]\tvalid_0's l1: 0.233174\tvalid_0's l2: 0.0797606\n",
      "[10]\tvalid_0's l1: 0.232622\tvalid_0's l2: 0.081064\n",
      "[11]\tvalid_0's l1: 0.231805\tvalid_0's l2: 0.0821764\n",
      "[12]\tvalid_0's l1: 0.231318\tvalid_0's l2: 0.0837196\n",
      "[13]\tvalid_0's l1: 0.23119\tvalid_0's l2: 0.0856214\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.235271\tvalid_0's l2: 0.0784335\n",
      "[1]\tvalid_0's l1: 0.25823\tvalid_0's l2: 0.0930537\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.250514\tvalid_0's l2: 0.0878319\n",
      "[3]\tvalid_0's l1: 0.244964\tvalid_0's l2: 0.0840095\n",
      "[4]\tvalid_0's l1: 0.240914\tvalid_0's l2: 0.0813122\n",
      "[5]\tvalid_0's l1: 0.23838\tvalid_0's l2: 0.0798783\n",
      "[6]\tvalid_0's l1: 0.236592\tvalid_0's l2: 0.0790879\n",
      "[7]\tvalid_0's l1: 0.234565\tvalid_0's l2: 0.0786078\n",
      "[8]\tvalid_0's l1: 0.233454\tvalid_0's l2: 0.0789568\n",
      "[9]\tvalid_0's l1: 0.233729\tvalid_0's l2: 0.0805525\n",
      "[10]\tvalid_0's l1: 0.233197\tvalid_0's l2: 0.08189\n",
      "[11]\tvalid_0's l1: 0.232526\tvalid_0's l2: 0.0831646\n",
      "[12]\tvalid_0's l1: 0.231825\tvalid_0's l2: 0.0844827\n",
      "[13]\tvalid_0's l1: 0.232208\tvalid_0's l2: 0.0868176\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.234565\tvalid_0's l2: 0.0786078\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DF_0 [col 10],\n",
    "        # DF_wm1 [col 11], \n",
    "        # DF_wm2 [col 12],\n",
    "        # DF_wm3 [col 13],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        x_train_withoutCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_train_withCD = df_train_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        x_test_withoutCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_test_withCD = df_test_dist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # y: response (target) variable from DFma_1 to DFma_6 (col 19 -> col 14)\n",
    "        y_train = df_train_dist.iloc[:, [19 - j]]\n",
    "        y_test = df_test_dist.iloc[:, [19 - j]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_dist['DFma_' + str(j + 1)])\n",
    "        y_test_true = np.array(df_test_dist['DFma_' + str(j + 1)])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                                  + str(i) + '_DFma_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                               + str(i) + '_DFma_' + str(j + 1) + '_withCD_' + str(num_leaves) \n",
    "                                               + '.csv', encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_ByDistrict_MA' + str(i) + '_DFma_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_dist_eval_' + str(num_leaves) + '.csv', \n",
    "                                header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.320476\tvalid_0's l2: 0.144048\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310479\tvalid_0's l2: 0.136154\n",
      "[3]\tvalid_0's l1: 0.3009\tvalid_0's l2: 0.128727\n",
      "[4]\tvalid_0's l1: 0.292464\tvalid_0's l2: 0.122536\n",
      "[5]\tvalid_0's l1: 0.284402\tvalid_0's l2: 0.116608\n",
      "[6]\tvalid_0's l1: 0.277052\tvalid_0's l2: 0.111426\n",
      "[7]\tvalid_0's l1: 0.270324\tvalid_0's l2: 0.106816\n",
      "[8]\tvalid_0's l1: 0.263979\tvalid_0's l2: 0.102709\n",
      "[9]\tvalid_0's l1: 0.258178\tvalid_0's l2: 0.0991075\n",
      "[10]\tvalid_0's l1: 0.252509\tvalid_0's l2: 0.0956931\n",
      "[11]\tvalid_0's l1: 0.24751\tvalid_0's l2: 0.0929538\n",
      "[12]\tvalid_0's l1: 0.242876\tvalid_0's l2: 0.0904785\n",
      "[13]\tvalid_0's l1: 0.23887\tvalid_0's l2: 0.0884331\n",
      "[14]\tvalid_0's l1: 0.234894\tvalid_0's l2: 0.0865239\n",
      "[15]\tvalid_0's l1: 0.231166\tvalid_0's l2: 0.0846408\n",
      "[16]\tvalid_0's l1: 0.227919\tvalid_0's l2: 0.083149\n",
      "[17]\tvalid_0's l1: 0.225068\tvalid_0's l2: 0.0819192\n",
      "[18]\tvalid_0's l1: 0.222278\tvalid_0's l2: 0.0807971\n",
      "[19]\tvalid_0's l1: 0.219724\tvalid_0's l2: 0.0797885\n",
      "[20]\tvalid_0's l1: 0.217521\tvalid_0's l2: 0.0789726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.217521\tvalid_0's l2: 0.0789726\n",
      "[1]\tvalid_0's l1: 0.320444\tvalid_0's l2: 0.143992\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310612\tvalid_0's l2: 0.136171\n",
      "[3]\tvalid_0's l1: 0.301012\tvalid_0's l2: 0.128808\n",
      "[4]\tvalid_0's l1: 0.292372\tvalid_0's l2: 0.12236\n",
      "[5]\tvalid_0's l1: 0.284453\tvalid_0's l2: 0.11676\n",
      "[6]\tvalid_0's l1: 0.276983\tvalid_0's l2: 0.111456\n",
      "[7]\tvalid_0's l1: 0.270014\tvalid_0's l2: 0.106824\n",
      "[8]\tvalid_0's l1: 0.263672\tvalid_0's l2: 0.102717\n",
      "[9]\tvalid_0's l1: 0.257463\tvalid_0's l2: 0.0987882\n",
      "[10]\tvalid_0's l1: 0.252109\tvalid_0's l2: 0.09566\n",
      "[11]\tvalid_0's l1: 0.247053\tvalid_0's l2: 0.0928114\n",
      "[12]\tvalid_0's l1: 0.242557\tvalid_0's l2: 0.0904053\n",
      "[13]\tvalid_0's l1: 0.238418\tvalid_0's l2: 0.0882964\n",
      "[14]\tvalid_0's l1: 0.234662\tvalid_0's l2: 0.0864283\n",
      "[15]\tvalid_0's l1: 0.231049\tvalid_0's l2: 0.0846515\n",
      "[16]\tvalid_0's l1: 0.227852\tvalid_0's l2: 0.0832091\n",
      "[17]\tvalid_0's l1: 0.224762\tvalid_0's l2: 0.0818603\n",
      "[18]\tvalid_0's l1: 0.221944\tvalid_0's l2: 0.0806974\n",
      "[19]\tvalid_0's l1: 0.219672\tvalid_0's l2: 0.0797795\n",
      "[20]\tvalid_0's l1: 0.217311\tvalid_0's l2: 0.0788743\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.217311\tvalid_0's l2: 0.0788743\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.318208\tvalid_0's l2: 0.143072\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.309152\tvalid_0's l2: 0.135674\n",
      "[3]\tvalid_0's l1: 0.300265\tvalid_0's l2: 0.128714\n",
      "[4]\tvalid_0's l1: 0.292883\tvalid_0's l2: 0.123057\n",
      "[5]\tvalid_0's l1: 0.285506\tvalid_0's l2: 0.11763\n",
      "[6]\tvalid_0's l1: 0.278979\tvalid_0's l2: 0.113052\n",
      "[7]\tvalid_0's l1: 0.273591\tvalid_0's l2: 0.109334\n",
      "[8]\tvalid_0's l1: 0.267948\tvalid_0's l2: 0.105824\n",
      "[9]\tvalid_0's l1: 0.263006\tvalid_0's l2: 0.102909\n",
      "[10]\tvalid_0's l1: 0.258331\tvalid_0's l2: 0.100235\n",
      "[11]\tvalid_0's l1: 0.25405\tvalid_0's l2: 0.0979098\n",
      "[12]\tvalid_0's l1: 0.250089\tvalid_0's l2: 0.0957941\n",
      "[13]\tvalid_0's l1: 0.246823\tvalid_0's l2: 0.0942018\n",
      "[14]\tvalid_0's l1: 0.243573\tvalid_0's l2: 0.092628\n",
      "[15]\tvalid_0's l1: 0.24051\tvalid_0's l2: 0.0913256\n",
      "[16]\tvalid_0's l1: 0.237884\tvalid_0's l2: 0.0903834\n",
      "[17]\tvalid_0's l1: 0.235694\tvalid_0's l2: 0.0896123\n",
      "[18]\tvalid_0's l1: 0.23383\tvalid_0's l2: 0.0891718\n",
      "[19]\tvalid_0's l1: 0.231975\tvalid_0's l2: 0.0886853\n",
      "[20]\tvalid_0's l1: 0.230347\tvalid_0's l2: 0.0884494\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.230347\tvalid_0's l2: 0.0884494\n",
      "[1]\tvalid_0's l1: 0.318273\tvalid_0's l2: 0.14315\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308978\tvalid_0's l2: 0.135582\n",
      "[3]\tvalid_0's l1: 0.300087\tvalid_0's l2: 0.128656\n",
      "[4]\tvalid_0's l1: 0.292048\tvalid_0's l2: 0.122379\n",
      "[5]\tvalid_0's l1: 0.284961\tvalid_0's l2: 0.117281\n",
      "[6]\tvalid_0's l1: 0.278478\tvalid_0's l2: 0.112686\n",
      "[7]\tvalid_0's l1: 0.272708\tvalid_0's l2: 0.108786\n",
      "[8]\tvalid_0's l1: 0.267368\tvalid_0's l2: 0.105415\n",
      "[9]\tvalid_0's l1: 0.262402\tvalid_0's l2: 0.102426\n",
      "[10]\tvalid_0's l1: 0.257901\tvalid_0's l2: 0.0998591\n",
      "[11]\tvalid_0's l1: 0.253828\tvalid_0's l2: 0.0975224\n",
      "[12]\tvalid_0's l1: 0.250178\tvalid_0's l2: 0.0955841\n",
      "[13]\tvalid_0's l1: 0.246966\tvalid_0's l2: 0.0940179\n",
      "[14]\tvalid_0's l1: 0.244063\tvalid_0's l2: 0.092667\n",
      "[15]\tvalid_0's l1: 0.241305\tvalid_0's l2: 0.0914934\n",
      "[16]\tvalid_0's l1: 0.239002\tvalid_0's l2: 0.0907343\n",
      "[17]\tvalid_0's l1: 0.236681\tvalid_0's l2: 0.0900036\n",
      "[18]\tvalid_0's l1: 0.234784\tvalid_0's l2: 0.0895218\n",
      "[19]\tvalid_0's l1: 0.233118\tvalid_0's l2: 0.0891897\n",
      "[20]\tvalid_0's l1: 0.231537\tvalid_0's l2: 0.0889278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.231537\tvalid_0's l2: 0.0889278\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315259\tvalid_0's l2: 0.141866\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306296\tvalid_0's l2: 0.134753\n",
      "[3]\tvalid_0's l1: 0.298531\tvalid_0's l2: 0.128434\n",
      "[4]\tvalid_0's l1: 0.291891\tvalid_0's l2: 0.1234\n",
      "[5]\tvalid_0's l1: 0.285483\tvalid_0's l2: 0.118765\n",
      "[6]\tvalid_0's l1: 0.279453\tvalid_0's l2: 0.11459\n",
      "[7]\tvalid_0's l1: 0.274585\tvalid_0's l2: 0.111244\n",
      "[8]\tvalid_0's l1: 0.270045\tvalid_0's l2: 0.108448\n",
      "[9]\tvalid_0's l1: 0.266105\tvalid_0's l2: 0.106161\n",
      "[10]\tvalid_0's l1: 0.262275\tvalid_0's l2: 0.104316\n",
      "[11]\tvalid_0's l1: 0.258751\tvalid_0's l2: 0.102566\n",
      "[12]\tvalid_0's l1: 0.255736\tvalid_0's l2: 0.101363\n",
      "[13]\tvalid_0's l1: 0.25286\tvalid_0's l2: 0.100523\n",
      "[14]\tvalid_0's l1: 0.250516\tvalid_0's l2: 0.0997441\n",
      "[15]\tvalid_0's l1: 0.248422\tvalid_0's l2: 0.0992681\n",
      "[16]\tvalid_0's l1: 0.2466\tvalid_0's l2: 0.0990372\n",
      "[17]\tvalid_0's l1: 0.245\tvalid_0's l2: 0.098879\n",
      "[18]\tvalid_0's l1: 0.243823\tvalid_0's l2: 0.0990443\n",
      "[19]\tvalid_0's l1: 0.242618\tvalid_0's l2: 0.0992765\n",
      "[20]\tvalid_0's l1: 0.241787\tvalid_0's l2: 0.0997699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.241787\tvalid_0's l2: 0.0997699\n",
      "[1]\tvalid_0's l1: 0.315323\tvalid_0's l2: 0.142014\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306662\tvalid_0's l2: 0.135055\n",
      "[3]\tvalid_0's l1: 0.298745\tvalid_0's l2: 0.12871\n",
      "[4]\tvalid_0's l1: 0.291476\tvalid_0's l2: 0.123238\n",
      "[5]\tvalid_0's l1: 0.285302\tvalid_0's l2: 0.118661\n",
      "[6]\tvalid_0's l1: 0.2793\tvalid_0's l2: 0.11443\n",
      "[7]\tvalid_0's l1: 0.274209\tvalid_0's l2: 0.111105\n",
      "[8]\tvalid_0's l1: 0.269697\tvalid_0's l2: 0.108419\n",
      "[9]\tvalid_0's l1: 0.265939\tvalid_0's l2: 0.106154\n",
      "[10]\tvalid_0's l1: 0.262435\tvalid_0's l2: 0.104342\n",
      "[11]\tvalid_0's l1: 0.258865\tvalid_0's l2: 0.102764\n",
      "[12]\tvalid_0's l1: 0.2561\tvalid_0's l2: 0.101664\n",
      "[13]\tvalid_0's l1: 0.253462\tvalid_0's l2: 0.100737\n",
      "[14]\tvalid_0's l1: 0.251065\tvalid_0's l2: 0.100032\n",
      "[15]\tvalid_0's l1: 0.249037\tvalid_0's l2: 0.0996378\n",
      "[16]\tvalid_0's l1: 0.246873\tvalid_0's l2: 0.0990273\n",
      "[17]\tvalid_0's l1: 0.245347\tvalid_0's l2: 0.098952\n",
      "[18]\tvalid_0's l1: 0.244222\tvalid_0's l2: 0.0992349\n",
      "[19]\tvalid_0's l1: 0.243006\tvalid_0's l2: 0.0992731\n",
      "[20]\tvalid_0's l1: 0.242231\tvalid_0's l2: 0.099732\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.242231\tvalid_0's l2: 0.099732\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.314163\tvalid_0's l2: 0.141138\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306302\tvalid_0's l2: 0.134546\n",
      "[3]\tvalid_0's l1: 0.298674\tvalid_0's l2: 0.128581\n",
      "[4]\tvalid_0's l1: 0.292686\tvalid_0's l2: 0.123902\n",
      "[5]\tvalid_0's l1: 0.287256\tvalid_0's l2: 0.119929\n",
      "[6]\tvalid_0's l1: 0.282556\tvalid_0's l2: 0.116653\n",
      "[7]\tvalid_0's l1: 0.278747\tvalid_0's l2: 0.114328\n",
      "[8]\tvalid_0's l1: 0.275222\tvalid_0's l2: 0.112461\n",
      "[9]\tvalid_0's l1: 0.272318\tvalid_0's l2: 0.111284\n",
      "[10]\tvalid_0's l1: 0.269416\tvalid_0's l2: 0.11019\n",
      "[11]\tvalid_0's l1: 0.266907\tvalid_0's l2: 0.109408\n",
      "[12]\tvalid_0's l1: 0.264893\tvalid_0's l2: 0.109108\n",
      "[13]\tvalid_0's l1: 0.263116\tvalid_0's l2: 0.109017\n",
      "[14]\tvalid_0's l1: 0.261722\tvalid_0's l2: 0.109095\n",
      "[15]\tvalid_0's l1: 0.260369\tvalid_0's l2: 0.109477\n",
      "[16]\tvalid_0's l1: 0.259222\tvalid_0's l2: 0.109971\n",
      "[17]\tvalid_0's l1: 0.258435\tvalid_0's l2: 0.110694\n",
      "[18]\tvalid_0's l1: 0.257686\tvalid_0's l2: 0.11151\n",
      "[19]\tvalid_0's l1: 0.257161\tvalid_0's l2: 0.112421\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.263116\tvalid_0's l2: 0.109017\n",
      "[1]\tvalid_0's l1: 0.314419\tvalid_0's l2: 0.141252\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306919\tvalid_0's l2: 0.134909\n",
      "[3]\tvalid_0's l1: 0.299218\tvalid_0's l2: 0.128745\n",
      "[4]\tvalid_0's l1: 0.292859\tvalid_0's l2: 0.12397\n",
      "[5]\tvalid_0's l1: 0.287388\tvalid_0's l2: 0.119925\n",
      "[6]\tvalid_0's l1: 0.282808\tvalid_0's l2: 0.116807\n",
      "[7]\tvalid_0's l1: 0.278691\tvalid_0's l2: 0.114338\n",
      "[8]\tvalid_0's l1: 0.275213\tvalid_0's l2: 0.112515\n",
      "[9]\tvalid_0's l1: 0.272181\tvalid_0's l2: 0.111016\n",
      "[10]\tvalid_0's l1: 0.269324\tvalid_0's l2: 0.110021\n",
      "[11]\tvalid_0's l1: 0.267175\tvalid_0's l2: 0.109568\n",
      "[12]\tvalid_0's l1: 0.265322\tvalid_0's l2: 0.109435\n",
      "[13]\tvalid_0's l1: 0.263884\tvalid_0's l2: 0.109685\n",
      "[14]\tvalid_0's l1: 0.262325\tvalid_0's l2: 0.109719\n",
      "[15]\tvalid_0's l1: 0.26145\tvalid_0's l2: 0.110398\n",
      "[16]\tvalid_0's l1: 0.2611\tvalid_0's l2: 0.111625\n",
      "[17]\tvalid_0's l1: 0.260708\tvalid_0's l2: 0.112736\n",
      "[18]\tvalid_0's l1: 0.260629\tvalid_0's l2: 0.114037\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.265322\tvalid_0's l2: 0.109435\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.311406\tvalid_0's l2: 0.140187\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.30414\tvalid_0's l2: 0.134518\n",
      "[3]\tvalid_0's l1: 0.298473\tvalid_0's l2: 0.13\n",
      "[4]\tvalid_0's l1: 0.293904\tvalid_0's l2: 0.126715\n",
      "[5]\tvalid_0's l1: 0.289932\tvalid_0's l2: 0.124174\n",
      "[6]\tvalid_0's l1: 0.286324\tvalid_0's l2: 0.122163\n",
      "[7]\tvalid_0's l1: 0.283461\tvalid_0's l2: 0.120599\n",
      "[8]\tvalid_0's l1: 0.280807\tvalid_0's l2: 0.119602\n",
      "[9]\tvalid_0's l1: 0.278894\tvalid_0's l2: 0.11924\n",
      "[10]\tvalid_0's l1: 0.277175\tvalid_0's l2: 0.119357\n",
      "[11]\tvalid_0's l1: 0.275837\tvalid_0's l2: 0.119451\n",
      "[12]\tvalid_0's l1: 0.274886\tvalid_0's l2: 0.120214\n",
      "[13]\tvalid_0's l1: 0.274198\tvalid_0's l2: 0.120947\n",
      "[14]\tvalid_0's l1: 0.273656\tvalid_0's l2: 0.121989\n",
      "[15]\tvalid_0's l1: 0.273194\tvalid_0's l2: 0.123295\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.278894\tvalid_0's l2: 0.11924\n",
      "[1]\tvalid_0's l1: 0.311631\tvalid_0's l2: 0.140189\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.304981\tvalid_0's l2: 0.134781\n",
      "[3]\tvalid_0's l1: 0.29951\tvalid_0's l2: 0.130616\n",
      "[4]\tvalid_0's l1: 0.294344\tvalid_0's l2: 0.12696\n",
      "[5]\tvalid_0's l1: 0.290448\tvalid_0's l2: 0.124559\n",
      "[6]\tvalid_0's l1: 0.287178\tvalid_0's l2: 0.122687\n",
      "[7]\tvalid_0's l1: 0.283932\tvalid_0's l2: 0.121162\n",
      "[8]\tvalid_0's l1: 0.281726\tvalid_0's l2: 0.120479\n",
      "[9]\tvalid_0's l1: 0.280262\tvalid_0's l2: 0.12036\n",
      "[10]\tvalid_0's l1: 0.279042\tvalid_0's l2: 0.120551\n",
      "[11]\tvalid_0's l1: 0.278226\tvalid_0's l2: 0.12106\n",
      "[12]\tvalid_0's l1: 0.277914\tvalid_0's l2: 0.12223\n",
      "[13]\tvalid_0's l1: 0.277432\tvalid_0's l2: 0.123459\n",
      "[14]\tvalid_0's l1: 0.277256\tvalid_0's l2: 0.125018\n",
      "[15]\tvalid_0's l1: 0.277566\tvalid_0's l2: 0.127261\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.280262\tvalid_0's l2: 0.12036\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.313762\tvalid_0's l2: 0.141956\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308348\tvalid_0's l2: 0.137458\n",
      "[3]\tvalid_0's l1: 0.304076\tvalid_0's l2: 0.134098\n",
      "[4]\tvalid_0's l1: 0.300607\tvalid_0's l2: 0.132045\n",
      "[5]\tvalid_0's l1: 0.297674\tvalid_0's l2: 0.130636\n",
      "[6]\tvalid_0's l1: 0.295449\tvalid_0's l2: 0.129952\n",
      "[7]\tvalid_0's l1: 0.293848\tvalid_0's l2: 0.129819\n",
      "[8]\tvalid_0's l1: 0.292839\tvalid_0's l2: 0.130483\n",
      "[9]\tvalid_0's l1: 0.292291\tvalid_0's l2: 0.131719\n",
      "[10]\tvalid_0's l1: 0.292249\tvalid_0's l2: 0.133665\n",
      "[11]\tvalid_0's l1: 0.291659\tvalid_0's l2: 0.135115\n",
      "[12]\tvalid_0's l1: 0.291769\tvalid_0's l2: 0.137366\n",
      "[13]\tvalid_0's l1: 0.292223\tvalid_0's l2: 0.140156\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l1: 0.293848\tvalid_0's l2: 0.129819\n",
      "[1]\tvalid_0's l1: 0.313963\tvalid_0's l2: 0.141899\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.309106\tvalid_0's l2: 0.137952\n",
      "[3]\tvalid_0's l1: 0.304843\tvalid_0's l2: 0.134726\n",
      "[4]\tvalid_0's l1: 0.30095\tvalid_0's l2: 0.132126\n",
      "[5]\tvalid_0's l1: 0.297859\tvalid_0's l2: 0.130503\n",
      "[6]\tvalid_0's l1: 0.295161\tvalid_0's l2: 0.129314\n",
      "[7]\tvalid_0's l1: 0.293631\tvalid_0's l2: 0.129551\n",
      "[8]\tvalid_0's l1: 0.292455\tvalid_0's l2: 0.129988\n",
      "[9]\tvalid_0's l1: 0.292211\tvalid_0's l2: 0.131231\n",
      "[10]\tvalid_0's l1: 0.292011\tvalid_0's l2: 0.133106\n",
      "[11]\tvalid_0's l1: 0.292122\tvalid_0's l2: 0.135182\n",
      "[12]\tvalid_0's l1: 0.291712\tvalid_0's l2: 0.136862\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's l1: 0.295161\tvalid_0's l2: 0.129314\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_dist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_dist_cd_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin [col 26],\n",
    "    # bowl [col 27],\n",
    "    # bucket [col 28],\n",
    "    # misc_short [col 29],\n",
    "    # jars [col 30],\n",
    "    # pottedplant [col 31],\n",
    "    # tire [col 32],\n",
    "    # misc_tall [col 33],\n",
    "    # and total [col 34]\n",
    "        \n",
    "    x_train_withoutCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_train_withCD = df_train_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    x_test_withoutCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_test_withCD = df_test_dist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # y: response (target) variable from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    y_train = df_train_dist.iloc[:, [9 - i]]\n",
    "    y_test = df_test_dist.iloc[:, [9 - i]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_dist['DF_' + str(i + 1)])\n",
    "    y_test_true = np.array(df_test_dist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                              + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) \n",
    "                                              + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                           + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) \n",
    "                                           + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "    \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_ByDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_dist_original_eval_' + str(num_leaves) + '.csv', \n",
    "                                header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sub-district level</h1>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.384872\tvalid_0's l2: 0.24629\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3726\tvalid_0's l2: 0.232502\n",
      "[3]\tvalid_0's l1: 0.360453\tvalid_0's l2: 0.218978\n",
      "[4]\tvalid_0's l1: 0.349779\tvalid_0's l2: 0.207874\n",
      "[5]\tvalid_0's l1: 0.338148\tvalid_0's l2: 0.195106\n",
      "[6]\tvalid_0's l1: 0.32797\tvalid_0's l2: 0.185136\n",
      "[7]\tvalid_0's l1: 0.322048\tvalid_0's l2: 0.180548\n",
      "[8]\tvalid_0's l1: 0.31222\tvalid_0's l2: 0.170802\n",
      "[9]\tvalid_0's l1: 0.304214\tvalid_0's l2: 0.163652\n",
      "[10]\tvalid_0's l1: 0.295606\tvalid_0's l2: 0.15565\n",
      "[11]\tvalid_0's l1: 0.287971\tvalid_0's l2: 0.149105\n",
      "[12]\tvalid_0's l1: 0.280955\tvalid_0's l2: 0.143072\n",
      "[13]\tvalid_0's l1: 0.27518\tvalid_0's l2: 0.138624\n",
      "[14]\tvalid_0's l1: 0.269013\tvalid_0's l2: 0.13344\n",
      "[15]\tvalid_0's l1: 0.262986\tvalid_0's l2: 0.128386\n",
      "[16]\tvalid_0's l1: 0.257241\tvalid_0's l2: 0.123842\n",
      "[17]\tvalid_0's l1: 0.254262\tvalid_0's l2: 0.122222\n",
      "[18]\tvalid_0's l1: 0.249621\tvalid_0's l2: 0.119171\n",
      "[19]\tvalid_0's l1: 0.244895\tvalid_0's l2: 0.115666\n",
      "[20]\tvalid_0's l1: 0.240954\tvalid_0's l2: 0.1133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.240954\tvalid_0's l2: 0.1133\n",
      "[1]\tvalid_0's l1: 0.384973\tvalid_0's l2: 0.246454\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.372683\tvalid_0's l2: 0.232626\n",
      "[3]\tvalid_0's l1: 0.360436\tvalid_0's l2: 0.219065\n",
      "[4]\tvalid_0's l1: 0.348088\tvalid_0's l2: 0.205088\n",
      "[5]\tvalid_0's l1: 0.336841\tvalid_0's l2: 0.193519\n",
      "[6]\tvalid_0's l1: 0.326235\tvalid_0's l2: 0.183004\n",
      "[7]\tvalid_0's l1: 0.316252\tvalid_0's l2: 0.173531\n",
      "[8]\tvalid_0's l1: 0.307133\tvalid_0's l2: 0.165004\n",
      "[9]\tvalid_0's l1: 0.301654\tvalid_0's l2: 0.160346\n",
      "[10]\tvalid_0's l1: 0.29352\tvalid_0's l2: 0.15324\n",
      "[11]\tvalid_0's l1: 0.286105\tvalid_0's l2: 0.146935\n",
      "[12]\tvalid_0's l1: 0.279335\tvalid_0's l2: 0.14122\n",
      "[13]\tvalid_0's l1: 0.272988\tvalid_0's l2: 0.13604\n",
      "[14]\tvalid_0's l1: 0.267097\tvalid_0's l2: 0.131299\n",
      "[15]\tvalid_0's l1: 0.261553\tvalid_0's l2: 0.127113\n",
      "[16]\tvalid_0's l1: 0.256331\tvalid_0's l2: 0.123505\n",
      "[17]\tvalid_0's l1: 0.25139\tvalid_0's l2: 0.120142\n",
      "[18]\tvalid_0's l1: 0.246939\tvalid_0's l2: 0.117204\n",
      "[19]\tvalid_0's l1: 0.244256\tvalid_0's l2: 0.115846\n",
      "[20]\tvalid_0's l1: 0.240136\tvalid_0's l2: 0.113203\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.240136\tvalid_0's l2: 0.113203\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.389882\tvalid_0's l2: 0.255768\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382221\tvalid_0's l2: 0.248047\n",
      "[3]\tvalid_0's l1: 0.37515\tvalid_0's l2: 0.241481\n",
      "[4]\tvalid_0's l1: 0.368258\tvalid_0's l2: 0.234954\n",
      "[5]\tvalid_0's l1: 0.361476\tvalid_0's l2: 0.227893\n",
      "[6]\tvalid_0's l1: 0.355351\tvalid_0's l2: 0.222785\n",
      "[7]\tvalid_0's l1: 0.349945\tvalid_0's l2: 0.218613\n",
      "[8]\tvalid_0's l1: 0.344591\tvalid_0's l2: 0.213618\n",
      "[9]\tvalid_0's l1: 0.339724\tvalid_0's l2: 0.210093\n",
      "[10]\tvalid_0's l1: 0.335199\tvalid_0's l2: 0.206173\n",
      "[11]\tvalid_0's l1: 0.331423\tvalid_0's l2: 0.203555\n",
      "[12]\tvalid_0's l1: 0.327911\tvalid_0's l2: 0.201279\n",
      "[13]\tvalid_0's l1: 0.324467\tvalid_0's l2: 0.199048\n",
      "[14]\tvalid_0's l1: 0.32155\tvalid_0's l2: 0.197285\n",
      "[15]\tvalid_0's l1: 0.318758\tvalid_0's l2: 0.195186\n",
      "[16]\tvalid_0's l1: 0.315968\tvalid_0's l2: 0.193138\n",
      "[17]\tvalid_0's l1: 0.313292\tvalid_0's l2: 0.191625\n",
      "[18]\tvalid_0's l1: 0.310923\tvalid_0's l2: 0.190509\n",
      "[19]\tvalid_0's l1: 0.308758\tvalid_0's l2: 0.189245\n",
      "[20]\tvalid_0's l1: 0.306739\tvalid_0's l2: 0.188414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.306739\tvalid_0's l2: 0.188414\n",
      "[1]\tvalid_0's l1: 0.389963\tvalid_0's l2: 0.255795\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382192\tvalid_0's l2: 0.247968\n",
      "[3]\tvalid_0's l1: 0.374847\tvalid_0's l2: 0.240872\n",
      "[4]\tvalid_0's l1: 0.367384\tvalid_0's l2: 0.233032\n",
      "[5]\tvalid_0's l1: 0.361117\tvalid_0's l2: 0.227482\n",
      "[6]\tvalid_0's l1: 0.355202\tvalid_0's l2: 0.222584\n",
      "[7]\tvalid_0's l1: 0.349652\tvalid_0's l2: 0.218161\n",
      "[8]\tvalid_0's l1: 0.344715\tvalid_0's l2: 0.214473\n",
      "[9]\tvalid_0's l1: 0.339981\tvalid_0's l2: 0.210206\n",
      "[10]\tvalid_0's l1: 0.335534\tvalid_0's l2: 0.206935\n",
      "[11]\tvalid_0's l1: 0.331555\tvalid_0's l2: 0.203992\n",
      "[12]\tvalid_0's l1: 0.328031\tvalid_0's l2: 0.201708\n",
      "[13]\tvalid_0's l1: 0.324732\tvalid_0's l2: 0.199409\n",
      "[14]\tvalid_0's l1: 0.321668\tvalid_0's l2: 0.19758\n",
      "[15]\tvalid_0's l1: 0.318826\tvalid_0's l2: 0.195867\n",
      "[16]\tvalid_0's l1: 0.316059\tvalid_0's l2: 0.194489\n",
      "[17]\tvalid_0's l1: 0.31341\tvalid_0's l2: 0.193127\n",
      "[18]\tvalid_0's l1: 0.311072\tvalid_0's l2: 0.191991\n",
      "[19]\tvalid_0's l1: 0.308892\tvalid_0's l2: 0.190902\n",
      "[20]\tvalid_0's l1: 0.306705\tvalid_0's l2: 0.189764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.306705\tvalid_0's l2: 0.189764\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.390094\tvalid_0's l2: 0.258094\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382637\tvalid_0's l2: 0.25082\n",
      "[3]\tvalid_0's l1: 0.375881\tvalid_0's l2: 0.244576\n",
      "[4]\tvalid_0's l1: 0.369783\tvalid_0's l2: 0.239091\n",
      "[5]\tvalid_0's l1: 0.36363\tvalid_0's l2: 0.232221\n",
      "[6]\tvalid_0's l1: 0.358096\tvalid_0's l2: 0.227649\n",
      "[7]\tvalid_0's l1: 0.353369\tvalid_0's l2: 0.224066\n",
      "[8]\tvalid_0's l1: 0.348587\tvalid_0's l2: 0.219518\n",
      "[9]\tvalid_0's l1: 0.344418\tvalid_0's l2: 0.216475\n",
      "[10]\tvalid_0's l1: 0.340216\tvalid_0's l2: 0.212875\n",
      "[11]\tvalid_0's l1: 0.336724\tvalid_0's l2: 0.21068\n",
      "[12]\tvalid_0's l1: 0.333486\tvalid_0's l2: 0.208688\n",
      "[13]\tvalid_0's l1: 0.33045\tvalid_0's l2: 0.207011\n",
      "[14]\tvalid_0's l1: 0.328154\tvalid_0's l2: 0.205725\n",
      "[15]\tvalid_0's l1: 0.325423\tvalid_0's l2: 0.203823\n",
      "[16]\tvalid_0's l1: 0.322947\tvalid_0's l2: 0.202078\n",
      "[17]\tvalid_0's l1: 0.320975\tvalid_0's l2: 0.201515\n",
      "[18]\tvalid_0's l1: 0.319009\tvalid_0's l2: 0.200927\n",
      "[19]\tvalid_0's l1: 0.317015\tvalid_0's l2: 0.199683\n",
      "[20]\tvalid_0's l1: 0.315358\tvalid_0's l2: 0.199541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.315358\tvalid_0's l2: 0.199541\n",
      "[1]\tvalid_0's l1: 0.390118\tvalid_0's l2: 0.258172\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.383099\tvalid_0's l2: 0.25151\n",
      "[3]\tvalid_0's l1: 0.376357\tvalid_0's l2: 0.245283\n",
      "[4]\tvalid_0's l1: 0.369503\tvalid_0's l2: 0.237178\n",
      "[5]\tvalid_0's l1: 0.364013\tvalid_0's l2: 0.232346\n",
      "[6]\tvalid_0's l1: 0.358373\tvalid_0's l2: 0.227579\n",
      "[7]\tvalid_0's l1: 0.353217\tvalid_0's l2: 0.223478\n",
      "[8]\tvalid_0's l1: 0.348284\tvalid_0's l2: 0.219608\n",
      "[9]\tvalid_0's l1: 0.343773\tvalid_0's l2: 0.215632\n",
      "[10]\tvalid_0's l1: 0.339709\tvalid_0's l2: 0.212814\n",
      "[11]\tvalid_0's l1: 0.336366\tvalid_0's l2: 0.210501\n",
      "[12]\tvalid_0's l1: 0.333431\tvalid_0's l2: 0.20855\n",
      "[13]\tvalid_0's l1: 0.330484\tvalid_0's l2: 0.206919\n",
      "[14]\tvalid_0's l1: 0.327967\tvalid_0's l2: 0.205785\n",
      "[15]\tvalid_0's l1: 0.325278\tvalid_0's l2: 0.20441\n",
      "[16]\tvalid_0's l1: 0.322714\tvalid_0's l2: 0.203024\n",
      "[17]\tvalid_0's l1: 0.320462\tvalid_0's l2: 0.202013\n",
      "[18]\tvalid_0's l1: 0.318325\tvalid_0's l2: 0.200837\n",
      "[19]\tvalid_0's l1: 0.316676\tvalid_0's l2: 0.200572\n",
      "[20]\tvalid_0's l1: 0.314965\tvalid_0's l2: 0.200009\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.314965\tvalid_0's l2: 0.200009\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.388784\tvalid_0's l2: 0.258282\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.381209\tvalid_0's l2: 0.249744\n",
      "[3]\tvalid_0's l1: 0.37486\tvalid_0's l2: 0.243162\n",
      "[4]\tvalid_0's l1: 0.36891\tvalid_0's l2: 0.237423\n",
      "[5]\tvalid_0's l1: 0.363275\tvalid_0's l2: 0.23132\n",
      "[6]\tvalid_0's l1: 0.358596\tvalid_0's l2: 0.227164\n",
      "[7]\tvalid_0's l1: 0.354054\tvalid_0's l2: 0.223662\n",
      "[8]\tvalid_0's l1: 0.350014\tvalid_0's l2: 0.219826\n",
      "[9]\tvalid_0's l1: 0.34689\tvalid_0's l2: 0.217486\n",
      "[10]\tvalid_0's l1: 0.343629\tvalid_0's l2: 0.214931\n",
      "[11]\tvalid_0's l1: 0.340685\tvalid_0's l2: 0.213123\n",
      "[12]\tvalid_0's l1: 0.338\tvalid_0's l2: 0.211537\n",
      "[13]\tvalid_0's l1: 0.3358\tvalid_0's l2: 0.210469\n",
      "[14]\tvalid_0's l1: 0.333674\tvalid_0's l2: 0.209489\n",
      "[15]\tvalid_0's l1: 0.331846\tvalid_0's l2: 0.208449\n",
      "[16]\tvalid_0's l1: 0.330061\tvalid_0's l2: 0.207656\n",
      "[17]\tvalid_0's l1: 0.328432\tvalid_0's l2: 0.207704\n",
      "[18]\tvalid_0's l1: 0.32702\tvalid_0's l2: 0.20778\n",
      "[19]\tvalid_0's l1: 0.325706\tvalid_0's l2: 0.207653\n",
      "[20]\tvalid_0's l1: 0.324436\tvalid_0's l2: 0.207901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.324436\tvalid_0's l2: 0.207901\n",
      "[1]\tvalid_0's l1: 0.388671\tvalid_0's l2: 0.258397\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.381777\tvalid_0's l2: 0.251228\n",
      "[3]\tvalid_0's l1: 0.375541\tvalid_0's l2: 0.244846\n",
      "[4]\tvalid_0's l1: 0.36933\tvalid_0's l2: 0.237849\n",
      "[5]\tvalid_0's l1: 0.364184\tvalid_0's l2: 0.232739\n",
      "[6]\tvalid_0's l1: 0.359407\tvalid_0's l2: 0.228415\n",
      "[7]\tvalid_0's l1: 0.355216\tvalid_0's l2: 0.224895\n",
      "[8]\tvalid_0's l1: 0.351727\tvalid_0's l2: 0.222066\n",
      "[9]\tvalid_0's l1: 0.348327\tvalid_0's l2: 0.219237\n",
      "[10]\tvalid_0's l1: 0.345184\tvalid_0's l2: 0.21715\n",
      "[11]\tvalid_0's l1: 0.342367\tvalid_0's l2: 0.215399\n",
      "[12]\tvalid_0's l1: 0.339898\tvalid_0's l2: 0.21412\n",
      "[13]\tvalid_0's l1: 0.337555\tvalid_0's l2: 0.213073\n",
      "[14]\tvalid_0's l1: 0.335627\tvalid_0's l2: 0.212523\n",
      "[15]\tvalid_0's l1: 0.334002\tvalid_0's l2: 0.212253\n",
      "[16]\tvalid_0's l1: 0.332046\tvalid_0's l2: 0.211712\n",
      "[17]\tvalid_0's l1: 0.330357\tvalid_0's l2: 0.211312\n",
      "[18]\tvalid_0's l1: 0.329027\tvalid_0's l2: 0.211095\n",
      "[19]\tvalid_0's l1: 0.327686\tvalid_0's l2: 0.211143\n",
      "[20]\tvalid_0's l1: 0.32673\tvalid_0's l2: 0.211384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.32673\tvalid_0's l2: 0.211384\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.388875\tvalid_0's l2: 0.259564\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382213\tvalid_0's l2: 0.251808\n",
      "[3]\tvalid_0's l1: 0.37652\tvalid_0's l2: 0.245931\n",
      "[4]\tvalid_0's l1: 0.371472\tvalid_0's l2: 0.240703\n",
      "[5]\tvalid_0's l1: 0.366954\tvalid_0's l2: 0.235854\n",
      "[6]\tvalid_0's l1: 0.363161\tvalid_0's l2: 0.232768\n",
      "[7]\tvalid_0's l1: 0.360102\tvalid_0's l2: 0.230598\n",
      "[8]\tvalid_0's l1: 0.356997\tvalid_0's l2: 0.228181\n",
      "[9]\tvalid_0's l1: 0.354291\tvalid_0's l2: 0.226592\n",
      "[10]\tvalid_0's l1: 0.352056\tvalid_0's l2: 0.22516\n",
      "[11]\tvalid_0's l1: 0.349685\tvalid_0's l2: 0.224047\n",
      "[12]\tvalid_0's l1: 0.347519\tvalid_0's l2: 0.223106\n",
      "[13]\tvalid_0's l1: 0.346027\tvalid_0's l2: 0.223099\n",
      "[14]\tvalid_0's l1: 0.344494\tvalid_0's l2: 0.22316\n",
      "[15]\tvalid_0's l1: 0.343523\tvalid_0's l2: 0.223761\n",
      "[16]\tvalid_0's l1: 0.342503\tvalid_0's l2: 0.224209\n",
      "[17]\tvalid_0's l1: 0.341635\tvalid_0's l2: 0.225061\n",
      "[18]\tvalid_0's l1: 0.340651\tvalid_0's l2: 0.225621\n",
      "[19]\tvalid_0's l1: 0.339994\tvalid_0's l2: 0.226305\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.346027\tvalid_0's l2: 0.223099\n",
      "[1]\tvalid_0's l1: 0.388848\tvalid_0's l2: 0.259321\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382564\tvalid_0's l2: 0.251956\n",
      "[3]\tvalid_0's l1: 0.376935\tvalid_0's l2: 0.245797\n",
      "[4]\tvalid_0's l1: 0.371563\tvalid_0's l2: 0.23989\n",
      "[5]\tvalid_0's l1: 0.3668\tvalid_0's l2: 0.235436\n",
      "[6]\tvalid_0's l1: 0.362875\tvalid_0's l2: 0.232009\n",
      "[7]\tvalid_0's l1: 0.35919\tvalid_0's l2: 0.229015\n",
      "[8]\tvalid_0's l1: 0.356362\tvalid_0's l2: 0.227064\n",
      "[9]\tvalid_0's l1: 0.353978\tvalid_0's l2: 0.22536\n",
      "[10]\tvalid_0's l1: 0.351987\tvalid_0's l2: 0.224481\n",
      "[11]\tvalid_0's l1: 0.349908\tvalid_0's l2: 0.223395\n",
      "[12]\tvalid_0's l1: 0.348384\tvalid_0's l2: 0.222878\n",
      "[13]\tvalid_0's l1: 0.347059\tvalid_0's l2: 0.222842\n",
      "[14]\tvalid_0's l1: 0.346058\tvalid_0's l2: 0.223113\n",
      "[15]\tvalid_0's l1: 0.345192\tvalid_0's l2: 0.223832\n",
      "[16]\tvalid_0's l1: 0.344193\tvalid_0's l2: 0.224503\n",
      "[17]\tvalid_0's l1: 0.343047\tvalid_0's l2: 0.224948\n",
      "[18]\tvalid_0's l1: 0.342363\tvalid_0's l2: 0.225803\n",
      "[19]\tvalid_0's l1: 0.342232\tvalid_0's l2: 0.227352\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.347059\tvalid_0's l2: 0.222842\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.38907\tvalid_0's l2: 0.26051\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.38374\tvalid_0's l2: 0.254557\n",
      "[3]\tvalid_0's l1: 0.378664\tvalid_0's l2: 0.250083\n",
      "[4]\tvalid_0's l1: 0.374402\tvalid_0's l2: 0.246251\n",
      "[5]\tvalid_0's l1: 0.370758\tvalid_0's l2: 0.243275\n",
      "[6]\tvalid_0's l1: 0.367664\tvalid_0's l2: 0.240924\n",
      "[7]\tvalid_0's l1: 0.365047\tvalid_0's l2: 0.239476\n",
      "[8]\tvalid_0's l1: 0.362763\tvalid_0's l2: 0.238193\n",
      "[9]\tvalid_0's l1: 0.360762\tvalid_0's l2: 0.237362\n",
      "[10]\tvalid_0's l1: 0.359246\tvalid_0's l2: 0.237152\n",
      "[11]\tvalid_0's l1: 0.357255\tvalid_0's l2: 0.236452\n",
      "[12]\tvalid_0's l1: 0.355477\tvalid_0's l2: 0.23598\n",
      "[13]\tvalid_0's l1: 0.354752\tvalid_0's l2: 0.236881\n",
      "[14]\tvalid_0's l1: 0.354104\tvalid_0's l2: 0.237872\n",
      "[15]\tvalid_0's l1: 0.353783\tvalid_0's l2: 0.239425\n",
      "[16]\tvalid_0's l1: 0.353299\tvalid_0's l2: 0.240639\n",
      "[17]\tvalid_0's l1: 0.35347\tvalid_0's l2: 0.242855\n",
      "[18]\tvalid_0's l1: 0.353084\tvalid_0's l2: 0.244514\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.355477\tvalid_0's l2: 0.23598\n",
      "[1]\tvalid_0's l1: 0.388975\tvalid_0's l2: 0.260523\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.383218\tvalid_0's l2: 0.254267\n",
      "[3]\tvalid_0's l1: 0.377858\tvalid_0's l2: 0.249342\n",
      "[4]\tvalid_0's l1: 0.374021\tvalid_0's l2: 0.24549\n",
      "[5]\tvalid_0's l1: 0.370483\tvalid_0's l2: 0.242601\n",
      "[6]\tvalid_0's l1: 0.367864\tvalid_0's l2: 0.240455\n",
      "[7]\tvalid_0's l1: 0.365418\tvalid_0's l2: 0.238927\n",
      "[8]\tvalid_0's l1: 0.363516\tvalid_0's l2: 0.238242\n",
      "[9]\tvalid_0's l1: 0.362529\tvalid_0's l2: 0.238564\n",
      "[10]\tvalid_0's l1: 0.361657\tvalid_0's l2: 0.239349\n",
      "[11]\tvalid_0's l1: 0.360882\tvalid_0's l2: 0.240346\n",
      "[12]\tvalid_0's l1: 0.360343\tvalid_0's l2: 0.24183\n",
      "[13]\tvalid_0's l1: 0.360014\tvalid_0's l2: 0.243566\n",
      "[14]\tvalid_0's l1: 0.359622\tvalid_0's l2: 0.245781\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.363516\tvalid_0's l2: 0.238242\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.354216\tvalid_0's l2: 0.202885\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.339778\tvalid_0's l2: 0.187412\n",
      "[3]\tvalid_0's l1: 0.326453\tvalid_0's l2: 0.17395\n",
      "[4]\tvalid_0's l1: 0.313627\tvalid_0's l2: 0.161192\n",
      "[5]\tvalid_0's l1: 0.301136\tvalid_0's l2: 0.149136\n",
      "[6]\tvalid_0's l1: 0.290114\tvalid_0's l2: 0.139402\n",
      "[7]\tvalid_0's l1: 0.281812\tvalid_0's l2: 0.132686\n",
      "[8]\tvalid_0's l1: 0.271321\tvalid_0's l2: 0.123571\n",
      "[9]\tvalid_0's l1: 0.26165\tvalid_0's l2: 0.115835\n",
      "[10]\tvalid_0's l1: 0.252399\tvalid_0's l2: 0.108431\n",
      "[11]\tvalid_0's l1: 0.24388\tvalid_0's l2: 0.102092\n",
      "[12]\tvalid_0's l1: 0.235865\tvalid_0's l2: 0.0963975\n",
      "[13]\tvalid_0's l1: 0.228421\tvalid_0's l2: 0.0911529\n",
      "[14]\tvalid_0's l1: 0.22159\tvalid_0's l2: 0.0865728\n",
      "[15]\tvalid_0's l1: 0.214921\tvalid_0's l2: 0.082239\n",
      "[16]\tvalid_0's l1: 0.208608\tvalid_0's l2: 0.0782115\n",
      "[17]\tvalid_0's l1: 0.204241\tvalid_0's l2: 0.0757455\n",
      "[18]\tvalid_0's l1: 0.199071\tvalid_0's l2: 0.0727304\n",
      "[19]\tvalid_0's l1: 0.193759\tvalid_0's l2: 0.069657\n",
      "[20]\tvalid_0's l1: 0.189155\tvalid_0's l2: 0.0672152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189155\tvalid_0's l2: 0.0672152\n",
      "[1]\tvalid_0's l1: 0.354263\tvalid_0's l2: 0.202906\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.340384\tvalid_0's l2: 0.188407\n",
      "[3]\tvalid_0's l1: 0.327131\tvalid_0's l2: 0.175124\n",
      "[4]\tvalid_0's l1: 0.313985\tvalid_0's l2: 0.161723\n",
      "[5]\tvalid_0's l1: 0.301884\tvalid_0's l2: 0.150365\n",
      "[6]\tvalid_0's l1: 0.290378\tvalid_0's l2: 0.140019\n",
      "[7]\tvalid_0's l1: 0.279743\tvalid_0's l2: 0.130876\n",
      "[8]\tvalid_0's l1: 0.2696\tvalid_0's l2: 0.122426\n",
      "[9]\tvalid_0's l1: 0.26151\tvalid_0's l2: 0.115706\n",
      "[10]\tvalid_0's l1: 0.252599\tvalid_0's l2: 0.108885\n",
      "[11]\tvalid_0's l1: 0.244102\tvalid_0's l2: 0.102455\n",
      "[12]\tvalid_0's l1: 0.236291\tvalid_0's l2: 0.0968093\n",
      "[13]\tvalid_0's l1: 0.228795\tvalid_0's l2: 0.091487\n",
      "[14]\tvalid_0's l1: 0.221983\tvalid_0's l2: 0.0869419\n",
      "[15]\tvalid_0's l1: 0.215311\tvalid_0's l2: 0.0826056\n",
      "[16]\tvalid_0's l1: 0.20929\tvalid_0's l2: 0.0788778\n",
      "[17]\tvalid_0's l1: 0.203533\tvalid_0's l2: 0.0753449\n",
      "[18]\tvalid_0's l1: 0.198117\tvalid_0's l2: 0.0721659\n",
      "[19]\tvalid_0's l1: 0.194435\tvalid_0's l2: 0.0703245\n",
      "[20]\tvalid_0's l1: 0.189761\tvalid_0's l2: 0.067735\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189761\tvalid_0's l2: 0.067735\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.356803\tvalid_0's l2: 0.20837\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345637\tvalid_0's l2: 0.197005\n",
      "[3]\tvalid_0's l1: 0.33511\tvalid_0's l2: 0.186665\n",
      "[4]\tvalid_0's l1: 0.325495\tvalid_0's l2: 0.177551\n",
      "[5]\tvalid_0's l1: 0.315647\tvalid_0's l2: 0.167518\n",
      "[6]\tvalid_0's l1: 0.306902\tvalid_0's l2: 0.159537\n",
      "[7]\tvalid_0's l1: 0.30102\tvalid_0's l2: 0.154976\n",
      "[8]\tvalid_0's l1: 0.29287\tvalid_0's l2: 0.147543\n",
      "[9]\tvalid_0's l1: 0.286397\tvalid_0's l2: 0.142243\n",
      "[10]\tvalid_0's l1: 0.279448\tvalid_0's l2: 0.136242\n",
      "[11]\tvalid_0's l1: 0.273308\tvalid_0's l2: 0.131539\n",
      "[12]\tvalid_0's l1: 0.267682\tvalid_0's l2: 0.127372\n",
      "[13]\tvalid_0's l1: 0.263025\tvalid_0's l2: 0.123983\n",
      "[14]\tvalid_0's l1: 0.258273\tvalid_0's l2: 0.120588\n",
      "[15]\tvalid_0's l1: 0.253453\tvalid_0's l2: 0.117004\n",
      "[16]\tvalid_0's l1: 0.249036\tvalid_0's l2: 0.113998\n",
      "[17]\tvalid_0's l1: 0.246418\tvalid_0's l2: 0.112605\n",
      "[18]\tvalid_0's l1: 0.242597\tvalid_0's l2: 0.110379\n",
      "[19]\tvalid_0's l1: 0.239109\tvalid_0's l2: 0.108212\n",
      "[20]\tvalid_0's l1: 0.236012\tvalid_0's l2: 0.106566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.236012\tvalid_0's l2: 0.106566\n",
      "[1]\tvalid_0's l1: 0.356878\tvalid_0's l2: 0.208454\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345847\tvalid_0's l2: 0.197142\n",
      "[3]\tvalid_0's l1: 0.335336\tvalid_0's l2: 0.186825\n",
      "[4]\tvalid_0's l1: 0.324664\tvalid_0's l2: 0.175922\n",
      "[5]\tvalid_0's l1: 0.315442\tvalid_0's l2: 0.167514\n",
      "[6]\tvalid_0's l1: 0.306582\tvalid_0's l2: 0.159088\n",
      "[7]\tvalid_0's l1: 0.298492\tvalid_0's l2: 0.152122\n",
      "[8]\tvalid_0's l1: 0.291035\tvalid_0's l2: 0.145942\n",
      "[9]\tvalid_0's l1: 0.285774\tvalid_0's l2: 0.141568\n",
      "[10]\tvalid_0's l1: 0.279252\tvalid_0's l2: 0.136323\n",
      "[11]\tvalid_0's l1: 0.273179\tvalid_0's l2: 0.131387\n",
      "[12]\tvalid_0's l1: 0.26764\tvalid_0's l2: 0.126985\n",
      "[13]\tvalid_0's l1: 0.262522\tvalid_0's l2: 0.123198\n",
      "[14]\tvalid_0's l1: 0.257821\tvalid_0's l2: 0.1198\n",
      "[15]\tvalid_0's l1: 0.253464\tvalid_0's l2: 0.116904\n",
      "[16]\tvalid_0's l1: 0.249163\tvalid_0's l2: 0.114158\n",
      "[17]\tvalid_0's l1: 0.245374\tvalid_0's l2: 0.111826\n",
      "[18]\tvalid_0's l1: 0.241947\tvalid_0's l2: 0.10982\n",
      "[19]\tvalid_0's l1: 0.239614\tvalid_0's l2: 0.108697\n",
      "[20]\tvalid_0's l1: 0.236561\tvalid_0's l2: 0.106903\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.236561\tvalid_0's l2: 0.106903\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.357747\tvalid_0's l2: 0.211692\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.349197\tvalid_0's l2: 0.203093\n",
      "[3]\tvalid_0's l1: 0.34136\tvalid_0's l2: 0.195574\n",
      "[4]\tvalid_0's l1: 0.334423\tvalid_0's l2: 0.189191\n",
      "[5]\tvalid_0's l1: 0.32727\tvalid_0's l2: 0.182175\n",
      "[6]\tvalid_0's l1: 0.321765\tvalid_0's l2: 0.177789\n",
      "[7]\tvalid_0's l1: 0.316686\tvalid_0's l2: 0.173723\n",
      "[8]\tvalid_0's l1: 0.31136\tvalid_0's l2: 0.169121\n",
      "[9]\tvalid_0's l1: 0.3072\tvalid_0's l2: 0.166205\n",
      "[10]\tvalid_0's l1: 0.302839\tvalid_0's l2: 0.162645\n",
      "[11]\tvalid_0's l1: 0.299101\tvalid_0's l2: 0.160142\n",
      "[12]\tvalid_0's l1: 0.295768\tvalid_0's l2: 0.158093\n",
      "[13]\tvalid_0's l1: 0.292835\tvalid_0's l2: 0.156455\n",
      "[14]\tvalid_0's l1: 0.290171\tvalid_0's l2: 0.155027\n",
      "[15]\tvalid_0's l1: 0.287766\tvalid_0's l2: 0.153318\n",
      "[16]\tvalid_0's l1: 0.285253\tvalid_0's l2: 0.15181\n",
      "[17]\tvalid_0's l1: 0.28307\tvalid_0's l2: 0.151008\n",
      "[18]\tvalid_0's l1: 0.280945\tvalid_0's l2: 0.150046\n",
      "[19]\tvalid_0's l1: 0.279125\tvalid_0's l2: 0.149305\n",
      "[20]\tvalid_0's l1: 0.27738\tvalid_0's l2: 0.148767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.27738\tvalid_0's l2: 0.148767\n",
      "[1]\tvalid_0's l1: 0.357754\tvalid_0's l2: 0.211883\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.349258\tvalid_0's l2: 0.203356\n",
      "[3]\tvalid_0's l1: 0.341525\tvalid_0's l2: 0.195888\n",
      "[4]\tvalid_0's l1: 0.333827\tvalid_0's l2: 0.18783\n",
      "[5]\tvalid_0's l1: 0.327643\tvalid_0's l2: 0.182682\n",
      "[6]\tvalid_0's l1: 0.322034\tvalid_0's l2: 0.17816\n",
      "[7]\tvalid_0's l1: 0.316831\tvalid_0's l2: 0.174014\n",
      "[8]\tvalid_0's l1: 0.312267\tvalid_0's l2: 0.170566\n",
      "[9]\tvalid_0's l1: 0.307765\tvalid_0's l2: 0.16673\n",
      "[10]\tvalid_0's l1: 0.304066\tvalid_0's l2: 0.164251\n",
      "[11]\tvalid_0's l1: 0.300583\tvalid_0's l2: 0.161969\n",
      "[12]\tvalid_0's l1: 0.297318\tvalid_0's l2: 0.159935\n",
      "[13]\tvalid_0's l1: 0.294376\tvalid_0's l2: 0.15824\n",
      "[14]\tvalid_0's l1: 0.291762\tvalid_0's l2: 0.156917\n",
      "[15]\tvalid_0's l1: 0.289235\tvalid_0's l2: 0.155526\n",
      "[16]\tvalid_0's l1: 0.286606\tvalid_0's l2: 0.153979\n",
      "[17]\tvalid_0's l1: 0.284315\tvalid_0's l2: 0.153106\n",
      "[18]\tvalid_0's l1: 0.282155\tvalid_0's l2: 0.151914\n",
      "[19]\tvalid_0's l1: 0.280494\tvalid_0's l2: 0.151484\n",
      "[20]\tvalid_0's l1: 0.279059\tvalid_0's l2: 0.150948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.279059\tvalid_0's l2: 0.150948\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.355965\tvalid_0's l2: 0.210927\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.348049\tvalid_0's l2: 0.202485\n",
      "[3]\tvalid_0's l1: 0.340973\tvalid_0's l2: 0.195275\n",
      "[4]\tvalid_0's l1: 0.334546\tvalid_0's l2: 0.188869\n",
      "[5]\tvalid_0's l1: 0.328351\tvalid_0's l2: 0.182733\n",
      "[6]\tvalid_0's l1: 0.323228\tvalid_0's l2: 0.178373\n",
      "[7]\tvalid_0's l1: 0.318625\tvalid_0's l2: 0.174765\n",
      "[8]\tvalid_0's l1: 0.314056\tvalid_0's l2: 0.170904\n",
      "[9]\tvalid_0's l1: 0.310442\tvalid_0's l2: 0.168248\n",
      "[10]\tvalid_0's l1: 0.306898\tvalid_0's l2: 0.165579\n",
      "[11]\tvalid_0's l1: 0.303753\tvalid_0's l2: 0.163688\n",
      "[12]\tvalid_0's l1: 0.300957\tvalid_0's l2: 0.162125\n",
      "[13]\tvalid_0's l1: 0.298761\tvalid_0's l2: 0.161017\n",
      "[14]\tvalid_0's l1: 0.297139\tvalid_0's l2: 0.160341\n",
      "[15]\tvalid_0's l1: 0.295443\tvalid_0's l2: 0.159782\n",
      "[16]\tvalid_0's l1: 0.293932\tvalid_0's l2: 0.159581\n",
      "[17]\tvalid_0's l1: 0.292376\tvalid_0's l2: 0.159204\n",
      "[18]\tvalid_0's l1: 0.291088\tvalid_0's l2: 0.15933\n",
      "[19]\tvalid_0's l1: 0.28991\tvalid_0's l2: 0.159583\n",
      "[20]\tvalid_0's l1: 0.28907\tvalid_0's l2: 0.160114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.28907\tvalid_0's l2: 0.160114\n",
      "[1]\tvalid_0's l1: 0.355987\tvalid_0's l2: 0.210661\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.348017\tvalid_0's l2: 0.202036\n",
      "[3]\tvalid_0's l1: 0.340701\tvalid_0's l2: 0.194629\n",
      "[4]\tvalid_0's l1: 0.333647\tvalid_0's l2: 0.187155\n",
      "[5]\tvalid_0's l1: 0.327857\tvalid_0's l2: 0.181595\n",
      "[6]\tvalid_0's l1: 0.322675\tvalid_0's l2: 0.177473\n",
      "[7]\tvalid_0's l1: 0.317888\tvalid_0's l2: 0.173437\n",
      "[8]\tvalid_0's l1: 0.313984\tvalid_0's l2: 0.170449\n",
      "[9]\tvalid_0's l1: 0.309993\tvalid_0's l2: 0.16736\n",
      "[10]\tvalid_0's l1: 0.306912\tvalid_0's l2: 0.165609\n",
      "[11]\tvalid_0's l1: 0.304131\tvalid_0's l2: 0.163929\n",
      "[12]\tvalid_0's l1: 0.301592\tvalid_0's l2: 0.162641\n",
      "[13]\tvalid_0's l1: 0.299185\tvalid_0's l2: 0.161403\n",
      "[14]\tvalid_0's l1: 0.297388\tvalid_0's l2: 0.160851\n",
      "[15]\tvalid_0's l1: 0.295839\tvalid_0's l2: 0.160521\n",
      "[16]\tvalid_0's l1: 0.294244\tvalid_0's l2: 0.160094\n",
      "[17]\tvalid_0's l1: 0.292739\tvalid_0's l2: 0.160141\n",
      "[18]\tvalid_0's l1: 0.291581\tvalid_0's l2: 0.160432\n",
      "[19]\tvalid_0's l1: 0.290812\tvalid_0's l2: 0.161187\n",
      "[20]\tvalid_0's l1: 0.289937\tvalid_0's l2: 0.161777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.289937\tvalid_0's l2: 0.161777\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.35446\tvalid_0's l2: 0.210666\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347123\tvalid_0's l2: 0.202797\n",
      "[3]\tvalid_0's l1: 0.340508\tvalid_0's l2: 0.196309\n",
      "[4]\tvalid_0's l1: 0.334679\tvalid_0's l2: 0.190776\n",
      "[5]\tvalid_0's l1: 0.329627\tvalid_0's l2: 0.186184\n",
      "[6]\tvalid_0's l1: 0.325502\tvalid_0's l2: 0.182881\n",
      "[7]\tvalid_0's l1: 0.322206\tvalid_0's l2: 0.180447\n",
      "[8]\tvalid_0's l1: 0.318985\tvalid_0's l2: 0.178266\n",
      "[9]\tvalid_0's l1: 0.316199\tvalid_0's l2: 0.176739\n",
      "[10]\tvalid_0's l1: 0.313929\tvalid_0's l2: 0.175713\n",
      "[11]\tvalid_0's l1: 0.311661\tvalid_0's l2: 0.174699\n",
      "[12]\tvalid_0's l1: 0.309819\tvalid_0's l2: 0.17423\n",
      "[13]\tvalid_0's l1: 0.308663\tvalid_0's l2: 0.174443\n",
      "[14]\tvalid_0's l1: 0.307616\tvalid_0's l2: 0.17495\n",
      "[15]\tvalid_0's l1: 0.30669\tvalid_0's l2: 0.175742\n",
      "[16]\tvalid_0's l1: 0.305856\tvalid_0's l2: 0.176499\n",
      "[17]\tvalid_0's l1: 0.305312\tvalid_0's l2: 0.177322\n",
      "[18]\tvalid_0's l1: 0.30465\tvalid_0's l2: 0.178159\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.309819\tvalid_0's l2: 0.17423\n",
      "[1]\tvalid_0's l1: 0.354263\tvalid_0's l2: 0.210619\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346466\tvalid_0's l2: 0.202309\n",
      "[3]\tvalid_0's l1: 0.339906\tvalid_0's l2: 0.195784\n",
      "[4]\tvalid_0's l1: 0.334135\tvalid_0's l2: 0.190066\n",
      "[5]\tvalid_0's l1: 0.329413\tvalid_0's l2: 0.185834\n",
      "[6]\tvalid_0's l1: 0.325254\tvalid_0's l2: 0.182422\n",
      "[7]\tvalid_0's l1: 0.32173\tvalid_0's l2: 0.179541\n",
      "[8]\tvalid_0's l1: 0.318846\tvalid_0's l2: 0.177562\n",
      "[9]\tvalid_0's l1: 0.316589\tvalid_0's l2: 0.176226\n",
      "[10]\tvalid_0's l1: 0.314195\tvalid_0's l2: 0.175108\n",
      "[11]\tvalid_0's l1: 0.311991\tvalid_0's l2: 0.174399\n",
      "[12]\tvalid_0's l1: 0.310349\tvalid_0's l2: 0.174213\n",
      "[13]\tvalid_0's l1: 0.308862\tvalid_0's l2: 0.174395\n",
      "[14]\tvalid_0's l1: 0.307669\tvalid_0's l2: 0.175052\n",
      "[15]\tvalid_0's l1: 0.30649\tvalid_0's l2: 0.175668\n",
      "[16]\tvalid_0's l1: 0.305863\tvalid_0's l2: 0.176753\n",
      "[17]\tvalid_0's l1: 0.305405\tvalid_0's l2: 0.178044\n",
      "[18]\tvalid_0's l1: 0.30483\tvalid_0's l2: 0.179262\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.310349\tvalid_0's l2: 0.174213\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.353819\tvalid_0's l2: 0.211984\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347307\tvalid_0's l2: 0.20528\n",
      "[3]\tvalid_0's l1: 0.341875\tvalid_0's l2: 0.199895\n",
      "[4]\tvalid_0's l1: 0.337155\tvalid_0's l2: 0.195786\n",
      "[5]\tvalid_0's l1: 0.333244\tvalid_0's l2: 0.192634\n",
      "[6]\tvalid_0's l1: 0.330014\tvalid_0's l2: 0.190176\n",
      "[7]\tvalid_0's l1: 0.327665\tvalid_0's l2: 0.188861\n",
      "[8]\tvalid_0's l1: 0.325439\tvalid_0's l2: 0.188145\n",
      "[9]\tvalid_0's l1: 0.323679\tvalid_0's l2: 0.188019\n",
      "[10]\tvalid_0's l1: 0.322449\tvalid_0's l2: 0.188567\n",
      "[11]\tvalid_0's l1: 0.320613\tvalid_0's l2: 0.188214\n",
      "[12]\tvalid_0's l1: 0.319136\tvalid_0's l2: 0.18806\n",
      "[13]\tvalid_0's l1: 0.318545\tvalid_0's l2: 0.189454\n",
      "[14]\tvalid_0's l1: 0.318151\tvalid_0's l2: 0.190873\n",
      "[15]\tvalid_0's l1: 0.317835\tvalid_0's l2: 0.192666\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.323679\tvalid_0's l2: 0.188019\n",
      "[1]\tvalid_0's l1: 0.353626\tvalid_0's l2: 0.212001\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347297\tvalid_0's l2: 0.205554\n",
      "[3]\tvalid_0's l1: 0.341602\tvalid_0's l2: 0.200201\n",
      "[4]\tvalid_0's l1: 0.336919\tvalid_0's l2: 0.196013\n",
      "[5]\tvalid_0's l1: 0.333552\tvalid_0's l2: 0.19329\n",
      "[6]\tvalid_0's l1: 0.330561\tvalid_0's l2: 0.191203\n",
      "[7]\tvalid_0's l1: 0.327685\tvalid_0's l2: 0.189093\n",
      "[8]\tvalid_0's l1: 0.32571\tvalid_0's l2: 0.188197\n",
      "[9]\tvalid_0's l1: 0.324325\tvalid_0's l2: 0.188002\n",
      "[10]\tvalid_0's l1: 0.322869\tvalid_0's l2: 0.188072\n",
      "[11]\tvalid_0's l1: 0.32214\tvalid_0's l2: 0.189178\n",
      "[12]\tvalid_0's l1: 0.321211\tvalid_0's l2: 0.190017\n",
      "[13]\tvalid_0's l1: 0.320451\tvalid_0's l2: 0.19144\n",
      "[14]\tvalid_0's l1: 0.320056\tvalid_0's l2: 0.193226\n",
      "[15]\tvalid_0's l1: 0.319893\tvalid_0's l2: 0.195409\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.324325\tvalid_0's l2: 0.188002\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.337211\tvalid_0's l2: 0.181185\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.322276\tvalid_0's l2: 0.165659\n",
      "[3]\tvalid_0's l1: 0.308239\tvalid_0's l2: 0.151718\n",
      "[4]\tvalid_0's l1: 0.295036\tvalid_0's l2: 0.139213\n",
      "[5]\tvalid_0's l1: 0.282451\tvalid_0's l2: 0.127732\n",
      "[6]\tvalid_0's l1: 0.270714\tvalid_0's l2: 0.117674\n",
      "[7]\tvalid_0's l1: 0.261256\tvalid_0's l2: 0.110215\n",
      "[8]\tvalid_0's l1: 0.250759\tvalid_0's l2: 0.101771\n",
      "[9]\tvalid_0's l1: 0.240941\tvalid_0's l2: 0.0943374\n",
      "[10]\tvalid_0's l1: 0.231613\tvalid_0's l2: 0.0875101\n",
      "[11]\tvalid_0's l1: 0.222925\tvalid_0's l2: 0.0815133\n",
      "[12]\tvalid_0's l1: 0.214752\tvalid_0's l2: 0.076106\n",
      "[13]\tvalid_0's l1: 0.207074\tvalid_0's l2: 0.0711497\n",
      "[14]\tvalid_0's l1: 0.199982\tvalid_0's l2: 0.0668079\n",
      "[15]\tvalid_0's l1: 0.193208\tvalid_0's l2: 0.0627339\n",
      "[16]\tvalid_0's l1: 0.186923\tvalid_0's l2: 0.0591467\n",
      "[17]\tvalid_0's l1: 0.181949\tvalid_0's l2: 0.0564448\n",
      "[18]\tvalid_0's l1: 0.17637\tvalid_0's l2: 0.0534924\n",
      "[19]\tvalid_0's l1: 0.171109\tvalid_0's l2: 0.0508083\n",
      "[20]\tvalid_0's l1: 0.166245\tvalid_0's l2: 0.0484123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.166245\tvalid_0's l2: 0.0484123\n",
      "[1]\tvalid_0's l1: 0.337218\tvalid_0's l2: 0.181258\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.322433\tvalid_0's l2: 0.165818\n",
      "[3]\tvalid_0's l1: 0.308469\tvalid_0's l2: 0.151911\n",
      "[4]\tvalid_0's l1: 0.295123\tvalid_0's l2: 0.139122\n",
      "[5]\tvalid_0's l1: 0.282601\tvalid_0's l2: 0.12776\n",
      "[6]\tvalid_0's l1: 0.270824\tvalid_0's l2: 0.117727\n",
      "[7]\tvalid_0's l1: 0.259742\tvalid_0's l2: 0.108708\n",
      "[8]\tvalid_0's l1: 0.24938\tvalid_0's l2: 0.100551\n",
      "[9]\tvalid_0's l1: 0.240602\tvalid_0's l2: 0.0937838\n",
      "[10]\tvalid_0's l1: 0.231347\tvalid_0's l2: 0.0871504\n",
      "[11]\tvalid_0's l1: 0.222633\tvalid_0's l2: 0.0810876\n",
      "[12]\tvalid_0's l1: 0.214499\tvalid_0's l2: 0.0757022\n",
      "[13]\tvalid_0's l1: 0.206832\tvalid_0's l2: 0.0707288\n",
      "[14]\tvalid_0's l1: 0.199718\tvalid_0's l2: 0.0662414\n",
      "[15]\tvalid_0's l1: 0.19292\tvalid_0's l2: 0.062242\n",
      "[16]\tvalid_0's l1: 0.186605\tvalid_0's l2: 0.0586272\n",
      "[17]\tvalid_0's l1: 0.180753\tvalid_0's l2: 0.0553832\n",
      "[18]\tvalid_0's l1: 0.17529\tvalid_0's l2: 0.052512\n",
      "[19]\tvalid_0's l1: 0.170985\tvalid_0's l2: 0.0503835\n",
      "[20]\tvalid_0's l1: 0.166137\tvalid_0's l2: 0.0480067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.166137\tvalid_0's l2: 0.0480067\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.337225\tvalid_0's l2: 0.183255\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.324347\tvalid_0's l2: 0.169919\n",
      "[3]\tvalid_0's l1: 0.312324\tvalid_0's l2: 0.157881\n",
      "[4]\tvalid_0's l1: 0.301008\tvalid_0's l2: 0.14706\n",
      "[5]\tvalid_0's l1: 0.290262\tvalid_0's l2: 0.136903\n",
      "[6]\tvalid_0's l1: 0.280583\tvalid_0's l2: 0.128281\n",
      "[7]\tvalid_0's l1: 0.273015\tvalid_0's l2: 0.122222\n",
      "[8]\tvalid_0's l1: 0.264097\tvalid_0's l2: 0.114638\n",
      "[9]\tvalid_0's l1: 0.255969\tvalid_0's l2: 0.108329\n",
      "[10]\tvalid_0's l1: 0.248321\tvalid_0's l2: 0.102447\n",
      "[11]\tvalid_0's l1: 0.241299\tvalid_0's l2: 0.0973424\n",
      "[12]\tvalid_0's l1: 0.234676\tvalid_0's l2: 0.0927346\n",
      "[13]\tvalid_0's l1: 0.228641\tvalid_0's l2: 0.088676\n",
      "[14]\tvalid_0's l1: 0.223046\tvalid_0's l2: 0.0849944\n",
      "[15]\tvalid_0's l1: 0.217677\tvalid_0's l2: 0.0815073\n",
      "[16]\tvalid_0's l1: 0.212728\tvalid_0's l2: 0.0783941\n",
      "[17]\tvalid_0's l1: 0.209101\tvalid_0's l2: 0.07639\n",
      "[18]\tvalid_0's l1: 0.205085\tvalid_0's l2: 0.0741039\n",
      "[19]\tvalid_0's l1: 0.201224\tvalid_0's l2: 0.0717996\n",
      "[20]\tvalid_0's l1: 0.198051\tvalid_0's l2: 0.0701208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.198051\tvalid_0's l2: 0.0701208\n",
      "[1]\tvalid_0's l1: 0.337273\tvalid_0's l2: 0.183385\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.324565\tvalid_0's l2: 0.170044\n",
      "[3]\tvalid_0's l1: 0.312432\tvalid_0's l2: 0.1578\n",
      "[4]\tvalid_0's l1: 0.3008\tvalid_0's l2: 0.146423\n",
      "[5]\tvalid_0's l1: 0.290111\tvalid_0's l2: 0.136633\n",
      "[6]\tvalid_0's l1: 0.280121\tvalid_0's l2: 0.127731\n",
      "[7]\tvalid_0's l1: 0.270808\tvalid_0's l2: 0.120089\n",
      "[8]\tvalid_0's l1: 0.262239\tvalid_0's l2: 0.113065\n",
      "[9]\tvalid_0's l1: 0.255076\tvalid_0's l2: 0.107532\n",
      "[10]\tvalid_0's l1: 0.247547\tvalid_0's l2: 0.101801\n",
      "[11]\tvalid_0's l1: 0.24057\tvalid_0's l2: 0.0966958\n",
      "[12]\tvalid_0's l1: 0.234314\tvalid_0's l2: 0.0923602\n",
      "[13]\tvalid_0's l1: 0.228254\tvalid_0's l2: 0.0881478\n",
      "[14]\tvalid_0's l1: 0.222757\tvalid_0's l2: 0.0845746\n",
      "[15]\tvalid_0's l1: 0.217801\tvalid_0's l2: 0.081591\n",
      "[16]\tvalid_0's l1: 0.212979\tvalid_0's l2: 0.0786415\n",
      "[17]\tvalid_0's l1: 0.208523\tvalid_0's l2: 0.0760244\n",
      "[18]\tvalid_0's l1: 0.204592\tvalid_0's l2: 0.0737644\n",
      "[19]\tvalid_0's l1: 0.201777\tvalid_0's l2: 0.0723862\n",
      "[20]\tvalid_0's l1: 0.198358\tvalid_0's l2: 0.0704897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.198358\tvalid_0's l2: 0.0704897\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.336801\tvalid_0's l2: 0.184589\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326389\tvalid_0's l2: 0.173546\n",
      "[3]\tvalid_0's l1: 0.316545\tvalid_0's l2: 0.163642\n",
      "[4]\tvalid_0's l1: 0.307605\tvalid_0's l2: 0.154968\n",
      "[5]\tvalid_0's l1: 0.298883\tvalid_0's l2: 0.146672\n",
      "[6]\tvalid_0's l1: 0.291111\tvalid_0's l2: 0.139675\n",
      "[7]\tvalid_0's l1: 0.285873\tvalid_0's l2: 0.135539\n",
      "[8]\tvalid_0's l1: 0.278691\tvalid_0's l2: 0.129518\n",
      "[9]\tvalid_0's l1: 0.272804\tvalid_0's l2: 0.124748\n",
      "[10]\tvalid_0's l1: 0.266844\tvalid_0's l2: 0.120039\n",
      "[11]\tvalid_0's l1: 0.261613\tvalid_0's l2: 0.11615\n",
      "[12]\tvalid_0's l1: 0.256846\tvalid_0's l2: 0.112701\n",
      "[13]\tvalid_0's l1: 0.253035\tvalid_0's l2: 0.110291\n",
      "[14]\tvalid_0's l1: 0.249159\tvalid_0's l2: 0.107919\n",
      "[15]\tvalid_0's l1: 0.245363\tvalid_0's l2: 0.105415\n",
      "[16]\tvalid_0's l1: 0.241784\tvalid_0's l2: 0.103239\n",
      "[17]\tvalid_0's l1: 0.239476\tvalid_0's l2: 0.102234\n",
      "[18]\tvalid_0's l1: 0.236871\tvalid_0's l2: 0.101045\n",
      "[19]\tvalid_0's l1: 0.23405\tvalid_0's l2: 0.0996005\n",
      "[20]\tvalid_0's l1: 0.231842\tvalid_0's l2: 0.0985783\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.231842\tvalid_0's l2: 0.0985783\n",
      "[1]\tvalid_0's l1: 0.33678\tvalid_0's l2: 0.184535\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326131\tvalid_0's l2: 0.173066\n",
      "[3]\tvalid_0's l1: 0.31617\tvalid_0's l2: 0.163104\n",
      "[4]\tvalid_0's l1: 0.306469\tvalid_0's l2: 0.153755\n",
      "[5]\tvalid_0's l1: 0.297858\tvalid_0's l2: 0.14596\n",
      "[6]\tvalid_0's l1: 0.289938\tvalid_0's l2: 0.138819\n",
      "[7]\tvalid_0's l1: 0.282689\tvalid_0's l2: 0.132843\n",
      "[8]\tvalid_0's l1: 0.276269\tvalid_0's l2: 0.127529\n",
      "[9]\tvalid_0's l1: 0.27143\tvalid_0's l2: 0.123803\n",
      "[10]\tvalid_0's l1: 0.2659\tvalid_0's l2: 0.119453\n",
      "[11]\tvalid_0's l1: 0.260993\tvalid_0's l2: 0.11596\n",
      "[12]\tvalid_0's l1: 0.256431\tvalid_0's l2: 0.112645\n",
      "[13]\tvalid_0's l1: 0.252277\tvalid_0's l2: 0.10982\n",
      "[14]\tvalid_0's l1: 0.248556\tvalid_0's l2: 0.107353\n",
      "[15]\tvalid_0's l1: 0.245139\tvalid_0's l2: 0.105252\n",
      "[16]\tvalid_0's l1: 0.241937\tvalid_0's l2: 0.103438\n",
      "[17]\tvalid_0's l1: 0.239028\tvalid_0's l2: 0.101922\n",
      "[18]\tvalid_0's l1: 0.236404\tvalid_0's l2: 0.100754\n",
      "[19]\tvalid_0's l1: 0.234674\tvalid_0's l2: 0.100154\n",
      "[20]\tvalid_0's l1: 0.232569\tvalid_0's l2: 0.0994099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.232569\tvalid_0's l2: 0.0994099\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.336084\tvalid_0's l2: 0.185552\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327703\tvalid_0's l2: 0.176676\n",
      "[3]\tvalid_0's l1: 0.319881\tvalid_0's l2: 0.168416\n",
      "[4]\tvalid_0's l1: 0.313061\tvalid_0's l2: 0.162025\n",
      "[5]\tvalid_0's l1: 0.306733\tvalid_0's l2: 0.156017\n",
      "[6]\tvalid_0's l1: 0.301293\tvalid_0's l2: 0.151385\n",
      "[7]\tvalid_0's l1: 0.296745\tvalid_0's l2: 0.14767\n",
      "[8]\tvalid_0's l1: 0.292101\tvalid_0's l2: 0.143984\n",
      "[9]\tvalid_0's l1: 0.288007\tvalid_0's l2: 0.140887\n",
      "[10]\tvalid_0's l1: 0.284304\tvalid_0's l2: 0.138382\n",
      "[11]\tvalid_0's l1: 0.280752\tvalid_0's l2: 0.135934\n",
      "[12]\tvalid_0's l1: 0.277698\tvalid_0's l2: 0.133956\n",
      "[13]\tvalid_0's l1: 0.27539\tvalid_0's l2: 0.132966\n",
      "[14]\tvalid_0's l1: 0.273382\tvalid_0's l2: 0.132101\n",
      "[15]\tvalid_0's l1: 0.271436\tvalid_0's l2: 0.13158\n",
      "[16]\tvalid_0's l1: 0.269525\tvalid_0's l2: 0.131087\n",
      "[17]\tvalid_0's l1: 0.268099\tvalid_0's l2: 0.130841\n",
      "[18]\tvalid_0's l1: 0.266853\tvalid_0's l2: 0.130897\n",
      "[19]\tvalid_0's l1: 0.26569\tvalid_0's l2: 0.130992\n",
      "[20]\tvalid_0's l1: 0.264933\tvalid_0's l2: 0.131537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.264933\tvalid_0's l2: 0.131537\n",
      "[1]\tvalid_0's l1: 0.336011\tvalid_0's l2: 0.185839\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327524\tvalid_0's l2: 0.177078\n",
      "[3]\tvalid_0's l1: 0.319625\tvalid_0's l2: 0.169095\n",
      "[4]\tvalid_0's l1: 0.312568\tvalid_0's l2: 0.162521\n",
      "[5]\tvalid_0's l1: 0.306289\tvalid_0's l2: 0.156823\n",
      "[6]\tvalid_0's l1: 0.300594\tvalid_0's l2: 0.152001\n",
      "[7]\tvalid_0's l1: 0.295659\tvalid_0's l2: 0.147935\n",
      "[8]\tvalid_0's l1: 0.291444\tvalid_0's l2: 0.14482\n",
      "[9]\tvalid_0's l1: 0.287425\tvalid_0's l2: 0.14171\n",
      "[10]\tvalid_0's l1: 0.283913\tvalid_0's l2: 0.139088\n",
      "[11]\tvalid_0's l1: 0.281007\tvalid_0's l2: 0.137145\n",
      "[12]\tvalid_0's l1: 0.278431\tvalid_0's l2: 0.135699\n",
      "[13]\tvalid_0's l1: 0.276222\tvalid_0's l2: 0.134381\n",
      "[14]\tvalid_0's l1: 0.274321\tvalid_0's l2: 0.133728\n",
      "[15]\tvalid_0's l1: 0.272641\tvalid_0's l2: 0.133269\n",
      "[16]\tvalid_0's l1: 0.270791\tvalid_0's l2: 0.132508\n",
      "[17]\tvalid_0's l1: 0.269128\tvalid_0's l2: 0.132073\n",
      "[18]\tvalid_0's l1: 0.267603\tvalid_0's l2: 0.131759\n",
      "[19]\tvalid_0's l1: 0.266566\tvalid_0's l2: 0.131837\n",
      "[20]\tvalid_0's l1: 0.265837\tvalid_0's l2: 0.132231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.265837\tvalid_0's l2: 0.132231\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334334\tvalid_0's l2: 0.185317\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326454\tvalid_0's l2: 0.176919\n",
      "[3]\tvalid_0's l1: 0.31963\tvalid_0's l2: 0.170148\n",
      "[4]\tvalid_0's l1: 0.313581\tvalid_0's l2: 0.164385\n",
      "[5]\tvalid_0's l1: 0.308297\tvalid_0's l2: 0.159619\n",
      "[6]\tvalid_0's l1: 0.303729\tvalid_0's l2: 0.156066\n",
      "[7]\tvalid_0's l1: 0.300019\tvalid_0's l2: 0.153432\n",
      "[8]\tvalid_0's l1: 0.296483\tvalid_0's l2: 0.150935\n",
      "[9]\tvalid_0's l1: 0.293298\tvalid_0's l2: 0.148927\n",
      "[10]\tvalid_0's l1: 0.290562\tvalid_0's l2: 0.147566\n",
      "[11]\tvalid_0's l1: 0.287733\tvalid_0's l2: 0.145693\n",
      "[12]\tvalid_0's l1: 0.285495\tvalid_0's l2: 0.144653\n",
      "[13]\tvalid_0's l1: 0.283883\tvalid_0's l2: 0.144369\n",
      "[14]\tvalid_0's l1: 0.28228\tvalid_0's l2: 0.144177\n",
      "[15]\tvalid_0's l1: 0.281206\tvalid_0's l2: 0.144553\n",
      "[16]\tvalid_0's l1: 0.280238\tvalid_0's l2: 0.144962\n",
      "[17]\tvalid_0's l1: 0.279419\tvalid_0's l2: 0.145494\n",
      "[18]\tvalid_0's l1: 0.27857\tvalid_0's l2: 0.146055\n",
      "[19]\tvalid_0's l1: 0.278062\tvalid_0's l2: 0.147037\n",
      "[20]\tvalid_0's l1: 0.277584\tvalid_0's l2: 0.148076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.277584\tvalid_0's l2: 0.148076\n",
      "[1]\tvalid_0's l1: 0.334111\tvalid_0's l2: 0.185879\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326182\tvalid_0's l2: 0.178057\n",
      "[3]\tvalid_0's l1: 0.31939\tvalid_0's l2: 0.171284\n",
      "[4]\tvalid_0's l1: 0.313287\tvalid_0's l2: 0.165386\n",
      "[5]\tvalid_0's l1: 0.308088\tvalid_0's l2: 0.16032\n",
      "[6]\tvalid_0's l1: 0.30327\tvalid_0's l2: 0.156278\n",
      "[7]\tvalid_0's l1: 0.299067\tvalid_0's l2: 0.153316\n",
      "[8]\tvalid_0's l1: 0.295655\tvalid_0's l2: 0.151054\n",
      "[9]\tvalid_0's l1: 0.293021\tvalid_0's l2: 0.149679\n",
      "[10]\tvalid_0's l1: 0.290884\tvalid_0's l2: 0.148765\n",
      "[11]\tvalid_0's l1: 0.288812\tvalid_0's l2: 0.147991\n",
      "[12]\tvalid_0's l1: 0.287133\tvalid_0's l2: 0.147469\n",
      "[13]\tvalid_0's l1: 0.285602\tvalid_0's l2: 0.147189\n",
      "[14]\tvalid_0's l1: 0.284353\tvalid_0's l2: 0.14726\n",
      "[15]\tvalid_0's l1: 0.283507\tvalid_0's l2: 0.147929\n",
      "[16]\tvalid_0's l1: 0.282711\tvalid_0's l2: 0.148692\n",
      "[17]\tvalid_0's l1: 0.282045\tvalid_0's l2: 0.149278\n",
      "[18]\tvalid_0's l1: 0.281394\tvalid_0's l2: 0.150215\n",
      "[19]\tvalid_0's l1: 0.281171\tvalid_0's l2: 0.151375\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.285602\tvalid_0's l2: 0.147189\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.333352\tvalid_0's l2: 0.186106\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326645\tvalid_0's l2: 0.179467\n",
      "[3]\tvalid_0's l1: 0.320624\tvalid_0's l2: 0.173911\n",
      "[4]\tvalid_0's l1: 0.315428\tvalid_0's l2: 0.16923\n",
      "[5]\tvalid_0's l1: 0.311453\tvalid_0's l2: 0.166025\n",
      "[6]\tvalid_0's l1: 0.307947\tvalid_0's l2: 0.163291\n",
      "[7]\tvalid_0's l1: 0.305317\tvalid_0's l2: 0.161785\n",
      "[8]\tvalid_0's l1: 0.302931\tvalid_0's l2: 0.160636\n",
      "[9]\tvalid_0's l1: 0.300847\tvalid_0's l2: 0.159835\n",
      "[10]\tvalid_0's l1: 0.299348\tvalid_0's l2: 0.159863\n",
      "[11]\tvalid_0's l1: 0.297217\tvalid_0's l2: 0.159105\n",
      "[12]\tvalid_0's l1: 0.295408\tvalid_0's l2: 0.158809\n",
      "[13]\tvalid_0's l1: 0.294669\tvalid_0's l2: 0.159885\n",
      "[14]\tvalid_0's l1: 0.293928\tvalid_0's l2: 0.160856\n",
      "[15]\tvalid_0's l1: 0.293387\tvalid_0's l2: 0.162079\n",
      "[16]\tvalid_0's l1: 0.293\tvalid_0's l2: 0.16341\n",
      "[17]\tvalid_0's l1: 0.292966\tvalid_0's l2: 0.165139\n",
      "[18]\tvalid_0's l1: 0.292982\tvalid_0's l2: 0.167113\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.295408\tvalid_0's l2: 0.158809\n",
      "[1]\tvalid_0's l1: 0.333014\tvalid_0's l2: 0.186196\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32611\tvalid_0's l2: 0.179667\n",
      "[3]\tvalid_0's l1: 0.320249\tvalid_0's l2: 0.174206\n",
      "[4]\tvalid_0's l1: 0.315271\tvalid_0's l2: 0.169617\n",
      "[5]\tvalid_0's l1: 0.311201\tvalid_0's l2: 0.166406\n",
      "[6]\tvalid_0's l1: 0.307925\tvalid_0's l2: 0.163725\n",
      "[7]\tvalid_0's l1: 0.304807\tvalid_0's l2: 0.16167\n",
      "[8]\tvalid_0's l1: 0.302995\tvalid_0's l2: 0.160838\n",
      "[9]\tvalid_0's l1: 0.3017\tvalid_0's l2: 0.160895\n",
      "[10]\tvalid_0's l1: 0.300502\tvalid_0's l2: 0.161131\n",
      "[11]\tvalid_0's l1: 0.299748\tvalid_0's l2: 0.161808\n",
      "[12]\tvalid_0's l1: 0.299015\tvalid_0's l2: 0.162556\n",
      "[13]\tvalid_0's l1: 0.298592\tvalid_0's l2: 0.16407\n",
      "[14]\tvalid_0's l1: 0.298126\tvalid_0's l2: 0.165678\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.302995\tvalid_0's l2: 0.160838\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                             'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21], \n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        x_train_withoutCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_train_withCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        x_test_withoutCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_test_withCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # y: response (target) variable from DFma_1 to DFma_6 (col 19 -> col 14)\n",
    "        y_train = df_train_subdist.iloc[:, [19 - j]]\n",
    "        y_test = df_test_subdist.iloc[:, [19 - j]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_subdist['DFma_' + str(j + 1)])\n",
    "        y_test_true = np.array(df_test_subdist['DFma_' + str(j + 1)])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                                     + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 \n",
    "                                                     + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) + '_withoutCD_' \n",
    "                                                     + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 \n",
    "                                                  + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) + '_withCD_' \n",
    "                                                  + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) + '/MA' \n",
    "                                   + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) + '/MA' \n",
    "                                + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each sub-district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            #print(k)\n",
    "            #print('MA' + str(i) + 'DFma_' + str(j + 1) + ' R2 without ' + str(r2_withoutCD_subdist))\n",
    "            #print('MA' + str(i) + 'DFma_' + str(j + 1) + ' R2 with ' + str(r2_withCD_subdist))\n",
    "            #print('MA' + str(i) + 'DFma_' + str(j + 1) + ' R2 % ' + str(r2_percent_improved_subdist))\n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                       mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                       smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                       r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "            \n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                           + '/MA' + str(i) + '/LGBM_' + province2 + '_BySubdistrict_MA' + str(i) \n",
    "                                           + '_DFma_' + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', \n",
    "                                           header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                                 'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                                 'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                                 'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_subdist_eval_' + str(num_leaves) + '.csv', \n",
    "                                header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.455561\tvalid_0's l2: 0.37591\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448209\tvalid_0's l2: 0.367978\n",
      "[3]\tvalid_0's l1: 0.44102\tvalid_0's l2: 0.359705\n",
      "[4]\tvalid_0's l1: 0.434646\tvalid_0's l2: 0.353175\n",
      "[5]\tvalid_0's l1: 0.428013\tvalid_0's l2: 0.345992\n",
      "[6]\tvalid_0's l1: 0.422287\tvalid_0's l2: 0.340866\n",
      "[7]\tvalid_0's l1: 0.417234\tvalid_0's l2: 0.335992\n",
      "[8]\tvalid_0's l1: 0.411945\tvalid_0's l2: 0.331023\n",
      "[9]\tvalid_0's l1: 0.407359\tvalid_0's l2: 0.327279\n",
      "[10]\tvalid_0's l1: 0.403033\tvalid_0's l2: 0.323422\n",
      "[11]\tvalid_0's l1: 0.399084\tvalid_0's l2: 0.320253\n",
      "[12]\tvalid_0's l1: 0.395205\tvalid_0's l2: 0.317306\n",
      "[13]\tvalid_0's l1: 0.392027\tvalid_0's l2: 0.315088\n",
      "[14]\tvalid_0's l1: 0.389053\tvalid_0's l2: 0.31273\n",
      "[15]\tvalid_0's l1: 0.385967\tvalid_0's l2: 0.310184\n",
      "[16]\tvalid_0's l1: 0.38295\tvalid_0's l2: 0.308012\n",
      "[17]\tvalid_0's l1: 0.380255\tvalid_0's l2: 0.306147\n",
      "[18]\tvalid_0's l1: 0.377841\tvalid_0's l2: 0.30468\n",
      "[19]\tvalid_0's l1: 0.375375\tvalid_0's l2: 0.30296\n",
      "[20]\tvalid_0's l1: 0.373195\tvalid_0's l2: 0.301865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.373195\tvalid_0's l2: 0.301865\n",
      "[1]\tvalid_0's l1: 0.455559\tvalid_0's l2: 0.376111\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448451\tvalid_0's l2: 0.368307\n",
      "[3]\tvalid_0's l1: 0.441525\tvalid_0's l2: 0.36068\n",
      "[4]\tvalid_0's l1: 0.434501\tvalid_0's l2: 0.352668\n",
      "[5]\tvalid_0's l1: 0.428384\tvalid_0's l2: 0.346762\n",
      "[6]\tvalid_0's l1: 0.422568\tvalid_0's l2: 0.341406\n",
      "[7]\tvalid_0's l1: 0.417156\tvalid_0's l2: 0.336543\n",
      "[8]\tvalid_0's l1: 0.412018\tvalid_0's l2: 0.332025\n",
      "[9]\tvalid_0's l1: 0.407632\tvalid_0's l2: 0.327254\n",
      "[10]\tvalid_0's l1: 0.40358\tvalid_0's l2: 0.324021\n",
      "[11]\tvalid_0's l1: 0.399751\tvalid_0's l2: 0.320774\n",
      "[12]\tvalid_0's l1: 0.396266\tvalid_0's l2: 0.317903\n",
      "[13]\tvalid_0's l1: 0.392849\tvalid_0's l2: 0.31553\n",
      "[14]\tvalid_0's l1: 0.389701\tvalid_0's l2: 0.313514\n",
      "[15]\tvalid_0's l1: 0.386788\tvalid_0's l2: 0.311479\n",
      "[16]\tvalid_0's l1: 0.38383\tvalid_0's l2: 0.309741\n",
      "[17]\tvalid_0's l1: 0.381138\tvalid_0's l2: 0.308443\n",
      "[18]\tvalid_0's l1: 0.37846\tvalid_0's l2: 0.307198\n",
      "[19]\tvalid_0's l1: 0.376495\tvalid_0's l2: 0.305753\n",
      "[20]\tvalid_0's l1: 0.374212\tvalid_0's l2: 0.304606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.374212\tvalid_0's l2: 0.304606\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.457587\tvalid_0's l2: 0.381829\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.451228\tvalid_0's l2: 0.375396\n",
      "[3]\tvalid_0's l1: 0.4452\tvalid_0's l2: 0.369167\n",
      "[4]\tvalid_0's l1: 0.439931\tvalid_0's l2: 0.364248\n",
      "[5]\tvalid_0's l1: 0.434137\tvalid_0's l2: 0.357004\n",
      "[6]\tvalid_0's l1: 0.429076\tvalid_0's l2: 0.352307\n",
      "[7]\tvalid_0's l1: 0.424329\tvalid_0's l2: 0.348194\n",
      "[8]\tvalid_0's l1: 0.419914\tvalid_0's l2: 0.343335\n",
      "[9]\tvalid_0's l1: 0.416036\tvalid_0's l2: 0.339986\n",
      "[10]\tvalid_0's l1: 0.412319\tvalid_0's l2: 0.336244\n",
      "[11]\tvalid_0's l1: 0.408819\tvalid_0's l2: 0.333749\n",
      "[12]\tvalid_0's l1: 0.405482\tvalid_0's l2: 0.331163\n",
      "[13]\tvalid_0's l1: 0.402738\tvalid_0's l2: 0.329462\n",
      "[14]\tvalid_0's l1: 0.4\tvalid_0's l2: 0.32787\n",
      "[15]\tvalid_0's l1: 0.39726\tvalid_0's l2: 0.325744\n",
      "[16]\tvalid_0's l1: 0.394624\tvalid_0's l2: 0.323955\n",
      "[17]\tvalid_0's l1: 0.392064\tvalid_0's l2: 0.322715\n",
      "[18]\tvalid_0's l1: 0.389667\tvalid_0's l2: 0.321875\n",
      "[19]\tvalid_0's l1: 0.387459\tvalid_0's l2: 0.320576\n",
      "[20]\tvalid_0's l1: 0.385319\tvalid_0's l2: 0.319929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.385319\tvalid_0's l2: 0.319929\n",
      "[1]\tvalid_0's l1: 0.45763\tvalid_0's l2: 0.38206\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.451103\tvalid_0's l2: 0.375244\n",
      "[3]\tvalid_0's l1: 0.445215\tvalid_0's l2: 0.369262\n",
      "[4]\tvalid_0's l1: 0.438986\tvalid_0's l2: 0.361541\n",
      "[5]\tvalid_0's l1: 0.433684\tvalid_0's l2: 0.356697\n",
      "[6]\tvalid_0's l1: 0.428678\tvalid_0's l2: 0.351773\n",
      "[7]\tvalid_0's l1: 0.423995\tvalid_0's l2: 0.347634\n",
      "[8]\tvalid_0's l1: 0.419933\tvalid_0's l2: 0.344109\n",
      "[9]\tvalid_0's l1: 0.416033\tvalid_0's l2: 0.339499\n",
      "[10]\tvalid_0's l1: 0.412552\tvalid_0's l2: 0.336643\n",
      "[11]\tvalid_0's l1: 0.409196\tvalid_0's l2: 0.33408\n",
      "[12]\tvalid_0's l1: 0.406105\tvalid_0's l2: 0.331853\n",
      "[13]\tvalid_0's l1: 0.403402\tvalid_0's l2: 0.329978\n",
      "[14]\tvalid_0's l1: 0.400347\tvalid_0's l2: 0.328038\n",
      "[15]\tvalid_0's l1: 0.397633\tvalid_0's l2: 0.326407\n",
      "[16]\tvalid_0's l1: 0.395267\tvalid_0's l2: 0.325404\n",
      "[17]\tvalid_0's l1: 0.392655\tvalid_0's l2: 0.324113\n",
      "[18]\tvalid_0's l1: 0.390283\tvalid_0's l2: 0.323211\n",
      "[19]\tvalid_0's l1: 0.388087\tvalid_0's l2: 0.322312\n",
      "[20]\tvalid_0's l1: 0.386054\tvalid_0's l2: 0.321741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.386054\tvalid_0's l2: 0.321741\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45814\tvalid_0's l2: 0.385352\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.452342\tvalid_0's l2: 0.379011\n",
      "[3]\tvalid_0's l1: 0.44655\tvalid_0's l2: 0.37289\n",
      "[4]\tvalid_0's l1: 0.44135\tvalid_0's l2: 0.367706\n",
      "[5]\tvalid_0's l1: 0.435894\tvalid_0's l2: 0.360385\n",
      "[6]\tvalid_0's l1: 0.431229\tvalid_0's l2: 0.355901\n",
      "[7]\tvalid_0's l1: 0.426994\tvalid_0's l2: 0.352404\n",
      "[8]\tvalid_0's l1: 0.42265\tvalid_0's l2: 0.347653\n",
      "[9]\tvalid_0's l1: 0.418828\tvalid_0's l2: 0.344602\n",
      "[10]\tvalid_0's l1: 0.41524\tvalid_0's l2: 0.341087\n",
      "[11]\tvalid_0's l1: 0.4121\tvalid_0's l2: 0.339039\n",
      "[12]\tvalid_0's l1: 0.409322\tvalid_0's l2: 0.337246\n",
      "[13]\tvalid_0's l1: 0.406411\tvalid_0's l2: 0.335524\n",
      "[14]\tvalid_0's l1: 0.403948\tvalid_0's l2: 0.334269\n",
      "[15]\tvalid_0's l1: 0.401771\tvalid_0's l2: 0.332704\n",
      "[16]\tvalid_0's l1: 0.399648\tvalid_0's l2: 0.331379\n",
      "[17]\tvalid_0's l1: 0.397377\tvalid_0's l2: 0.330449\n",
      "[18]\tvalid_0's l1: 0.395494\tvalid_0's l2: 0.329998\n",
      "[19]\tvalid_0's l1: 0.393666\tvalid_0's l2: 0.328915\n",
      "[20]\tvalid_0's l1: 0.39191\tvalid_0's l2: 0.328627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.39191\tvalid_0's l2: 0.328627\n",
      "[1]\tvalid_0's l1: 0.458162\tvalid_0's l2: 0.385173\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.452186\tvalid_0's l2: 0.37861\n",
      "[3]\tvalid_0's l1: 0.446994\tvalid_0's l2: 0.37276\n",
      "[4]\tvalid_0's l1: 0.441116\tvalid_0's l2: 0.364974\n",
      "[5]\tvalid_0's l1: 0.436104\tvalid_0's l2: 0.360051\n",
      "[6]\tvalid_0's l1: 0.43151\tvalid_0's l2: 0.355687\n",
      "[7]\tvalid_0's l1: 0.427275\tvalid_0's l2: 0.351805\n",
      "[8]\tvalid_0's l1: 0.423451\tvalid_0's l2: 0.34858\n",
      "[9]\tvalid_0's l1: 0.419879\tvalid_0's l2: 0.344524\n",
      "[10]\tvalid_0's l1: 0.416378\tvalid_0's l2: 0.341829\n",
      "[11]\tvalid_0's l1: 0.413293\tvalid_0's l2: 0.339964\n",
      "[12]\tvalid_0's l1: 0.410665\tvalid_0's l2: 0.338504\n",
      "[13]\tvalid_0's l1: 0.408112\tvalid_0's l2: 0.337386\n",
      "[14]\tvalid_0's l1: 0.405737\tvalid_0's l2: 0.336571\n",
      "[15]\tvalid_0's l1: 0.403567\tvalid_0's l2: 0.335585\n",
      "[16]\tvalid_0's l1: 0.401303\tvalid_0's l2: 0.334685\n",
      "[17]\tvalid_0's l1: 0.399191\tvalid_0's l2: 0.334007\n",
      "[18]\tvalid_0's l1: 0.397403\tvalid_0's l2: 0.333661\n",
      "[19]\tvalid_0's l1: 0.395487\tvalid_0's l2: 0.333394\n",
      "[20]\tvalid_0's l1: 0.393699\tvalid_0's l2: 0.333019\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.393699\tvalid_0's l2: 0.333019\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.460589\tvalid_0's l2: 0.391921\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.45512\tvalid_0's l2: 0.385081\n",
      "[3]\tvalid_0's l1: 0.449872\tvalid_0's l2: 0.378617\n",
      "[4]\tvalid_0's l1: 0.445458\tvalid_0's l2: 0.373569\n",
      "[5]\tvalid_0's l1: 0.440442\tvalid_0's l2: 0.366965\n",
      "[6]\tvalid_0's l1: 0.436478\tvalid_0's l2: 0.362585\n",
      "[7]\tvalid_0's l1: 0.432692\tvalid_0's l2: 0.359329\n",
      "[8]\tvalid_0's l1: 0.429002\tvalid_0's l2: 0.355484\n",
      "[9]\tvalid_0's l1: 0.425998\tvalid_0's l2: 0.353268\n",
      "[10]\tvalid_0's l1: 0.423035\tvalid_0's l2: 0.350502\n",
      "[11]\tvalid_0's l1: 0.42045\tvalid_0's l2: 0.348488\n",
      "[12]\tvalid_0's l1: 0.417906\tvalid_0's l2: 0.347118\n",
      "[13]\tvalid_0's l1: 0.41559\tvalid_0's l2: 0.345965\n",
      "[14]\tvalid_0's l1: 0.413817\tvalid_0's l2: 0.34526\n",
      "[15]\tvalid_0's l1: 0.411955\tvalid_0's l2: 0.343835\n",
      "[16]\tvalid_0's l1: 0.409914\tvalid_0's l2: 0.342598\n",
      "[17]\tvalid_0's l1: 0.407941\tvalid_0's l2: 0.341955\n",
      "[18]\tvalid_0's l1: 0.406308\tvalid_0's l2: 0.341603\n",
      "[19]\tvalid_0's l1: 0.404714\tvalid_0's l2: 0.34067\n",
      "[20]\tvalid_0's l1: 0.403512\tvalid_0's l2: 0.340689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.403512\tvalid_0's l2: 0.340689\n",
      "[1]\tvalid_0's l1: 0.460559\tvalid_0's l2: 0.391767\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.45553\tvalid_0's l2: 0.385526\n",
      "[3]\tvalid_0's l1: 0.450421\tvalid_0's l2: 0.378579\n",
      "[4]\tvalid_0's l1: 0.445311\tvalid_0's l2: 0.371506\n",
      "[5]\tvalid_0's l1: 0.440999\tvalid_0's l2: 0.366248\n",
      "[6]\tvalid_0's l1: 0.436828\tvalid_0's l2: 0.361989\n",
      "[7]\tvalid_0's l1: 0.433065\tvalid_0's l2: 0.358752\n",
      "[8]\tvalid_0's l1: 0.429708\tvalid_0's l2: 0.355737\n",
      "[9]\tvalid_0's l1: 0.426822\tvalid_0's l2: 0.353001\n",
      "[10]\tvalid_0's l1: 0.424372\tvalid_0's l2: 0.350921\n",
      "[11]\tvalid_0's l1: 0.421647\tvalid_0's l2: 0.349113\n",
      "[12]\tvalid_0's l1: 0.419607\tvalid_0's l2: 0.348151\n",
      "[13]\tvalid_0's l1: 0.417907\tvalid_0's l2: 0.347529\n",
      "[14]\tvalid_0's l1: 0.416085\tvalid_0's l2: 0.347399\n",
      "[15]\tvalid_0's l1: 0.414564\tvalid_0's l2: 0.347045\n",
      "[16]\tvalid_0's l1: 0.41299\tvalid_0's l2: 0.346424\n",
      "[17]\tvalid_0's l1: 0.411462\tvalid_0's l2: 0.346084\n",
      "[18]\tvalid_0's l1: 0.409795\tvalid_0's l2: 0.345412\n",
      "[19]\tvalid_0's l1: 0.408275\tvalid_0's l2: 0.345431\n",
      "[20]\tvalid_0's l1: 0.406816\tvalid_0's l2: 0.345488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.406816\tvalid_0's l2: 0.345488\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.46092\tvalid_0's l2: 0.393605\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.455875\tvalid_0's l2: 0.387431\n",
      "[3]\tvalid_0's l1: 0.451199\tvalid_0's l2: 0.382666\n",
      "[4]\tvalid_0's l1: 0.447329\tvalid_0's l2: 0.378546\n",
      "[5]\tvalid_0's l1: 0.443374\tvalid_0's l2: 0.374407\n",
      "[6]\tvalid_0's l1: 0.4404\tvalid_0's l2: 0.371908\n",
      "[7]\tvalid_0's l1: 0.438018\tvalid_0's l2: 0.369916\n",
      "[8]\tvalid_0's l1: 0.435173\tvalid_0's l2: 0.367822\n",
      "[9]\tvalid_0's l1: 0.43318\tvalid_0's l2: 0.366669\n",
      "[10]\tvalid_0's l1: 0.431138\tvalid_0's l2: 0.365963\n",
      "[11]\tvalid_0's l1: 0.42927\tvalid_0's l2: 0.365228\n",
      "[12]\tvalid_0's l1: 0.427472\tvalid_0's l2: 0.364578\n",
      "[13]\tvalid_0's l1: 0.426077\tvalid_0's l2: 0.364837\n",
      "[14]\tvalid_0's l1: 0.424815\tvalid_0's l2: 0.365321\n",
      "[15]\tvalid_0's l1: 0.423875\tvalid_0's l2: 0.366458\n",
      "[16]\tvalid_0's l1: 0.422825\tvalid_0's l2: 0.367089\n",
      "[17]\tvalid_0's l1: 0.422166\tvalid_0's l2: 0.368083\n",
      "[18]\tvalid_0's l1: 0.421389\tvalid_0's l2: 0.368596\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.427472\tvalid_0's l2: 0.364578\n",
      "[1]\tvalid_0's l1: 0.4611\tvalid_0's l2: 0.393458\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.456545\tvalid_0's l2: 0.387771\n",
      "[3]\tvalid_0's l1: 0.45204\tvalid_0's l2: 0.382775\n",
      "[4]\tvalid_0's l1: 0.447853\tvalid_0's l2: 0.378356\n",
      "[5]\tvalid_0's l1: 0.444197\tvalid_0's l2: 0.375009\n",
      "[6]\tvalid_0's l1: 0.440921\tvalid_0's l2: 0.372211\n",
      "[7]\tvalid_0's l1: 0.437744\tvalid_0's l2: 0.369373\n",
      "[8]\tvalid_0's l1: 0.43522\tvalid_0's l2: 0.367267\n",
      "[9]\tvalid_0's l1: 0.433852\tvalid_0's l2: 0.366223\n",
      "[10]\tvalid_0's l1: 0.432165\tvalid_0's l2: 0.365817\n",
      "[11]\tvalid_0's l1: 0.430534\tvalid_0's l2: 0.364936\n",
      "[12]\tvalid_0's l1: 0.429186\tvalid_0's l2: 0.365592\n",
      "[13]\tvalid_0's l1: 0.427768\tvalid_0's l2: 0.366193\n",
      "[14]\tvalid_0's l1: 0.426632\tvalid_0's l2: 0.367308\n",
      "[15]\tvalid_0's l1: 0.426002\tvalid_0's l2: 0.369148\n",
      "[16]\tvalid_0's l1: 0.425371\tvalid_0's l2: 0.370078\n",
      "[17]\tvalid_0's l1: 0.424671\tvalid_0's l2: 0.371385\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.430534\tvalid_0's l2: 0.364936\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.46246\tvalid_0's l2: 0.395022\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.458257\tvalid_0's l2: 0.389705\n",
      "[3]\tvalid_0's l1: 0.454257\tvalid_0's l2: 0.385248\n",
      "[4]\tvalid_0's l1: 0.451306\tvalid_0's l2: 0.382245\n",
      "[5]\tvalid_0's l1: 0.447902\tvalid_0's l2: 0.379302\n",
      "[6]\tvalid_0's l1: 0.445138\tvalid_0's l2: 0.376999\n",
      "[7]\tvalid_0's l1: 0.443325\tvalid_0's l2: 0.375886\n",
      "[8]\tvalid_0's l1: 0.441568\tvalid_0's l2: 0.375069\n",
      "[9]\tvalid_0's l1: 0.440186\tvalid_0's l2: 0.374869\n",
      "[10]\tvalid_0's l1: 0.439145\tvalid_0's l2: 0.375349\n",
      "[11]\tvalid_0's l1: 0.43769\tvalid_0's l2: 0.374781\n",
      "[12]\tvalid_0's l1: 0.436292\tvalid_0's l2: 0.374386\n",
      "[13]\tvalid_0's l1: 0.435751\tvalid_0's l2: 0.375344\n",
      "[14]\tvalid_0's l1: 0.434883\tvalid_0's l2: 0.375916\n",
      "[15]\tvalid_0's l1: 0.434674\tvalid_0's l2: 0.377732\n",
      "[16]\tvalid_0's l1: 0.434172\tvalid_0's l2: 0.379153\n",
      "[17]\tvalid_0's l1: 0.433709\tvalid_0's l2: 0.38045\n",
      "[18]\tvalid_0's l1: 0.433275\tvalid_0's l2: 0.382021\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.436292\tvalid_0's l2: 0.374386\n",
      "[1]\tvalid_0's l1: 0.462133\tvalid_0's l2: 0.394798\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.458322\tvalid_0's l2: 0.389965\n",
      "[3]\tvalid_0's l1: 0.454137\tvalid_0's l2: 0.385148\n",
      "[4]\tvalid_0's l1: 0.45062\tvalid_0's l2: 0.381662\n",
      "[5]\tvalid_0's l1: 0.447711\tvalid_0's l2: 0.379162\n",
      "[6]\tvalid_0's l1: 0.445322\tvalid_0's l2: 0.377248\n",
      "[7]\tvalid_0's l1: 0.443342\tvalid_0's l2: 0.3758\n",
      "[8]\tvalid_0's l1: 0.441485\tvalid_0's l2: 0.374894\n",
      "[9]\tvalid_0's l1: 0.440265\tvalid_0's l2: 0.374712\n",
      "[10]\tvalid_0's l1: 0.438959\tvalid_0's l2: 0.374815\n",
      "[11]\tvalid_0's l1: 0.438402\tvalid_0's l2: 0.375648\n",
      "[12]\tvalid_0's l1: 0.437802\tvalid_0's l2: 0.377323\n",
      "[13]\tvalid_0's l1: 0.437502\tvalid_0's l2: 0.379245\n",
      "[14]\tvalid_0's l1: 0.43724\tvalid_0's l2: 0.381442\n",
      "[15]\tvalid_0's l1: 0.436602\tvalid_0's l2: 0.383073\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.440265\tvalid_0's l2: 0.374712\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                             'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_total_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin [col 26],\n",
    "    # bowl [col 27],\n",
    "    # bucket [col 28],\n",
    "    # misc_short [col 29],\n",
    "    # jars [col 30],\n",
    "    # pottedplant [col 31],\n",
    "    # tire [col 32],\n",
    "    # misc_tall [col 33],\n",
    "    # and total [col 34]\n",
    "        \n",
    "    x_train_withoutCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_train_withCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    x_test_withoutCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_test_withCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # y: response (target) variable from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    y_train = df_train_subdist.iloc[:, [9 - i]]\n",
    "    y_test = df_test_subdist.iloc[:, [9 - i]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_subdist['DF_' + str(i + 1)])\n",
    "    y_test_true = np.array(df_test_subdist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                                 + str(num_leaves) + '/Original DF_0/LGBM_' + province2 \n",
    "                                                 + '_subdist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                                                 + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 \n",
    "                                              + '_subdist_original_DF_' + str(i + 1) + '_withCD_' + str(num_leaves) \n",
    "                                              + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) \n",
    "                               + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) \n",
    "                            + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                   mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                   smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                   r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                       + '/Original DF_0/LGBM_' + province2 + '_BySubDistrict_Original_DF_' + str(i + 1) \n",
    "                                       + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_subdist_original_eval_' + str(num_leaves) + '.csv', \n",
    "                                header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.384872\tvalid_0's l2: 0.24629\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3726\tvalid_0's l2: 0.232502\n",
      "[3]\tvalid_0's l1: 0.360453\tvalid_0's l2: 0.218978\n",
      "[4]\tvalid_0's l1: 0.349779\tvalid_0's l2: 0.207874\n",
      "[5]\tvalid_0's l1: 0.338148\tvalid_0's l2: 0.195106\n",
      "[6]\tvalid_0's l1: 0.32797\tvalid_0's l2: 0.185136\n",
      "[7]\tvalid_0's l1: 0.322048\tvalid_0's l2: 0.180548\n",
      "[8]\tvalid_0's l1: 0.31222\tvalid_0's l2: 0.170802\n",
      "[9]\tvalid_0's l1: 0.304214\tvalid_0's l2: 0.163652\n",
      "[10]\tvalid_0's l1: 0.295606\tvalid_0's l2: 0.15565\n",
      "[11]\tvalid_0's l1: 0.287971\tvalid_0's l2: 0.149105\n",
      "[12]\tvalid_0's l1: 0.280955\tvalid_0's l2: 0.143072\n",
      "[13]\tvalid_0's l1: 0.27518\tvalid_0's l2: 0.138624\n",
      "[14]\tvalid_0's l1: 0.269013\tvalid_0's l2: 0.13344\n",
      "[15]\tvalid_0's l1: 0.262986\tvalid_0's l2: 0.128386\n",
      "[16]\tvalid_0's l1: 0.257241\tvalid_0's l2: 0.123842\n",
      "[17]\tvalid_0's l1: 0.254262\tvalid_0's l2: 0.122222\n",
      "[18]\tvalid_0's l1: 0.249621\tvalid_0's l2: 0.119171\n",
      "[19]\tvalid_0's l1: 0.244895\tvalid_0's l2: 0.115666\n",
      "[20]\tvalid_0's l1: 0.240954\tvalid_0's l2: 0.1133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.240954\tvalid_0's l2: 0.1133\n",
      "[1]\tvalid_0's l1: 0.384845\tvalid_0's l2: 0.246232\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.372547\tvalid_0's l2: 0.232407\n",
      "[3]\tvalid_0's l1: 0.360384\tvalid_0's l2: 0.218784\n",
      "[4]\tvalid_0's l1: 0.348102\tvalid_0's l2: 0.204982\n",
      "[5]\tvalid_0's l1: 0.336914\tvalid_0's l2: 0.193574\n",
      "[6]\tvalid_0's l1: 0.326353\tvalid_0's l2: 0.183236\n",
      "[7]\tvalid_0's l1: 0.316447\tvalid_0's l2: 0.17391\n",
      "[8]\tvalid_0's l1: 0.307288\tvalid_0's l2: 0.165333\n",
      "[9]\tvalid_0's l1: 0.301838\tvalid_0's l2: 0.160509\n",
      "[10]\tvalid_0's l1: 0.293646\tvalid_0's l2: 0.153392\n",
      "[11]\tvalid_0's l1: 0.286146\tvalid_0's l2: 0.146922\n",
      "[12]\tvalid_0's l1: 0.279291\tvalid_0's l2: 0.141179\n",
      "[13]\tvalid_0's l1: 0.272884\tvalid_0's l2: 0.135798\n",
      "[14]\tvalid_0's l1: 0.267032\tvalid_0's l2: 0.131125\n",
      "[15]\tvalid_0's l1: 0.261432\tvalid_0's l2: 0.126695\n",
      "[16]\tvalid_0's l1: 0.256177\tvalid_0's l2: 0.122987\n",
      "[17]\tvalid_0's l1: 0.251291\tvalid_0's l2: 0.119681\n",
      "[18]\tvalid_0's l1: 0.246641\tvalid_0's l2: 0.116705\n",
      "[19]\tvalid_0's l1: 0.243969\tvalid_0's l2: 0.115234\n",
      "[20]\tvalid_0's l1: 0.23979\tvalid_0's l2: 0.112497\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.23979\tvalid_0's l2: 0.112497\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.389882\tvalid_0's l2: 0.255768\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382221\tvalid_0's l2: 0.248047\n",
      "[3]\tvalid_0's l1: 0.37515\tvalid_0's l2: 0.241481\n",
      "[4]\tvalid_0's l1: 0.368258\tvalid_0's l2: 0.234954\n",
      "[5]\tvalid_0's l1: 0.361476\tvalid_0's l2: 0.227893\n",
      "[6]\tvalid_0's l1: 0.355351\tvalid_0's l2: 0.222785\n",
      "[7]\tvalid_0's l1: 0.349945\tvalid_0's l2: 0.218613\n",
      "[8]\tvalid_0's l1: 0.344591\tvalid_0's l2: 0.213618\n",
      "[9]\tvalid_0's l1: 0.339724\tvalid_0's l2: 0.210093\n",
      "[10]\tvalid_0's l1: 0.335199\tvalid_0's l2: 0.206173\n",
      "[11]\tvalid_0's l1: 0.331423\tvalid_0's l2: 0.203555\n",
      "[12]\tvalid_0's l1: 0.327911\tvalid_0's l2: 0.201279\n",
      "[13]\tvalid_0's l1: 0.324467\tvalid_0's l2: 0.199048\n",
      "[14]\tvalid_0's l1: 0.32155\tvalid_0's l2: 0.197285\n",
      "[15]\tvalid_0's l1: 0.318758\tvalid_0's l2: 0.195186\n",
      "[16]\tvalid_0's l1: 0.315968\tvalid_0's l2: 0.193138\n",
      "[17]\tvalid_0's l1: 0.313292\tvalid_0's l2: 0.191625\n",
      "[18]\tvalid_0's l1: 0.310923\tvalid_0's l2: 0.190509\n",
      "[19]\tvalid_0's l1: 0.308758\tvalid_0's l2: 0.189245\n",
      "[20]\tvalid_0's l1: 0.306739\tvalid_0's l2: 0.188414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.306739\tvalid_0's l2: 0.188414\n",
      "[1]\tvalid_0's l1: 0.389907\tvalid_0's l2: 0.255654\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.381862\tvalid_0's l2: 0.24751\n",
      "[3]\tvalid_0's l1: 0.374536\tvalid_0's l2: 0.240434\n",
      "[4]\tvalid_0's l1: 0.367073\tvalid_0's l2: 0.232287\n",
      "[5]\tvalid_0's l1: 0.360833\tvalid_0's l2: 0.226757\n",
      "[6]\tvalid_0's l1: 0.354907\tvalid_0's l2: 0.221682\n",
      "[7]\tvalid_0's l1: 0.349356\tvalid_0's l2: 0.217474\n",
      "[8]\tvalid_0's l1: 0.344057\tvalid_0's l2: 0.213409\n",
      "[9]\tvalid_0's l1: 0.33914\tvalid_0's l2: 0.208887\n",
      "[10]\tvalid_0's l1: 0.334633\tvalid_0's l2: 0.205622\n",
      "[11]\tvalid_0's l1: 0.330754\tvalid_0's l2: 0.202816\n",
      "[12]\tvalid_0's l1: 0.327237\tvalid_0's l2: 0.200295\n",
      "[13]\tvalid_0's l1: 0.324043\tvalid_0's l2: 0.198232\n",
      "[14]\tvalid_0's l1: 0.320909\tvalid_0's l2: 0.196155\n",
      "[15]\tvalid_0's l1: 0.318233\tvalid_0's l2: 0.194529\n",
      "[16]\tvalid_0's l1: 0.315683\tvalid_0's l2: 0.193085\n",
      "[17]\tvalid_0's l1: 0.313145\tvalid_0's l2: 0.191985\n",
      "[18]\tvalid_0's l1: 0.310838\tvalid_0's l2: 0.190876\n",
      "[19]\tvalid_0's l1: 0.30856\tvalid_0's l2: 0.189705\n",
      "[20]\tvalid_0's l1: 0.306616\tvalid_0's l2: 0.189035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.306616\tvalid_0's l2: 0.189035\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.390094\tvalid_0's l2: 0.258094\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382637\tvalid_0's l2: 0.25082\n",
      "[3]\tvalid_0's l1: 0.375881\tvalid_0's l2: 0.244576\n",
      "[4]\tvalid_0's l1: 0.369783\tvalid_0's l2: 0.239091\n",
      "[5]\tvalid_0's l1: 0.36363\tvalid_0's l2: 0.232221\n",
      "[6]\tvalid_0's l1: 0.358096\tvalid_0's l2: 0.227649\n",
      "[7]\tvalid_0's l1: 0.353369\tvalid_0's l2: 0.224066\n",
      "[8]\tvalid_0's l1: 0.348587\tvalid_0's l2: 0.219518\n",
      "[9]\tvalid_0's l1: 0.344418\tvalid_0's l2: 0.216475\n",
      "[10]\tvalid_0's l1: 0.340216\tvalid_0's l2: 0.212875\n",
      "[11]\tvalid_0's l1: 0.336724\tvalid_0's l2: 0.21068\n",
      "[12]\tvalid_0's l1: 0.333486\tvalid_0's l2: 0.208688\n",
      "[13]\tvalid_0's l1: 0.33045\tvalid_0's l2: 0.207011\n",
      "[14]\tvalid_0's l1: 0.328154\tvalid_0's l2: 0.205725\n",
      "[15]\tvalid_0's l1: 0.325423\tvalid_0's l2: 0.203823\n",
      "[16]\tvalid_0's l1: 0.322947\tvalid_0's l2: 0.202078\n",
      "[17]\tvalid_0's l1: 0.320975\tvalid_0's l2: 0.201515\n",
      "[18]\tvalid_0's l1: 0.319009\tvalid_0's l2: 0.200927\n",
      "[19]\tvalid_0's l1: 0.317015\tvalid_0's l2: 0.199683\n",
      "[20]\tvalid_0's l1: 0.315358\tvalid_0's l2: 0.199541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.315358\tvalid_0's l2: 0.199541\n",
      "[1]\tvalid_0's l1: 0.39017\tvalid_0's l2: 0.258473\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.383058\tvalid_0's l2: 0.251817\n",
      "[3]\tvalid_0's l1: 0.37645\tvalid_0's l2: 0.245936\n",
      "[4]\tvalid_0's l1: 0.369819\tvalid_0's l2: 0.238496\n",
      "[5]\tvalid_0's l1: 0.36438\tvalid_0's l2: 0.233833\n",
      "[6]\tvalid_0's l1: 0.358922\tvalid_0's l2: 0.229342\n",
      "[7]\tvalid_0's l1: 0.353788\tvalid_0's l2: 0.225097\n",
      "[8]\tvalid_0's l1: 0.348968\tvalid_0's l2: 0.221144\n",
      "[9]\tvalid_0's l1: 0.344601\tvalid_0's l2: 0.217155\n",
      "[10]\tvalid_0's l1: 0.340759\tvalid_0's l2: 0.214416\n",
      "[11]\tvalid_0's l1: 0.337431\tvalid_0's l2: 0.212042\n",
      "[12]\tvalid_0's l1: 0.334687\tvalid_0's l2: 0.210308\n",
      "[13]\tvalid_0's l1: 0.331993\tvalid_0's l2: 0.20872\n",
      "[14]\tvalid_0's l1: 0.329094\tvalid_0's l2: 0.20702\n",
      "[15]\tvalid_0's l1: 0.326628\tvalid_0's l2: 0.205694\n",
      "[16]\tvalid_0's l1: 0.324174\tvalid_0's l2: 0.204748\n",
      "[17]\tvalid_0's l1: 0.321857\tvalid_0's l2: 0.203728\n",
      "[18]\tvalid_0's l1: 0.319868\tvalid_0's l2: 0.2032\n",
      "[19]\tvalid_0's l1: 0.318085\tvalid_0's l2: 0.202785\n",
      "[20]\tvalid_0's l1: 0.316398\tvalid_0's l2: 0.202513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.316398\tvalid_0's l2: 0.202513\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.388784\tvalid_0's l2: 0.258282\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.381209\tvalid_0's l2: 0.249744\n",
      "[3]\tvalid_0's l1: 0.37486\tvalid_0's l2: 0.243162\n",
      "[4]\tvalid_0's l1: 0.36891\tvalid_0's l2: 0.237423\n",
      "[5]\tvalid_0's l1: 0.363275\tvalid_0's l2: 0.23132\n",
      "[6]\tvalid_0's l1: 0.358596\tvalid_0's l2: 0.227164\n",
      "[7]\tvalid_0's l1: 0.354054\tvalid_0's l2: 0.223662\n",
      "[8]\tvalid_0's l1: 0.350014\tvalid_0's l2: 0.219826\n",
      "[9]\tvalid_0's l1: 0.34689\tvalid_0's l2: 0.217486\n",
      "[10]\tvalid_0's l1: 0.343629\tvalid_0's l2: 0.214931\n",
      "[11]\tvalid_0's l1: 0.340685\tvalid_0's l2: 0.213123\n",
      "[12]\tvalid_0's l1: 0.338\tvalid_0's l2: 0.211537\n",
      "[13]\tvalid_0's l1: 0.3358\tvalid_0's l2: 0.210469\n",
      "[14]\tvalid_0's l1: 0.333674\tvalid_0's l2: 0.209489\n",
      "[15]\tvalid_0's l1: 0.331846\tvalid_0's l2: 0.208449\n",
      "[16]\tvalid_0's l1: 0.330061\tvalid_0's l2: 0.207656\n",
      "[17]\tvalid_0's l1: 0.328432\tvalid_0's l2: 0.207704\n",
      "[18]\tvalid_0's l1: 0.32702\tvalid_0's l2: 0.20778\n",
      "[19]\tvalid_0's l1: 0.325706\tvalid_0's l2: 0.207653\n",
      "[20]\tvalid_0's l1: 0.324436\tvalid_0's l2: 0.207901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.324436\tvalid_0's l2: 0.207901\n",
      "[1]\tvalid_0's l1: 0.388888\tvalid_0's l2: 0.258708\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382518\tvalid_0's l2: 0.251699\n",
      "[3]\tvalid_0's l1: 0.376344\tvalid_0's l2: 0.245514\n",
      "[4]\tvalid_0's l1: 0.369994\tvalid_0's l2: 0.23763\n",
      "[5]\tvalid_0's l1: 0.364541\tvalid_0's l2: 0.232149\n",
      "[6]\tvalid_0's l1: 0.360159\tvalid_0's l2: 0.2284\n",
      "[7]\tvalid_0's l1: 0.35593\tvalid_0's l2: 0.225009\n",
      "[8]\tvalid_0's l1: 0.352534\tvalid_0's l2: 0.22241\n",
      "[9]\tvalid_0's l1: 0.349072\tvalid_0's l2: 0.219449\n",
      "[10]\tvalid_0's l1: 0.346272\tvalid_0's l2: 0.217775\n",
      "[11]\tvalid_0's l1: 0.343738\tvalid_0's l2: 0.216307\n",
      "[12]\tvalid_0's l1: 0.341096\tvalid_0's l2: 0.214833\n",
      "[13]\tvalid_0's l1: 0.338792\tvalid_0's l2: 0.213764\n",
      "[14]\tvalid_0's l1: 0.336598\tvalid_0's l2: 0.212961\n",
      "[15]\tvalid_0's l1: 0.334652\tvalid_0's l2: 0.212232\n",
      "[16]\tvalid_0's l1: 0.332587\tvalid_0's l2: 0.211278\n",
      "[17]\tvalid_0's l1: 0.330963\tvalid_0's l2: 0.211004\n",
      "[18]\tvalid_0's l1: 0.329474\tvalid_0's l2: 0.210837\n",
      "[19]\tvalid_0's l1: 0.328025\tvalid_0's l2: 0.210615\n",
      "[20]\tvalid_0's l1: 0.326948\tvalid_0's l2: 0.210646\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.326948\tvalid_0's l2: 0.210646\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.388875\tvalid_0's l2: 0.259564\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382213\tvalid_0's l2: 0.251808\n",
      "[3]\tvalid_0's l1: 0.37652\tvalid_0's l2: 0.245931\n",
      "[4]\tvalid_0's l1: 0.371472\tvalid_0's l2: 0.240703\n",
      "[5]\tvalid_0's l1: 0.366954\tvalid_0's l2: 0.235854\n",
      "[6]\tvalid_0's l1: 0.363161\tvalid_0's l2: 0.232768\n",
      "[7]\tvalid_0's l1: 0.360102\tvalid_0's l2: 0.230598\n",
      "[8]\tvalid_0's l1: 0.356997\tvalid_0's l2: 0.228181\n",
      "[9]\tvalid_0's l1: 0.354291\tvalid_0's l2: 0.226592\n",
      "[10]\tvalid_0's l1: 0.352056\tvalid_0's l2: 0.22516\n",
      "[11]\tvalid_0's l1: 0.349685\tvalid_0's l2: 0.224047\n",
      "[12]\tvalid_0's l1: 0.347519\tvalid_0's l2: 0.223106\n",
      "[13]\tvalid_0's l1: 0.346027\tvalid_0's l2: 0.223099\n",
      "[14]\tvalid_0's l1: 0.344494\tvalid_0's l2: 0.22316\n",
      "[15]\tvalid_0's l1: 0.343523\tvalid_0's l2: 0.223761\n",
      "[16]\tvalid_0's l1: 0.342503\tvalid_0's l2: 0.224209\n",
      "[17]\tvalid_0's l1: 0.341635\tvalid_0's l2: 0.225061\n",
      "[18]\tvalid_0's l1: 0.340651\tvalid_0's l2: 0.225621\n",
      "[19]\tvalid_0's l1: 0.339994\tvalid_0's l2: 0.226305\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.346027\tvalid_0's l2: 0.223099\n",
      "[1]\tvalid_0's l1: 0.388772\tvalid_0's l2: 0.259253\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.382332\tvalid_0's l2: 0.251807\n",
      "[3]\tvalid_0's l1: 0.376643\tvalid_0's l2: 0.245916\n",
      "[4]\tvalid_0's l1: 0.371352\tvalid_0's l2: 0.240262\n",
      "[5]\tvalid_0's l1: 0.366629\tvalid_0's l2: 0.235987\n",
      "[6]\tvalid_0's l1: 0.362848\tvalid_0's l2: 0.232794\n",
      "[7]\tvalid_0's l1: 0.359685\tvalid_0's l2: 0.230363\n",
      "[8]\tvalid_0's l1: 0.357073\tvalid_0's l2: 0.228638\n",
      "[9]\tvalid_0's l1: 0.355089\tvalid_0's l2: 0.227712\n",
      "[10]\tvalid_0's l1: 0.353384\tvalid_0's l2: 0.227111\n",
      "[11]\tvalid_0's l1: 0.351374\tvalid_0's l2: 0.225962\n",
      "[12]\tvalid_0's l1: 0.350304\tvalid_0's l2: 0.226232\n",
      "[13]\tvalid_0's l1: 0.349467\tvalid_0's l2: 0.227251\n",
      "[14]\tvalid_0's l1: 0.348745\tvalid_0's l2: 0.228764\n",
      "[15]\tvalid_0's l1: 0.347578\tvalid_0's l2: 0.22947\n",
      "[16]\tvalid_0's l1: 0.3464\tvalid_0's l2: 0.229808\n",
      "[17]\tvalid_0's l1: 0.345322\tvalid_0's l2: 0.23054\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.351374\tvalid_0's l2: 0.225962\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.38907\tvalid_0's l2: 0.26051\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.38374\tvalid_0's l2: 0.254557\n",
      "[3]\tvalid_0's l1: 0.378664\tvalid_0's l2: 0.250083\n",
      "[4]\tvalid_0's l1: 0.374402\tvalid_0's l2: 0.246251\n",
      "[5]\tvalid_0's l1: 0.370758\tvalid_0's l2: 0.243275\n",
      "[6]\tvalid_0's l1: 0.367664\tvalid_0's l2: 0.240924\n",
      "[7]\tvalid_0's l1: 0.365047\tvalid_0's l2: 0.239476\n",
      "[8]\tvalid_0's l1: 0.362763\tvalid_0's l2: 0.238193\n",
      "[9]\tvalid_0's l1: 0.360762\tvalid_0's l2: 0.237362\n",
      "[10]\tvalid_0's l1: 0.359246\tvalid_0's l2: 0.237152\n",
      "[11]\tvalid_0's l1: 0.357255\tvalid_0's l2: 0.236452\n",
      "[12]\tvalid_0's l1: 0.355477\tvalid_0's l2: 0.23598\n",
      "[13]\tvalid_0's l1: 0.354752\tvalid_0's l2: 0.236881\n",
      "[14]\tvalid_0's l1: 0.354104\tvalid_0's l2: 0.237872\n",
      "[15]\tvalid_0's l1: 0.353783\tvalid_0's l2: 0.239425\n",
      "[16]\tvalid_0's l1: 0.353299\tvalid_0's l2: 0.240639\n",
      "[17]\tvalid_0's l1: 0.35347\tvalid_0's l2: 0.242855\n",
      "[18]\tvalid_0's l1: 0.353084\tvalid_0's l2: 0.244514\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.355477\tvalid_0's l2: 0.23598\n",
      "[1]\tvalid_0's l1: 0.388939\tvalid_0's l2: 0.259596\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.383229\tvalid_0's l2: 0.253254\n",
      "[3]\tvalid_0's l1: 0.378018\tvalid_0's l2: 0.248679\n",
      "[4]\tvalid_0's l1: 0.373834\tvalid_0's l2: 0.244873\n",
      "[5]\tvalid_0's l1: 0.370582\tvalid_0's l2: 0.242276\n",
      "[6]\tvalid_0's l1: 0.367847\tvalid_0's l2: 0.240188\n",
      "[7]\tvalid_0's l1: 0.365349\tvalid_0's l2: 0.238882\n",
      "[8]\tvalid_0's l1: 0.363377\tvalid_0's l2: 0.237904\n",
      "[9]\tvalid_0's l1: 0.362122\tvalid_0's l2: 0.238446\n",
      "[10]\tvalid_0's l1: 0.361026\tvalid_0's l2: 0.238967\n",
      "[11]\tvalid_0's l1: 0.360308\tvalid_0's l2: 0.240173\n",
      "[12]\tvalid_0's l1: 0.359775\tvalid_0's l2: 0.241917\n",
      "[13]\tvalid_0's l1: 0.358914\tvalid_0's l2: 0.243262\n",
      "[14]\tvalid_0's l1: 0.35854\tvalid_0's l2: 0.245253\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.363377\tvalid_0's l2: 0.237904\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.354216\tvalid_0's l2: 0.202885\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.339778\tvalid_0's l2: 0.187412\n",
      "[3]\tvalid_0's l1: 0.326453\tvalid_0's l2: 0.17395\n",
      "[4]\tvalid_0's l1: 0.313627\tvalid_0's l2: 0.161192\n",
      "[5]\tvalid_0's l1: 0.301136\tvalid_0's l2: 0.149136\n",
      "[6]\tvalid_0's l1: 0.290114\tvalid_0's l2: 0.139402\n",
      "[7]\tvalid_0's l1: 0.281812\tvalid_0's l2: 0.132686\n",
      "[8]\tvalid_0's l1: 0.271321\tvalid_0's l2: 0.123571\n",
      "[9]\tvalid_0's l1: 0.26165\tvalid_0's l2: 0.115835\n",
      "[10]\tvalid_0's l1: 0.252399\tvalid_0's l2: 0.108431\n",
      "[11]\tvalid_0's l1: 0.24388\tvalid_0's l2: 0.102092\n",
      "[12]\tvalid_0's l1: 0.235865\tvalid_0's l2: 0.0963975\n",
      "[13]\tvalid_0's l1: 0.228421\tvalid_0's l2: 0.0911529\n",
      "[14]\tvalid_0's l1: 0.22159\tvalid_0's l2: 0.0865728\n",
      "[15]\tvalid_0's l1: 0.214921\tvalid_0's l2: 0.082239\n",
      "[16]\tvalid_0's l1: 0.208608\tvalid_0's l2: 0.0782115\n",
      "[17]\tvalid_0's l1: 0.204241\tvalid_0's l2: 0.0757455\n",
      "[18]\tvalid_0's l1: 0.199071\tvalid_0's l2: 0.0727304\n",
      "[19]\tvalid_0's l1: 0.193759\tvalid_0's l2: 0.069657\n",
      "[20]\tvalid_0's l1: 0.189155\tvalid_0's l2: 0.0672152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189155\tvalid_0's l2: 0.0672152\n",
      "[1]\tvalid_0's l1: 0.35424\tvalid_0's l2: 0.202748\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.340288\tvalid_0's l2: 0.188181\n",
      "[3]\tvalid_0's l1: 0.327016\tvalid_0's l2: 0.174859\n",
      "[4]\tvalid_0's l1: 0.313908\tvalid_0's l2: 0.161494\n",
      "[5]\tvalid_0's l1: 0.301853\tvalid_0's l2: 0.150287\n",
      "[6]\tvalid_0's l1: 0.290333\tvalid_0's l2: 0.139983\n",
      "[7]\tvalid_0's l1: 0.27978\tvalid_0's l2: 0.131012\n",
      "[8]\tvalid_0's l1: 0.269581\tvalid_0's l2: 0.122549\n",
      "[9]\tvalid_0's l1: 0.261539\tvalid_0's l2: 0.116113\n",
      "[10]\tvalid_0's l1: 0.252562\tvalid_0's l2: 0.108996\n",
      "[11]\tvalid_0's l1: 0.243954\tvalid_0's l2: 0.102429\n",
      "[12]\tvalid_0's l1: 0.235965\tvalid_0's l2: 0.0966091\n",
      "[13]\tvalid_0's l1: 0.228594\tvalid_0's l2: 0.0914509\n",
      "[14]\tvalid_0's l1: 0.221692\tvalid_0's l2: 0.0867939\n",
      "[15]\tvalid_0's l1: 0.215289\tvalid_0's l2: 0.082739\n",
      "[16]\tvalid_0's l1: 0.209323\tvalid_0's l2: 0.0791176\n",
      "[17]\tvalid_0's l1: 0.203473\tvalid_0's l2: 0.0755534\n",
      "[18]\tvalid_0's l1: 0.198044\tvalid_0's l2: 0.0724244\n",
      "[19]\tvalid_0's l1: 0.194356\tvalid_0's l2: 0.0705354\n",
      "[20]\tvalid_0's l1: 0.189411\tvalid_0's l2: 0.0678734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189411\tvalid_0's l2: 0.0678734\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.356803\tvalid_0's l2: 0.20837\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345637\tvalid_0's l2: 0.197005\n",
      "[3]\tvalid_0's l1: 0.33511\tvalid_0's l2: 0.186665\n",
      "[4]\tvalid_0's l1: 0.325495\tvalid_0's l2: 0.177551\n",
      "[5]\tvalid_0's l1: 0.315647\tvalid_0's l2: 0.167518\n",
      "[6]\tvalid_0's l1: 0.306902\tvalid_0's l2: 0.159537\n",
      "[7]\tvalid_0's l1: 0.30102\tvalid_0's l2: 0.154976\n",
      "[8]\tvalid_0's l1: 0.29287\tvalid_0's l2: 0.147543\n",
      "[9]\tvalid_0's l1: 0.286397\tvalid_0's l2: 0.142243\n",
      "[10]\tvalid_0's l1: 0.279448\tvalid_0's l2: 0.136242\n",
      "[11]\tvalid_0's l1: 0.273308\tvalid_0's l2: 0.131539\n",
      "[12]\tvalid_0's l1: 0.267682\tvalid_0's l2: 0.127372\n",
      "[13]\tvalid_0's l1: 0.263025\tvalid_0's l2: 0.123983\n",
      "[14]\tvalid_0's l1: 0.258273\tvalid_0's l2: 0.120588\n",
      "[15]\tvalid_0's l1: 0.253453\tvalid_0's l2: 0.117004\n",
      "[16]\tvalid_0's l1: 0.249036\tvalid_0's l2: 0.113998\n",
      "[17]\tvalid_0's l1: 0.246418\tvalid_0's l2: 0.112605\n",
      "[18]\tvalid_0's l1: 0.242597\tvalid_0's l2: 0.110379\n",
      "[19]\tvalid_0's l1: 0.239109\tvalid_0's l2: 0.108212\n",
      "[20]\tvalid_0's l1: 0.236012\tvalid_0's l2: 0.106566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.236012\tvalid_0's l2: 0.106566\n",
      "[1]\tvalid_0's l1: 0.35687\tvalid_0's l2: 0.208536\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345798\tvalid_0's l2: 0.197282\n",
      "[3]\tvalid_0's l1: 0.335308\tvalid_0's l2: 0.187007\n",
      "[4]\tvalid_0's l1: 0.324698\tvalid_0's l2: 0.176355\n",
      "[5]\tvalid_0's l1: 0.315535\tvalid_0's l2: 0.167992\n",
      "[6]\tvalid_0's l1: 0.306725\tvalid_0's l2: 0.159933\n",
      "[7]\tvalid_0's l1: 0.298641\tvalid_0's l2: 0.152857\n",
      "[8]\tvalid_0's l1: 0.291149\tvalid_0's l2: 0.14644\n",
      "[9]\tvalid_0's l1: 0.28575\tvalid_0's l2: 0.142194\n",
      "[10]\tvalid_0's l1: 0.279305\tvalid_0's l2: 0.136887\n",
      "[11]\tvalid_0's l1: 0.273166\tvalid_0's l2: 0.131931\n",
      "[12]\tvalid_0's l1: 0.267348\tvalid_0's l2: 0.12733\n",
      "[13]\tvalid_0's l1: 0.262052\tvalid_0's l2: 0.123092\n",
      "[14]\tvalid_0's l1: 0.257278\tvalid_0's l2: 0.119749\n",
      "[15]\tvalid_0's l1: 0.253017\tvalid_0's l2: 0.116851\n",
      "[16]\tvalid_0's l1: 0.248878\tvalid_0's l2: 0.114148\n",
      "[17]\tvalid_0's l1: 0.245012\tvalid_0's l2: 0.111749\n",
      "[18]\tvalid_0's l1: 0.241365\tvalid_0's l2: 0.109598\n",
      "[19]\tvalid_0's l1: 0.239025\tvalid_0's l2: 0.108533\n",
      "[20]\tvalid_0's l1: 0.236043\tvalid_0's l2: 0.106885\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.236043\tvalid_0's l2: 0.106885\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.357747\tvalid_0's l2: 0.211692\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.349197\tvalid_0's l2: 0.203093\n",
      "[3]\tvalid_0's l1: 0.34136\tvalid_0's l2: 0.195574\n",
      "[4]\tvalid_0's l1: 0.334423\tvalid_0's l2: 0.189191\n",
      "[5]\tvalid_0's l1: 0.32727\tvalid_0's l2: 0.182175\n",
      "[6]\tvalid_0's l1: 0.321765\tvalid_0's l2: 0.177789\n",
      "[7]\tvalid_0's l1: 0.316686\tvalid_0's l2: 0.173723\n",
      "[8]\tvalid_0's l1: 0.31136\tvalid_0's l2: 0.169121\n",
      "[9]\tvalid_0's l1: 0.3072\tvalid_0's l2: 0.166205\n",
      "[10]\tvalid_0's l1: 0.302839\tvalid_0's l2: 0.162645\n",
      "[11]\tvalid_0's l1: 0.299101\tvalid_0's l2: 0.160142\n",
      "[12]\tvalid_0's l1: 0.295768\tvalid_0's l2: 0.158093\n",
      "[13]\tvalid_0's l1: 0.292835\tvalid_0's l2: 0.156455\n",
      "[14]\tvalid_0's l1: 0.290171\tvalid_0's l2: 0.155027\n",
      "[15]\tvalid_0's l1: 0.287766\tvalid_0's l2: 0.153318\n",
      "[16]\tvalid_0's l1: 0.285253\tvalid_0's l2: 0.15181\n",
      "[17]\tvalid_0's l1: 0.28307\tvalid_0's l2: 0.151008\n",
      "[18]\tvalid_0's l1: 0.280945\tvalid_0's l2: 0.150046\n",
      "[19]\tvalid_0's l1: 0.279125\tvalid_0's l2: 0.149305\n",
      "[20]\tvalid_0's l1: 0.27738\tvalid_0's l2: 0.148767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.27738\tvalid_0's l2: 0.148767\n",
      "[1]\tvalid_0's l1: 0.357943\tvalid_0's l2: 0.212486\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.349644\tvalid_0's l2: 0.204203\n",
      "[3]\tvalid_0's l1: 0.341906\tvalid_0's l2: 0.19669\n",
      "[4]\tvalid_0's l1: 0.334377\tvalid_0's l2: 0.189318\n",
      "[5]\tvalid_0's l1: 0.328078\tvalid_0's l2: 0.183984\n",
      "[6]\tvalid_0's l1: 0.322461\tvalid_0's l2: 0.179355\n",
      "[7]\tvalid_0's l1: 0.317249\tvalid_0's l2: 0.175437\n",
      "[8]\tvalid_0's l1: 0.312644\tvalid_0's l2: 0.17168\n",
      "[9]\tvalid_0's l1: 0.308083\tvalid_0's l2: 0.167923\n",
      "[10]\tvalid_0's l1: 0.304489\tvalid_0's l2: 0.165176\n",
      "[11]\tvalid_0's l1: 0.300985\tvalid_0's l2: 0.162982\n",
      "[12]\tvalid_0's l1: 0.29786\tvalid_0's l2: 0.161045\n",
      "[13]\tvalid_0's l1: 0.295028\tvalid_0's l2: 0.159431\n",
      "[14]\tvalid_0's l1: 0.292318\tvalid_0's l2: 0.157857\n",
      "[15]\tvalid_0's l1: 0.289891\tvalid_0's l2: 0.156637\n",
      "[16]\tvalid_0's l1: 0.287219\tvalid_0's l2: 0.155349\n",
      "[17]\tvalid_0's l1: 0.284677\tvalid_0's l2: 0.154245\n",
      "[18]\tvalid_0's l1: 0.282582\tvalid_0's l2: 0.152744\n",
      "[19]\tvalid_0's l1: 0.280822\tvalid_0's l2: 0.152315\n",
      "[20]\tvalid_0's l1: 0.27915\tvalid_0's l2: 0.151588\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.27915\tvalid_0's l2: 0.151588\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.355965\tvalid_0's l2: 0.210927\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.348049\tvalid_0's l2: 0.202485\n",
      "[3]\tvalid_0's l1: 0.340973\tvalid_0's l2: 0.195275\n",
      "[4]\tvalid_0's l1: 0.334546\tvalid_0's l2: 0.188869\n",
      "[5]\tvalid_0's l1: 0.328351\tvalid_0's l2: 0.182733\n",
      "[6]\tvalid_0's l1: 0.323228\tvalid_0's l2: 0.178373\n",
      "[7]\tvalid_0's l1: 0.318625\tvalid_0's l2: 0.174765\n",
      "[8]\tvalid_0's l1: 0.314056\tvalid_0's l2: 0.170904\n",
      "[9]\tvalid_0's l1: 0.310442\tvalid_0's l2: 0.168248\n",
      "[10]\tvalid_0's l1: 0.306898\tvalid_0's l2: 0.165579\n",
      "[11]\tvalid_0's l1: 0.303753\tvalid_0's l2: 0.163688\n",
      "[12]\tvalid_0's l1: 0.300957\tvalid_0's l2: 0.162125\n",
      "[13]\tvalid_0's l1: 0.298761\tvalid_0's l2: 0.161017\n",
      "[14]\tvalid_0's l1: 0.297139\tvalid_0's l2: 0.160341\n",
      "[15]\tvalid_0's l1: 0.295443\tvalid_0's l2: 0.159782\n",
      "[16]\tvalid_0's l1: 0.293932\tvalid_0's l2: 0.159581\n",
      "[17]\tvalid_0's l1: 0.292376\tvalid_0's l2: 0.159204\n",
      "[18]\tvalid_0's l1: 0.291088\tvalid_0's l2: 0.15933\n",
      "[19]\tvalid_0's l1: 0.28991\tvalid_0's l2: 0.159583\n",
      "[20]\tvalid_0's l1: 0.28907\tvalid_0's l2: 0.160114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.28907\tvalid_0's l2: 0.160114\n",
      "[1]\tvalid_0's l1: 0.355896\tvalid_0's l2: 0.210795\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347739\tvalid_0's l2: 0.201727\n",
      "[3]\tvalid_0's l1: 0.340617\tvalid_0's l2: 0.194562\n",
      "[4]\tvalid_0's l1: 0.333712\tvalid_0's l2: 0.187537\n",
      "[5]\tvalid_0's l1: 0.327937\tvalid_0's l2: 0.182057\n",
      "[6]\tvalid_0's l1: 0.322686\tvalid_0's l2: 0.177388\n",
      "[7]\tvalid_0's l1: 0.31802\tvalid_0's l2: 0.173574\n",
      "[8]\tvalid_0's l1: 0.313985\tvalid_0's l2: 0.170778\n",
      "[9]\tvalid_0's l1: 0.310317\tvalid_0's l2: 0.167927\n",
      "[10]\tvalid_0's l1: 0.307233\tvalid_0's l2: 0.1661\n",
      "[11]\tvalid_0's l1: 0.304521\tvalid_0's l2: 0.164804\n",
      "[12]\tvalid_0's l1: 0.302428\tvalid_0's l2: 0.164129\n",
      "[13]\tvalid_0's l1: 0.300533\tvalid_0's l2: 0.16352\n",
      "[14]\tvalid_0's l1: 0.298947\tvalid_0's l2: 0.163298\n",
      "[15]\tvalid_0's l1: 0.297445\tvalid_0's l2: 0.163363\n",
      "[16]\tvalid_0's l1: 0.295974\tvalid_0's l2: 0.162896\n",
      "[17]\tvalid_0's l1: 0.294649\tvalid_0's l2: 0.162911\n",
      "[18]\tvalid_0's l1: 0.293348\tvalid_0's l2: 0.162856\n",
      "[19]\tvalid_0's l1: 0.292214\tvalid_0's l2: 0.162978\n",
      "[20]\tvalid_0's l1: 0.291302\tvalid_0's l2: 0.163333\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.291302\tvalid_0's l2: 0.163333\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.35446\tvalid_0's l2: 0.210666\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347123\tvalid_0's l2: 0.202797\n",
      "[3]\tvalid_0's l1: 0.340508\tvalid_0's l2: 0.196309\n",
      "[4]\tvalid_0's l1: 0.334679\tvalid_0's l2: 0.190776\n",
      "[5]\tvalid_0's l1: 0.329627\tvalid_0's l2: 0.186184\n",
      "[6]\tvalid_0's l1: 0.325502\tvalid_0's l2: 0.182881\n",
      "[7]\tvalid_0's l1: 0.322206\tvalid_0's l2: 0.180447\n",
      "[8]\tvalid_0's l1: 0.318985\tvalid_0's l2: 0.178266\n",
      "[9]\tvalid_0's l1: 0.316199\tvalid_0's l2: 0.176739\n",
      "[10]\tvalid_0's l1: 0.313929\tvalid_0's l2: 0.175713\n",
      "[11]\tvalid_0's l1: 0.311661\tvalid_0's l2: 0.174699\n",
      "[12]\tvalid_0's l1: 0.309819\tvalid_0's l2: 0.17423\n",
      "[13]\tvalid_0's l1: 0.308663\tvalid_0's l2: 0.174443\n",
      "[14]\tvalid_0's l1: 0.307616\tvalid_0's l2: 0.17495\n",
      "[15]\tvalid_0's l1: 0.30669\tvalid_0's l2: 0.175742\n",
      "[16]\tvalid_0's l1: 0.305856\tvalid_0's l2: 0.176499\n",
      "[17]\tvalid_0's l1: 0.305312\tvalid_0's l2: 0.177322\n",
      "[18]\tvalid_0's l1: 0.30465\tvalid_0's l2: 0.178159\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.309819\tvalid_0's l2: 0.17423\n",
      "[1]\tvalid_0's l1: 0.354263\tvalid_0's l2: 0.210588\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346601\tvalid_0's l2: 0.202512\n",
      "[3]\tvalid_0's l1: 0.340012\tvalid_0's l2: 0.196157\n",
      "[4]\tvalid_0's l1: 0.334165\tvalid_0's l2: 0.190715\n",
      "[5]\tvalid_0's l1: 0.329081\tvalid_0's l2: 0.185976\n",
      "[6]\tvalid_0's l1: 0.324885\tvalid_0's l2: 0.182523\n",
      "[7]\tvalid_0's l1: 0.321159\tvalid_0's l2: 0.179274\n",
      "[8]\tvalid_0's l1: 0.318243\tvalid_0's l2: 0.177491\n",
      "[9]\tvalid_0's l1: 0.316247\tvalid_0's l2: 0.176498\n",
      "[10]\tvalid_0's l1: 0.313842\tvalid_0's l2: 0.175214\n",
      "[11]\tvalid_0's l1: 0.31194\tvalid_0's l2: 0.174863\n",
      "[12]\tvalid_0's l1: 0.310642\tvalid_0's l2: 0.175296\n",
      "[13]\tvalid_0's l1: 0.309177\tvalid_0's l2: 0.175731\n",
      "[14]\tvalid_0's l1: 0.308355\tvalid_0's l2: 0.176855\n",
      "[15]\tvalid_0's l1: 0.307441\tvalid_0's l2: 0.177915\n",
      "[16]\tvalid_0's l1: 0.306694\tvalid_0's l2: 0.178819\n",
      "[17]\tvalid_0's l1: 0.305905\tvalid_0's l2: 0.179665\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.31194\tvalid_0's l2: 0.174863\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.353819\tvalid_0's l2: 0.211984\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347307\tvalid_0's l2: 0.20528\n",
      "[3]\tvalid_0's l1: 0.341875\tvalid_0's l2: 0.199895\n",
      "[4]\tvalid_0's l1: 0.337155\tvalid_0's l2: 0.195786\n",
      "[5]\tvalid_0's l1: 0.333244\tvalid_0's l2: 0.192634\n",
      "[6]\tvalid_0's l1: 0.330014\tvalid_0's l2: 0.190176\n",
      "[7]\tvalid_0's l1: 0.327665\tvalid_0's l2: 0.188861\n",
      "[8]\tvalid_0's l1: 0.325439\tvalid_0's l2: 0.188145\n",
      "[9]\tvalid_0's l1: 0.323679\tvalid_0's l2: 0.188019\n",
      "[10]\tvalid_0's l1: 0.322449\tvalid_0's l2: 0.188567\n",
      "[11]\tvalid_0's l1: 0.320613\tvalid_0's l2: 0.188214\n",
      "[12]\tvalid_0's l1: 0.319136\tvalid_0's l2: 0.18806\n",
      "[13]\tvalid_0's l1: 0.318545\tvalid_0's l2: 0.189454\n",
      "[14]\tvalid_0's l1: 0.318151\tvalid_0's l2: 0.190873\n",
      "[15]\tvalid_0's l1: 0.317835\tvalid_0's l2: 0.192666\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.323679\tvalid_0's l2: 0.188019\n",
      "[1]\tvalid_0's l1: 0.353602\tvalid_0's l2: 0.211694\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.347104\tvalid_0's l2: 0.205008\n",
      "[3]\tvalid_0's l1: 0.341297\tvalid_0's l2: 0.199495\n",
      "[4]\tvalid_0's l1: 0.336812\tvalid_0's l2: 0.195542\n",
      "[5]\tvalid_0's l1: 0.332935\tvalid_0's l2: 0.192267\n",
      "[6]\tvalid_0's l1: 0.329905\tvalid_0's l2: 0.190448\n",
      "[7]\tvalid_0's l1: 0.327183\tvalid_0's l2: 0.188742\n",
      "[8]\tvalid_0's l1: 0.325659\tvalid_0's l2: 0.188324\n",
      "[9]\tvalid_0's l1: 0.324325\tvalid_0's l2: 0.188147\n",
      "[10]\tvalid_0's l1: 0.323285\tvalid_0's l2: 0.188671\n",
      "[11]\tvalid_0's l1: 0.322356\tvalid_0's l2: 0.189876\n",
      "[12]\tvalid_0's l1: 0.32149\tvalid_0's l2: 0.191347\n",
      "[13]\tvalid_0's l1: 0.321175\tvalid_0's l2: 0.193323\n",
      "[14]\tvalid_0's l1: 0.321087\tvalid_0's l2: 0.195771\n",
      "[15]\tvalid_0's l1: 0.321248\tvalid_0's l2: 0.198698\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.324325\tvalid_0's l2: 0.188147\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.337211\tvalid_0's l2: 0.181185\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.322276\tvalid_0's l2: 0.165659\n",
      "[3]\tvalid_0's l1: 0.308239\tvalid_0's l2: 0.151718\n",
      "[4]\tvalid_0's l1: 0.295036\tvalid_0's l2: 0.139213\n",
      "[5]\tvalid_0's l1: 0.282451\tvalid_0's l2: 0.127732\n",
      "[6]\tvalid_0's l1: 0.270714\tvalid_0's l2: 0.117674\n",
      "[7]\tvalid_0's l1: 0.261256\tvalid_0's l2: 0.110215\n",
      "[8]\tvalid_0's l1: 0.250759\tvalid_0's l2: 0.101771\n",
      "[9]\tvalid_0's l1: 0.240941\tvalid_0's l2: 0.0943374\n",
      "[10]\tvalid_0's l1: 0.231613\tvalid_0's l2: 0.0875101\n",
      "[11]\tvalid_0's l1: 0.222925\tvalid_0's l2: 0.0815133\n",
      "[12]\tvalid_0's l1: 0.214752\tvalid_0's l2: 0.076106\n",
      "[13]\tvalid_0's l1: 0.207074\tvalid_0's l2: 0.0711497\n",
      "[14]\tvalid_0's l1: 0.199982\tvalid_0's l2: 0.0668079\n",
      "[15]\tvalid_0's l1: 0.193208\tvalid_0's l2: 0.0627339\n",
      "[16]\tvalid_0's l1: 0.186923\tvalid_0's l2: 0.0591467\n",
      "[17]\tvalid_0's l1: 0.181949\tvalid_0's l2: 0.0564448\n",
      "[18]\tvalid_0's l1: 0.17637\tvalid_0's l2: 0.0534924\n",
      "[19]\tvalid_0's l1: 0.171109\tvalid_0's l2: 0.0508083\n",
      "[20]\tvalid_0's l1: 0.166245\tvalid_0's l2: 0.0484123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.166245\tvalid_0's l2: 0.0484123\n",
      "[1]\tvalid_0's l1: 0.337202\tvalid_0's l2: 0.181229\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32234\tvalid_0's l2: 0.16571\n",
      "[3]\tvalid_0's l1: 0.308318\tvalid_0's l2: 0.151802\n",
      "[4]\tvalid_0's l1: 0.29496\tvalid_0's l2: 0.138992\n",
      "[5]\tvalid_0's l1: 0.282396\tvalid_0's l2: 0.127642\n",
      "[6]\tvalid_0's l1: 0.270613\tvalid_0's l2: 0.117522\n",
      "[7]\tvalid_0's l1: 0.259473\tvalid_0's l2: 0.108405\n",
      "[8]\tvalid_0's l1: 0.249027\tvalid_0's l2: 0.100118\n",
      "[9]\tvalid_0's l1: 0.240218\tvalid_0's l2: 0.0932574\n",
      "[10]\tvalid_0's l1: 0.231077\tvalid_0's l2: 0.086707\n",
      "[11]\tvalid_0's l1: 0.222442\tvalid_0's l2: 0.0807172\n",
      "[12]\tvalid_0's l1: 0.214316\tvalid_0's l2: 0.0753134\n",
      "[13]\tvalid_0's l1: 0.206621\tvalid_0's l2: 0.0703904\n",
      "[14]\tvalid_0's l1: 0.199414\tvalid_0's l2: 0.0659816\n",
      "[15]\tvalid_0's l1: 0.192694\tvalid_0's l2: 0.0620351\n",
      "[16]\tvalid_0's l1: 0.186488\tvalid_0's l2: 0.0584832\n",
      "[17]\tvalid_0's l1: 0.180677\tvalid_0's l2: 0.0553261\n",
      "[18]\tvalid_0's l1: 0.175282\tvalid_0's l2: 0.052539\n",
      "[19]\tvalid_0's l1: 0.170964\tvalid_0's l2: 0.0504004\n",
      "[20]\tvalid_0's l1: 0.166171\tvalid_0's l2: 0.0480587\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.166171\tvalid_0's l2: 0.0480587\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.337225\tvalid_0's l2: 0.183255\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.324347\tvalid_0's l2: 0.169919\n",
      "[3]\tvalid_0's l1: 0.312324\tvalid_0's l2: 0.157881\n",
      "[4]\tvalid_0's l1: 0.301008\tvalid_0's l2: 0.14706\n",
      "[5]\tvalid_0's l1: 0.290262\tvalid_0's l2: 0.136903\n",
      "[6]\tvalid_0's l1: 0.280583\tvalid_0's l2: 0.128281\n",
      "[7]\tvalid_0's l1: 0.273015\tvalid_0's l2: 0.122222\n",
      "[8]\tvalid_0's l1: 0.264097\tvalid_0's l2: 0.114638\n",
      "[9]\tvalid_0's l1: 0.255969\tvalid_0's l2: 0.108329\n",
      "[10]\tvalid_0's l1: 0.248321\tvalid_0's l2: 0.102447\n",
      "[11]\tvalid_0's l1: 0.241299\tvalid_0's l2: 0.0973424\n",
      "[12]\tvalid_0's l1: 0.234676\tvalid_0's l2: 0.0927346\n",
      "[13]\tvalid_0's l1: 0.228641\tvalid_0's l2: 0.088676\n",
      "[14]\tvalid_0's l1: 0.223046\tvalid_0's l2: 0.0849944\n",
      "[15]\tvalid_0's l1: 0.217677\tvalid_0's l2: 0.0815073\n",
      "[16]\tvalid_0's l1: 0.212728\tvalid_0's l2: 0.0783941\n",
      "[17]\tvalid_0's l1: 0.209101\tvalid_0's l2: 0.07639\n",
      "[18]\tvalid_0's l1: 0.205085\tvalid_0's l2: 0.0741039\n",
      "[19]\tvalid_0's l1: 0.201224\tvalid_0's l2: 0.0717996\n",
      "[20]\tvalid_0's l1: 0.198051\tvalid_0's l2: 0.0701208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.198051\tvalid_0's l2: 0.0701208\n",
      "[1]\tvalid_0's l1: 0.337249\tvalid_0's l2: 0.183397\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.324475\tvalid_0's l2: 0.169921\n",
      "[3]\tvalid_0's l1: 0.312458\tvalid_0's l2: 0.15792\n",
      "[4]\tvalid_0's l1: 0.300976\tvalid_0's l2: 0.146803\n",
      "[5]\tvalid_0's l1: 0.290306\tvalid_0's l2: 0.137093\n",
      "[6]\tvalid_0's l1: 0.280222\tvalid_0's l2: 0.128038\n",
      "[7]\tvalid_0's l1: 0.270861\tvalid_0's l2: 0.120364\n",
      "[8]\tvalid_0's l1: 0.262244\tvalid_0's l2: 0.113438\n",
      "[9]\tvalid_0's l1: 0.255159\tvalid_0's l2: 0.107856\n",
      "[10]\tvalid_0's l1: 0.247681\tvalid_0's l2: 0.102227\n",
      "[11]\tvalid_0's l1: 0.240627\tvalid_0's l2: 0.0970862\n",
      "[12]\tvalid_0's l1: 0.234223\tvalid_0's l2: 0.0926215\n",
      "[13]\tvalid_0's l1: 0.228329\tvalid_0's l2: 0.0886306\n",
      "[14]\tvalid_0's l1: 0.222892\tvalid_0's l2: 0.0851244\n",
      "[15]\tvalid_0's l1: 0.217932\tvalid_0's l2: 0.0819457\n",
      "[16]\tvalid_0's l1: 0.213125\tvalid_0's l2: 0.0789947\n",
      "[17]\tvalid_0's l1: 0.208771\tvalid_0's l2: 0.0764286\n",
      "[18]\tvalid_0's l1: 0.204905\tvalid_0's l2: 0.074251\n",
      "[19]\tvalid_0's l1: 0.202\tvalid_0's l2: 0.0726468\n",
      "[20]\tvalid_0's l1: 0.198648\tvalid_0's l2: 0.0708306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.198648\tvalid_0's l2: 0.0708306\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.336801\tvalid_0's l2: 0.184589\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326389\tvalid_0's l2: 0.173546\n",
      "[3]\tvalid_0's l1: 0.316545\tvalid_0's l2: 0.163642\n",
      "[4]\tvalid_0's l1: 0.307605\tvalid_0's l2: 0.154968\n",
      "[5]\tvalid_0's l1: 0.298883\tvalid_0's l2: 0.146672\n",
      "[6]\tvalid_0's l1: 0.291111\tvalid_0's l2: 0.139675\n",
      "[7]\tvalid_0's l1: 0.285873\tvalid_0's l2: 0.135539\n",
      "[8]\tvalid_0's l1: 0.278691\tvalid_0's l2: 0.129518\n",
      "[9]\tvalid_0's l1: 0.272804\tvalid_0's l2: 0.124748\n",
      "[10]\tvalid_0's l1: 0.266844\tvalid_0's l2: 0.120039\n",
      "[11]\tvalid_0's l1: 0.261613\tvalid_0's l2: 0.11615\n",
      "[12]\tvalid_0's l1: 0.256846\tvalid_0's l2: 0.112701\n",
      "[13]\tvalid_0's l1: 0.253035\tvalid_0's l2: 0.110291\n",
      "[14]\tvalid_0's l1: 0.249159\tvalid_0's l2: 0.107919\n",
      "[15]\tvalid_0's l1: 0.245363\tvalid_0's l2: 0.105415\n",
      "[16]\tvalid_0's l1: 0.241784\tvalid_0's l2: 0.103239\n",
      "[17]\tvalid_0's l1: 0.239476\tvalid_0's l2: 0.102234\n",
      "[18]\tvalid_0's l1: 0.236871\tvalid_0's l2: 0.101045\n",
      "[19]\tvalid_0's l1: 0.23405\tvalid_0's l2: 0.0996005\n",
      "[20]\tvalid_0's l1: 0.231842\tvalid_0's l2: 0.0985783\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.231842\tvalid_0's l2: 0.0985783\n",
      "[1]\tvalid_0's l1: 0.336959\tvalid_0's l2: 0.185068\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326507\tvalid_0's l2: 0.174175\n",
      "[3]\tvalid_0's l1: 0.316667\tvalid_0's l2: 0.164389\n",
      "[4]\tvalid_0's l1: 0.307166\tvalid_0's l2: 0.155173\n",
      "[5]\tvalid_0's l1: 0.298748\tvalid_0's l2: 0.147597\n",
      "[6]\tvalid_0's l1: 0.290797\tvalid_0's l2: 0.140527\n",
      "[7]\tvalid_0's l1: 0.283555\tvalid_0's l2: 0.134494\n",
      "[8]\tvalid_0's l1: 0.276948\tvalid_0's l2: 0.128862\n",
      "[9]\tvalid_0's l1: 0.272108\tvalid_0's l2: 0.12512\n",
      "[10]\tvalid_0's l1: 0.266735\tvalid_0's l2: 0.121108\n",
      "[11]\tvalid_0's l1: 0.261768\tvalid_0's l2: 0.117473\n",
      "[12]\tvalid_0's l1: 0.257244\tvalid_0's l2: 0.114434\n",
      "[13]\tvalid_0's l1: 0.252989\tvalid_0's l2: 0.111441\n",
      "[14]\tvalid_0's l1: 0.249103\tvalid_0's l2: 0.108855\n",
      "[15]\tvalid_0's l1: 0.245434\tvalid_0's l2: 0.106421\n",
      "[16]\tvalid_0's l1: 0.242186\tvalid_0's l2: 0.104508\n",
      "[17]\tvalid_0's l1: 0.239264\tvalid_0's l2: 0.102964\n",
      "[18]\tvalid_0's l1: 0.236731\tvalid_0's l2: 0.101786\n",
      "[19]\tvalid_0's l1: 0.234964\tvalid_0's l2: 0.101108\n",
      "[20]\tvalid_0's l1: 0.232662\tvalid_0's l2: 0.0998459\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.232662\tvalid_0's l2: 0.0998459\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.336084\tvalid_0's l2: 0.185552\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327703\tvalid_0's l2: 0.176676\n",
      "[3]\tvalid_0's l1: 0.319881\tvalid_0's l2: 0.168416\n",
      "[4]\tvalid_0's l1: 0.313061\tvalid_0's l2: 0.162025\n",
      "[5]\tvalid_0's l1: 0.306733\tvalid_0's l2: 0.156017\n",
      "[6]\tvalid_0's l1: 0.301293\tvalid_0's l2: 0.151385\n",
      "[7]\tvalid_0's l1: 0.296745\tvalid_0's l2: 0.14767\n",
      "[8]\tvalid_0's l1: 0.292101\tvalid_0's l2: 0.143984\n",
      "[9]\tvalid_0's l1: 0.288007\tvalid_0's l2: 0.140887\n",
      "[10]\tvalid_0's l1: 0.284304\tvalid_0's l2: 0.138382\n",
      "[11]\tvalid_0's l1: 0.280752\tvalid_0's l2: 0.135934\n",
      "[12]\tvalid_0's l1: 0.277698\tvalid_0's l2: 0.133956\n",
      "[13]\tvalid_0's l1: 0.27539\tvalid_0's l2: 0.132966\n",
      "[14]\tvalid_0's l1: 0.273382\tvalid_0's l2: 0.132101\n",
      "[15]\tvalid_0's l1: 0.271436\tvalid_0's l2: 0.13158\n",
      "[16]\tvalid_0's l1: 0.269525\tvalid_0's l2: 0.131087\n",
      "[17]\tvalid_0's l1: 0.268099\tvalid_0's l2: 0.130841\n",
      "[18]\tvalid_0's l1: 0.266853\tvalid_0's l2: 0.130897\n",
      "[19]\tvalid_0's l1: 0.26569\tvalid_0's l2: 0.130992\n",
      "[20]\tvalid_0's l1: 0.264933\tvalid_0's l2: 0.131537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.264933\tvalid_0's l2: 0.131537\n",
      "[1]\tvalid_0's l1: 0.336382\tvalid_0's l2: 0.186548\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.328131\tvalid_0's l2: 0.178302\n",
      "[3]\tvalid_0's l1: 0.320186\tvalid_0's l2: 0.170058\n",
      "[4]\tvalid_0's l1: 0.313164\tvalid_0's l2: 0.163392\n",
      "[5]\tvalid_0's l1: 0.30687\tvalid_0's l2: 0.15742\n",
      "[6]\tvalid_0's l1: 0.301234\tvalid_0's l2: 0.15241\n",
      "[7]\tvalid_0's l1: 0.296134\tvalid_0's l2: 0.148007\n",
      "[8]\tvalid_0's l1: 0.292011\tvalid_0's l2: 0.14511\n",
      "[9]\tvalid_0's l1: 0.288322\tvalid_0's l2: 0.142079\n",
      "[10]\tvalid_0's l1: 0.285054\tvalid_0's l2: 0.139862\n",
      "[11]\tvalid_0's l1: 0.282398\tvalid_0's l2: 0.138501\n",
      "[12]\tvalid_0's l1: 0.279987\tvalid_0's l2: 0.137447\n",
      "[13]\tvalid_0's l1: 0.277658\tvalid_0's l2: 0.136111\n",
      "[14]\tvalid_0's l1: 0.27576\tvalid_0's l2: 0.135595\n",
      "[15]\tvalid_0's l1: 0.273895\tvalid_0's l2: 0.135228\n",
      "[16]\tvalid_0's l1: 0.272232\tvalid_0's l2: 0.134326\n",
      "[17]\tvalid_0's l1: 0.270629\tvalid_0's l2: 0.133768\n",
      "[18]\tvalid_0's l1: 0.2693\tvalid_0's l2: 0.133574\n",
      "[19]\tvalid_0's l1: 0.268273\tvalid_0's l2: 0.133768\n",
      "[20]\tvalid_0's l1: 0.267092\tvalid_0's l2: 0.133854\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.267092\tvalid_0's l2: 0.133854\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334334\tvalid_0's l2: 0.185317\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326454\tvalid_0's l2: 0.176919\n",
      "[3]\tvalid_0's l1: 0.31963\tvalid_0's l2: 0.170148\n",
      "[4]\tvalid_0's l1: 0.313581\tvalid_0's l2: 0.164385\n",
      "[5]\tvalid_0's l1: 0.308297\tvalid_0's l2: 0.159619\n",
      "[6]\tvalid_0's l1: 0.303729\tvalid_0's l2: 0.156066\n",
      "[7]\tvalid_0's l1: 0.300019\tvalid_0's l2: 0.153432\n",
      "[8]\tvalid_0's l1: 0.296483\tvalid_0's l2: 0.150935\n",
      "[9]\tvalid_0's l1: 0.293298\tvalid_0's l2: 0.148927\n",
      "[10]\tvalid_0's l1: 0.290562\tvalid_0's l2: 0.147566\n",
      "[11]\tvalid_0's l1: 0.287733\tvalid_0's l2: 0.145693\n",
      "[12]\tvalid_0's l1: 0.285495\tvalid_0's l2: 0.144653\n",
      "[13]\tvalid_0's l1: 0.283883\tvalid_0's l2: 0.144369\n",
      "[14]\tvalid_0's l1: 0.28228\tvalid_0's l2: 0.144177\n",
      "[15]\tvalid_0's l1: 0.281206\tvalid_0's l2: 0.144553\n",
      "[16]\tvalid_0's l1: 0.280238\tvalid_0's l2: 0.144962\n",
      "[17]\tvalid_0's l1: 0.279419\tvalid_0's l2: 0.145494\n",
      "[18]\tvalid_0's l1: 0.27857\tvalid_0's l2: 0.146055\n",
      "[19]\tvalid_0's l1: 0.278062\tvalid_0's l2: 0.147037\n",
      "[20]\tvalid_0's l1: 0.277584\tvalid_0's l2: 0.148076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.277584\tvalid_0's l2: 0.148076\n",
      "[1]\tvalid_0's l1: 0.334217\tvalid_0's l2: 0.185563\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326468\tvalid_0's l2: 0.177902\n",
      "[3]\tvalid_0's l1: 0.319577\tvalid_0's l2: 0.171112\n",
      "[4]\tvalid_0's l1: 0.313427\tvalid_0's l2: 0.164952\n",
      "[5]\tvalid_0's l1: 0.308536\tvalid_0's l2: 0.160623\n",
      "[6]\tvalid_0's l1: 0.30384\tvalid_0's l2: 0.156687\n",
      "[7]\tvalid_0's l1: 0.299829\tvalid_0's l2: 0.153502\n",
      "[8]\tvalid_0's l1: 0.296535\tvalid_0's l2: 0.15145\n",
      "[9]\tvalid_0's l1: 0.293836\tvalid_0's l2: 0.149868\n",
      "[10]\tvalid_0's l1: 0.291573\tvalid_0's l2: 0.149043\n",
      "[11]\tvalid_0's l1: 0.289676\tvalid_0's l2: 0.148659\n",
      "[12]\tvalid_0's l1: 0.287819\tvalid_0's l2: 0.148294\n",
      "[13]\tvalid_0's l1: 0.286302\tvalid_0's l2: 0.148229\n",
      "[14]\tvalid_0's l1: 0.285112\tvalid_0's l2: 0.148795\n",
      "[15]\tvalid_0's l1: 0.284263\tvalid_0's l2: 0.149421\n",
      "[16]\tvalid_0's l1: 0.283266\tvalid_0's l2: 0.149796\n",
      "[17]\tvalid_0's l1: 0.282456\tvalid_0's l2: 0.150153\n",
      "[18]\tvalid_0's l1: 0.281821\tvalid_0's l2: 0.151093\n",
      "[19]\tvalid_0's l1: 0.28155\tvalid_0's l2: 0.15231\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.286302\tvalid_0's l2: 0.148229\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.333352\tvalid_0's l2: 0.186106\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326645\tvalid_0's l2: 0.179467\n",
      "[3]\tvalid_0's l1: 0.320624\tvalid_0's l2: 0.173911\n",
      "[4]\tvalid_0's l1: 0.315428\tvalid_0's l2: 0.16923\n",
      "[5]\tvalid_0's l1: 0.311453\tvalid_0's l2: 0.166025\n",
      "[6]\tvalid_0's l1: 0.307947\tvalid_0's l2: 0.163291\n",
      "[7]\tvalid_0's l1: 0.305317\tvalid_0's l2: 0.161785\n",
      "[8]\tvalid_0's l1: 0.302931\tvalid_0's l2: 0.160636\n",
      "[9]\tvalid_0's l1: 0.300847\tvalid_0's l2: 0.159835\n",
      "[10]\tvalid_0's l1: 0.299348\tvalid_0's l2: 0.159863\n",
      "[11]\tvalid_0's l1: 0.297217\tvalid_0's l2: 0.159105\n",
      "[12]\tvalid_0's l1: 0.295408\tvalid_0's l2: 0.158809\n",
      "[13]\tvalid_0's l1: 0.294669\tvalid_0's l2: 0.159885\n",
      "[14]\tvalid_0's l1: 0.293928\tvalid_0's l2: 0.160856\n",
      "[15]\tvalid_0's l1: 0.293387\tvalid_0's l2: 0.162079\n",
      "[16]\tvalid_0's l1: 0.293\tvalid_0's l2: 0.16341\n",
      "[17]\tvalid_0's l1: 0.292966\tvalid_0's l2: 0.165139\n",
      "[18]\tvalid_0's l1: 0.292982\tvalid_0's l2: 0.167113\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.295408\tvalid_0's l2: 0.158809\n",
      "[1]\tvalid_0's l1: 0.333197\tvalid_0's l2: 0.186303\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326379\tvalid_0's l2: 0.179884\n",
      "[3]\tvalid_0's l1: 0.320515\tvalid_0's l2: 0.174819\n",
      "[4]\tvalid_0's l1: 0.315288\tvalid_0's l2: 0.170312\n",
      "[5]\tvalid_0's l1: 0.311605\tvalid_0's l2: 0.167571\n",
      "[6]\tvalid_0's l1: 0.308469\tvalid_0's l2: 0.165386\n",
      "[7]\tvalid_0's l1: 0.305484\tvalid_0's l2: 0.163394\n",
      "[8]\tvalid_0's l1: 0.303535\tvalid_0's l2: 0.162515\n",
      "[9]\tvalid_0's l1: 0.302547\tvalid_0's l2: 0.162822\n",
      "[10]\tvalid_0's l1: 0.301039\tvalid_0's l2: 0.162949\n",
      "[11]\tvalid_0's l1: 0.300102\tvalid_0's l2: 0.16367\n",
      "[12]\tvalid_0's l1: 0.299041\tvalid_0's l2: 0.164103\n",
      "[13]\tvalid_0's l1: 0.298686\tvalid_0's l2: 0.16544\n",
      "[14]\tvalid_0's l1: 0.298805\tvalid_0's l2: 0.167716\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.303535\tvalid_0's l2: 0.162515\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1 - DFma_6), \n",
    "# MAE (DFma_1 - DFma_6), \n",
    "# SMAPE (DFma_1 - DFma_6), \n",
    "# R-squared (DFma_1 - DFma_6)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header=0, skiprows=0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header=0, skiprows=0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 19 - j]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 20],\n",
    "        # DFma_wm1 [col 21],\n",
    "        # DFma_wm2 [col 22],\n",
    "        # DFma_wm3 [col 23],\n",
    "        # RF_wm6 [col 24],\n",
    "        # and LST_wm4 [col 25]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DF_0 [col 10],\n",
    "        # DF_wm1 [col 11], \n",
    "        # DF_wm2 [col 12],\n",
    "        # DF_wm3 [col 13],\n",
    "        # RF_wm6 [col 24],\n",
    "        # LST_wm4 [col 25],\n",
    "        # bin_pop9s [col 26],\n",
    "        # bowl_pop9s [col 27],\n",
    "        # bucket_pop9s [col 28],\n",
    "        # misc_short_pop9s [col 29],\n",
    "        # jar_pop9s [col 30],\n",
    "        # pottedplant_pop9s [col 31],\n",
    "        # tire_pop9s [col 32],\n",
    "        # misc_tall_pop9s [col 33],\n",
    "        # and total_pop9s [col 34]\n",
    "        \n",
    "        x_train_withoutCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_train_withCD = df_train_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        x_test_withoutCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25]]\n",
    "        x_test_withCD = df_test_subdist.iloc[:, [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "        \n",
    "        # y: response (target) variable from DFma_1 to DFma_6 (col 19 -> col 14)\n",
    "        y_train = df_train_subdist.iloc[:, [19 - j]]\n",
    "        y_test = df_test_subdist.iloc[:, [19 - j]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_subdist['DFma_' + str(j + 1)])\n",
    "        y_test_true = np.array(df_test_subdist['DFma_' + str(j + 1)])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                                     + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 \n",
    "                                                     + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) + '_withoutCD_' \n",
    "                                                     + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 \n",
    "                                                  + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) + '_withCD_' \n",
    "                                                  + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) + '/MA' \n",
    "                                   + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) + '/MA' \n",
    "                                + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_DFma_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                           + '/MA' + str(i) + '/LGBM_' + province2 + '_BySubDistrict_MA' + str(i) \n",
    "                                           + '_DFma_' + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', \n",
    "                                           header = False, encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) + \n",
    "                                '/LGBM_' + province2 + '_subdist_eval_' + str(num_leaves) + '.csv', \n",
    "                                header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.455561\tvalid_0's l2: 0.37591\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448209\tvalid_0's l2: 0.367978\n",
      "[3]\tvalid_0's l1: 0.44102\tvalid_0's l2: 0.359705\n",
      "[4]\tvalid_0's l1: 0.434646\tvalid_0's l2: 0.353175\n",
      "[5]\tvalid_0's l1: 0.428013\tvalid_0's l2: 0.345992\n",
      "[6]\tvalid_0's l1: 0.422287\tvalid_0's l2: 0.340866\n",
      "[7]\tvalid_0's l1: 0.417234\tvalid_0's l2: 0.335992\n",
      "[8]\tvalid_0's l1: 0.411945\tvalid_0's l2: 0.331023\n",
      "[9]\tvalid_0's l1: 0.407359\tvalid_0's l2: 0.327279\n",
      "[10]\tvalid_0's l1: 0.403033\tvalid_0's l2: 0.323422\n",
      "[11]\tvalid_0's l1: 0.399084\tvalid_0's l2: 0.320253\n",
      "[12]\tvalid_0's l1: 0.395205\tvalid_0's l2: 0.317306\n",
      "[13]\tvalid_0's l1: 0.392027\tvalid_0's l2: 0.315088\n",
      "[14]\tvalid_0's l1: 0.389053\tvalid_0's l2: 0.31273\n",
      "[15]\tvalid_0's l1: 0.385967\tvalid_0's l2: 0.310184\n",
      "[16]\tvalid_0's l1: 0.38295\tvalid_0's l2: 0.308012\n",
      "[17]\tvalid_0's l1: 0.380255\tvalid_0's l2: 0.306147\n",
      "[18]\tvalid_0's l1: 0.377841\tvalid_0's l2: 0.30468\n",
      "[19]\tvalid_0's l1: 0.375375\tvalid_0's l2: 0.30296\n",
      "[20]\tvalid_0's l1: 0.373195\tvalid_0's l2: 0.301865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.373195\tvalid_0's l2: 0.301865\n",
      "[1]\tvalid_0's l1: 0.45553\tvalid_0's l2: 0.375861\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448669\tvalid_0's l2: 0.368416\n",
      "[3]\tvalid_0's l1: 0.442023\tvalid_0's l2: 0.36141\n",
      "[4]\tvalid_0's l1: 0.435264\tvalid_0's l2: 0.354016\n",
      "[5]\tvalid_0's l1: 0.429173\tvalid_0's l2: 0.348172\n",
      "[6]\tvalid_0's l1: 0.423383\tvalid_0's l2: 0.342991\n",
      "[7]\tvalid_0's l1: 0.41806\tvalid_0's l2: 0.338265\n",
      "[8]\tvalid_0's l1: 0.412838\tvalid_0's l2: 0.333736\n",
      "[9]\tvalid_0's l1: 0.408296\tvalid_0's l2: 0.328734\n",
      "[10]\tvalid_0's l1: 0.404238\tvalid_0's l2: 0.325312\n",
      "[11]\tvalid_0's l1: 0.400323\tvalid_0's l2: 0.322027\n",
      "[12]\tvalid_0's l1: 0.396786\tvalid_0's l2: 0.31939\n",
      "[13]\tvalid_0's l1: 0.393647\tvalid_0's l2: 0.317229\n",
      "[14]\tvalid_0's l1: 0.390538\tvalid_0's l2: 0.314884\n",
      "[15]\tvalid_0's l1: 0.387872\tvalid_0's l2: 0.313412\n",
      "[16]\tvalid_0's l1: 0.384972\tvalid_0's l2: 0.31178\n",
      "[17]\tvalid_0's l1: 0.382257\tvalid_0's l2: 0.310214\n",
      "[18]\tvalid_0's l1: 0.379656\tvalid_0's l2: 0.30882\n",
      "[19]\tvalid_0's l1: 0.377576\tvalid_0's l2: 0.307334\n",
      "[20]\tvalid_0's l1: 0.375411\tvalid_0's l2: 0.306235\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.375411\tvalid_0's l2: 0.306235\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.457587\tvalid_0's l2: 0.381829\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.451228\tvalid_0's l2: 0.375396\n",
      "[3]\tvalid_0's l1: 0.4452\tvalid_0's l2: 0.369167\n",
      "[4]\tvalid_0's l1: 0.439931\tvalid_0's l2: 0.364248\n",
      "[5]\tvalid_0's l1: 0.434137\tvalid_0's l2: 0.357004\n",
      "[6]\tvalid_0's l1: 0.429076\tvalid_0's l2: 0.352307\n",
      "[7]\tvalid_0's l1: 0.424329\tvalid_0's l2: 0.348194\n",
      "[8]\tvalid_0's l1: 0.419914\tvalid_0's l2: 0.343335\n",
      "[9]\tvalid_0's l1: 0.416036\tvalid_0's l2: 0.339986\n",
      "[10]\tvalid_0's l1: 0.412319\tvalid_0's l2: 0.336244\n",
      "[11]\tvalid_0's l1: 0.408819\tvalid_0's l2: 0.333749\n",
      "[12]\tvalid_0's l1: 0.405482\tvalid_0's l2: 0.331163\n",
      "[13]\tvalid_0's l1: 0.402738\tvalid_0's l2: 0.329462\n",
      "[14]\tvalid_0's l1: 0.4\tvalid_0's l2: 0.32787\n",
      "[15]\tvalid_0's l1: 0.39726\tvalid_0's l2: 0.325744\n",
      "[16]\tvalid_0's l1: 0.394624\tvalid_0's l2: 0.323955\n",
      "[17]\tvalid_0's l1: 0.392064\tvalid_0's l2: 0.322715\n",
      "[18]\tvalid_0's l1: 0.389667\tvalid_0's l2: 0.321875\n",
      "[19]\tvalid_0's l1: 0.387459\tvalid_0's l2: 0.320576\n",
      "[20]\tvalid_0's l1: 0.385319\tvalid_0's l2: 0.319929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.385319\tvalid_0's l2: 0.319929\n",
      "[1]\tvalid_0's l1: 0.457573\tvalid_0's l2: 0.381963\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.451057\tvalid_0's l2: 0.375597\n",
      "[3]\tvalid_0's l1: 0.44506\tvalid_0's l2: 0.369494\n",
      "[4]\tvalid_0's l1: 0.439052\tvalid_0's l2: 0.361706\n",
      "[5]\tvalid_0's l1: 0.433659\tvalid_0's l2: 0.357049\n",
      "[6]\tvalid_0's l1: 0.428621\tvalid_0's l2: 0.352108\n",
      "[7]\tvalid_0's l1: 0.423841\tvalid_0's l2: 0.347553\n",
      "[8]\tvalid_0's l1: 0.419547\tvalid_0's l2: 0.343866\n",
      "[9]\tvalid_0's l1: 0.415253\tvalid_0's l2: 0.338663\n",
      "[10]\tvalid_0's l1: 0.411827\tvalid_0's l2: 0.335925\n",
      "[11]\tvalid_0's l1: 0.408499\tvalid_0's l2: 0.333589\n",
      "[12]\tvalid_0's l1: 0.405245\tvalid_0's l2: 0.330896\n",
      "[13]\tvalid_0's l1: 0.402168\tvalid_0's l2: 0.329041\n",
      "[14]\tvalid_0's l1: 0.399402\tvalid_0's l2: 0.327207\n",
      "[15]\tvalid_0's l1: 0.396966\tvalid_0's l2: 0.325807\n",
      "[16]\tvalid_0's l1: 0.394293\tvalid_0's l2: 0.324363\n",
      "[17]\tvalid_0's l1: 0.391569\tvalid_0's l2: 0.322888\n",
      "[18]\tvalid_0's l1: 0.389014\tvalid_0's l2: 0.321768\n",
      "[19]\tvalid_0's l1: 0.386878\tvalid_0's l2: 0.320892\n",
      "[20]\tvalid_0's l1: 0.384716\tvalid_0's l2: 0.32007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.384716\tvalid_0's l2: 0.32007\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45814\tvalid_0's l2: 0.385352\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.452342\tvalid_0's l2: 0.379011\n",
      "[3]\tvalid_0's l1: 0.44655\tvalid_0's l2: 0.37289\n",
      "[4]\tvalid_0's l1: 0.44135\tvalid_0's l2: 0.367706\n",
      "[5]\tvalid_0's l1: 0.435894\tvalid_0's l2: 0.360385\n",
      "[6]\tvalid_0's l1: 0.431229\tvalid_0's l2: 0.355901\n",
      "[7]\tvalid_0's l1: 0.426994\tvalid_0's l2: 0.352404\n",
      "[8]\tvalid_0's l1: 0.42265\tvalid_0's l2: 0.347653\n",
      "[9]\tvalid_0's l1: 0.418828\tvalid_0's l2: 0.344602\n",
      "[10]\tvalid_0's l1: 0.41524\tvalid_0's l2: 0.341087\n",
      "[11]\tvalid_0's l1: 0.4121\tvalid_0's l2: 0.339039\n",
      "[12]\tvalid_0's l1: 0.409322\tvalid_0's l2: 0.337246\n",
      "[13]\tvalid_0's l1: 0.406411\tvalid_0's l2: 0.335524\n",
      "[14]\tvalid_0's l1: 0.403948\tvalid_0's l2: 0.334269\n",
      "[15]\tvalid_0's l1: 0.401771\tvalid_0's l2: 0.332704\n",
      "[16]\tvalid_0's l1: 0.399648\tvalid_0's l2: 0.331379\n",
      "[17]\tvalid_0's l1: 0.397377\tvalid_0's l2: 0.330449\n",
      "[18]\tvalid_0's l1: 0.395494\tvalid_0's l2: 0.329998\n",
      "[19]\tvalid_0's l1: 0.393666\tvalid_0's l2: 0.328915\n",
      "[20]\tvalid_0's l1: 0.39191\tvalid_0's l2: 0.328627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.39191\tvalid_0's l2: 0.328627\n",
      "[1]\tvalid_0's l1: 0.45814\tvalid_0's l2: 0.385017\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.452161\tvalid_0's l2: 0.378223\n",
      "[3]\tvalid_0's l1: 0.446838\tvalid_0's l2: 0.372769\n",
      "[4]\tvalid_0's l1: 0.441065\tvalid_0's l2: 0.364711\n",
      "[5]\tvalid_0's l1: 0.436202\tvalid_0's l2: 0.360184\n",
      "[6]\tvalid_0's l1: 0.431643\tvalid_0's l2: 0.355801\n",
      "[7]\tvalid_0's l1: 0.4274\tvalid_0's l2: 0.351902\n",
      "[8]\tvalid_0's l1: 0.4233\tvalid_0's l2: 0.348418\n",
      "[9]\tvalid_0's l1: 0.419745\tvalid_0's l2: 0.344776\n",
      "[10]\tvalid_0's l1: 0.416487\tvalid_0's l2: 0.342144\n",
      "[11]\tvalid_0's l1: 0.413763\tvalid_0's l2: 0.34042\n",
      "[12]\tvalid_0's l1: 0.41083\tvalid_0's l2: 0.338595\n",
      "[13]\tvalid_0's l1: 0.40836\tvalid_0's l2: 0.337431\n",
      "[14]\tvalid_0's l1: 0.406141\tvalid_0's l2: 0.336479\n",
      "[15]\tvalid_0's l1: 0.404095\tvalid_0's l2: 0.335791\n",
      "[16]\tvalid_0's l1: 0.402023\tvalid_0's l2: 0.335003\n",
      "[17]\tvalid_0's l1: 0.400025\tvalid_0's l2: 0.334452\n",
      "[18]\tvalid_0's l1: 0.397975\tvalid_0's l2: 0.333745\n",
      "[19]\tvalid_0's l1: 0.3961\tvalid_0's l2: 0.333463\n",
      "[20]\tvalid_0's l1: 0.394068\tvalid_0's l2: 0.332766\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.394068\tvalid_0's l2: 0.332766\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.460589\tvalid_0's l2: 0.391921\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.45512\tvalid_0's l2: 0.385081\n",
      "[3]\tvalid_0's l1: 0.449872\tvalid_0's l2: 0.378617\n",
      "[4]\tvalid_0's l1: 0.445458\tvalid_0's l2: 0.373569\n",
      "[5]\tvalid_0's l1: 0.440442\tvalid_0's l2: 0.366965\n",
      "[6]\tvalid_0's l1: 0.436478\tvalid_0's l2: 0.362585\n",
      "[7]\tvalid_0's l1: 0.432692\tvalid_0's l2: 0.359329\n",
      "[8]\tvalid_0's l1: 0.429002\tvalid_0's l2: 0.355484\n",
      "[9]\tvalid_0's l1: 0.425998\tvalid_0's l2: 0.353268\n",
      "[10]\tvalid_0's l1: 0.423035\tvalid_0's l2: 0.350502\n",
      "[11]\tvalid_0's l1: 0.42045\tvalid_0's l2: 0.348488\n",
      "[12]\tvalid_0's l1: 0.417906\tvalid_0's l2: 0.347118\n",
      "[13]\tvalid_0's l1: 0.41559\tvalid_0's l2: 0.345965\n",
      "[14]\tvalid_0's l1: 0.413817\tvalid_0's l2: 0.34526\n",
      "[15]\tvalid_0's l1: 0.411955\tvalid_0's l2: 0.343835\n",
      "[16]\tvalid_0's l1: 0.409914\tvalid_0's l2: 0.342598\n",
      "[17]\tvalid_0's l1: 0.407941\tvalid_0's l2: 0.341955\n",
      "[18]\tvalid_0's l1: 0.406308\tvalid_0's l2: 0.341603\n",
      "[19]\tvalid_0's l1: 0.404714\tvalid_0's l2: 0.34067\n",
      "[20]\tvalid_0's l1: 0.403512\tvalid_0's l2: 0.340689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.403512\tvalid_0's l2: 0.340689\n",
      "[1]\tvalid_0's l1: 0.460573\tvalid_0's l2: 0.391772\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.455553\tvalid_0's l2: 0.385508\n",
      "[3]\tvalid_0's l1: 0.450375\tvalid_0's l2: 0.378664\n",
      "[4]\tvalid_0's l1: 0.445166\tvalid_0's l2: 0.37199\n",
      "[5]\tvalid_0's l1: 0.440639\tvalid_0's l2: 0.367319\n",
      "[6]\tvalid_0's l1: 0.436481\tvalid_0's l2: 0.362951\n",
      "[7]\tvalid_0's l1: 0.432661\tvalid_0's l2: 0.359575\n",
      "[8]\tvalid_0's l1: 0.429208\tvalid_0's l2: 0.35641\n",
      "[9]\tvalid_0's l1: 0.426289\tvalid_0's l2: 0.353447\n",
      "[10]\tvalid_0's l1: 0.423625\tvalid_0's l2: 0.351239\n",
      "[11]\tvalid_0's l1: 0.421015\tvalid_0's l2: 0.349422\n",
      "[12]\tvalid_0's l1: 0.419101\tvalid_0's l2: 0.348499\n",
      "[13]\tvalid_0's l1: 0.416989\tvalid_0's l2: 0.347454\n",
      "[14]\tvalid_0's l1: 0.415295\tvalid_0's l2: 0.347134\n",
      "[15]\tvalid_0's l1: 0.413726\tvalid_0's l2: 0.346863\n",
      "[16]\tvalid_0's l1: 0.412043\tvalid_0's l2: 0.346025\n",
      "[17]\tvalid_0's l1: 0.410695\tvalid_0's l2: 0.346117\n",
      "[18]\tvalid_0's l1: 0.409323\tvalid_0's l2: 0.346107\n",
      "[19]\tvalid_0's l1: 0.407858\tvalid_0's l2: 0.34601\n",
      "[20]\tvalid_0's l1: 0.406646\tvalid_0's l2: 0.346204\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.406646\tvalid_0's l2: 0.346204\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.46092\tvalid_0's l2: 0.393605\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.455875\tvalid_0's l2: 0.387431\n",
      "[3]\tvalid_0's l1: 0.451199\tvalid_0's l2: 0.382666\n",
      "[4]\tvalid_0's l1: 0.447329\tvalid_0's l2: 0.378546\n",
      "[5]\tvalid_0's l1: 0.443374\tvalid_0's l2: 0.374407\n",
      "[6]\tvalid_0's l1: 0.4404\tvalid_0's l2: 0.371908\n",
      "[7]\tvalid_0's l1: 0.438018\tvalid_0's l2: 0.369916\n",
      "[8]\tvalid_0's l1: 0.435173\tvalid_0's l2: 0.367822\n",
      "[9]\tvalid_0's l1: 0.43318\tvalid_0's l2: 0.366669\n",
      "[10]\tvalid_0's l1: 0.431138\tvalid_0's l2: 0.365963\n",
      "[11]\tvalid_0's l1: 0.42927\tvalid_0's l2: 0.365228\n",
      "[12]\tvalid_0's l1: 0.427472\tvalid_0's l2: 0.364578\n",
      "[13]\tvalid_0's l1: 0.426077\tvalid_0's l2: 0.364837\n",
      "[14]\tvalid_0's l1: 0.424815\tvalid_0's l2: 0.365321\n",
      "[15]\tvalid_0's l1: 0.423875\tvalid_0's l2: 0.366458\n",
      "[16]\tvalid_0's l1: 0.422825\tvalid_0's l2: 0.367089\n",
      "[17]\tvalid_0's l1: 0.422166\tvalid_0's l2: 0.368083\n",
      "[18]\tvalid_0's l1: 0.421389\tvalid_0's l2: 0.368596\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.427472\tvalid_0's l2: 0.364578\n",
      "[1]\tvalid_0's l1: 0.46071\tvalid_0's l2: 0.392757\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.456416\tvalid_0's l2: 0.387384\n",
      "[3]\tvalid_0's l1: 0.451773\tvalid_0's l2: 0.382345\n",
      "[4]\tvalid_0's l1: 0.447684\tvalid_0's l2: 0.377805\n",
      "[5]\tvalid_0's l1: 0.443994\tvalid_0's l2: 0.37432\n",
      "[6]\tvalid_0's l1: 0.440783\tvalid_0's l2: 0.371461\n",
      "[7]\tvalid_0's l1: 0.437701\tvalid_0's l2: 0.368613\n",
      "[8]\tvalid_0's l1: 0.435259\tvalid_0's l2: 0.367009\n",
      "[9]\tvalid_0's l1: 0.433558\tvalid_0's l2: 0.365817\n",
      "[10]\tvalid_0's l1: 0.432022\tvalid_0's l2: 0.365425\n",
      "[11]\tvalid_0's l1: 0.430333\tvalid_0's l2: 0.365702\n",
      "[12]\tvalid_0's l1: 0.428962\tvalid_0's l2: 0.366383\n",
      "[13]\tvalid_0's l1: 0.427685\tvalid_0's l2: 0.367425\n",
      "[14]\tvalid_0's l1: 0.426341\tvalid_0's l2: 0.368316\n",
      "[15]\tvalid_0's l1: 0.425057\tvalid_0's l2: 0.368951\n",
      "[16]\tvalid_0's l1: 0.424309\tvalid_0's l2: 0.369796\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.432022\tvalid_0's l2: 0.365425\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.46246\tvalid_0's l2: 0.395022\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.458257\tvalid_0's l2: 0.389705\n",
      "[3]\tvalid_0's l1: 0.454257\tvalid_0's l2: 0.385248\n",
      "[4]\tvalid_0's l1: 0.451306\tvalid_0's l2: 0.382245\n",
      "[5]\tvalid_0's l1: 0.447902\tvalid_0's l2: 0.379302\n",
      "[6]\tvalid_0's l1: 0.445138\tvalid_0's l2: 0.376999\n",
      "[7]\tvalid_0's l1: 0.443325\tvalid_0's l2: 0.375886\n",
      "[8]\tvalid_0's l1: 0.441568\tvalid_0's l2: 0.375069\n",
      "[9]\tvalid_0's l1: 0.440186\tvalid_0's l2: 0.374869\n",
      "[10]\tvalid_0's l1: 0.439145\tvalid_0's l2: 0.375349\n",
      "[11]\tvalid_0's l1: 0.43769\tvalid_0's l2: 0.374781\n",
      "[12]\tvalid_0's l1: 0.436292\tvalid_0's l2: 0.374386\n",
      "[13]\tvalid_0's l1: 0.435751\tvalid_0's l2: 0.375344\n",
      "[14]\tvalid_0's l1: 0.434883\tvalid_0's l2: 0.375916\n",
      "[15]\tvalid_0's l1: 0.434674\tvalid_0's l2: 0.377732\n",
      "[16]\tvalid_0's l1: 0.434172\tvalid_0's l2: 0.379153\n",
      "[17]\tvalid_0's l1: 0.433709\tvalid_0's l2: 0.38045\n",
      "[18]\tvalid_0's l1: 0.433275\tvalid_0's l2: 0.382021\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.436292\tvalid_0's l2: 0.374386\n",
      "[1]\tvalid_0's l1: 0.462293\tvalid_0's l2: 0.394985\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.458225\tvalid_0's l2: 0.390084\n",
      "[3]\tvalid_0's l1: 0.454593\tvalid_0's l2: 0.385866\n",
      "[4]\tvalid_0's l1: 0.450953\tvalid_0's l2: 0.382393\n",
      "[5]\tvalid_0's l1: 0.447798\tvalid_0's l2: 0.379413\n",
      "[6]\tvalid_0's l1: 0.445305\tvalid_0's l2: 0.377267\n",
      "[7]\tvalid_0's l1: 0.44311\tvalid_0's l2: 0.37535\n",
      "[8]\tvalid_0's l1: 0.441447\tvalid_0's l2: 0.374749\n",
      "[9]\tvalid_0's l1: 0.439922\tvalid_0's l2: 0.374471\n",
      "[10]\tvalid_0's l1: 0.439017\tvalid_0's l2: 0.374822\n",
      "[11]\tvalid_0's l1: 0.438149\tvalid_0's l2: 0.37567\n",
      "[12]\tvalid_0's l1: 0.437336\tvalid_0's l2: 0.377095\n",
      "[13]\tvalid_0's l1: 0.437307\tvalid_0's l2: 0.378974\n",
      "[14]\tvalid_0's l1: 0.437498\tvalid_0's l2: 0.381959\n",
      "[15]\tvalid_0's l1: 0.437007\tvalid_0's l2: 0.383846\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.439922\tvalid_0's l2: 0.374471\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                             'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                             'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                             'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Normal Lags/train_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Normal Lags/test_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 10 - i]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # and LST_wm4 [col 25]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 10],\n",
    "    # DF_wm1 [col 11], \n",
    "    # DF_wm2 [col 12],\n",
    "    # DF_wm3 [col 13],\n",
    "    # RF_wm6 [col 24],\n",
    "    # LST_wm4 [col 25],\n",
    "    # bin [col 26],\n",
    "    # bowl [col 27],\n",
    "    # bucket [col 28],\n",
    "    # misc_short [col 29],\n",
    "    # jars [col 30],\n",
    "    # pottedplant [col 31],\n",
    "    # tire [col 32],\n",
    "    # misc_tall [col 33],\n",
    "    # and total [col 34]\n",
    "        \n",
    "    x_train_withoutCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_train_withCD = df_train_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    x_test_withoutCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25]]\n",
    "    x_test_withCD = df_test_subdist.iloc[:, [10, 11, 12, 13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]\n",
    "    \n",
    "    # y: response (target) variable from DF_1 to DF_6 (col 9 -> col 4)\n",
    "    y_train = df_train_subdist.iloc[:, [9 - i]]\n",
    "    y_test = df_test_subdist.iloc[:, [9 - i]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_subdist['DF_' + str(i + 1)])\n",
    "    y_test_true = np.array(df_test_subdist['DF_' + str(i + 1)])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                                 + str(num_leaves) + '/Original DF_0/LGBM_' + province2 \n",
    "                                                 + '_subdist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                                                 + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 \n",
    "                                              + '_subdist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                                              + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) \n",
    "                               + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) \n",
    "                            + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "    \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                   mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                   smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                   r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                       + '/Original DF_0/LGBM_' + province2 + '_BySubDistrict_Original_DF_' \n",
    "                                       + str(i + 1) + '_eval_' + str(num_leaves) + '.csv', \n",
    "                                       header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Normal Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_subdist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modified Lags</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict DFma_1 as the target<br>\n",
    "- Predict DF_1 as the target<br>\n",
    "But adjust the independent variables <b>according to the different time horizons</b><br>\n",
    " - 1 week ahead = independent variables are DFma_0, DFma_wm1, DFma_wm2, ..., and DFma_wm6<br>\n",
    " - 2 weeks ahead = independent variables are DFma_wm1, DFma_wm2, DFma_wm3, ..., and DFma_wm6<br>\n",
    " - 3 weeks ahead = independent variables are DFma_wm2, DFma_wm3, DFma_wm4, ..., and DFma_wm6<br>\n",
    "Maximum time horizon = 6 weeks ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>District level</h2>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.283641\tvalid_0's l2: 0.110376\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.271572\tvalid_0's l2: 0.101492\n",
      "[3]\tvalid_0's l1: 0.26041\tvalid_0's l2: 0.0935903\n",
      "[4]\tvalid_0's l1: 0.249939\tvalid_0's l2: 0.086458\n",
      "[5]\tvalid_0's l1: 0.240266\tvalid_0's l2: 0.0800588\n",
      "[6]\tvalid_0's l1: 0.230778\tvalid_0's l2: 0.0739703\n",
      "[7]\tvalid_0's l1: 0.222297\tvalid_0's l2: 0.0687202\n",
      "[8]\tvalid_0's l1: 0.214238\tvalid_0's l2: 0.0639262\n",
      "[9]\tvalid_0's l1: 0.206957\tvalid_0's l2: 0.0597754\n",
      "[10]\tvalid_0's l1: 0.19999\tvalid_0's l2: 0.0559453\n",
      "[11]\tvalid_0's l1: 0.193503\tvalid_0's l2: 0.0526016\n",
      "[12]\tvalid_0's l1: 0.187519\tvalid_0's l2: 0.0496168\n",
      "[13]\tvalid_0's l1: 0.181837\tvalid_0's l2: 0.0468264\n",
      "[14]\tvalid_0's l1: 0.176483\tvalid_0's l2: 0.044302\n",
      "[15]\tvalid_0's l1: 0.171885\tvalid_0's l2: 0.0422899\n",
      "[16]\tvalid_0's l1: 0.167348\tvalid_0's l2: 0.0403468\n",
      "[17]\tvalid_0's l1: 0.163089\tvalid_0's l2: 0.0385858\n",
      "[18]\tvalid_0's l1: 0.159218\tvalid_0's l2: 0.0370312\n",
      "[19]\tvalid_0's l1: 0.155495\tvalid_0's l2: 0.035631\n",
      "[20]\tvalid_0's l1: 0.152831\tvalid_0's l2: 0.0347121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.152831\tvalid_0's l2: 0.0347121\n",
      "[1]\tvalid_0's l1: 0.283514\tvalid_0's l2: 0.110252\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.271352\tvalid_0's l2: 0.101342\n",
      "[3]\tvalid_0's l1: 0.259999\tvalid_0's l2: 0.0932881\n",
      "[4]\tvalid_0's l1: 0.249546\tvalid_0's l2: 0.0861798\n",
      "[5]\tvalid_0's l1: 0.23987\tvalid_0's l2: 0.0797751\n",
      "[6]\tvalid_0's l1: 0.230582\tvalid_0's l2: 0.0737696\n",
      "[7]\tvalid_0's l1: 0.22199\tvalid_0's l2: 0.0684558\n",
      "[8]\tvalid_0's l1: 0.214131\tvalid_0's l2: 0.0638457\n",
      "[9]\tvalid_0's l1: 0.206732\tvalid_0's l2: 0.0596056\n",
      "[10]\tvalid_0's l1: 0.199774\tvalid_0's l2: 0.0557795\n",
      "[11]\tvalid_0's l1: 0.193331\tvalid_0's l2: 0.0524633\n",
      "[12]\tvalid_0's l1: 0.187367\tvalid_0's l2: 0.0495166\n",
      "[13]\tvalid_0's l1: 0.181992\tvalid_0's l2: 0.0469255\n",
      "[14]\tvalid_0's l1: 0.176835\tvalid_0's l2: 0.0445211\n",
      "[15]\tvalid_0's l1: 0.173048\tvalid_0's l2: 0.0428899\n",
      "[16]\tvalid_0's l1: 0.169587\tvalid_0's l2: 0.0415326\n",
      "[17]\tvalid_0's l1: 0.165105\tvalid_0's l2: 0.0396168\n",
      "[18]\tvalid_0's l1: 0.162264\tvalid_0's l2: 0.0385542\n",
      "[19]\tvalid_0's l1: 0.158435\tvalid_0's l2: 0.0370148\n",
      "[20]\tvalid_0's l1: 0.154901\tvalid_0's l2: 0.0356656\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.154901\tvalid_0's l2: 0.0356656\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285646\tvalid_0's l2: 0.112008\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275985\tvalid_0's l2: 0.104912\n",
      "[3]\tvalid_0's l1: 0.266773\tvalid_0's l2: 0.0984341\n",
      "[4]\tvalid_0's l1: 0.258522\tvalid_0's l2: 0.0928206\n",
      "[5]\tvalid_0's l1: 0.25124\tvalid_0's l2: 0.0879765\n",
      "[6]\tvalid_0's l1: 0.244114\tvalid_0's l2: 0.0833693\n",
      "[7]\tvalid_0's l1: 0.237791\tvalid_0's l2: 0.0795048\n",
      "[8]\tvalid_0's l1: 0.231924\tvalid_0's l2: 0.0760697\n",
      "[9]\tvalid_0's l1: 0.226631\tvalid_0's l2: 0.0731354\n",
      "[10]\tvalid_0's l1: 0.221882\tvalid_0's l2: 0.0706267\n",
      "[11]\tvalid_0's l1: 0.217581\tvalid_0's l2: 0.0685689\n",
      "[12]\tvalid_0's l1: 0.213341\tvalid_0's l2: 0.0665987\n",
      "[13]\tvalid_0's l1: 0.209892\tvalid_0's l2: 0.065159\n",
      "[14]\tvalid_0's l1: 0.207002\tvalid_0's l2: 0.0640132\n",
      "[15]\tvalid_0's l1: 0.204097\tvalid_0's l2: 0.0628613\n",
      "[16]\tvalid_0's l1: 0.201678\tvalid_0's l2: 0.0620067\n",
      "[17]\tvalid_0's l1: 0.19897\tvalid_0's l2: 0.0609856\n",
      "[18]\tvalid_0's l1: 0.19654\tvalid_0's l2: 0.0601754\n",
      "[19]\tvalid_0's l1: 0.194524\tvalid_0's l2: 0.0597132\n",
      "[20]\tvalid_0's l1: 0.192429\tvalid_0's l2: 0.0591639\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192429\tvalid_0's l2: 0.0591639\n",
      "[1]\tvalid_0's l1: 0.285785\tvalid_0's l2: 0.112194\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275874\tvalid_0's l2: 0.104873\n",
      "[3]\tvalid_0's l1: 0.26668\tvalid_0's l2: 0.0983993\n",
      "[4]\tvalid_0's l1: 0.258589\tvalid_0's l2: 0.0928497\n",
      "[5]\tvalid_0's l1: 0.251292\tvalid_0's l2: 0.08793\n",
      "[6]\tvalid_0's l1: 0.244301\tvalid_0's l2: 0.0835155\n",
      "[7]\tvalid_0's l1: 0.238036\tvalid_0's l2: 0.0797887\n",
      "[8]\tvalid_0's l1: 0.232083\tvalid_0's l2: 0.0763848\n",
      "[9]\tvalid_0's l1: 0.226622\tvalid_0's l2: 0.0734142\n",
      "[10]\tvalid_0's l1: 0.221571\tvalid_0's l2: 0.0707721\n",
      "[11]\tvalid_0's l1: 0.217103\tvalid_0's l2: 0.0686427\n",
      "[12]\tvalid_0's l1: 0.213061\tvalid_0's l2: 0.0667756\n",
      "[13]\tvalid_0's l1: 0.209482\tvalid_0's l2: 0.0652338\n",
      "[14]\tvalid_0's l1: 0.206139\tvalid_0's l2: 0.0639272\n",
      "[15]\tvalid_0's l1: 0.203162\tvalid_0's l2: 0.0628292\n",
      "[16]\tvalid_0's l1: 0.200673\tvalid_0's l2: 0.0619258\n",
      "[17]\tvalid_0's l1: 0.198244\tvalid_0's l2: 0.061104\n",
      "[18]\tvalid_0's l1: 0.196128\tvalid_0's l2: 0.0605545\n",
      "[19]\tvalid_0's l1: 0.194308\tvalid_0's l2: 0.0601726\n",
      "[20]\tvalid_0's l1: 0.192507\tvalid_0's l2: 0.0598698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192507\tvalid_0's l2: 0.0598698\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285507\tvalid_0's l2: 0.111886\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275761\tvalid_0's l2: 0.104751\n",
      "[3]\tvalid_0's l1: 0.267218\tvalid_0's l2: 0.0986081\n",
      "[4]\tvalid_0's l1: 0.259935\tvalid_0's l2: 0.0935163\n",
      "[5]\tvalid_0's l1: 0.253803\tvalid_0's l2: 0.0892985\n",
      "[6]\tvalid_0's l1: 0.247654\tvalid_0's l2: 0.0853686\n",
      "[7]\tvalid_0's l1: 0.242216\tvalid_0's l2: 0.0820264\n",
      "[8]\tvalid_0's l1: 0.238116\tvalid_0's l2: 0.079662\n",
      "[9]\tvalid_0's l1: 0.233781\tvalid_0's l2: 0.0773174\n",
      "[10]\tvalid_0's l1: 0.229879\tvalid_0's l2: 0.0754622\n",
      "[11]\tvalid_0's l1: 0.226192\tvalid_0's l2: 0.0738489\n",
      "[12]\tvalid_0's l1: 0.222872\tvalid_0's l2: 0.0725582\n",
      "[13]\tvalid_0's l1: 0.2199\tvalid_0's l2: 0.0716218\n",
      "[14]\tvalid_0's l1: 0.217347\tvalid_0's l2: 0.0709308\n",
      "[15]\tvalid_0's l1: 0.21519\tvalid_0's l2: 0.070532\n",
      "[16]\tvalid_0's l1: 0.213208\tvalid_0's l2: 0.0701737\n",
      "[17]\tvalid_0's l1: 0.211362\tvalid_0's l2: 0.0699198\n",
      "[18]\tvalid_0's l1: 0.209784\tvalid_0's l2: 0.0698639\n",
      "[19]\tvalid_0's l1: 0.208512\tvalid_0's l2: 0.0700761\n",
      "[20]\tvalid_0's l1: 0.207114\tvalid_0's l2: 0.0701661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.207114\tvalid_0's l2: 0.0701661\n",
      "[1]\tvalid_0's l1: 0.285677\tvalid_0's l2: 0.111959\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275849\tvalid_0's l2: 0.104761\n",
      "[3]\tvalid_0's l1: 0.267504\tvalid_0's l2: 0.0988158\n",
      "[4]\tvalid_0's l1: 0.259447\tvalid_0's l2: 0.0932405\n",
      "[5]\tvalid_0's l1: 0.252652\tvalid_0's l2: 0.0886959\n",
      "[6]\tvalid_0's l1: 0.246434\tvalid_0's l2: 0.0846174\n",
      "[7]\tvalid_0's l1: 0.241499\tvalid_0's l2: 0.0816013\n",
      "[8]\tvalid_0's l1: 0.236467\tvalid_0's l2: 0.0786611\n",
      "[9]\tvalid_0's l1: 0.232021\tvalid_0's l2: 0.0761764\n",
      "[10]\tvalid_0's l1: 0.228346\tvalid_0's l2: 0.0743637\n",
      "[11]\tvalid_0's l1: 0.224801\tvalid_0's l2: 0.0727292\n",
      "[12]\tvalid_0's l1: 0.221771\tvalid_0's l2: 0.0715607\n",
      "[13]\tvalid_0's l1: 0.219197\tvalid_0's l2: 0.0706887\n",
      "[14]\tvalid_0's l1: 0.21689\tvalid_0's l2: 0.0702042\n",
      "[15]\tvalid_0's l1: 0.214743\tvalid_0's l2: 0.0697326\n",
      "[16]\tvalid_0's l1: 0.212859\tvalid_0's l2: 0.0694801\n",
      "[17]\tvalid_0's l1: 0.211037\tvalid_0's l2: 0.069187\n",
      "[18]\tvalid_0's l1: 0.210087\tvalid_0's l2: 0.0694306\n",
      "[19]\tvalid_0's l1: 0.208738\tvalid_0's l2: 0.069522\n",
      "[20]\tvalid_0's l1: 0.207518\tvalid_0's l2: 0.0698101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.207518\tvalid_0's l2: 0.0698101\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285999\tvalid_0's l2: 0.112255\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.276909\tvalid_0's l2: 0.105507\n",
      "[3]\tvalid_0's l1: 0.268952\tvalid_0's l2: 0.0997182\n",
      "[4]\tvalid_0's l1: 0.262133\tvalid_0's l2: 0.0948572\n",
      "[5]\tvalid_0's l1: 0.256099\tvalid_0's l2: 0.0907271\n",
      "[6]\tvalid_0's l1: 0.25068\tvalid_0's l2: 0.0872825\n",
      "[7]\tvalid_0's l1: 0.246734\tvalid_0's l2: 0.0848273\n",
      "[8]\tvalid_0's l1: 0.242438\tvalid_0's l2: 0.0825122\n",
      "[9]\tvalid_0's l1: 0.23909\tvalid_0's l2: 0.0808561\n",
      "[10]\tvalid_0's l1: 0.235827\tvalid_0's l2: 0.0794628\n",
      "[11]\tvalid_0's l1: 0.233005\tvalid_0's l2: 0.0784227\n",
      "[12]\tvalid_0's l1: 0.230584\tvalid_0's l2: 0.0778041\n",
      "[13]\tvalid_0's l1: 0.228381\tvalid_0's l2: 0.0772972\n",
      "[14]\tvalid_0's l1: 0.226263\tvalid_0's l2: 0.0770375\n",
      "[15]\tvalid_0's l1: 0.224698\tvalid_0's l2: 0.0772138\n",
      "[16]\tvalid_0's l1: 0.223175\tvalid_0's l2: 0.0773809\n",
      "[17]\tvalid_0's l1: 0.222812\tvalid_0's l2: 0.078386\n",
      "[18]\tvalid_0's l1: 0.222011\tvalid_0's l2: 0.0791757\n",
      "[19]\tvalid_0's l1: 0.220963\tvalid_0's l2: 0.0797387\n",
      "[20]\tvalid_0's l1: 0.220404\tvalid_0's l2: 0.0805634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.220404\tvalid_0's l2: 0.0805634\n",
      "[1]\tvalid_0's l1: 0.286076\tvalid_0's l2: 0.112228\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.2768\tvalid_0's l2: 0.105341\n",
      "[3]\tvalid_0's l1: 0.268999\tvalid_0's l2: 0.0995748\n",
      "[4]\tvalid_0's l1: 0.261961\tvalid_0's l2: 0.0946986\n",
      "[5]\tvalid_0's l1: 0.255928\tvalid_0's l2: 0.090536\n",
      "[6]\tvalid_0's l1: 0.250488\tvalid_0's l2: 0.0870066\n",
      "[7]\tvalid_0's l1: 0.245906\tvalid_0's l2: 0.0842243\n",
      "[8]\tvalid_0's l1: 0.242059\tvalid_0's l2: 0.082048\n",
      "[9]\tvalid_0's l1: 0.238915\tvalid_0's l2: 0.0805675\n",
      "[10]\tvalid_0's l1: 0.236082\tvalid_0's l2: 0.0793654\n",
      "[11]\tvalid_0's l1: 0.233476\tvalid_0's l2: 0.078438\n",
      "[12]\tvalid_0's l1: 0.23092\tvalid_0's l2: 0.0776957\n",
      "[13]\tvalid_0's l1: 0.228903\tvalid_0's l2: 0.0773352\n",
      "[14]\tvalid_0's l1: 0.226956\tvalid_0's l2: 0.0771337\n",
      "[15]\tvalid_0's l1: 0.225117\tvalid_0's l2: 0.0770567\n",
      "[16]\tvalid_0's l1: 0.223689\tvalid_0's l2: 0.0772224\n",
      "[17]\tvalid_0's l1: 0.222639\tvalid_0's l2: 0.077746\n",
      "[18]\tvalid_0's l1: 0.221854\tvalid_0's l2: 0.0784206\n",
      "[19]\tvalid_0's l1: 0.221531\tvalid_0's l2: 0.0794363\n",
      "[20]\tvalid_0's l1: 0.220946\tvalid_0's l2: 0.0802754\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.220946\tvalid_0's l2: 0.0802754\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.286456\tvalid_0's l2: 0.112864\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27821\tvalid_0's l2: 0.106555\n",
      "[3]\tvalid_0's l1: 0.271292\tvalid_0's l2: 0.101491\n",
      "[4]\tvalid_0's l1: 0.265564\tvalid_0's l2: 0.0974065\n",
      "[5]\tvalid_0's l1: 0.260955\tvalid_0's l2: 0.0942011\n",
      "[6]\tvalid_0's l1: 0.256499\tvalid_0's l2: 0.0913524\n",
      "[7]\tvalid_0's l1: 0.253219\tvalid_0's l2: 0.0894192\n",
      "[8]\tvalid_0's l1: 0.250239\tvalid_0's l2: 0.087907\n",
      "[9]\tvalid_0's l1: 0.247597\tvalid_0's l2: 0.0868757\n",
      "[10]\tvalid_0's l1: 0.245143\tvalid_0's l2: 0.0862237\n",
      "[11]\tvalid_0's l1: 0.242977\tvalid_0's l2: 0.0857874\n",
      "[12]\tvalid_0's l1: 0.240693\tvalid_0's l2: 0.085384\n",
      "[13]\tvalid_0's l1: 0.239166\tvalid_0's l2: 0.0857084\n",
      "[14]\tvalid_0's l1: 0.237841\tvalid_0's l2: 0.0863646\n",
      "[15]\tvalid_0's l1: 0.236823\tvalid_0's l2: 0.0872521\n",
      "[16]\tvalid_0's l1: 0.236068\tvalid_0's l2: 0.0884058\n",
      "[17]\tvalid_0's l1: 0.235002\tvalid_0's l2: 0.0892528\n",
      "[18]\tvalid_0's l1: 0.234272\tvalid_0's l2: 0.0903308\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.240693\tvalid_0's l2: 0.085384\n",
      "[1]\tvalid_0's l1: 0.286602\tvalid_0's l2: 0.112878\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27868\tvalid_0's l2: 0.106775\n",
      "[3]\tvalid_0's l1: 0.27219\tvalid_0's l2: 0.101869\n",
      "[4]\tvalid_0's l1: 0.266165\tvalid_0's l2: 0.0975913\n",
      "[5]\tvalid_0's l1: 0.261152\tvalid_0's l2: 0.0943696\n",
      "[6]\tvalid_0's l1: 0.256946\tvalid_0's l2: 0.0917023\n",
      "[7]\tvalid_0's l1: 0.253544\tvalid_0's l2: 0.0898399\n",
      "[8]\tvalid_0's l1: 0.250378\tvalid_0's l2: 0.0885252\n",
      "[9]\tvalid_0's l1: 0.247749\tvalid_0's l2: 0.0874782\n",
      "[10]\tvalid_0's l1: 0.245945\tvalid_0's l2: 0.0871507\n",
      "[11]\tvalid_0's l1: 0.244143\tvalid_0's l2: 0.0869006\n",
      "[12]\tvalid_0's l1: 0.242721\tvalid_0's l2: 0.0870644\n",
      "[13]\tvalid_0's l1: 0.241025\tvalid_0's l2: 0.0871405\n",
      "[14]\tvalid_0's l1: 0.240012\tvalid_0's l2: 0.0878407\n",
      "[15]\tvalid_0's l1: 0.238803\tvalid_0's l2: 0.0885244\n",
      "[16]\tvalid_0's l1: 0.238331\tvalid_0's l2: 0.0896219\n",
      "[17]\tvalid_0's l1: 0.2382\tvalid_0's l2: 0.0910205\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.244143\tvalid_0's l2: 0.0869006\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.287395\tvalid_0's l2: 0.113319\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.280068\tvalid_0's l2: 0.107723\n",
      "[3]\tvalid_0's l1: 0.2738\tvalid_0's l2: 0.103153\n",
      "[4]\tvalid_0's l1: 0.2681\tvalid_0's l2: 0.0990855\n",
      "[5]\tvalid_0's l1: 0.263739\tvalid_0's l2: 0.0964158\n",
      "[6]\tvalid_0's l1: 0.260391\tvalid_0's l2: 0.0943406\n",
      "[7]\tvalid_0's l1: 0.257773\tvalid_0's l2: 0.0929774\n",
      "[8]\tvalid_0's l1: 0.255733\tvalid_0's l2: 0.0922044\n",
      "[9]\tvalid_0's l1: 0.254252\tvalid_0's l2: 0.0919834\n",
      "[10]\tvalid_0's l1: 0.25298\tvalid_0's l2: 0.0921771\n",
      "[11]\tvalid_0's l1: 0.252231\tvalid_0's l2: 0.0929115\n",
      "[12]\tvalid_0's l1: 0.250514\tvalid_0's l2: 0.0932078\n",
      "[13]\tvalid_0's l1: 0.249578\tvalid_0's l2: 0.0940585\n",
      "[14]\tvalid_0's l1: 0.249088\tvalid_0's l2: 0.0951854\n",
      "[15]\tvalid_0's l1: 0.248279\tvalid_0's l2: 0.0963908\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.254252\tvalid_0's l2: 0.0919834\n",
      "[1]\tvalid_0's l1: 0.286574\tvalid_0's l2: 0.112671\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.279567\tvalid_0's l2: 0.107323\n",
      "[3]\tvalid_0's l1: 0.27283\tvalid_0's l2: 0.102311\n",
      "[4]\tvalid_0's l1: 0.2679\tvalid_0's l2: 0.0989464\n",
      "[5]\tvalid_0's l1: 0.263723\tvalid_0's l2: 0.0961936\n",
      "[6]\tvalid_0's l1: 0.260123\tvalid_0's l2: 0.0941724\n",
      "[7]\tvalid_0's l1: 0.257386\tvalid_0's l2: 0.0928516\n",
      "[8]\tvalid_0's l1: 0.255219\tvalid_0's l2: 0.0922893\n",
      "[9]\tvalid_0's l1: 0.253425\tvalid_0's l2: 0.0920257\n",
      "[10]\tvalid_0's l1: 0.251248\tvalid_0's l2: 0.0917017\n",
      "[11]\tvalid_0's l1: 0.250014\tvalid_0's l2: 0.0921879\n",
      "[12]\tvalid_0's l1: 0.249499\tvalid_0's l2: 0.0933211\n",
      "[13]\tvalid_0's l1: 0.248898\tvalid_0's l2: 0.0946818\n",
      "[14]\tvalid_0's l1: 0.248341\tvalid_0's l2: 0.0958985\n",
      "[15]\tvalid_0's l1: 0.247859\tvalid_0's l2: 0.0973083\n",
      "[16]\tvalid_0's l1: 0.24766\tvalid_0's l2: 0.0991406\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.251248\tvalid_0's l2: 0.0917017\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.271761\tvalid_0's l2: 0.100101\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.259341\tvalid_0's l2: 0.0912645\n",
      "[3]\tvalid_0's l1: 0.247386\tvalid_0's l2: 0.0831183\n",
      "[4]\tvalid_0's l1: 0.236085\tvalid_0's l2: 0.0757815\n",
      "[5]\tvalid_0's l1: 0.225672\tvalid_0's l2: 0.0693332\n",
      "[6]\tvalid_0's l1: 0.21583\tvalid_0's l2: 0.0634708\n",
      "[7]\tvalid_0's l1: 0.206614\tvalid_0's l2: 0.0582152\n",
      "[8]\tvalid_0's l1: 0.197784\tvalid_0's l2: 0.0534868\n",
      "[9]\tvalid_0's l1: 0.189439\tvalid_0's l2: 0.0491711\n",
      "[10]\tvalid_0's l1: 0.181656\tvalid_0's l2: 0.0453312\n",
      "[11]\tvalid_0's l1: 0.174382\tvalid_0's l2: 0.0419233\n",
      "[12]\tvalid_0's l1: 0.167601\tvalid_0's l2: 0.0388926\n",
      "[13]\tvalid_0's l1: 0.161201\tvalid_0's l2: 0.0361545\n",
      "[14]\tvalid_0's l1: 0.155264\tvalid_0's l2: 0.0336703\n",
      "[15]\tvalid_0's l1: 0.14965\tvalid_0's l2: 0.0314196\n",
      "[16]\tvalid_0's l1: 0.14448\tvalid_0's l2: 0.0294483\n",
      "[17]\tvalid_0's l1: 0.139594\tvalid_0's l2: 0.0276838\n",
      "[18]\tvalid_0's l1: 0.135231\tvalid_0's l2: 0.0261385\n",
      "[19]\tvalid_0's l1: 0.130973\tvalid_0's l2: 0.0247018\n",
      "[20]\tvalid_0's l1: 0.127627\tvalid_0's l2: 0.0236049\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.127627\tvalid_0's l2: 0.0236049\n",
      "[1]\tvalid_0's l1: 0.271775\tvalid_0's l2: 0.10012\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.25911\tvalid_0's l2: 0.0911342\n",
      "[3]\tvalid_0's l1: 0.24726\tvalid_0's l2: 0.0830486\n",
      "[4]\tvalid_0's l1: 0.236111\tvalid_0's l2: 0.0759155\n",
      "[5]\tvalid_0's l1: 0.225566\tvalid_0's l2: 0.0694013\n",
      "[6]\tvalid_0's l1: 0.215752\tvalid_0's l2: 0.0635383\n",
      "[7]\tvalid_0's l1: 0.206284\tvalid_0's l2: 0.0581447\n",
      "[8]\tvalid_0's l1: 0.197515\tvalid_0's l2: 0.0533913\n",
      "[9]\tvalid_0's l1: 0.18923\tvalid_0's l2: 0.0490846\n",
      "[10]\tvalid_0's l1: 0.181534\tvalid_0's l2: 0.0452845\n",
      "[11]\tvalid_0's l1: 0.174237\tvalid_0's l2: 0.0419043\n",
      "[12]\tvalid_0's l1: 0.167351\tvalid_0's l2: 0.0388486\n",
      "[13]\tvalid_0's l1: 0.160982\tvalid_0's l2: 0.0361193\n",
      "[14]\tvalid_0's l1: 0.155025\tvalid_0's l2: 0.0336562\n",
      "[15]\tvalid_0's l1: 0.150132\tvalid_0's l2: 0.0316935\n",
      "[16]\tvalid_0's l1: 0.145691\tvalid_0's l2: 0.0300327\n",
      "[17]\tvalid_0's l1: 0.140895\tvalid_0's l2: 0.0282521\n",
      "[18]\tvalid_0's l1: 0.137031\tvalid_0's l2: 0.0268981\n",
      "[19]\tvalid_0's l1: 0.132761\tvalid_0's l2: 0.0254219\n",
      "[20]\tvalid_0's l1: 0.128807\tvalid_0's l2: 0.0240999\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.128807\tvalid_0's l2: 0.0240999\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273244\tvalid_0's l2: 0.101099\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.262051\tvalid_0's l2: 0.0930538\n",
      "[3]\tvalid_0's l1: 0.252483\tvalid_0's l2: 0.0866479\n",
      "[4]\tvalid_0's l1: 0.242872\tvalid_0's l2: 0.0802418\n",
      "[5]\tvalid_0's l1: 0.234817\tvalid_0's l2: 0.0752999\n",
      "[6]\tvalid_0's l1: 0.226088\tvalid_0's l2: 0.0699477\n",
      "[7]\tvalid_0's l1: 0.218362\tvalid_0's l2: 0.0654062\n",
      "[8]\tvalid_0's l1: 0.21136\tvalid_0's l2: 0.0613521\n",
      "[9]\tvalid_0's l1: 0.204574\tvalid_0's l2: 0.0575725\n",
      "[10]\tvalid_0's l1: 0.198728\tvalid_0's l2: 0.0544639\n",
      "[11]\tvalid_0's l1: 0.19306\tvalid_0's l2: 0.0515729\n",
      "[12]\tvalid_0's l1: 0.187664\tvalid_0's l2: 0.0489633\n",
      "[13]\tvalid_0's l1: 0.183854\tvalid_0's l2: 0.0472927\n",
      "[14]\tvalid_0's l1: 0.18054\tvalid_0's l2: 0.0459147\n",
      "[15]\tvalid_0's l1: 0.176309\tvalid_0's l2: 0.0441083\n",
      "[16]\tvalid_0's l1: 0.173606\tvalid_0's l2: 0.0431599\n",
      "[17]\tvalid_0's l1: 0.169849\tvalid_0's l2: 0.0416898\n",
      "[18]\tvalid_0's l1: 0.16641\tvalid_0's l2: 0.0404245\n",
      "[19]\tvalid_0's l1: 0.163379\tvalid_0's l2: 0.0393901\n",
      "[20]\tvalid_0's l1: 0.160411\tvalid_0's l2: 0.0383478\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.160411\tvalid_0's l2: 0.0383478\n",
      "[1]\tvalid_0's l1: 0.273091\tvalid_0's l2: 0.10113\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.262784\tvalid_0's l2: 0.0938795\n",
      "[3]\tvalid_0's l1: 0.252126\tvalid_0's l2: 0.0864754\n",
      "[4]\tvalid_0's l1: 0.242593\tvalid_0's l2: 0.0801977\n",
      "[5]\tvalid_0's l1: 0.233462\tvalid_0's l2: 0.0744524\n",
      "[6]\tvalid_0's l1: 0.225153\tvalid_0's l2: 0.0693721\n",
      "[7]\tvalid_0's l1: 0.217444\tvalid_0's l2: 0.0648794\n",
      "[8]\tvalid_0's l1: 0.210477\tvalid_0's l2: 0.0609002\n",
      "[9]\tvalid_0's l1: 0.203876\tvalid_0's l2: 0.0572451\n",
      "[10]\tvalid_0's l1: 0.19795\tvalid_0's l2: 0.0540246\n",
      "[11]\tvalid_0's l1: 0.192584\tvalid_0's l2: 0.051329\n",
      "[12]\tvalid_0's l1: 0.187175\tvalid_0's l2: 0.0487511\n",
      "[13]\tvalid_0's l1: 0.182551\tvalid_0's l2: 0.0466248\n",
      "[14]\tvalid_0's l1: 0.178371\tvalid_0's l2: 0.0447823\n",
      "[15]\tvalid_0's l1: 0.174391\tvalid_0's l2: 0.0431007\n",
      "[16]\tvalid_0's l1: 0.170682\tvalid_0's l2: 0.0416913\n",
      "[17]\tvalid_0's l1: 0.167875\tvalid_0's l2: 0.0407942\n",
      "[18]\tvalid_0's l1: 0.164717\tvalid_0's l2: 0.0396804\n",
      "[19]\tvalid_0's l1: 0.162661\tvalid_0's l2: 0.0391223\n",
      "[20]\tvalid_0's l1: 0.159898\tvalid_0's l2: 0.0382251\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.159898\tvalid_0's l2: 0.0382251\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273941\tvalid_0's l2: 0.101831\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.263662\tvalid_0's l2: 0.0945538\n",
      "[3]\tvalid_0's l1: 0.254726\tvalid_0's l2: 0.088533\n",
      "[4]\tvalid_0's l1: 0.246928\tvalid_0's l2: 0.0835239\n",
      "[5]\tvalid_0's l1: 0.240052\tvalid_0's l2: 0.0792437\n",
      "[6]\tvalid_0's l1: 0.233552\tvalid_0's l2: 0.0752471\n",
      "[7]\tvalid_0's l1: 0.227505\tvalid_0's l2: 0.0716614\n",
      "[8]\tvalid_0's l1: 0.223143\tvalid_0's l2: 0.0691763\n",
      "[9]\tvalid_0's l1: 0.218188\tvalid_0's l2: 0.0665136\n",
      "[10]\tvalid_0's l1: 0.213805\tvalid_0's l2: 0.0642877\n",
      "[11]\tvalid_0's l1: 0.209855\tvalid_0's l2: 0.0624407\n",
      "[12]\tvalid_0's l1: 0.206305\tvalid_0's l2: 0.0609559\n",
      "[13]\tvalid_0's l1: 0.203076\tvalid_0's l2: 0.0596966\n",
      "[14]\tvalid_0's l1: 0.200039\tvalid_0's l2: 0.0586393\n",
      "[15]\tvalid_0's l1: 0.19755\tvalid_0's l2: 0.0578463\n",
      "[16]\tvalid_0's l1: 0.195369\tvalid_0's l2: 0.0572276\n",
      "[17]\tvalid_0's l1: 0.193324\tvalid_0's l2: 0.0567586\n",
      "[18]\tvalid_0's l1: 0.19158\tvalid_0's l2: 0.056523\n",
      "[19]\tvalid_0's l1: 0.190093\tvalid_0's l2: 0.0564138\n",
      "[20]\tvalid_0's l1: 0.188651\tvalid_0's l2: 0.0563239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.188651\tvalid_0's l2: 0.0563239\n",
      "[1]\tvalid_0's l1: 0.274\tvalid_0's l2: 0.101939\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.263818\tvalid_0's l2: 0.0947511\n",
      "[3]\tvalid_0's l1: 0.25528\tvalid_0's l2: 0.0889379\n",
      "[4]\tvalid_0's l1: 0.246997\tvalid_0's l2: 0.0834677\n",
      "[5]\tvalid_0's l1: 0.239526\tvalid_0's l2: 0.0786471\n",
      "[6]\tvalid_0's l1: 0.232908\tvalid_0's l2: 0.0745613\n",
      "[7]\tvalid_0's l1: 0.227587\tvalid_0's l2: 0.0714661\n",
      "[8]\tvalid_0's l1: 0.222704\tvalid_0's l2: 0.0686845\n",
      "[9]\tvalid_0's l1: 0.218232\tvalid_0's l2: 0.066333\n",
      "[10]\tvalid_0's l1: 0.214252\tvalid_0's l2: 0.0643807\n",
      "[11]\tvalid_0's l1: 0.210372\tvalid_0's l2: 0.0625948\n",
      "[12]\tvalid_0's l1: 0.207126\tvalid_0's l2: 0.0612217\n",
      "[13]\tvalid_0's l1: 0.204176\tvalid_0's l2: 0.0601471\n",
      "[14]\tvalid_0's l1: 0.201518\tvalid_0's l2: 0.0592941\n",
      "[15]\tvalid_0's l1: 0.199135\tvalid_0's l2: 0.0585508\n",
      "[16]\tvalid_0's l1: 0.197158\tvalid_0's l2: 0.0581485\n",
      "[17]\tvalid_0's l1: 0.195154\tvalid_0's l2: 0.0577026\n",
      "[18]\tvalid_0's l1: 0.194015\tvalid_0's l2: 0.0578153\n",
      "[19]\tvalid_0's l1: 0.192646\tvalid_0's l2: 0.0578313\n",
      "[20]\tvalid_0's l1: 0.191465\tvalid_0's l2: 0.0579673\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.191465\tvalid_0's l2: 0.0579673\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.274396\tvalid_0's l2: 0.102063\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.264768\tvalid_0's l2: 0.0952675\n",
      "[3]\tvalid_0's l1: 0.256052\tvalid_0's l2: 0.0894586\n",
      "[4]\tvalid_0's l1: 0.248748\tvalid_0's l2: 0.084695\n",
      "[5]\tvalid_0's l1: 0.241941\tvalid_0's l2: 0.0802754\n",
      "[6]\tvalid_0's l1: 0.236454\tvalid_0's l2: 0.076877\n",
      "[7]\tvalid_0's l1: 0.232197\tvalid_0's l2: 0.0743569\n",
      "[8]\tvalid_0's l1: 0.227663\tvalid_0's l2: 0.0717961\n",
      "[9]\tvalid_0's l1: 0.224076\tvalid_0's l2: 0.0700357\n",
      "[10]\tvalid_0's l1: 0.220564\tvalid_0's l2: 0.0683551\n",
      "[11]\tvalid_0's l1: 0.217684\tvalid_0's l2: 0.0673486\n",
      "[12]\tvalid_0's l1: 0.215221\tvalid_0's l2: 0.0666968\n",
      "[13]\tvalid_0's l1: 0.2129\tvalid_0's l2: 0.0662305\n",
      "[14]\tvalid_0's l1: 0.210763\tvalid_0's l2: 0.0659448\n",
      "[15]\tvalid_0's l1: 0.208781\tvalid_0's l2: 0.0656755\n",
      "[16]\tvalid_0's l1: 0.206936\tvalid_0's l2: 0.065457\n",
      "[17]\tvalid_0's l1: 0.20597\tvalid_0's l2: 0.0659432\n",
      "[18]\tvalid_0's l1: 0.204751\tvalid_0's l2: 0.0661147\n",
      "[19]\tvalid_0's l1: 0.203578\tvalid_0's l2: 0.0662966\n",
      "[20]\tvalid_0's l1: 0.203033\tvalid_0's l2: 0.0669397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.203033\tvalid_0's l2: 0.0669397\n",
      "[1]\tvalid_0's l1: 0.274498\tvalid_0's l2: 0.102193\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.264874\tvalid_0's l2: 0.0954552\n",
      "[3]\tvalid_0's l1: 0.256058\tvalid_0's l2: 0.0895798\n",
      "[4]\tvalid_0's l1: 0.248487\tvalid_0's l2: 0.0844568\n",
      "[5]\tvalid_0's l1: 0.242158\tvalid_0's l2: 0.0803733\n",
      "[6]\tvalid_0's l1: 0.236691\tvalid_0's l2: 0.0769625\n",
      "[7]\tvalid_0's l1: 0.23219\tvalid_0's l2: 0.0742834\n",
      "[8]\tvalid_0's l1: 0.228251\tvalid_0's l2: 0.0721026\n",
      "[9]\tvalid_0's l1: 0.224884\tvalid_0's l2: 0.0705007\n",
      "[10]\tvalid_0's l1: 0.221795\tvalid_0's l2: 0.0690997\n",
      "[11]\tvalid_0's l1: 0.219031\tvalid_0's l2: 0.0679623\n",
      "[12]\tvalid_0's l1: 0.216657\tvalid_0's l2: 0.0672644\n",
      "[13]\tvalid_0's l1: 0.214713\tvalid_0's l2: 0.0670523\n",
      "[14]\tvalid_0's l1: 0.212987\tvalid_0's l2: 0.067007\n",
      "[15]\tvalid_0's l1: 0.211314\tvalid_0's l2: 0.0670066\n",
      "[16]\tvalid_0's l1: 0.210011\tvalid_0's l2: 0.0672041\n",
      "[17]\tvalid_0's l1: 0.208962\tvalid_0's l2: 0.0675609\n",
      "[18]\tvalid_0's l1: 0.207959\tvalid_0's l2: 0.0680024\n",
      "[19]\tvalid_0's l1: 0.207782\tvalid_0's l2: 0.0690933\n",
      "[20]\tvalid_0's l1: 0.207219\tvalid_0's l2: 0.0698824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.207219\tvalid_0's l2: 0.0698824\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.274945\tvalid_0's l2: 0.102545\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265976\tvalid_0's l2: 0.0961744\n",
      "[3]\tvalid_0's l1: 0.258357\tvalid_0's l2: 0.0909848\n",
      "[4]\tvalid_0's l1: 0.251915\tvalid_0's l2: 0.0867807\n",
      "[5]\tvalid_0's l1: 0.24636\tvalid_0's l2: 0.0834044\n",
      "[6]\tvalid_0's l1: 0.241508\tvalid_0's l2: 0.0805454\n",
      "[7]\tvalid_0's l1: 0.237945\tvalid_0's l2: 0.0785701\n",
      "[8]\tvalid_0's l1: 0.234771\tvalid_0's l2: 0.0771813\n",
      "[9]\tvalid_0's l1: 0.232804\tvalid_0's l2: 0.0765511\n",
      "[10]\tvalid_0's l1: 0.230641\tvalid_0's l2: 0.0760311\n",
      "[11]\tvalid_0's l1: 0.228555\tvalid_0's l2: 0.0757991\n",
      "[12]\tvalid_0's l1: 0.226413\tvalid_0's l2: 0.0755583\n",
      "[13]\tvalid_0's l1: 0.225147\tvalid_0's l2: 0.0760343\n",
      "[14]\tvalid_0's l1: 0.224171\tvalid_0's l2: 0.0768094\n",
      "[15]\tvalid_0's l1: 0.22323\tvalid_0's l2: 0.0776384\n",
      "[16]\tvalid_0's l1: 0.222534\tvalid_0's l2: 0.0785937\n",
      "[17]\tvalid_0's l1: 0.221601\tvalid_0's l2: 0.0794627\n",
      "[18]\tvalid_0's l1: 0.220881\tvalid_0's l2: 0.0805379\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.226413\tvalid_0's l2: 0.0755583\n",
      "[1]\tvalid_0's l1: 0.27478\tvalid_0's l2: 0.102492\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265921\tvalid_0's l2: 0.0962359\n",
      "[3]\tvalid_0's l1: 0.258651\tvalid_0's l2: 0.0915291\n",
      "[4]\tvalid_0's l1: 0.252271\tvalid_0's l2: 0.0872808\n",
      "[5]\tvalid_0's l1: 0.24692\tvalid_0's l2: 0.0838649\n",
      "[6]\tvalid_0's l1: 0.242235\tvalid_0's l2: 0.081054\n",
      "[7]\tvalid_0's l1: 0.238913\tvalid_0's l2: 0.079142\n",
      "[8]\tvalid_0's l1: 0.236072\tvalid_0's l2: 0.0778343\n",
      "[9]\tvalid_0's l1: 0.233659\tvalid_0's l2: 0.076871\n",
      "[10]\tvalid_0's l1: 0.231263\tvalid_0's l2: 0.0761612\n",
      "[11]\tvalid_0's l1: 0.229432\tvalid_0's l2: 0.0760214\n",
      "[12]\tvalid_0's l1: 0.227977\tvalid_0's l2: 0.0760322\n",
      "[13]\tvalid_0's l1: 0.22634\tvalid_0's l2: 0.0762495\n",
      "[14]\tvalid_0's l1: 0.225368\tvalid_0's l2: 0.0771115\n",
      "[15]\tvalid_0's l1: 0.224759\tvalid_0's l2: 0.0783361\n",
      "[16]\tvalid_0's l1: 0.224353\tvalid_0's l2: 0.0793335\n",
      "[17]\tvalid_0's l1: 0.224058\tvalid_0's l2: 0.0805596\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.229432\tvalid_0's l2: 0.0760214\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.275517\tvalid_0's l2: 0.102978\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267358\tvalid_0's l2: 0.097279\n",
      "[3]\tvalid_0's l1: 0.260674\tvalid_0's l2: 0.0928154\n",
      "[4]\tvalid_0's l1: 0.254176\tvalid_0's l2: 0.0885479\n",
      "[5]\tvalid_0's l1: 0.25036\tvalid_0's l2: 0.0859783\n",
      "[6]\tvalid_0's l1: 0.246885\tvalid_0's l2: 0.0838807\n",
      "[7]\tvalid_0's l1: 0.244106\tvalid_0's l2: 0.0824908\n",
      "[8]\tvalid_0's l1: 0.242173\tvalid_0's l2: 0.0818952\n",
      "[9]\tvalid_0's l1: 0.240786\tvalid_0's l2: 0.0818923\n",
      "[10]\tvalid_0's l1: 0.239685\tvalid_0's l2: 0.0822586\n",
      "[11]\tvalid_0's l1: 0.238833\tvalid_0's l2: 0.0828976\n",
      "[12]\tvalid_0's l1: 0.23691\tvalid_0's l2: 0.0829092\n",
      "[13]\tvalid_0's l1: 0.236144\tvalid_0's l2: 0.0839018\n",
      "[14]\tvalid_0's l1: 0.235531\tvalid_0's l2: 0.0850253\n",
      "[15]\tvalid_0's l1: 0.234438\tvalid_0's l2: 0.0858302\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.240786\tvalid_0's l2: 0.0818923\n",
      "[1]\tvalid_0's l1: 0.275218\tvalid_0's l2: 0.102855\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267304\tvalid_0's l2: 0.0973561\n",
      "[3]\tvalid_0's l1: 0.259864\tvalid_0's l2: 0.0924223\n",
      "[4]\tvalid_0's l1: 0.254341\tvalid_0's l2: 0.0888416\n",
      "[5]\tvalid_0's l1: 0.2502\tvalid_0's l2: 0.086167\n",
      "[6]\tvalid_0's l1: 0.247107\tvalid_0's l2: 0.0841499\n",
      "[7]\tvalid_0's l1: 0.24444\tvalid_0's l2: 0.0827291\n",
      "[8]\tvalid_0's l1: 0.242498\tvalid_0's l2: 0.0820966\n",
      "[9]\tvalid_0's l1: 0.240963\tvalid_0's l2: 0.0818989\n",
      "[10]\tvalid_0's l1: 0.238784\tvalid_0's l2: 0.0815279\n",
      "[11]\tvalid_0's l1: 0.237619\tvalid_0's l2: 0.0820212\n",
      "[12]\tvalid_0's l1: 0.236821\tvalid_0's l2: 0.0831821\n",
      "[13]\tvalid_0's l1: 0.236037\tvalid_0's l2: 0.0845567\n",
      "[14]\tvalid_0's l1: 0.235221\tvalid_0's l2: 0.0857149\n",
      "[15]\tvalid_0's l1: 0.23499\tvalid_0's l2: 0.08759\n",
      "[16]\tvalid_0's l1: 0.235161\tvalid_0's l2: 0.0896879\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.238784\tvalid_0's l2: 0.0815279\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.263514\tvalid_0's l2: 0.0938624\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.250934\tvalid_0's l2: 0.0851496\n",
      "[3]\tvalid_0's l1: 0.239062\tvalid_0's l2: 0.0772854\n",
      "[4]\tvalid_0's l1: 0.227776\tvalid_0's l2: 0.0701867\n",
      "[5]\tvalid_0's l1: 0.217209\tvalid_0's l2: 0.0638335\n",
      "[6]\tvalid_0's l1: 0.207223\tvalid_0's l2: 0.0580765\n",
      "[7]\tvalid_0's l1: 0.197795\tvalid_0's l2: 0.0528953\n",
      "[8]\tvalid_0's l1: 0.18881\tvalid_0's l2: 0.0482259\n",
      "[9]\tvalid_0's l1: 0.180389\tvalid_0's l2: 0.0440176\n",
      "[10]\tvalid_0's l1: 0.172586\tvalid_0's l2: 0.0402947\n",
      "[11]\tvalid_0's l1: 0.165197\tvalid_0's l2: 0.0369492\n",
      "[12]\tvalid_0's l1: 0.158277\tvalid_0's l2: 0.0339428\n",
      "[13]\tvalid_0's l1: 0.151732\tvalid_0's l2: 0.0312259\n",
      "[14]\tvalid_0's l1: 0.145538\tvalid_0's l2: 0.0287703\n",
      "[15]\tvalid_0's l1: 0.139602\tvalid_0's l2: 0.0265104\n",
      "[16]\tvalid_0's l1: 0.13409\tvalid_0's l2: 0.0245161\n",
      "[17]\tvalid_0's l1: 0.128784\tvalid_0's l2: 0.0226932\n",
      "[18]\tvalid_0's l1: 0.123931\tvalid_0's l2: 0.0210987\n",
      "[19]\tvalid_0's l1: 0.119365\tvalid_0's l2: 0.0196532\n",
      "[20]\tvalid_0's l1: 0.115513\tvalid_0's l2: 0.0184864\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.115513\tvalid_0's l2: 0.0184864\n",
      "[1]\tvalid_0's l1: 0.263456\tvalid_0's l2: 0.0938476\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.250803\tvalid_0's l2: 0.0850641\n",
      "[3]\tvalid_0's l1: 0.238812\tvalid_0's l2: 0.0771201\n",
      "[4]\tvalid_0's l1: 0.227603\tvalid_0's l2: 0.070072\n",
      "[5]\tvalid_0's l1: 0.216911\tvalid_0's l2: 0.0636656\n",
      "[6]\tvalid_0's l1: 0.206837\tvalid_0's l2: 0.0578773\n",
      "[7]\tvalid_0's l1: 0.197286\tvalid_0's l2: 0.0526647\n",
      "[8]\tvalid_0's l1: 0.188371\tvalid_0's l2: 0.0480239\n",
      "[9]\tvalid_0's l1: 0.180071\tvalid_0's l2: 0.0438877\n",
      "[10]\tvalid_0's l1: 0.17221\tvalid_0's l2: 0.0401553\n",
      "[11]\tvalid_0's l1: 0.164759\tvalid_0's l2: 0.0367718\n",
      "[12]\tvalid_0's l1: 0.157733\tvalid_0's l2: 0.0337503\n",
      "[13]\tvalid_0's l1: 0.151267\tvalid_0's l2: 0.0310662\n",
      "[14]\tvalid_0's l1: 0.145088\tvalid_0's l2: 0.0286386\n",
      "[15]\tvalid_0's l1: 0.13954\tvalid_0's l2: 0.0265704\n",
      "[16]\tvalid_0's l1: 0.134563\tvalid_0's l2: 0.0247853\n",
      "[17]\tvalid_0's l1: 0.129397\tvalid_0's l2: 0.0229688\n",
      "[18]\tvalid_0's l1: 0.125068\tvalid_0's l2: 0.0215234\n",
      "[19]\tvalid_0's l1: 0.120616\tvalid_0's l2: 0.0200714\n",
      "[20]\tvalid_0's l1: 0.11643\tvalid_0's l2: 0.0187665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.11643\tvalid_0's l2: 0.0187665\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.264139\tvalid_0's l2: 0.0944372\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.2524\tvalid_0's l2: 0.0863359\n",
      "[3]\tvalid_0's l1: 0.242096\tvalid_0's l2: 0.0796151\n",
      "[4]\tvalid_0's l1: 0.231557\tvalid_0's l2: 0.072934\n",
      "[5]\tvalid_0's l1: 0.222919\tvalid_0's l2: 0.0677499\n",
      "[6]\tvalid_0's l1: 0.213771\tvalid_0's l2: 0.0624104\n",
      "[7]\tvalid_0's l1: 0.205201\tvalid_0's l2: 0.0575353\n",
      "[8]\tvalid_0's l1: 0.197139\tvalid_0's l2: 0.0531934\n",
      "[9]\tvalid_0's l1: 0.189581\tvalid_0's l2: 0.0493162\n",
      "[10]\tvalid_0's l1: 0.182791\tvalid_0's l2: 0.045907\n",
      "[11]\tvalid_0's l1: 0.176386\tvalid_0's l2: 0.0428114\n",
      "[12]\tvalid_0's l1: 0.170615\tvalid_0's l2: 0.0401306\n",
      "[13]\tvalid_0's l1: 0.1661\tvalid_0's l2: 0.038116\n",
      "[14]\tvalid_0's l1: 0.162046\tvalid_0's l2: 0.0363853\n",
      "[15]\tvalid_0's l1: 0.157294\tvalid_0's l2: 0.0343939\n",
      "[16]\tvalid_0's l1: 0.153961\tvalid_0's l2: 0.0331272\n",
      "[17]\tvalid_0's l1: 0.150029\tvalid_0's l2: 0.0316653\n",
      "[18]\tvalid_0's l1: 0.146406\tvalid_0's l2: 0.030381\n",
      "[19]\tvalid_0's l1: 0.143112\tvalid_0's l2: 0.0292165\n",
      "[20]\tvalid_0's l1: 0.139946\tvalid_0's l2: 0.028158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.139946\tvalid_0's l2: 0.028158\n",
      "[1]\tvalid_0's l1: 0.264205\tvalid_0's l2: 0.0944997\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.253018\tvalid_0's l2: 0.086905\n",
      "[3]\tvalid_0's l1: 0.241831\tvalid_0's l2: 0.0795533\n",
      "[4]\tvalid_0's l1: 0.231243\tvalid_0's l2: 0.0728705\n",
      "[5]\tvalid_0's l1: 0.221587\tvalid_0's l2: 0.0669867\n",
      "[6]\tvalid_0's l1: 0.212193\tvalid_0's l2: 0.0615346\n",
      "[7]\tvalid_0's l1: 0.203758\tvalid_0's l2: 0.0568127\n",
      "[8]\tvalid_0's l1: 0.195675\tvalid_0's l2: 0.0524877\n",
      "[9]\tvalid_0's l1: 0.188333\tvalid_0's l2: 0.0486794\n",
      "[10]\tvalid_0's l1: 0.181485\tvalid_0's l2: 0.0452525\n",
      "[11]\tvalid_0's l1: 0.175442\tvalid_0's l2: 0.042391\n",
      "[12]\tvalid_0's l1: 0.169529\tvalid_0's l2: 0.0396363\n",
      "[13]\tvalid_0's l1: 0.164155\tvalid_0's l2: 0.037243\n",
      "[14]\tvalid_0's l1: 0.159135\tvalid_0's l2: 0.0350956\n",
      "[15]\tvalid_0's l1: 0.154798\tvalid_0's l2: 0.0333124\n",
      "[16]\tvalid_0's l1: 0.150872\tvalid_0's l2: 0.0317244\n",
      "[17]\tvalid_0's l1: 0.14751\tvalid_0's l2: 0.0305107\n",
      "[18]\tvalid_0's l1: 0.143908\tvalid_0's l2: 0.0291998\n",
      "[19]\tvalid_0's l1: 0.141547\tvalid_0's l2: 0.0284545\n",
      "[20]\tvalid_0's l1: 0.138487\tvalid_0's l2: 0.0274464\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.138487\tvalid_0's l2: 0.0274464\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265138\tvalid_0's l2: 0.0952026\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254267\tvalid_0's l2: 0.0877008\n",
      "[3]\tvalid_0's l1: 0.245303\tvalid_0's l2: 0.0817602\n",
      "[4]\tvalid_0's l1: 0.23724\tvalid_0's l2: 0.076661\n",
      "[5]\tvalid_0's l1: 0.230067\tvalid_0's l2: 0.0723346\n",
      "[6]\tvalid_0's l1: 0.222709\tvalid_0's l2: 0.0678396\n",
      "[7]\tvalid_0's l1: 0.215533\tvalid_0's l2: 0.0636402\n",
      "[8]\tvalid_0's l1: 0.210811\tvalid_0's l2: 0.0609655\n",
      "[9]\tvalid_0's l1: 0.204671\tvalid_0's l2: 0.0576351\n",
      "[10]\tvalid_0's l1: 0.199366\tvalid_0's l2: 0.0549886\n",
      "[11]\tvalid_0's l1: 0.194462\tvalid_0's l2: 0.0524833\n",
      "[12]\tvalid_0's l1: 0.190085\tvalid_0's l2: 0.050363\n",
      "[13]\tvalid_0's l1: 0.185865\tvalid_0's l2: 0.0484135\n",
      "[14]\tvalid_0's l1: 0.182149\tvalid_0's l2: 0.0468328\n",
      "[15]\tvalid_0's l1: 0.178818\tvalid_0's l2: 0.0455223\n",
      "[16]\tvalid_0's l1: 0.17557\tvalid_0's l2: 0.0442828\n",
      "[17]\tvalid_0's l1: 0.172746\tvalid_0's l2: 0.043318\n",
      "[18]\tvalid_0's l1: 0.170266\tvalid_0's l2: 0.0426221\n",
      "[19]\tvalid_0's l1: 0.167974\tvalid_0's l2: 0.0419639\n",
      "[20]\tvalid_0's l1: 0.165904\tvalid_0's l2: 0.0414518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.165904\tvalid_0's l2: 0.0414518\n",
      "[1]\tvalid_0's l1: 0.264963\tvalid_0's l2: 0.0951161\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254316\tvalid_0's l2: 0.0878999\n",
      "[3]\tvalid_0's l1: 0.24507\tvalid_0's l2: 0.0819679\n",
      "[4]\tvalid_0's l1: 0.235649\tvalid_0's l2: 0.0760071\n",
      "[5]\tvalid_0's l1: 0.227486\tvalid_0's l2: 0.0709997\n",
      "[6]\tvalid_0's l1: 0.219756\tvalid_0's l2: 0.0663468\n",
      "[7]\tvalid_0's l1: 0.214534\tvalid_0's l2: 0.0631208\n",
      "[8]\tvalid_0's l1: 0.208236\tvalid_0's l2: 0.059518\n",
      "[9]\tvalid_0's l1: 0.202538\tvalid_0's l2: 0.0564307\n",
      "[10]\tvalid_0's l1: 0.197396\tvalid_0's l2: 0.0537536\n",
      "[11]\tvalid_0's l1: 0.192709\tvalid_0's l2: 0.0514433\n",
      "[12]\tvalid_0's l1: 0.188608\tvalid_0's l2: 0.0495499\n",
      "[13]\tvalid_0's l1: 0.185057\tvalid_0's l2: 0.0479478\n",
      "[14]\tvalid_0's l1: 0.181765\tvalid_0's l2: 0.0465904\n",
      "[15]\tvalid_0's l1: 0.178286\tvalid_0's l2: 0.0451918\n",
      "[16]\tvalid_0's l1: 0.175478\tvalid_0's l2: 0.044205\n",
      "[17]\tvalid_0's l1: 0.172985\tvalid_0's l2: 0.0433863\n",
      "[18]\tvalid_0's l1: 0.171787\tvalid_0's l2: 0.0433776\n",
      "[19]\tvalid_0's l1: 0.169411\tvalid_0's l2: 0.0427446\n",
      "[20]\tvalid_0's l1: 0.167396\tvalid_0's l2: 0.0423043\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.167396\tvalid_0's l2: 0.0423043\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265881\tvalid_0's l2: 0.09572\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256068\tvalid_0's l2: 0.0890418\n",
      "[3]\tvalid_0's l1: 0.247565\tvalid_0's l2: 0.0833853\n",
      "[4]\tvalid_0's l1: 0.239895\tvalid_0's l2: 0.0785399\n",
      "[5]\tvalid_0's l1: 0.233077\tvalid_0's l2: 0.0742948\n",
      "[6]\tvalid_0's l1: 0.227306\tvalid_0's l2: 0.0708473\n",
      "[7]\tvalid_0's l1: 0.222849\tvalid_0's l2: 0.0683094\n",
      "[8]\tvalid_0's l1: 0.21815\tvalid_0's l2: 0.0657437\n",
      "[9]\tvalid_0's l1: 0.214485\tvalid_0's l2: 0.0639577\n",
      "[10]\tvalid_0's l1: 0.210718\tvalid_0's l2: 0.062262\n",
      "[11]\tvalid_0's l1: 0.207592\tvalid_0's l2: 0.0610144\n",
      "[12]\tvalid_0's l1: 0.20482\tvalid_0's l2: 0.0600801\n",
      "[13]\tvalid_0's l1: 0.202644\tvalid_0's l2: 0.0595613\n",
      "[14]\tvalid_0's l1: 0.200524\tvalid_0's l2: 0.0590113\n",
      "[15]\tvalid_0's l1: 0.198653\tvalid_0's l2: 0.0586544\n",
      "[16]\tvalid_0's l1: 0.196775\tvalid_0's l2: 0.0584629\n",
      "[17]\tvalid_0's l1: 0.195909\tvalid_0's l2: 0.0589562\n",
      "[18]\tvalid_0's l1: 0.194393\tvalid_0's l2: 0.0589945\n",
      "[19]\tvalid_0's l1: 0.192684\tvalid_0's l2: 0.058921\n",
      "[20]\tvalid_0's l1: 0.191534\tvalid_0's l2: 0.0591525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.191534\tvalid_0's l2: 0.0591525\n",
      "[1]\tvalid_0's l1: 0.265303\tvalid_0's l2: 0.0954924\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.255228\tvalid_0's l2: 0.0887257\n",
      "[3]\tvalid_0's l1: 0.246382\tvalid_0's l2: 0.0829535\n",
      "[4]\tvalid_0's l1: 0.238344\tvalid_0's l2: 0.0778529\n",
      "[5]\tvalid_0's l1: 0.231931\tvalid_0's l2: 0.0738554\n",
      "[6]\tvalid_0's l1: 0.226354\tvalid_0's l2: 0.0704151\n",
      "[7]\tvalid_0's l1: 0.22139\tvalid_0's l2: 0.0675419\n",
      "[8]\tvalid_0's l1: 0.217093\tvalid_0's l2: 0.0651284\n",
      "[9]\tvalid_0's l1: 0.213145\tvalid_0's l2: 0.0631187\n",
      "[10]\tvalid_0's l1: 0.209888\tvalid_0's l2: 0.0617034\n",
      "[11]\tvalid_0's l1: 0.206936\tvalid_0's l2: 0.0605684\n",
      "[12]\tvalid_0's l1: 0.20439\tvalid_0's l2: 0.0597108\n",
      "[13]\tvalid_0's l1: 0.202254\tvalid_0's l2: 0.0592222\n",
      "[14]\tvalid_0's l1: 0.200255\tvalid_0's l2: 0.0588716\n",
      "[15]\tvalid_0's l1: 0.19843\tvalid_0's l2: 0.0586593\n",
      "[16]\tvalid_0's l1: 0.196982\tvalid_0's l2: 0.0586694\n",
      "[17]\tvalid_0's l1: 0.195716\tvalid_0's l2: 0.0588016\n",
      "[18]\tvalid_0's l1: 0.194809\tvalid_0's l2: 0.0592015\n",
      "[19]\tvalid_0's l1: 0.19432\tvalid_0's l2: 0.0599465\n",
      "[20]\tvalid_0's l1: 0.193578\tvalid_0's l2: 0.0606189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.193578\tvalid_0's l2: 0.0606189\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.266376\tvalid_0's l2: 0.0960921\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.257052\tvalid_0's l2: 0.0896502\n",
      "[3]\tvalid_0's l1: 0.249402\tvalid_0's l2: 0.0844811\n",
      "[4]\tvalid_0's l1: 0.243069\tvalid_0's l2: 0.0802362\n",
      "[5]\tvalid_0's l1: 0.237738\tvalid_0's l2: 0.076786\n",
      "[6]\tvalid_0's l1: 0.232679\tvalid_0's l2: 0.0736859\n",
      "[7]\tvalid_0's l1: 0.228958\tvalid_0's l2: 0.071568\n",
      "[8]\tvalid_0's l1: 0.225615\tvalid_0's l2: 0.0698964\n",
      "[9]\tvalid_0's l1: 0.22316\tvalid_0's l2: 0.069034\n",
      "[10]\tvalid_0's l1: 0.22068\tvalid_0's l2: 0.0682072\n",
      "[11]\tvalid_0's l1: 0.218561\tvalid_0's l2: 0.0677982\n",
      "[12]\tvalid_0's l1: 0.216288\tvalid_0's l2: 0.0672888\n",
      "[13]\tvalid_0's l1: 0.214888\tvalid_0's l2: 0.067462\n",
      "[14]\tvalid_0's l1: 0.213533\tvalid_0's l2: 0.0678073\n",
      "[15]\tvalid_0's l1: 0.212383\tvalid_0's l2: 0.0683252\n",
      "[16]\tvalid_0's l1: 0.211686\tvalid_0's l2: 0.0691729\n",
      "[17]\tvalid_0's l1: 0.210426\tvalid_0's l2: 0.069549\n",
      "[18]\tvalid_0's l1: 0.209409\tvalid_0's l2: 0.0701561\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.216288\tvalid_0's l2: 0.0672888\n",
      "[1]\tvalid_0's l1: 0.266147\tvalid_0's l2: 0.0960039\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256734\tvalid_0's l2: 0.0896532\n",
      "[3]\tvalid_0's l1: 0.249653\tvalid_0's l2: 0.0848086\n",
      "[4]\tvalid_0's l1: 0.242837\tvalid_0's l2: 0.0802284\n",
      "[5]\tvalid_0's l1: 0.237227\tvalid_0's l2: 0.0765096\n",
      "[6]\tvalid_0's l1: 0.232388\tvalid_0's l2: 0.0734844\n",
      "[7]\tvalid_0's l1: 0.228615\tvalid_0's l2: 0.0714529\n",
      "[8]\tvalid_0's l1: 0.225521\tvalid_0's l2: 0.0699093\n",
      "[9]\tvalid_0's l1: 0.223035\tvalid_0's l2: 0.0688013\n",
      "[10]\tvalid_0's l1: 0.220817\tvalid_0's l2: 0.0681615\n",
      "[11]\tvalid_0's l1: 0.218883\tvalid_0's l2: 0.0677843\n",
      "[12]\tvalid_0's l1: 0.217184\tvalid_0's l2: 0.0677822\n",
      "[13]\tvalid_0's l1: 0.215531\tvalid_0's l2: 0.0677602\n",
      "[14]\tvalid_0's l1: 0.214641\tvalid_0's l2: 0.0683476\n",
      "[15]\tvalid_0's l1: 0.213823\tvalid_0's l2: 0.0690616\n",
      "[16]\tvalid_0's l1: 0.213251\tvalid_0's l2: 0.069977\n",
      "[17]\tvalid_0's l1: 0.212918\tvalid_0's l2: 0.0710817\n",
      "[18]\tvalid_0's l1: 0.212605\tvalid_0's l2: 0.0722591\n",
      "[19]\tvalid_0's l1: 0.212524\tvalid_0's l2: 0.0737259\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.215531\tvalid_0's l2: 0.0677602\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.267044\tvalid_0's l2: 0.0965503\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.258778\tvalid_0's l2: 0.0908885\n",
      "[3]\tvalid_0's l1: 0.251983\tvalid_0's l2: 0.0863183\n",
      "[4]\tvalid_0's l1: 0.245742\tvalid_0's l2: 0.0821527\n",
      "[5]\tvalid_0's l1: 0.241616\tvalid_0's l2: 0.079479\n",
      "[6]\tvalid_0's l1: 0.237954\tvalid_0's l2: 0.0772299\n",
      "[7]\tvalid_0's l1: 0.234927\tvalid_0's l2: 0.0756538\n",
      "[8]\tvalid_0's l1: 0.232816\tvalid_0's l2: 0.0749192\n",
      "[9]\tvalid_0's l1: 0.231392\tvalid_0's l2: 0.0747636\n",
      "[10]\tvalid_0's l1: 0.23045\tvalid_0's l2: 0.0751543\n",
      "[11]\tvalid_0's l1: 0.229692\tvalid_0's l2: 0.0759712\n",
      "[12]\tvalid_0's l1: 0.227953\tvalid_0's l2: 0.0760925\n",
      "[13]\tvalid_0's l1: 0.226938\tvalid_0's l2: 0.0768009\n",
      "[14]\tvalid_0's l1: 0.226309\tvalid_0's l2: 0.0778807\n",
      "[15]\tvalid_0's l1: 0.225241\tvalid_0's l2: 0.0787932\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.231392\tvalid_0's l2: 0.0747636\n",
      "[1]\tvalid_0's l1: 0.266712\tvalid_0's l2: 0.096305\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.25904\tvalid_0's l2: 0.0909215\n",
      "[3]\tvalid_0's l1: 0.251157\tvalid_0's l2: 0.0857221\n",
      "[4]\tvalid_0's l1: 0.245353\tvalid_0's l2: 0.0819823\n",
      "[5]\tvalid_0's l1: 0.241131\tvalid_0's l2: 0.0792992\n",
      "[6]\tvalid_0's l1: 0.237113\tvalid_0's l2: 0.0769243\n",
      "[7]\tvalid_0's l1: 0.233947\tvalid_0's l2: 0.0753739\n",
      "[8]\tvalid_0's l1: 0.231925\tvalid_0's l2: 0.0745744\n",
      "[9]\tvalid_0's l1: 0.23047\tvalid_0's l2: 0.0744474\n",
      "[10]\tvalid_0's l1: 0.228502\tvalid_0's l2: 0.0742376\n",
      "[11]\tvalid_0's l1: 0.22728\tvalid_0's l2: 0.0745299\n",
      "[12]\tvalid_0's l1: 0.226246\tvalid_0's l2: 0.0751938\n",
      "[13]\tvalid_0's l1: 0.2254\tvalid_0's l2: 0.0762682\n",
      "[14]\tvalid_0's l1: 0.224549\tvalid_0's l2: 0.077257\n",
      "[15]\tvalid_0's l1: 0.224343\tvalid_0's l2: 0.0788982\n",
      "[16]\tvalid_0's l1: 0.224085\tvalid_0's l2: 0.0801546\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.228502\tvalid_0's l2: 0.0742376\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        x_train_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        x_train_withCD = df_train_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        x_test_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        x_test_withCD = df_test_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # y: response (target) variable DFma_1 [col 12]\n",
    "        y_train = df_train_dist.iloc[:, [12]]\n",
    "        y_test = df_test_dist.iloc[:, [12]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_dist['DFma_1'])\n",
    "        y_test_true = np.array(df_test_dist['DFma_1'])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                                  + str(i) + '_horizon_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                               + str(i) + '_horizon_' + str(j + 1) + '_withCD_' + str(num_leaves) + '.csv', \n",
    "                                               encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_ByDistrict_MA' + str(i) + '_horizon_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_dist_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.31428\tvalid_0's l2: 0.139405\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305192\tvalid_0's l2: 0.132154\n",
      "[3]\tvalid_0's l1: 0.296936\tvalid_0's l2: 0.125953\n",
      "[4]\tvalid_0's l1: 0.289451\tvalid_0's l2: 0.120464\n",
      "[5]\tvalid_0's l1: 0.28261\tvalid_0's l2: 0.115405\n",
      "[6]\tvalid_0's l1: 0.27608\tvalid_0's l2: 0.11089\n",
      "[7]\tvalid_0's l1: 0.270015\tvalid_0's l2: 0.106922\n",
      "[8]\tvalid_0's l1: 0.264622\tvalid_0's l2: 0.10356\n",
      "[9]\tvalid_0's l1: 0.259604\tvalid_0's l2: 0.100467\n",
      "[10]\tvalid_0's l1: 0.255125\tvalid_0's l2: 0.0978501\n",
      "[11]\tvalid_0's l1: 0.250901\tvalid_0's l2: 0.0954956\n",
      "[12]\tvalid_0's l1: 0.247003\tvalid_0's l2: 0.0933007\n",
      "[13]\tvalid_0's l1: 0.243492\tvalid_0's l2: 0.0914733\n",
      "[14]\tvalid_0's l1: 0.240292\tvalid_0's l2: 0.0900979\n",
      "[15]\tvalid_0's l1: 0.23739\tvalid_0's l2: 0.088925\n",
      "[16]\tvalid_0's l1: 0.234363\tvalid_0's l2: 0.0876695\n",
      "[17]\tvalid_0's l1: 0.231615\tvalid_0's l2: 0.0866116\n",
      "[18]\tvalid_0's l1: 0.22914\tvalid_0's l2: 0.0857226\n",
      "[19]\tvalid_0's l1: 0.226897\tvalid_0's l2: 0.085056\n",
      "[20]\tvalid_0's l1: 0.224723\tvalid_0's l2: 0.0842725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.224723\tvalid_0's l2: 0.0842725\n",
      "[1]\tvalid_0's l1: 0.314237\tvalid_0's l2: 0.139391\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305186\tvalid_0's l2: 0.132354\n",
      "[3]\tvalid_0's l1: 0.296532\tvalid_0's l2: 0.125741\n",
      "[4]\tvalid_0's l1: 0.288997\tvalid_0's l2: 0.120086\n",
      "[5]\tvalid_0's l1: 0.282243\tvalid_0's l2: 0.115316\n",
      "[6]\tvalid_0's l1: 0.275712\tvalid_0's l2: 0.110827\n",
      "[7]\tvalid_0's l1: 0.269616\tvalid_0's l2: 0.106831\n",
      "[8]\tvalid_0's l1: 0.264563\tvalid_0's l2: 0.103633\n",
      "[9]\tvalid_0's l1: 0.259599\tvalid_0's l2: 0.100595\n",
      "[10]\tvalid_0's l1: 0.254825\tvalid_0's l2: 0.097763\n",
      "[11]\tvalid_0's l1: 0.250502\tvalid_0's l2: 0.0952673\n",
      "[12]\tvalid_0's l1: 0.246633\tvalid_0's l2: 0.0931071\n",
      "[13]\tvalid_0's l1: 0.243194\tvalid_0's l2: 0.091425\n",
      "[14]\tvalid_0's l1: 0.239893\tvalid_0's l2: 0.0899551\n",
      "[15]\tvalid_0's l1: 0.236659\tvalid_0's l2: 0.0882054\n",
      "[16]\tvalid_0's l1: 0.233664\tvalid_0's l2: 0.0868091\n",
      "[17]\tvalid_0's l1: 0.230924\tvalid_0's l2: 0.0857987\n",
      "[18]\tvalid_0's l1: 0.228591\tvalid_0's l2: 0.0848418\n",
      "[19]\tvalid_0's l1: 0.226349\tvalid_0's l2: 0.0841249\n",
      "[20]\tvalid_0's l1: 0.224298\tvalid_0's l2: 0.0834519\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.224298\tvalid_0's l2: 0.0834519\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.314619\tvalid_0's l2: 0.139536\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306053\tvalid_0's l2: 0.132621\n",
      "[3]\tvalid_0's l1: 0.29795\tvalid_0's l2: 0.126341\n",
      "[4]\tvalid_0's l1: 0.290721\tvalid_0's l2: 0.120911\n",
      "[5]\tvalid_0's l1: 0.28422\tvalid_0's l2: 0.116329\n",
      "[6]\tvalid_0's l1: 0.27818\tvalid_0's l2: 0.111959\n",
      "[7]\tvalid_0's l1: 0.27294\tvalid_0's l2: 0.108376\n",
      "[8]\tvalid_0's l1: 0.267988\tvalid_0's l2: 0.105236\n",
      "[9]\tvalid_0's l1: 0.263329\tvalid_0's l2: 0.102319\n",
      "[10]\tvalid_0's l1: 0.259285\tvalid_0's l2: 0.100018\n",
      "[11]\tvalid_0's l1: 0.255285\tvalid_0's l2: 0.0978365\n",
      "[12]\tvalid_0's l1: 0.251511\tvalid_0's l2: 0.0958526\n",
      "[13]\tvalid_0's l1: 0.2486\tvalid_0's l2: 0.0944785\n",
      "[14]\tvalid_0's l1: 0.245994\tvalid_0's l2: 0.0935231\n",
      "[15]\tvalid_0's l1: 0.243116\tvalid_0's l2: 0.0923157\n",
      "[16]\tvalid_0's l1: 0.241176\tvalid_0's l2: 0.0917436\n",
      "[17]\tvalid_0's l1: 0.238985\tvalid_0's l2: 0.0911063\n",
      "[18]\tvalid_0's l1: 0.237123\tvalid_0's l2: 0.0906322\n",
      "[19]\tvalid_0's l1: 0.235635\tvalid_0's l2: 0.0905163\n",
      "[20]\tvalid_0's l1: 0.234195\tvalid_0's l2: 0.0905119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.234195\tvalid_0's l2: 0.0905119\n",
      "[1]\tvalid_0's l1: 0.31467\tvalid_0's l2: 0.139609\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.30573\tvalid_0's l2: 0.13252\n",
      "[3]\tvalid_0's l1: 0.297481\tvalid_0's l2: 0.126045\n",
      "[4]\tvalid_0's l1: 0.29042\tvalid_0's l2: 0.12062\n",
      "[5]\tvalid_0's l1: 0.284088\tvalid_0's l2: 0.115943\n",
      "[6]\tvalid_0's l1: 0.278084\tvalid_0's l2: 0.111796\n",
      "[7]\tvalid_0's l1: 0.272563\tvalid_0's l2: 0.108203\n",
      "[8]\tvalid_0's l1: 0.267718\tvalid_0's l2: 0.104959\n",
      "[9]\tvalid_0's l1: 0.263168\tvalid_0's l2: 0.102214\n",
      "[10]\tvalid_0's l1: 0.258883\tvalid_0's l2: 0.0998402\n",
      "[11]\tvalid_0's l1: 0.255118\tvalid_0's l2: 0.0977597\n",
      "[12]\tvalid_0's l1: 0.251368\tvalid_0's l2: 0.0958627\n",
      "[13]\tvalid_0's l1: 0.248136\tvalid_0's l2: 0.0944138\n",
      "[14]\tvalid_0's l1: 0.245256\tvalid_0's l2: 0.093188\n",
      "[15]\tvalid_0's l1: 0.242412\tvalid_0's l2: 0.0921593\n",
      "[16]\tvalid_0's l1: 0.240217\tvalid_0's l2: 0.0915145\n",
      "[17]\tvalid_0's l1: 0.238031\tvalid_0's l2: 0.0907097\n",
      "[18]\tvalid_0's l1: 0.236296\tvalid_0's l2: 0.0901818\n",
      "[19]\tvalid_0's l1: 0.234642\tvalid_0's l2: 0.0896942\n",
      "[20]\tvalid_0's l1: 0.233068\tvalid_0's l2: 0.0893139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.233068\tvalid_0's l2: 0.0893139\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.31451\tvalid_0's l2: 0.139618\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305823\tvalid_0's l2: 0.132834\n",
      "[3]\tvalid_0's l1: 0.298706\tvalid_0's l2: 0.127435\n",
      "[4]\tvalid_0's l1: 0.292604\tvalid_0's l2: 0.122812\n",
      "[5]\tvalid_0's l1: 0.287279\tvalid_0's l2: 0.119115\n",
      "[6]\tvalid_0's l1: 0.28179\tvalid_0's l2: 0.115382\n",
      "[7]\tvalid_0's l1: 0.276682\tvalid_0's l2: 0.112055\n",
      "[8]\tvalid_0's l1: 0.272774\tvalid_0's l2: 0.109803\n",
      "[9]\tvalid_0's l1: 0.26871\tvalid_0's l2: 0.107537\n",
      "[10]\tvalid_0's l1: 0.265132\tvalid_0's l2: 0.10571\n",
      "[11]\tvalid_0's l1: 0.261904\tvalid_0's l2: 0.104255\n",
      "[12]\tvalid_0's l1: 0.259059\tvalid_0's l2: 0.103197\n",
      "[13]\tvalid_0's l1: 0.256536\tvalid_0's l2: 0.102499\n",
      "[14]\tvalid_0's l1: 0.254569\tvalid_0's l2: 0.102234\n",
      "[15]\tvalid_0's l1: 0.252967\tvalid_0's l2: 0.102291\n",
      "[16]\tvalid_0's l1: 0.25126\tvalid_0's l2: 0.102174\n",
      "[17]\tvalid_0's l1: 0.249588\tvalid_0's l2: 0.102126\n",
      "[18]\tvalid_0's l1: 0.248447\tvalid_0's l2: 0.102519\n",
      "[19]\tvalid_0's l1: 0.247482\tvalid_0's l2: 0.103082\n",
      "[20]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.103696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.103696\n",
      "[1]\tvalid_0's l1: 0.314667\tvalid_0's l2: 0.13977\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306229\tvalid_0's l2: 0.133105\n",
      "[3]\tvalid_0's l1: 0.29923\tvalid_0's l2: 0.127683\n",
      "[4]\tvalid_0's l1: 0.291936\tvalid_0's l2: 0.122246\n",
      "[5]\tvalid_0's l1: 0.28596\tvalid_0's l2: 0.118027\n",
      "[6]\tvalid_0's l1: 0.280623\tvalid_0's l2: 0.114317\n",
      "[7]\tvalid_0's l1: 0.276268\tvalid_0's l2: 0.111438\n",
      "[8]\tvalid_0's l1: 0.271841\tvalid_0's l2: 0.108734\n",
      "[9]\tvalid_0's l1: 0.268044\tvalid_0's l2: 0.106583\n",
      "[10]\tvalid_0's l1: 0.264809\tvalid_0's l2: 0.105014\n",
      "[11]\tvalid_0's l1: 0.261748\tvalid_0's l2: 0.103811\n",
      "[12]\tvalid_0's l1: 0.259186\tvalid_0's l2: 0.103082\n",
      "[13]\tvalid_0's l1: 0.256772\tvalid_0's l2: 0.102537\n",
      "[14]\tvalid_0's l1: 0.254794\tvalid_0's l2: 0.102235\n",
      "[15]\tvalid_0's l1: 0.253095\tvalid_0's l2: 0.102155\n",
      "[16]\tvalid_0's l1: 0.251543\tvalid_0's l2: 0.102069\n",
      "[17]\tvalid_0's l1: 0.25026\tvalid_0's l2: 0.102132\n",
      "[18]\tvalid_0's l1: 0.249238\tvalid_0's l2: 0.102457\n",
      "[19]\tvalid_0's l1: 0.247997\tvalid_0's l2: 0.102738\n",
      "[20]\tvalid_0's l1: 0.247017\tvalid_0's l2: 0.103179\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.247017\tvalid_0's l2: 0.103179\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315081\tvalid_0's l2: 0.14009\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.307523\tvalid_0's l2: 0.134156\n",
      "[3]\tvalid_0's l1: 0.300575\tvalid_0's l2: 0.128597\n",
      "[4]\tvalid_0's l1: 0.294792\tvalid_0's l2: 0.12428\n",
      "[5]\tvalid_0's l1: 0.289206\tvalid_0's l2: 0.120216\n",
      "[6]\tvalid_0's l1: 0.284573\tvalid_0's l2: 0.117054\n",
      "[7]\tvalid_0's l1: 0.280893\tvalid_0's l2: 0.114553\n",
      "[8]\tvalid_0's l1: 0.277019\tvalid_0's l2: 0.112283\n",
      "[9]\tvalid_0's l1: 0.273924\tvalid_0's l2: 0.110793\n",
      "[10]\tvalid_0's l1: 0.270768\tvalid_0's l2: 0.109342\n",
      "[11]\tvalid_0's l1: 0.268323\tvalid_0's l2: 0.108317\n",
      "[12]\tvalid_0's l1: 0.266179\tvalid_0's l2: 0.107735\n",
      "[13]\tvalid_0's l1: 0.264109\tvalid_0's l2: 0.10727\n",
      "[14]\tvalid_0's l1: 0.26269\tvalid_0's l2: 0.107406\n",
      "[15]\tvalid_0's l1: 0.260956\tvalid_0's l2: 0.107218\n",
      "[16]\tvalid_0's l1: 0.259286\tvalid_0's l2: 0.107293\n",
      "[17]\tvalid_0's l1: 0.258548\tvalid_0's l2: 0.108174\n",
      "[18]\tvalid_0's l1: 0.257256\tvalid_0's l2: 0.108531\n",
      "[19]\tvalid_0's l1: 0.256128\tvalid_0's l2: 0.109069\n",
      "[20]\tvalid_0's l1: 0.255228\tvalid_0's l2: 0.109802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.255228\tvalid_0's l2: 0.109802\n",
      "[1]\tvalid_0's l1: 0.315087\tvalid_0's l2: 0.140198\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.307715\tvalid_0's l2: 0.133963\n",
      "[3]\tvalid_0's l1: 0.301172\tvalid_0's l2: 0.128545\n",
      "[4]\tvalid_0's l1: 0.294469\tvalid_0's l2: 0.123702\n",
      "[5]\tvalid_0's l1: 0.289194\tvalid_0's l2: 0.11999\n",
      "[6]\tvalid_0's l1: 0.284426\tvalid_0's l2: 0.116795\n",
      "[7]\tvalid_0's l1: 0.28051\tvalid_0's l2: 0.11447\n",
      "[8]\tvalid_0's l1: 0.276625\tvalid_0's l2: 0.112257\n",
      "[9]\tvalid_0's l1: 0.273465\tvalid_0's l2: 0.110489\n",
      "[10]\tvalid_0's l1: 0.270944\tvalid_0's l2: 0.109457\n",
      "[11]\tvalid_0's l1: 0.268749\tvalid_0's l2: 0.10855\n",
      "[12]\tvalid_0's l1: 0.266817\tvalid_0's l2: 0.107908\n",
      "[13]\tvalid_0's l1: 0.265389\tvalid_0's l2: 0.107713\n",
      "[14]\tvalid_0's l1: 0.264052\tvalid_0's l2: 0.107908\n",
      "[15]\tvalid_0's l1: 0.262769\tvalid_0's l2: 0.108242\n",
      "[16]\tvalid_0's l1: 0.26163\tvalid_0's l2: 0.108854\n",
      "[17]\tvalid_0's l1: 0.260526\tvalid_0's l2: 0.109342\n",
      "[18]\tvalid_0's l1: 0.259704\tvalid_0's l2: 0.110268\n",
      "[19]\tvalid_0's l1: 0.259343\tvalid_0's l2: 0.111027\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.265389\tvalid_0's l2: 0.107713\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315479\tvalid_0's l2: 0.140282\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308749\tvalid_0's l2: 0.134484\n",
      "[3]\tvalid_0's l1: 0.302685\tvalid_0's l2: 0.129557\n",
      "[4]\tvalid_0's l1: 0.297787\tvalid_0's l2: 0.125835\n",
      "[5]\tvalid_0's l1: 0.293558\tvalid_0's l2: 0.12276\n",
      "[6]\tvalid_0's l1: 0.289579\tvalid_0's l2: 0.119919\n",
      "[7]\tvalid_0's l1: 0.286596\tvalid_0's l2: 0.118055\n",
      "[8]\tvalid_0's l1: 0.284009\tvalid_0's l2: 0.116676\n",
      "[9]\tvalid_0's l1: 0.281736\tvalid_0's l2: 0.115773\n",
      "[10]\tvalid_0's l1: 0.27965\tvalid_0's l2: 0.115259\n",
      "[11]\tvalid_0's l1: 0.278097\tvalid_0's l2: 0.114976\n",
      "[12]\tvalid_0's l1: 0.276321\tvalid_0's l2: 0.114741\n",
      "[13]\tvalid_0's l1: 0.275249\tvalid_0's l2: 0.115117\n",
      "[14]\tvalid_0's l1: 0.274344\tvalid_0's l2: 0.11579\n",
      "[15]\tvalid_0's l1: 0.273604\tvalid_0's l2: 0.116738\n",
      "[16]\tvalid_0's l1: 0.273224\tvalid_0's l2: 0.118049\n",
      "[17]\tvalid_0's l1: 0.272328\tvalid_0's l2: 0.119011\n",
      "[18]\tvalid_0's l1: 0.271665\tvalid_0's l2: 0.120289\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.276321\tvalid_0's l2: 0.114741\n",
      "[1]\tvalid_0's l1: 0.315142\tvalid_0's l2: 0.140092\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308155\tvalid_0's l2: 0.134471\n",
      "[3]\tvalid_0's l1: 0.302994\tvalid_0's l2: 0.130053\n",
      "[4]\tvalid_0's l1: 0.298303\tvalid_0's l2: 0.126255\n",
      "[5]\tvalid_0's l1: 0.294513\tvalid_0's l2: 0.123496\n",
      "[6]\tvalid_0's l1: 0.290648\tvalid_0's l2: 0.120721\n",
      "[7]\tvalid_0's l1: 0.287349\tvalid_0's l2: 0.11863\n",
      "[8]\tvalid_0's l1: 0.284827\tvalid_0's l2: 0.117292\n",
      "[9]\tvalid_0's l1: 0.282513\tvalid_0's l2: 0.116425\n",
      "[10]\tvalid_0's l1: 0.280827\tvalid_0's l2: 0.115852\n",
      "[11]\tvalid_0's l1: 0.279278\tvalid_0's l2: 0.11575\n",
      "[12]\tvalid_0's l1: 0.278201\tvalid_0's l2: 0.116208\n",
      "[13]\tvalid_0's l1: 0.276808\tvalid_0's l2: 0.116476\n",
      "[14]\tvalid_0's l1: 0.276021\tvalid_0's l2: 0.117388\n",
      "[15]\tvalid_0's l1: 0.275427\tvalid_0's l2: 0.118704\n",
      "[16]\tvalid_0's l1: 0.275308\tvalid_0's l2: 0.120353\n",
      "[17]\tvalid_0's l1: 0.27501\tvalid_0's l2: 0.121755\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.279278\tvalid_0's l2: 0.11575\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.316786\tvalid_0's l2: 0.141243\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310552\tvalid_0's l2: 0.136147\n",
      "[3]\tvalid_0's l1: 0.30561\tvalid_0's l2: 0.13227\n",
      "[4]\tvalid_0's l1: 0.301393\tvalid_0's l2: 0.128907\n",
      "[5]\tvalid_0's l1: 0.298188\tvalid_0's l2: 0.126527\n",
      "[6]\tvalid_0's l1: 0.295356\tvalid_0's l2: 0.124603\n",
      "[7]\tvalid_0's l1: 0.293223\tvalid_0's l2: 0.123624\n",
      "[8]\tvalid_0's l1: 0.29129\tvalid_0's l2: 0.122936\n",
      "[9]\tvalid_0's l1: 0.290065\tvalid_0's l2: 0.122995\n",
      "[10]\tvalid_0's l1: 0.289312\tvalid_0's l2: 0.123713\n",
      "[11]\tvalid_0's l1: 0.288403\tvalid_0's l2: 0.124434\n",
      "[12]\tvalid_0's l1: 0.286723\tvalid_0's l2: 0.124697\n",
      "[13]\tvalid_0's l1: 0.285757\tvalid_0's l2: 0.125602\n",
      "[14]\tvalid_0's l1: 0.285086\tvalid_0's l2: 0.126752\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.29129\tvalid_0's l2: 0.122936\n",
      "[1]\tvalid_0's l1: 0.316993\tvalid_0's l2: 0.141339\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.311822\tvalid_0's l2: 0.137117\n",
      "[3]\tvalid_0's l1: 0.306196\tvalid_0's l2: 0.13267\n",
      "[4]\tvalid_0's l1: 0.302682\tvalid_0's l2: 0.130172\n",
      "[5]\tvalid_0's l1: 0.299262\tvalid_0's l2: 0.12787\n",
      "[6]\tvalid_0's l1: 0.296225\tvalid_0's l2: 0.126066\n",
      "[7]\tvalid_0's l1: 0.293854\tvalid_0's l2: 0.125216\n",
      "[8]\tvalid_0's l1: 0.292003\tvalid_0's l2: 0.124884\n",
      "[9]\tvalid_0's l1: 0.289937\tvalid_0's l2: 0.124382\n",
      "[10]\tvalid_0's l1: 0.288326\tvalid_0's l2: 0.12445\n",
      "[11]\tvalid_0's l1: 0.287342\tvalid_0's l2: 0.125067\n",
      "[12]\tvalid_0's l1: 0.2867\tvalid_0's l2: 0.126175\n",
      "[13]\tvalid_0's l1: 0.285563\tvalid_0's l2: 0.126984\n",
      "[14]\tvalid_0's l1: 0.2845\tvalid_0's l2: 0.127816\n",
      "[15]\tvalid_0's l1: 0.28416\tvalid_0's l2: 0.129472\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.289937\tvalid_0's l2: 0.124382\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_total_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i):12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i):12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 31]\n",
    "        \n",
    "    x_train_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    x_train_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    x_test_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    x_test_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # y: response (target) variable DF_1 (col 4)\n",
    "    y_train = df_train_dist.iloc[:, [4]]\n",
    "    y_test = df_test_dist.iloc[:, [4]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_dist['DF_1'])\n",
    "    y_test_true = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                              + str(i + 1) + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                           + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                           + str(i + 1) + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_ByDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_dist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.283641\tvalid_0's l2: 0.110376\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.271572\tvalid_0's l2: 0.101492\n",
      "[3]\tvalid_0's l1: 0.26041\tvalid_0's l2: 0.0935903\n",
      "[4]\tvalid_0's l1: 0.249939\tvalid_0's l2: 0.086458\n",
      "[5]\tvalid_0's l1: 0.240266\tvalid_0's l2: 0.0800588\n",
      "[6]\tvalid_0's l1: 0.230778\tvalid_0's l2: 0.0739703\n",
      "[7]\tvalid_0's l1: 0.222297\tvalid_0's l2: 0.0687202\n",
      "[8]\tvalid_0's l1: 0.214238\tvalid_0's l2: 0.0639262\n",
      "[9]\tvalid_0's l1: 0.206957\tvalid_0's l2: 0.0597754\n",
      "[10]\tvalid_0's l1: 0.19999\tvalid_0's l2: 0.0559453\n",
      "[11]\tvalid_0's l1: 0.193503\tvalid_0's l2: 0.0526016\n",
      "[12]\tvalid_0's l1: 0.187519\tvalid_0's l2: 0.0496168\n",
      "[13]\tvalid_0's l1: 0.181837\tvalid_0's l2: 0.0468264\n",
      "[14]\tvalid_0's l1: 0.176483\tvalid_0's l2: 0.044302\n",
      "[15]\tvalid_0's l1: 0.171885\tvalid_0's l2: 0.0422899\n",
      "[16]\tvalid_0's l1: 0.167348\tvalid_0's l2: 0.0403468\n",
      "[17]\tvalid_0's l1: 0.163089\tvalid_0's l2: 0.0385858\n",
      "[18]\tvalid_0's l1: 0.159218\tvalid_0's l2: 0.0370312\n",
      "[19]\tvalid_0's l1: 0.155495\tvalid_0's l2: 0.035631\n",
      "[20]\tvalid_0's l1: 0.152831\tvalid_0's l2: 0.0347121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.152831\tvalid_0's l2: 0.0347121\n",
      "[1]\tvalid_0's l1: 0.283534\tvalid_0's l2: 0.110239\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27131\tvalid_0's l2: 0.10129\n",
      "[3]\tvalid_0's l1: 0.260058\tvalid_0's l2: 0.0933261\n",
      "[4]\tvalid_0's l1: 0.249552\tvalid_0's l2: 0.0861605\n",
      "[5]\tvalid_0's l1: 0.239806\tvalid_0's l2: 0.0797004\n",
      "[6]\tvalid_0's l1: 0.230543\tvalid_0's l2: 0.0737179\n",
      "[7]\tvalid_0's l1: 0.221881\tvalid_0's l2: 0.0683911\n",
      "[8]\tvalid_0's l1: 0.214053\tvalid_0's l2: 0.0637709\n",
      "[9]\tvalid_0's l1: 0.206678\tvalid_0's l2: 0.0595522\n",
      "[10]\tvalid_0's l1: 0.199914\tvalid_0's l2: 0.0558097\n",
      "[11]\tvalid_0's l1: 0.193473\tvalid_0's l2: 0.0524806\n",
      "[12]\tvalid_0's l1: 0.187508\tvalid_0's l2: 0.0495212\n",
      "[13]\tvalid_0's l1: 0.182106\tvalid_0's l2: 0.0469712\n",
      "[14]\tvalid_0's l1: 0.176837\tvalid_0's l2: 0.044434\n",
      "[15]\tvalid_0's l1: 0.173032\tvalid_0's l2: 0.0428168\n",
      "[16]\tvalid_0's l1: 0.16958\tvalid_0's l2: 0.0414621\n",
      "[17]\tvalid_0's l1: 0.165296\tvalid_0's l2: 0.039637\n",
      "[18]\tvalid_0's l1: 0.162385\tvalid_0's l2: 0.0385978\n",
      "[19]\tvalid_0's l1: 0.158584\tvalid_0's l2: 0.0371182\n",
      "[20]\tvalid_0's l1: 0.155046\tvalid_0's l2: 0.0357623\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.155046\tvalid_0's l2: 0.0357623\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285646\tvalid_0's l2: 0.112008\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275985\tvalid_0's l2: 0.104912\n",
      "[3]\tvalid_0's l1: 0.266773\tvalid_0's l2: 0.0984341\n",
      "[4]\tvalid_0's l1: 0.258522\tvalid_0's l2: 0.0928206\n",
      "[5]\tvalid_0's l1: 0.25124\tvalid_0's l2: 0.0879765\n",
      "[6]\tvalid_0's l1: 0.244114\tvalid_0's l2: 0.0833693\n",
      "[7]\tvalid_0's l1: 0.237791\tvalid_0's l2: 0.0795048\n",
      "[8]\tvalid_0's l1: 0.231924\tvalid_0's l2: 0.0760697\n",
      "[9]\tvalid_0's l1: 0.226631\tvalid_0's l2: 0.0731354\n",
      "[10]\tvalid_0's l1: 0.221882\tvalid_0's l2: 0.0706267\n",
      "[11]\tvalid_0's l1: 0.217581\tvalid_0's l2: 0.0685689\n",
      "[12]\tvalid_0's l1: 0.213341\tvalid_0's l2: 0.0665987\n",
      "[13]\tvalid_0's l1: 0.209892\tvalid_0's l2: 0.065159\n",
      "[14]\tvalid_0's l1: 0.207002\tvalid_0's l2: 0.0640132\n",
      "[15]\tvalid_0's l1: 0.204097\tvalid_0's l2: 0.0628613\n",
      "[16]\tvalid_0's l1: 0.201678\tvalid_0's l2: 0.0620067\n",
      "[17]\tvalid_0's l1: 0.19897\tvalid_0's l2: 0.0609856\n",
      "[18]\tvalid_0's l1: 0.19654\tvalid_0's l2: 0.0601754\n",
      "[19]\tvalid_0's l1: 0.194524\tvalid_0's l2: 0.0597132\n",
      "[20]\tvalid_0's l1: 0.192429\tvalid_0's l2: 0.0591639\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192429\tvalid_0's l2: 0.0591639\n",
      "[1]\tvalid_0's l1: 0.285628\tvalid_0's l2: 0.11208\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275694\tvalid_0's l2: 0.104723\n",
      "[3]\tvalid_0's l1: 0.266505\tvalid_0's l2: 0.0982367\n",
      "[4]\tvalid_0's l1: 0.258262\tvalid_0's l2: 0.0926111\n",
      "[5]\tvalid_0's l1: 0.250977\tvalid_0's l2: 0.0878353\n",
      "[6]\tvalid_0's l1: 0.244014\tvalid_0's l2: 0.0833877\n",
      "[7]\tvalid_0's l1: 0.237556\tvalid_0's l2: 0.0794549\n",
      "[8]\tvalid_0's l1: 0.231982\tvalid_0's l2: 0.0761778\n",
      "[9]\tvalid_0's l1: 0.226543\tvalid_0's l2: 0.0731647\n",
      "[10]\tvalid_0's l1: 0.221614\tvalid_0's l2: 0.0705583\n",
      "[11]\tvalid_0's l1: 0.217252\tvalid_0's l2: 0.068364\n",
      "[12]\tvalid_0's l1: 0.213292\tvalid_0's l2: 0.0665033\n",
      "[13]\tvalid_0's l1: 0.209827\tvalid_0's l2: 0.0649874\n",
      "[14]\tvalid_0's l1: 0.206537\tvalid_0's l2: 0.0636861\n",
      "[15]\tvalid_0's l1: 0.20349\tvalid_0's l2: 0.0626128\n",
      "[16]\tvalid_0's l1: 0.200908\tvalid_0's l2: 0.0616636\n",
      "[17]\tvalid_0's l1: 0.198622\tvalid_0's l2: 0.0608673\n",
      "[18]\tvalid_0's l1: 0.196512\tvalid_0's l2: 0.0602506\n",
      "[19]\tvalid_0's l1: 0.194589\tvalid_0's l2: 0.0598018\n",
      "[20]\tvalid_0's l1: 0.192886\tvalid_0's l2: 0.0595418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.192886\tvalid_0's l2: 0.0595418\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285507\tvalid_0's l2: 0.111886\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275761\tvalid_0's l2: 0.104751\n",
      "[3]\tvalid_0's l1: 0.267218\tvalid_0's l2: 0.0986081\n",
      "[4]\tvalid_0's l1: 0.259935\tvalid_0's l2: 0.0935163\n",
      "[5]\tvalid_0's l1: 0.253803\tvalid_0's l2: 0.0892985\n",
      "[6]\tvalid_0's l1: 0.247654\tvalid_0's l2: 0.0853686\n",
      "[7]\tvalid_0's l1: 0.242216\tvalid_0's l2: 0.0820264\n",
      "[8]\tvalid_0's l1: 0.238116\tvalid_0's l2: 0.079662\n",
      "[9]\tvalid_0's l1: 0.233781\tvalid_0's l2: 0.0773174\n",
      "[10]\tvalid_0's l1: 0.229879\tvalid_0's l2: 0.0754622\n",
      "[11]\tvalid_0's l1: 0.226192\tvalid_0's l2: 0.0738489\n",
      "[12]\tvalid_0's l1: 0.222872\tvalid_0's l2: 0.0725582\n",
      "[13]\tvalid_0's l1: 0.2199\tvalid_0's l2: 0.0716218\n",
      "[14]\tvalid_0's l1: 0.217347\tvalid_0's l2: 0.0709308\n",
      "[15]\tvalid_0's l1: 0.21519\tvalid_0's l2: 0.070532\n",
      "[16]\tvalid_0's l1: 0.213208\tvalid_0's l2: 0.0701737\n",
      "[17]\tvalid_0's l1: 0.211362\tvalid_0's l2: 0.0699198\n",
      "[18]\tvalid_0's l1: 0.209784\tvalid_0's l2: 0.0698639\n",
      "[19]\tvalid_0's l1: 0.208512\tvalid_0's l2: 0.0700761\n",
      "[20]\tvalid_0's l1: 0.207114\tvalid_0's l2: 0.0701661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.207114\tvalid_0's l2: 0.0701661\n",
      "[1]\tvalid_0's l1: 0.285652\tvalid_0's l2: 0.11197\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.275777\tvalid_0's l2: 0.104651\n",
      "[3]\tvalid_0's l1: 0.267212\tvalid_0's l2: 0.0985758\n",
      "[4]\tvalid_0's l1: 0.259305\tvalid_0's l2: 0.0931451\n",
      "[5]\tvalid_0's l1: 0.252372\tvalid_0's l2: 0.0885947\n",
      "[6]\tvalid_0's l1: 0.246489\tvalid_0's l2: 0.0847224\n",
      "[7]\tvalid_0's l1: 0.241628\tvalid_0's l2: 0.081795\n",
      "[8]\tvalid_0's l1: 0.236832\tvalid_0's l2: 0.0790262\n",
      "[9]\tvalid_0's l1: 0.232503\tvalid_0's l2: 0.0766489\n",
      "[10]\tvalid_0's l1: 0.22864\tvalid_0's l2: 0.0747569\n",
      "[11]\tvalid_0's l1: 0.225247\tvalid_0's l2: 0.0731863\n",
      "[12]\tvalid_0's l1: 0.22239\tvalid_0's l2: 0.0720961\n",
      "[13]\tvalid_0's l1: 0.219721\tvalid_0's l2: 0.0713088\n",
      "[14]\tvalid_0's l1: 0.217385\tvalid_0's l2: 0.070722\n",
      "[15]\tvalid_0's l1: 0.215421\tvalid_0's l2: 0.0704054\n",
      "[16]\tvalid_0's l1: 0.213468\tvalid_0's l2: 0.070105\n",
      "[17]\tvalid_0's l1: 0.21171\tvalid_0's l2: 0.0700182\n",
      "[18]\tvalid_0's l1: 0.21069\tvalid_0's l2: 0.0702286\n",
      "[19]\tvalid_0's l1: 0.20926\tvalid_0's l2: 0.0703352\n",
      "[20]\tvalid_0's l1: 0.20839\tvalid_0's l2: 0.0707226\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.20839\tvalid_0's l2: 0.0707226\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.285999\tvalid_0's l2: 0.112255\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.276909\tvalid_0's l2: 0.105507\n",
      "[3]\tvalid_0's l1: 0.268952\tvalid_0's l2: 0.0997182\n",
      "[4]\tvalid_0's l1: 0.262133\tvalid_0's l2: 0.0948572\n",
      "[5]\tvalid_0's l1: 0.256099\tvalid_0's l2: 0.0907271\n",
      "[6]\tvalid_0's l1: 0.25068\tvalid_0's l2: 0.0872825\n",
      "[7]\tvalid_0's l1: 0.246734\tvalid_0's l2: 0.0848273\n",
      "[8]\tvalid_0's l1: 0.242438\tvalid_0's l2: 0.0825122\n",
      "[9]\tvalid_0's l1: 0.23909\tvalid_0's l2: 0.0808561\n",
      "[10]\tvalid_0's l1: 0.235827\tvalid_0's l2: 0.0794628\n",
      "[11]\tvalid_0's l1: 0.233005\tvalid_0's l2: 0.0784227\n",
      "[12]\tvalid_0's l1: 0.230584\tvalid_0's l2: 0.0778041\n",
      "[13]\tvalid_0's l1: 0.228381\tvalid_0's l2: 0.0772972\n",
      "[14]\tvalid_0's l1: 0.226263\tvalid_0's l2: 0.0770375\n",
      "[15]\tvalid_0's l1: 0.224698\tvalid_0's l2: 0.0772138\n",
      "[16]\tvalid_0's l1: 0.223175\tvalid_0's l2: 0.0773809\n",
      "[17]\tvalid_0's l1: 0.222812\tvalid_0's l2: 0.078386\n",
      "[18]\tvalid_0's l1: 0.222011\tvalid_0's l2: 0.0791757\n",
      "[19]\tvalid_0's l1: 0.220963\tvalid_0's l2: 0.0797387\n",
      "[20]\tvalid_0's l1: 0.220404\tvalid_0's l2: 0.0805634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.220404\tvalid_0's l2: 0.0805634\n",
      "[1]\tvalid_0's l1: 0.285985\tvalid_0's l2: 0.112235\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.276821\tvalid_0's l2: 0.105365\n",
      "[3]\tvalid_0's l1: 0.268863\tvalid_0's l2: 0.0996187\n",
      "[4]\tvalid_0's l1: 0.261674\tvalid_0's l2: 0.0945868\n",
      "[5]\tvalid_0's l1: 0.255545\tvalid_0's l2: 0.0904656\n",
      "[6]\tvalid_0's l1: 0.250241\tvalid_0's l2: 0.0869877\n",
      "[7]\tvalid_0's l1: 0.245742\tvalid_0's l2: 0.0842278\n",
      "[8]\tvalid_0's l1: 0.242012\tvalid_0's l2: 0.0820772\n",
      "[9]\tvalid_0's l1: 0.238758\tvalid_0's l2: 0.0804136\n",
      "[10]\tvalid_0's l1: 0.235798\tvalid_0's l2: 0.0792378\n",
      "[11]\tvalid_0's l1: 0.233118\tvalid_0's l2: 0.0781866\n",
      "[12]\tvalid_0's l1: 0.230748\tvalid_0's l2: 0.0776077\n",
      "[13]\tvalid_0's l1: 0.228737\tvalid_0's l2: 0.077207\n",
      "[14]\tvalid_0's l1: 0.226871\tvalid_0's l2: 0.0770677\n",
      "[15]\tvalid_0's l1: 0.225565\tvalid_0's l2: 0.077311\n",
      "[16]\tvalid_0's l1: 0.224255\tvalid_0's l2: 0.0775753\n",
      "[17]\tvalid_0's l1: 0.223253\tvalid_0's l2: 0.0782483\n",
      "[18]\tvalid_0's l1: 0.22237\tvalid_0's l2: 0.0790131\n",
      "[19]\tvalid_0's l1: 0.22202\tvalid_0's l2: 0.0799166\n",
      "[20]\tvalid_0's l1: 0.221644\tvalid_0's l2: 0.0809756\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.221644\tvalid_0's l2: 0.0809756\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.286456\tvalid_0's l2: 0.112864\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.27821\tvalid_0's l2: 0.106555\n",
      "[3]\tvalid_0's l1: 0.271292\tvalid_0's l2: 0.101491\n",
      "[4]\tvalid_0's l1: 0.265564\tvalid_0's l2: 0.0974065\n",
      "[5]\tvalid_0's l1: 0.260955\tvalid_0's l2: 0.0942011\n",
      "[6]\tvalid_0's l1: 0.256499\tvalid_0's l2: 0.0913524\n",
      "[7]\tvalid_0's l1: 0.253219\tvalid_0's l2: 0.0894192\n",
      "[8]\tvalid_0's l1: 0.250239\tvalid_0's l2: 0.087907\n",
      "[9]\tvalid_0's l1: 0.247597\tvalid_0's l2: 0.0868757\n",
      "[10]\tvalid_0's l1: 0.245143\tvalid_0's l2: 0.0862237\n",
      "[11]\tvalid_0's l1: 0.242977\tvalid_0's l2: 0.0857874\n",
      "[12]\tvalid_0's l1: 0.240693\tvalid_0's l2: 0.085384\n",
      "[13]\tvalid_0's l1: 0.239166\tvalid_0's l2: 0.0857084\n",
      "[14]\tvalid_0's l1: 0.237841\tvalid_0's l2: 0.0863646\n",
      "[15]\tvalid_0's l1: 0.236823\tvalid_0's l2: 0.0872521\n",
      "[16]\tvalid_0's l1: 0.236068\tvalid_0's l2: 0.0884058\n",
      "[17]\tvalid_0's l1: 0.235002\tvalid_0's l2: 0.0892528\n",
      "[18]\tvalid_0's l1: 0.234272\tvalid_0's l2: 0.0903308\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.240693\tvalid_0's l2: 0.085384\n",
      "[1]\tvalid_0's l1: 0.286184\tvalid_0's l2: 0.112713\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.278347\tvalid_0's l2: 0.106603\n",
      "[3]\tvalid_0's l1: 0.271957\tvalid_0's l2: 0.101819\n",
      "[4]\tvalid_0's l1: 0.266041\tvalid_0's l2: 0.0977309\n",
      "[5]\tvalid_0's l1: 0.261147\tvalid_0's l2: 0.0944771\n",
      "[6]\tvalid_0's l1: 0.256903\tvalid_0's l2: 0.091905\n",
      "[7]\tvalid_0's l1: 0.253797\tvalid_0's l2: 0.0903751\n",
      "[8]\tvalid_0's l1: 0.251356\tvalid_0's l2: 0.0896366\n",
      "[9]\tvalid_0's l1: 0.248828\tvalid_0's l2: 0.0888508\n",
      "[10]\tvalid_0's l1: 0.246882\tvalid_0's l2: 0.0885853\n",
      "[11]\tvalid_0's l1: 0.245198\tvalid_0's l2: 0.0885039\n",
      "[12]\tvalid_0's l1: 0.243645\tvalid_0's l2: 0.0886353\n",
      "[13]\tvalid_0's l1: 0.242098\tvalid_0's l2: 0.0888143\n",
      "[14]\tvalid_0's l1: 0.241061\tvalid_0's l2: 0.089594\n",
      "[15]\tvalid_0's l1: 0.240331\tvalid_0's l2: 0.0907555\n",
      "[16]\tvalid_0's l1: 0.239839\tvalid_0's l2: 0.0921321\n",
      "[17]\tvalid_0's l1: 0.239469\tvalid_0's l2: 0.0934627\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.245198\tvalid_0's l2: 0.0885039\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.287395\tvalid_0's l2: 0.113319\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.280068\tvalid_0's l2: 0.107723\n",
      "[3]\tvalid_0's l1: 0.2738\tvalid_0's l2: 0.103153\n",
      "[4]\tvalid_0's l1: 0.2681\tvalid_0's l2: 0.0990855\n",
      "[5]\tvalid_0's l1: 0.263739\tvalid_0's l2: 0.0964158\n",
      "[6]\tvalid_0's l1: 0.260391\tvalid_0's l2: 0.0943406\n",
      "[7]\tvalid_0's l1: 0.257773\tvalid_0's l2: 0.0929774\n",
      "[8]\tvalid_0's l1: 0.255733\tvalid_0's l2: 0.0922044\n",
      "[9]\tvalid_0's l1: 0.254252\tvalid_0's l2: 0.0919834\n",
      "[10]\tvalid_0's l1: 0.25298\tvalid_0's l2: 0.0921771\n",
      "[11]\tvalid_0's l1: 0.252231\tvalid_0's l2: 0.0929115\n",
      "[12]\tvalid_0's l1: 0.250514\tvalid_0's l2: 0.0932078\n",
      "[13]\tvalid_0's l1: 0.249578\tvalid_0's l2: 0.0940585\n",
      "[14]\tvalid_0's l1: 0.249088\tvalid_0's l2: 0.0951854\n",
      "[15]\tvalid_0's l1: 0.248279\tvalid_0's l2: 0.0963908\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.254252\tvalid_0's l2: 0.0919834\n",
      "[1]\tvalid_0's l1: 0.286967\tvalid_0's l2: 0.112769\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.279829\tvalid_0's l2: 0.107306\n",
      "[3]\tvalid_0's l1: 0.273083\tvalid_0's l2: 0.102502\n",
      "[4]\tvalid_0's l1: 0.268208\tvalid_0's l2: 0.0992669\n",
      "[5]\tvalid_0's l1: 0.264394\tvalid_0's l2: 0.0968808\n",
      "[6]\tvalid_0's l1: 0.261262\tvalid_0's l2: 0.0952001\n",
      "[7]\tvalid_0's l1: 0.258546\tvalid_0's l2: 0.0941827\n",
      "[8]\tvalid_0's l1: 0.256523\tvalid_0's l2: 0.0938749\n",
      "[9]\tvalid_0's l1: 0.254869\tvalid_0's l2: 0.0936933\n",
      "[10]\tvalid_0's l1: 0.252758\tvalid_0's l2: 0.0936661\n",
      "[11]\tvalid_0's l1: 0.251696\tvalid_0's l2: 0.0941486\n",
      "[12]\tvalid_0's l1: 0.250972\tvalid_0's l2: 0.094931\n",
      "[13]\tvalid_0's l1: 0.25022\tvalid_0's l2: 0.0959638\n",
      "[14]\tvalid_0's l1: 0.248926\tvalid_0's l2: 0.0966268\n",
      "[15]\tvalid_0's l1: 0.248608\tvalid_0's l2: 0.0980749\n",
      "[16]\tvalid_0's l1: 0.248941\tvalid_0's l2: 0.100277\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.252758\tvalid_0's l2: 0.0936661\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.271761\tvalid_0's l2: 0.100101\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.259341\tvalid_0's l2: 0.0912645\n",
      "[3]\tvalid_0's l1: 0.247386\tvalid_0's l2: 0.0831183\n",
      "[4]\tvalid_0's l1: 0.236085\tvalid_0's l2: 0.0757815\n",
      "[5]\tvalid_0's l1: 0.225672\tvalid_0's l2: 0.0693332\n",
      "[6]\tvalid_0's l1: 0.21583\tvalid_0's l2: 0.0634708\n",
      "[7]\tvalid_0's l1: 0.206614\tvalid_0's l2: 0.0582152\n",
      "[8]\tvalid_0's l1: 0.197784\tvalid_0's l2: 0.0534868\n",
      "[9]\tvalid_0's l1: 0.189439\tvalid_0's l2: 0.0491711\n",
      "[10]\tvalid_0's l1: 0.181656\tvalid_0's l2: 0.0453312\n",
      "[11]\tvalid_0's l1: 0.174382\tvalid_0's l2: 0.0419233\n",
      "[12]\tvalid_0's l1: 0.167601\tvalid_0's l2: 0.0388926\n",
      "[13]\tvalid_0's l1: 0.161201\tvalid_0's l2: 0.0361545\n",
      "[14]\tvalid_0's l1: 0.155264\tvalid_0's l2: 0.0336703\n",
      "[15]\tvalid_0's l1: 0.14965\tvalid_0's l2: 0.0314196\n",
      "[16]\tvalid_0's l1: 0.14448\tvalid_0's l2: 0.0294483\n",
      "[17]\tvalid_0's l1: 0.139594\tvalid_0's l2: 0.0276838\n",
      "[18]\tvalid_0's l1: 0.135231\tvalid_0's l2: 0.0261385\n",
      "[19]\tvalid_0's l1: 0.130973\tvalid_0's l2: 0.0247018\n",
      "[20]\tvalid_0's l1: 0.127627\tvalid_0's l2: 0.0236049\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.127627\tvalid_0's l2: 0.0236049\n",
      "[1]\tvalid_0's l1: 0.271743\tvalid_0's l2: 0.100109\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.259155\tvalid_0's l2: 0.0911551\n",
      "[3]\tvalid_0's l1: 0.247237\tvalid_0's l2: 0.0830138\n",
      "[4]\tvalid_0's l1: 0.235916\tvalid_0's l2: 0.0757172\n",
      "[5]\tvalid_0's l1: 0.225408\tvalid_0's l2: 0.0692255\n",
      "[6]\tvalid_0's l1: 0.215597\tvalid_0's l2: 0.0633914\n",
      "[7]\tvalid_0's l1: 0.206255\tvalid_0's l2: 0.058113\n",
      "[8]\tvalid_0's l1: 0.197455\tvalid_0's l2: 0.0533365\n",
      "[9]\tvalid_0's l1: 0.189074\tvalid_0's l2: 0.0490009\n",
      "[10]\tvalid_0's l1: 0.181267\tvalid_0's l2: 0.0451609\n",
      "[11]\tvalid_0's l1: 0.173889\tvalid_0's l2: 0.0417479\n",
      "[12]\tvalid_0's l1: 0.167016\tvalid_0's l2: 0.0386945\n",
      "[13]\tvalid_0's l1: 0.160774\tvalid_0's l2: 0.0360342\n",
      "[14]\tvalid_0's l1: 0.15486\tvalid_0's l2: 0.0335862\n",
      "[15]\tvalid_0's l1: 0.14992\tvalid_0's l2: 0.0315962\n",
      "[16]\tvalid_0's l1: 0.145526\tvalid_0's l2: 0.029917\n",
      "[17]\tvalid_0's l1: 0.140649\tvalid_0's l2: 0.0281214\n",
      "[18]\tvalid_0's l1: 0.136851\tvalid_0's l2: 0.0267865\n",
      "[19]\tvalid_0's l1: 0.1325\tvalid_0's l2: 0.0252658\n",
      "[20]\tvalid_0's l1: 0.128491\tvalid_0's l2: 0.0239216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.128491\tvalid_0's l2: 0.0239216\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273244\tvalid_0's l2: 0.101099\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.262051\tvalid_0's l2: 0.0930538\n",
      "[3]\tvalid_0's l1: 0.252483\tvalid_0's l2: 0.0866479\n",
      "[4]\tvalid_0's l1: 0.242872\tvalid_0's l2: 0.0802418\n",
      "[5]\tvalid_0's l1: 0.234817\tvalid_0's l2: 0.0752999\n",
      "[6]\tvalid_0's l1: 0.226088\tvalid_0's l2: 0.0699477\n",
      "[7]\tvalid_0's l1: 0.218362\tvalid_0's l2: 0.0654062\n",
      "[8]\tvalid_0's l1: 0.21136\tvalid_0's l2: 0.0613521\n",
      "[9]\tvalid_0's l1: 0.204574\tvalid_0's l2: 0.0575725\n",
      "[10]\tvalid_0's l1: 0.198728\tvalid_0's l2: 0.0544639\n",
      "[11]\tvalid_0's l1: 0.19306\tvalid_0's l2: 0.0515729\n",
      "[12]\tvalid_0's l1: 0.187664\tvalid_0's l2: 0.0489633\n",
      "[13]\tvalid_0's l1: 0.183854\tvalid_0's l2: 0.0472927\n",
      "[14]\tvalid_0's l1: 0.18054\tvalid_0's l2: 0.0459147\n",
      "[15]\tvalid_0's l1: 0.176309\tvalid_0's l2: 0.0441083\n",
      "[16]\tvalid_0's l1: 0.173606\tvalid_0's l2: 0.0431599\n",
      "[17]\tvalid_0's l1: 0.169849\tvalid_0's l2: 0.0416898\n",
      "[18]\tvalid_0's l1: 0.16641\tvalid_0's l2: 0.0404245\n",
      "[19]\tvalid_0's l1: 0.163379\tvalid_0's l2: 0.0393901\n",
      "[20]\tvalid_0's l1: 0.160411\tvalid_0's l2: 0.0383478\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.160411\tvalid_0's l2: 0.0383478\n",
      "[1]\tvalid_0's l1: 0.272958\tvalid_0's l2: 0.100929\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.262386\tvalid_0's l2: 0.0935466\n",
      "[3]\tvalid_0's l1: 0.251892\tvalid_0's l2: 0.0863243\n",
      "[4]\tvalid_0's l1: 0.241921\tvalid_0's l2: 0.0797651\n",
      "[5]\tvalid_0's l1: 0.23295\tvalid_0's l2: 0.0740647\n",
      "[6]\tvalid_0's l1: 0.22452\tvalid_0's l2: 0.0689406\n",
      "[7]\tvalid_0's l1: 0.216618\tvalid_0's l2: 0.0642585\n",
      "[8]\tvalid_0's l1: 0.209469\tvalid_0's l2: 0.060243\n",
      "[9]\tvalid_0's l1: 0.203072\tvalid_0's l2: 0.0566963\n",
      "[10]\tvalid_0's l1: 0.197055\tvalid_0's l2: 0.0534782\n",
      "[11]\tvalid_0's l1: 0.191586\tvalid_0's l2: 0.0507296\n",
      "[12]\tvalid_0's l1: 0.186526\tvalid_0's l2: 0.0483121\n",
      "[13]\tvalid_0's l1: 0.181765\tvalid_0's l2: 0.0461165\n",
      "[14]\tvalid_0's l1: 0.177497\tvalid_0's l2: 0.0442347\n",
      "[15]\tvalid_0's l1: 0.173554\tvalid_0's l2: 0.0425954\n",
      "[16]\tvalid_0's l1: 0.169949\tvalid_0's l2: 0.0411973\n",
      "[17]\tvalid_0's l1: 0.167251\tvalid_0's l2: 0.0402756\n",
      "[18]\tvalid_0's l1: 0.163964\tvalid_0's l2: 0.03915\n",
      "[19]\tvalid_0's l1: 0.161917\tvalid_0's l2: 0.0386334\n",
      "[20]\tvalid_0's l1: 0.159128\tvalid_0's l2: 0.0377309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.159128\tvalid_0's l2: 0.0377309\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.273941\tvalid_0's l2: 0.101831\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.263662\tvalid_0's l2: 0.0945538\n",
      "[3]\tvalid_0's l1: 0.254726\tvalid_0's l2: 0.088533\n",
      "[4]\tvalid_0's l1: 0.246928\tvalid_0's l2: 0.0835239\n",
      "[5]\tvalid_0's l1: 0.240052\tvalid_0's l2: 0.0792437\n",
      "[6]\tvalid_0's l1: 0.233552\tvalid_0's l2: 0.0752471\n",
      "[7]\tvalid_0's l1: 0.227505\tvalid_0's l2: 0.0716614\n",
      "[8]\tvalid_0's l1: 0.223143\tvalid_0's l2: 0.0691763\n",
      "[9]\tvalid_0's l1: 0.218188\tvalid_0's l2: 0.0665136\n",
      "[10]\tvalid_0's l1: 0.213805\tvalid_0's l2: 0.0642877\n",
      "[11]\tvalid_0's l1: 0.209855\tvalid_0's l2: 0.0624407\n",
      "[12]\tvalid_0's l1: 0.206305\tvalid_0's l2: 0.0609559\n",
      "[13]\tvalid_0's l1: 0.203076\tvalid_0's l2: 0.0596966\n",
      "[14]\tvalid_0's l1: 0.200039\tvalid_0's l2: 0.0586393\n",
      "[15]\tvalid_0's l1: 0.19755\tvalid_0's l2: 0.0578463\n",
      "[16]\tvalid_0's l1: 0.195369\tvalid_0's l2: 0.0572276\n",
      "[17]\tvalid_0's l1: 0.193324\tvalid_0's l2: 0.0567586\n",
      "[18]\tvalid_0's l1: 0.19158\tvalid_0's l2: 0.056523\n",
      "[19]\tvalid_0's l1: 0.190093\tvalid_0's l2: 0.0564138\n",
      "[20]\tvalid_0's l1: 0.188651\tvalid_0's l2: 0.0563239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.188651\tvalid_0's l2: 0.0563239\n",
      "[1]\tvalid_0's l1: 0.273841\tvalid_0's l2: 0.101848\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.263717\tvalid_0's l2: 0.0946407\n",
      "[3]\tvalid_0's l1: 0.255033\tvalid_0's l2: 0.0887698\n",
      "[4]\tvalid_0's l1: 0.246789\tvalid_0's l2: 0.0833579\n",
      "[5]\tvalid_0's l1: 0.239278\tvalid_0's l2: 0.0785864\n",
      "[6]\tvalid_0's l1: 0.232774\tvalid_0's l2: 0.0745534\n",
      "[7]\tvalid_0's l1: 0.227606\tvalid_0's l2: 0.0714831\n",
      "[8]\tvalid_0's l1: 0.222539\tvalid_0's l2: 0.0685191\n",
      "[9]\tvalid_0's l1: 0.217994\tvalid_0's l2: 0.0660289\n",
      "[10]\tvalid_0's l1: 0.213822\tvalid_0's l2: 0.0639301\n",
      "[11]\tvalid_0's l1: 0.210218\tvalid_0's l2: 0.0621959\n",
      "[12]\tvalid_0's l1: 0.206995\tvalid_0's l2: 0.0607831\n",
      "[13]\tvalid_0's l1: 0.203947\tvalid_0's l2: 0.0595838\n",
      "[14]\tvalid_0's l1: 0.201287\tvalid_0's l2: 0.0586465\n",
      "[15]\tvalid_0's l1: 0.198926\tvalid_0's l2: 0.0579595\n",
      "[16]\tvalid_0's l1: 0.197081\tvalid_0's l2: 0.0576601\n",
      "[17]\tvalid_0's l1: 0.195167\tvalid_0's l2: 0.0573293\n",
      "[18]\tvalid_0's l1: 0.193877\tvalid_0's l2: 0.0574912\n",
      "[19]\tvalid_0's l1: 0.192316\tvalid_0's l2: 0.0573626\n",
      "[20]\tvalid_0's l1: 0.191174\tvalid_0's l2: 0.0575739\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.191174\tvalid_0's l2: 0.0575739\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.274396\tvalid_0's l2: 0.102063\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.264768\tvalid_0's l2: 0.0952675\n",
      "[3]\tvalid_0's l1: 0.256052\tvalid_0's l2: 0.0894586\n",
      "[4]\tvalid_0's l1: 0.248748\tvalid_0's l2: 0.084695\n",
      "[5]\tvalid_0's l1: 0.241941\tvalid_0's l2: 0.0802754\n",
      "[6]\tvalid_0's l1: 0.236454\tvalid_0's l2: 0.076877\n",
      "[7]\tvalid_0's l1: 0.232197\tvalid_0's l2: 0.0743569\n",
      "[8]\tvalid_0's l1: 0.227663\tvalid_0's l2: 0.0717961\n",
      "[9]\tvalid_0's l1: 0.224076\tvalid_0's l2: 0.0700357\n",
      "[10]\tvalid_0's l1: 0.220564\tvalid_0's l2: 0.0683551\n",
      "[11]\tvalid_0's l1: 0.217684\tvalid_0's l2: 0.0673486\n",
      "[12]\tvalid_0's l1: 0.215221\tvalid_0's l2: 0.0666968\n",
      "[13]\tvalid_0's l1: 0.2129\tvalid_0's l2: 0.0662305\n",
      "[14]\tvalid_0's l1: 0.210763\tvalid_0's l2: 0.0659448\n",
      "[15]\tvalid_0's l1: 0.208781\tvalid_0's l2: 0.0656755\n",
      "[16]\tvalid_0's l1: 0.206936\tvalid_0's l2: 0.065457\n",
      "[17]\tvalid_0's l1: 0.20597\tvalid_0's l2: 0.0659432\n",
      "[18]\tvalid_0's l1: 0.204751\tvalid_0's l2: 0.0661147\n",
      "[19]\tvalid_0's l1: 0.203578\tvalid_0's l2: 0.0662966\n",
      "[20]\tvalid_0's l1: 0.203033\tvalid_0's l2: 0.0669397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.203033\tvalid_0's l2: 0.0669397\n",
      "[1]\tvalid_0's l1: 0.274212\tvalid_0's l2: 0.102039\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.264463\tvalid_0's l2: 0.0951816\n",
      "[3]\tvalid_0's l1: 0.255566\tvalid_0's l2: 0.0892412\n",
      "[4]\tvalid_0's l1: 0.247948\tvalid_0's l2: 0.0841366\n",
      "[5]\tvalid_0's l1: 0.241757\tvalid_0's l2: 0.08006\n",
      "[6]\tvalid_0's l1: 0.236338\tvalid_0's l2: 0.076666\n",
      "[7]\tvalid_0's l1: 0.231909\tvalid_0's l2: 0.0741107\n",
      "[8]\tvalid_0's l1: 0.228229\tvalid_0's l2: 0.0720276\n",
      "[9]\tvalid_0's l1: 0.224868\tvalid_0's l2: 0.0703376\n",
      "[10]\tvalid_0's l1: 0.222059\tvalid_0's l2: 0.0690856\n",
      "[11]\tvalid_0's l1: 0.21944\tvalid_0's l2: 0.0682237\n",
      "[12]\tvalid_0's l1: 0.217348\tvalid_0's l2: 0.0677546\n",
      "[13]\tvalid_0's l1: 0.21571\tvalid_0's l2: 0.0677359\n",
      "[14]\tvalid_0's l1: 0.214322\tvalid_0's l2: 0.0679937\n",
      "[15]\tvalid_0's l1: 0.212995\tvalid_0's l2: 0.0682745\n",
      "[16]\tvalid_0's l1: 0.211747\tvalid_0's l2: 0.068447\n",
      "[17]\tvalid_0's l1: 0.21058\tvalid_0's l2: 0.0688415\n",
      "[18]\tvalid_0's l1: 0.210025\tvalid_0's l2: 0.0695877\n",
      "[19]\tvalid_0's l1: 0.209625\tvalid_0's l2: 0.0703539\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 0.21571\tvalid_0's l2: 0.0677359\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.274945\tvalid_0's l2: 0.102545\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265976\tvalid_0's l2: 0.0961744\n",
      "[3]\tvalid_0's l1: 0.258357\tvalid_0's l2: 0.0909848\n",
      "[4]\tvalid_0's l1: 0.251915\tvalid_0's l2: 0.0867807\n",
      "[5]\tvalid_0's l1: 0.24636\tvalid_0's l2: 0.0834044\n",
      "[6]\tvalid_0's l1: 0.241508\tvalid_0's l2: 0.0805454\n",
      "[7]\tvalid_0's l1: 0.237945\tvalid_0's l2: 0.0785701\n",
      "[8]\tvalid_0's l1: 0.234771\tvalid_0's l2: 0.0771813\n",
      "[9]\tvalid_0's l1: 0.232804\tvalid_0's l2: 0.0765511\n",
      "[10]\tvalid_0's l1: 0.230641\tvalid_0's l2: 0.0760311\n",
      "[11]\tvalid_0's l1: 0.228555\tvalid_0's l2: 0.0757991\n",
      "[12]\tvalid_0's l1: 0.226413\tvalid_0's l2: 0.0755583\n",
      "[13]\tvalid_0's l1: 0.225147\tvalid_0's l2: 0.0760343\n",
      "[14]\tvalid_0's l1: 0.224171\tvalid_0's l2: 0.0768094\n",
      "[15]\tvalid_0's l1: 0.22323\tvalid_0's l2: 0.0776384\n",
      "[16]\tvalid_0's l1: 0.222534\tvalid_0's l2: 0.0785937\n",
      "[17]\tvalid_0's l1: 0.221601\tvalid_0's l2: 0.0794627\n",
      "[18]\tvalid_0's l1: 0.220881\tvalid_0's l2: 0.0805379\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.226413\tvalid_0's l2: 0.0755583\n",
      "[1]\tvalid_0's l1: 0.274765\tvalid_0's l2: 0.102533\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.265851\tvalid_0's l2: 0.0963248\n",
      "[3]\tvalid_0's l1: 0.25847\tvalid_0's l2: 0.0914689\n",
      "[4]\tvalid_0's l1: 0.25212\tvalid_0's l2: 0.0872088\n",
      "[5]\tvalid_0's l1: 0.246902\tvalid_0's l2: 0.0839181\n",
      "[6]\tvalid_0's l1: 0.242425\tvalid_0's l2: 0.0810183\n",
      "[7]\tvalid_0's l1: 0.239285\tvalid_0's l2: 0.0791647\n",
      "[8]\tvalid_0's l1: 0.23658\tvalid_0's l2: 0.0778295\n",
      "[9]\tvalid_0's l1: 0.234163\tvalid_0's l2: 0.076859\n",
      "[10]\tvalid_0's l1: 0.231905\tvalid_0's l2: 0.0763506\n",
      "[11]\tvalid_0's l1: 0.230314\tvalid_0's l2: 0.0763259\n",
      "[12]\tvalid_0's l1: 0.229121\tvalid_0's l2: 0.076609\n",
      "[13]\tvalid_0's l1: 0.227644\tvalid_0's l2: 0.0769512\n",
      "[14]\tvalid_0's l1: 0.227191\tvalid_0's l2: 0.0779512\n",
      "[15]\tvalid_0's l1: 0.226387\tvalid_0's l2: 0.0790453\n",
      "[16]\tvalid_0's l1: 0.225943\tvalid_0's l2: 0.0802248\n",
      "[17]\tvalid_0's l1: 0.225689\tvalid_0's l2: 0.0815879\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.230314\tvalid_0's l2: 0.0763259\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.275517\tvalid_0's l2: 0.102978\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267358\tvalid_0's l2: 0.097279\n",
      "[3]\tvalid_0's l1: 0.260674\tvalid_0's l2: 0.0928154\n",
      "[4]\tvalid_0's l1: 0.254176\tvalid_0's l2: 0.0885479\n",
      "[5]\tvalid_0's l1: 0.25036\tvalid_0's l2: 0.0859783\n",
      "[6]\tvalid_0's l1: 0.246885\tvalid_0's l2: 0.0838807\n",
      "[7]\tvalid_0's l1: 0.244106\tvalid_0's l2: 0.0824908\n",
      "[8]\tvalid_0's l1: 0.242173\tvalid_0's l2: 0.0818952\n",
      "[9]\tvalid_0's l1: 0.240786\tvalid_0's l2: 0.0818923\n",
      "[10]\tvalid_0's l1: 0.239685\tvalid_0's l2: 0.0822586\n",
      "[11]\tvalid_0's l1: 0.238833\tvalid_0's l2: 0.0828976\n",
      "[12]\tvalid_0's l1: 0.23691\tvalid_0's l2: 0.0829092\n",
      "[13]\tvalid_0's l1: 0.236144\tvalid_0's l2: 0.0839018\n",
      "[14]\tvalid_0's l1: 0.235531\tvalid_0's l2: 0.0850253\n",
      "[15]\tvalid_0's l1: 0.234438\tvalid_0's l2: 0.0858302\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.240786\tvalid_0's l2: 0.0818923\n",
      "[1]\tvalid_0's l1: 0.27523\tvalid_0's l2: 0.102892\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.267754\tvalid_0's l2: 0.097671\n",
      "[3]\tvalid_0's l1: 0.259832\tvalid_0's l2: 0.0926168\n",
      "[4]\tvalid_0's l1: 0.254495\tvalid_0's l2: 0.0889173\n",
      "[5]\tvalid_0's l1: 0.250342\tvalid_0's l2: 0.0863042\n",
      "[6]\tvalid_0's l1: 0.247472\tvalid_0's l2: 0.084631\n",
      "[7]\tvalid_0's l1: 0.245258\tvalid_0's l2: 0.083695\n",
      "[8]\tvalid_0's l1: 0.243638\tvalid_0's l2: 0.0835448\n",
      "[9]\tvalid_0's l1: 0.2421\tvalid_0's l2: 0.0833784\n",
      "[10]\tvalid_0's l1: 0.240032\tvalid_0's l2: 0.0831554\n",
      "[11]\tvalid_0's l1: 0.238908\tvalid_0's l2: 0.0838797\n",
      "[12]\tvalid_0's l1: 0.238372\tvalid_0's l2: 0.0852374\n",
      "[13]\tvalid_0's l1: 0.237272\tvalid_0's l2: 0.0862091\n",
      "[14]\tvalid_0's l1: 0.23627\tvalid_0's l2: 0.0870151\n",
      "[15]\tvalid_0's l1: 0.235756\tvalid_0's l2: 0.0884708\n",
      "[16]\tvalid_0's l1: 0.235747\tvalid_0's l2: 0.0903469\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.240032\tvalid_0's l2: 0.0831554\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.263514\tvalid_0's l2: 0.0938624\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.250934\tvalid_0's l2: 0.0851496\n",
      "[3]\tvalid_0's l1: 0.239062\tvalid_0's l2: 0.0772854\n",
      "[4]\tvalid_0's l1: 0.227776\tvalid_0's l2: 0.0701867\n",
      "[5]\tvalid_0's l1: 0.217209\tvalid_0's l2: 0.0638335\n",
      "[6]\tvalid_0's l1: 0.207223\tvalid_0's l2: 0.0580765\n",
      "[7]\tvalid_0's l1: 0.197795\tvalid_0's l2: 0.0528953\n",
      "[8]\tvalid_0's l1: 0.18881\tvalid_0's l2: 0.0482259\n",
      "[9]\tvalid_0's l1: 0.180389\tvalid_0's l2: 0.0440176\n",
      "[10]\tvalid_0's l1: 0.172586\tvalid_0's l2: 0.0402947\n",
      "[11]\tvalid_0's l1: 0.165197\tvalid_0's l2: 0.0369492\n",
      "[12]\tvalid_0's l1: 0.158277\tvalid_0's l2: 0.0339428\n",
      "[13]\tvalid_0's l1: 0.151732\tvalid_0's l2: 0.0312259\n",
      "[14]\tvalid_0's l1: 0.145538\tvalid_0's l2: 0.0287703\n",
      "[15]\tvalid_0's l1: 0.139602\tvalid_0's l2: 0.0265104\n",
      "[16]\tvalid_0's l1: 0.13409\tvalid_0's l2: 0.0245161\n",
      "[17]\tvalid_0's l1: 0.128784\tvalid_0's l2: 0.0226932\n",
      "[18]\tvalid_0's l1: 0.123931\tvalid_0's l2: 0.0210987\n",
      "[19]\tvalid_0's l1: 0.119365\tvalid_0's l2: 0.0196532\n",
      "[20]\tvalid_0's l1: 0.115513\tvalid_0's l2: 0.0184864\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.115513\tvalid_0's l2: 0.0184864\n",
      "[1]\tvalid_0's l1: 0.263424\tvalid_0's l2: 0.0938239\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.250776\tvalid_0's l2: 0.0850336\n",
      "[3]\tvalid_0's l1: 0.238798\tvalid_0's l2: 0.0771153\n",
      "[4]\tvalid_0's l1: 0.227474\tvalid_0's l2: 0.0699653\n",
      "[5]\tvalid_0's l1: 0.216869\tvalid_0's l2: 0.0636149\n",
      "[6]\tvalid_0's l1: 0.206849\tvalid_0's l2: 0.0578507\n",
      "[7]\tvalid_0's l1: 0.197326\tvalid_0's l2: 0.0526739\n",
      "[8]\tvalid_0's l1: 0.188489\tvalid_0's l2: 0.048035\n",
      "[9]\tvalid_0's l1: 0.180129\tvalid_0's l2: 0.0438561\n",
      "[10]\tvalid_0's l1: 0.172235\tvalid_0's l2: 0.0400955\n",
      "[11]\tvalid_0's l1: 0.164795\tvalid_0's l2: 0.0367413\n",
      "[12]\tvalid_0's l1: 0.157878\tvalid_0's l2: 0.0337669\n",
      "[13]\tvalid_0's l1: 0.151437\tvalid_0's l2: 0.0310954\n",
      "[14]\tvalid_0's l1: 0.145237\tvalid_0's l2: 0.028655\n",
      "[15]\tvalid_0's l1: 0.13976\tvalid_0's l2: 0.0266076\n",
      "[16]\tvalid_0's l1: 0.134675\tvalid_0's l2: 0.0247725\n",
      "[17]\tvalid_0's l1: 0.129474\tvalid_0's l2: 0.0229542\n",
      "[18]\tvalid_0's l1: 0.125063\tvalid_0's l2: 0.0215027\n",
      "[19]\tvalid_0's l1: 0.120575\tvalid_0's l2: 0.0200511\n",
      "[20]\tvalid_0's l1: 0.116323\tvalid_0's l2: 0.0187441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.116323\tvalid_0's l2: 0.0187441\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.264139\tvalid_0's l2: 0.0944372\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.2524\tvalid_0's l2: 0.0863359\n",
      "[3]\tvalid_0's l1: 0.242096\tvalid_0's l2: 0.0796151\n",
      "[4]\tvalid_0's l1: 0.231557\tvalid_0's l2: 0.072934\n",
      "[5]\tvalid_0's l1: 0.222919\tvalid_0's l2: 0.0677499\n",
      "[6]\tvalid_0's l1: 0.213771\tvalid_0's l2: 0.0624104\n",
      "[7]\tvalid_0's l1: 0.205201\tvalid_0's l2: 0.0575353\n",
      "[8]\tvalid_0's l1: 0.197139\tvalid_0's l2: 0.0531934\n",
      "[9]\tvalid_0's l1: 0.189581\tvalid_0's l2: 0.0493162\n",
      "[10]\tvalid_0's l1: 0.182791\tvalid_0's l2: 0.045907\n",
      "[11]\tvalid_0's l1: 0.176386\tvalid_0's l2: 0.0428114\n",
      "[12]\tvalid_0's l1: 0.170615\tvalid_0's l2: 0.0401306\n",
      "[13]\tvalid_0's l1: 0.1661\tvalid_0's l2: 0.038116\n",
      "[14]\tvalid_0's l1: 0.162046\tvalid_0's l2: 0.0363853\n",
      "[15]\tvalid_0's l1: 0.157294\tvalid_0's l2: 0.0343939\n",
      "[16]\tvalid_0's l1: 0.153961\tvalid_0's l2: 0.0331272\n",
      "[17]\tvalid_0's l1: 0.150029\tvalid_0's l2: 0.0316653\n",
      "[18]\tvalid_0's l1: 0.146406\tvalid_0's l2: 0.030381\n",
      "[19]\tvalid_0's l1: 0.143112\tvalid_0's l2: 0.0292165\n",
      "[20]\tvalid_0's l1: 0.139946\tvalid_0's l2: 0.028158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.139946\tvalid_0's l2: 0.028158\n",
      "[1]\tvalid_0's l1: 0.264133\tvalid_0's l2: 0.0944508\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.252968\tvalid_0's l2: 0.0868887\n",
      "[3]\tvalid_0's l1: 0.241676\tvalid_0's l2: 0.0794508\n",
      "[4]\tvalid_0's l1: 0.231155\tvalid_0's l2: 0.0727864\n",
      "[5]\tvalid_0's l1: 0.221456\tvalid_0's l2: 0.0669342\n",
      "[6]\tvalid_0's l1: 0.212108\tvalid_0's l2: 0.061478\n",
      "[7]\tvalid_0's l1: 0.203795\tvalid_0's l2: 0.0567681\n",
      "[8]\tvalid_0's l1: 0.195844\tvalid_0's l2: 0.0524553\n",
      "[9]\tvalid_0's l1: 0.188429\tvalid_0's l2: 0.0486452\n",
      "[10]\tvalid_0's l1: 0.181588\tvalid_0's l2: 0.045282\n",
      "[11]\tvalid_0's l1: 0.175619\tvalid_0's l2: 0.0424673\n",
      "[12]\tvalid_0's l1: 0.169752\tvalid_0's l2: 0.0397552\n",
      "[13]\tvalid_0's l1: 0.164526\tvalid_0's l2: 0.037437\n",
      "[14]\tvalid_0's l1: 0.159601\tvalid_0's l2: 0.035362\n",
      "[15]\tvalid_0's l1: 0.155099\tvalid_0's l2: 0.03349\n",
      "[16]\tvalid_0's l1: 0.151144\tvalid_0's l2: 0.0319149\n",
      "[17]\tvalid_0's l1: 0.147891\tvalid_0's l2: 0.0307197\n",
      "[18]\tvalid_0's l1: 0.144228\tvalid_0's l2: 0.0293852\n",
      "[19]\tvalid_0's l1: 0.141845\tvalid_0's l2: 0.0286116\n",
      "[20]\tvalid_0's l1: 0.138565\tvalid_0's l2: 0.0275231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.138565\tvalid_0's l2: 0.0275231\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265138\tvalid_0's l2: 0.0952026\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254267\tvalid_0's l2: 0.0877008\n",
      "[3]\tvalid_0's l1: 0.245303\tvalid_0's l2: 0.0817602\n",
      "[4]\tvalid_0's l1: 0.23724\tvalid_0's l2: 0.076661\n",
      "[5]\tvalid_0's l1: 0.230067\tvalid_0's l2: 0.0723346\n",
      "[6]\tvalid_0's l1: 0.222709\tvalid_0's l2: 0.0678396\n",
      "[7]\tvalid_0's l1: 0.215533\tvalid_0's l2: 0.0636402\n",
      "[8]\tvalid_0's l1: 0.210811\tvalid_0's l2: 0.0609655\n",
      "[9]\tvalid_0's l1: 0.204671\tvalid_0's l2: 0.0576351\n",
      "[10]\tvalid_0's l1: 0.199366\tvalid_0's l2: 0.0549886\n",
      "[11]\tvalid_0's l1: 0.194462\tvalid_0's l2: 0.0524833\n",
      "[12]\tvalid_0's l1: 0.190085\tvalid_0's l2: 0.050363\n",
      "[13]\tvalid_0's l1: 0.185865\tvalid_0's l2: 0.0484135\n",
      "[14]\tvalid_0's l1: 0.182149\tvalid_0's l2: 0.0468328\n",
      "[15]\tvalid_0's l1: 0.178818\tvalid_0's l2: 0.0455223\n",
      "[16]\tvalid_0's l1: 0.17557\tvalid_0's l2: 0.0442828\n",
      "[17]\tvalid_0's l1: 0.172746\tvalid_0's l2: 0.043318\n",
      "[18]\tvalid_0's l1: 0.170266\tvalid_0's l2: 0.0426221\n",
      "[19]\tvalid_0's l1: 0.167974\tvalid_0's l2: 0.0419639\n",
      "[20]\tvalid_0's l1: 0.165904\tvalid_0's l2: 0.0414518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.165904\tvalid_0's l2: 0.0414518\n",
      "[1]\tvalid_0's l1: 0.264978\tvalid_0's l2: 0.0951468\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.254417\tvalid_0's l2: 0.0880934\n",
      "[3]\tvalid_0's l1: 0.245009\tvalid_0's l2: 0.0820442\n",
      "[4]\tvalid_0's l1: 0.235769\tvalid_0's l2: 0.0761796\n",
      "[5]\tvalid_0's l1: 0.227619\tvalid_0's l2: 0.0710895\n",
      "[6]\tvalid_0's l1: 0.219896\tvalid_0's l2: 0.0664627\n",
      "[7]\tvalid_0's l1: 0.214658\tvalid_0's l2: 0.0632736\n",
      "[8]\tvalid_0's l1: 0.208223\tvalid_0's l2: 0.0596779\n",
      "[9]\tvalid_0's l1: 0.202529\tvalid_0's l2: 0.0565896\n",
      "[10]\tvalid_0's l1: 0.197515\tvalid_0's l2: 0.053929\n",
      "[11]\tvalid_0's l1: 0.193043\tvalid_0's l2: 0.0516874\n",
      "[12]\tvalid_0's l1: 0.188951\tvalid_0's l2: 0.0497383\n",
      "[13]\tvalid_0's l1: 0.18525\tvalid_0's l2: 0.0480854\n",
      "[14]\tvalid_0's l1: 0.181667\tvalid_0's l2: 0.0465777\n",
      "[15]\tvalid_0's l1: 0.178592\tvalid_0's l2: 0.0453748\n",
      "[16]\tvalid_0's l1: 0.175753\tvalid_0's l2: 0.0443193\n",
      "[17]\tvalid_0's l1: 0.173144\tvalid_0's l2: 0.043424\n",
      "[18]\tvalid_0's l1: 0.171934\tvalid_0's l2: 0.0433421\n",
      "[19]\tvalid_0's l1: 0.169734\tvalid_0's l2: 0.0427773\n",
      "[20]\tvalid_0's l1: 0.167631\tvalid_0's l2: 0.0422432\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.167631\tvalid_0's l2: 0.0422432\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.265881\tvalid_0's l2: 0.09572\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256068\tvalid_0's l2: 0.0890418\n",
      "[3]\tvalid_0's l1: 0.247565\tvalid_0's l2: 0.0833853\n",
      "[4]\tvalid_0's l1: 0.239895\tvalid_0's l2: 0.0785399\n",
      "[5]\tvalid_0's l1: 0.233077\tvalid_0's l2: 0.0742948\n",
      "[6]\tvalid_0's l1: 0.227306\tvalid_0's l2: 0.0708473\n",
      "[7]\tvalid_0's l1: 0.222849\tvalid_0's l2: 0.0683094\n",
      "[8]\tvalid_0's l1: 0.21815\tvalid_0's l2: 0.0657437\n",
      "[9]\tvalid_0's l1: 0.214485\tvalid_0's l2: 0.0639577\n",
      "[10]\tvalid_0's l1: 0.210718\tvalid_0's l2: 0.062262\n",
      "[11]\tvalid_0's l1: 0.207592\tvalid_0's l2: 0.0610144\n",
      "[12]\tvalid_0's l1: 0.20482\tvalid_0's l2: 0.0600801\n",
      "[13]\tvalid_0's l1: 0.202644\tvalid_0's l2: 0.0595613\n",
      "[14]\tvalid_0's l1: 0.200524\tvalid_0's l2: 0.0590113\n",
      "[15]\tvalid_0's l1: 0.198653\tvalid_0's l2: 0.0586544\n",
      "[16]\tvalid_0's l1: 0.196775\tvalid_0's l2: 0.0584629\n",
      "[17]\tvalid_0's l1: 0.195909\tvalid_0's l2: 0.0589562\n",
      "[18]\tvalid_0's l1: 0.194393\tvalid_0's l2: 0.0589945\n",
      "[19]\tvalid_0's l1: 0.192684\tvalid_0's l2: 0.058921\n",
      "[20]\tvalid_0's l1: 0.191534\tvalid_0's l2: 0.0591525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.191534\tvalid_0's l2: 0.0591525\n",
      "[1]\tvalid_0's l1: 0.265432\tvalid_0's l2: 0.0954787\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.255332\tvalid_0's l2: 0.08862\n",
      "[3]\tvalid_0's l1: 0.246539\tvalid_0's l2: 0.0828446\n",
      "[4]\tvalid_0's l1: 0.238499\tvalid_0's l2: 0.0778427\n",
      "[5]\tvalid_0's l1: 0.231948\tvalid_0's l2: 0.0736662\n",
      "[6]\tvalid_0's l1: 0.226604\tvalid_0's l2: 0.0702817\n",
      "[7]\tvalid_0's l1: 0.221501\tvalid_0's l2: 0.0673717\n",
      "[8]\tvalid_0's l1: 0.21762\tvalid_0's l2: 0.0651566\n",
      "[9]\tvalid_0's l1: 0.213947\tvalid_0's l2: 0.0631773\n",
      "[10]\tvalid_0's l1: 0.210934\tvalid_0's l2: 0.0618288\n",
      "[11]\tvalid_0's l1: 0.208039\tvalid_0's l2: 0.0607072\n",
      "[12]\tvalid_0's l1: 0.205708\tvalid_0's l2: 0.0600123\n",
      "[13]\tvalid_0's l1: 0.203576\tvalid_0's l2: 0.0594933\n",
      "[14]\tvalid_0's l1: 0.201659\tvalid_0's l2: 0.059097\n",
      "[15]\tvalid_0's l1: 0.200001\tvalid_0's l2: 0.0589487\n",
      "[16]\tvalid_0's l1: 0.198298\tvalid_0's l2: 0.0589263\n",
      "[17]\tvalid_0's l1: 0.196789\tvalid_0's l2: 0.0589897\n",
      "[18]\tvalid_0's l1: 0.195597\tvalid_0's l2: 0.0592351\n",
      "[19]\tvalid_0's l1: 0.195518\tvalid_0's l2: 0.0602364\n",
      "[20]\tvalid_0's l1: 0.194508\tvalid_0's l2: 0.0607074\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.194508\tvalid_0's l2: 0.0607074\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.266376\tvalid_0's l2: 0.0960921\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.257052\tvalid_0's l2: 0.0896502\n",
      "[3]\tvalid_0's l1: 0.249402\tvalid_0's l2: 0.0844811\n",
      "[4]\tvalid_0's l1: 0.243069\tvalid_0's l2: 0.0802362\n",
      "[5]\tvalid_0's l1: 0.237738\tvalid_0's l2: 0.076786\n",
      "[6]\tvalid_0's l1: 0.232679\tvalid_0's l2: 0.0736859\n",
      "[7]\tvalid_0's l1: 0.228958\tvalid_0's l2: 0.071568\n",
      "[8]\tvalid_0's l1: 0.225615\tvalid_0's l2: 0.0698964\n",
      "[9]\tvalid_0's l1: 0.22316\tvalid_0's l2: 0.069034\n",
      "[10]\tvalid_0's l1: 0.22068\tvalid_0's l2: 0.0682072\n",
      "[11]\tvalid_0's l1: 0.218561\tvalid_0's l2: 0.0677982\n",
      "[12]\tvalid_0's l1: 0.216288\tvalid_0's l2: 0.0672888\n",
      "[13]\tvalid_0's l1: 0.214888\tvalid_0's l2: 0.067462\n",
      "[14]\tvalid_0's l1: 0.213533\tvalid_0's l2: 0.0678073\n",
      "[15]\tvalid_0's l1: 0.212383\tvalid_0's l2: 0.0683252\n",
      "[16]\tvalid_0's l1: 0.211686\tvalid_0's l2: 0.0691729\n",
      "[17]\tvalid_0's l1: 0.210426\tvalid_0's l2: 0.069549\n",
      "[18]\tvalid_0's l1: 0.209409\tvalid_0's l2: 0.0701561\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.216288\tvalid_0's l2: 0.0672888\n",
      "[1]\tvalid_0's l1: 0.265958\tvalid_0's l2: 0.0958895\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.256231\tvalid_0's l2: 0.089481\n",
      "[3]\tvalid_0's l1: 0.249224\tvalid_0's l2: 0.0847324\n",
      "[4]\tvalid_0's l1: 0.24293\tvalid_0's l2: 0.080443\n",
      "[5]\tvalid_0's l1: 0.23756\tvalid_0's l2: 0.0769521\n",
      "[6]\tvalid_0's l1: 0.232804\tvalid_0's l2: 0.0738912\n",
      "[7]\tvalid_0's l1: 0.228949\tvalid_0's l2: 0.0716599\n",
      "[8]\tvalid_0's l1: 0.225988\tvalid_0's l2: 0.070219\n",
      "[9]\tvalid_0's l1: 0.223429\tvalid_0's l2: 0.0690904\n",
      "[10]\tvalid_0's l1: 0.220825\tvalid_0's l2: 0.0681489\n",
      "[11]\tvalid_0's l1: 0.219122\tvalid_0's l2: 0.0680333\n",
      "[12]\tvalid_0's l1: 0.217812\tvalid_0's l2: 0.0682577\n",
      "[13]\tvalid_0's l1: 0.216015\tvalid_0's l2: 0.0683032\n",
      "[14]\tvalid_0's l1: 0.215153\tvalid_0's l2: 0.0689807\n",
      "[15]\tvalid_0's l1: 0.214414\tvalid_0's l2: 0.0698799\n",
      "[16]\tvalid_0's l1: 0.213958\tvalid_0's l2: 0.0709319\n",
      "[17]\tvalid_0's l1: 0.213625\tvalid_0's l2: 0.0722544\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.219122\tvalid_0's l2: 0.0680333\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.267044\tvalid_0's l2: 0.0965503\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.258778\tvalid_0's l2: 0.0908885\n",
      "[3]\tvalid_0's l1: 0.251983\tvalid_0's l2: 0.0863183\n",
      "[4]\tvalid_0's l1: 0.245742\tvalid_0's l2: 0.0821527\n",
      "[5]\tvalid_0's l1: 0.241616\tvalid_0's l2: 0.079479\n",
      "[6]\tvalid_0's l1: 0.237954\tvalid_0's l2: 0.0772299\n",
      "[7]\tvalid_0's l1: 0.234927\tvalid_0's l2: 0.0756538\n",
      "[8]\tvalid_0's l1: 0.232816\tvalid_0's l2: 0.0749192\n",
      "[9]\tvalid_0's l1: 0.231392\tvalid_0's l2: 0.0747636\n",
      "[10]\tvalid_0's l1: 0.23045\tvalid_0's l2: 0.0751543\n",
      "[11]\tvalid_0's l1: 0.229692\tvalid_0's l2: 0.0759712\n",
      "[12]\tvalid_0's l1: 0.227953\tvalid_0's l2: 0.0760925\n",
      "[13]\tvalid_0's l1: 0.226938\tvalid_0's l2: 0.0768009\n",
      "[14]\tvalid_0's l1: 0.226309\tvalid_0's l2: 0.0778807\n",
      "[15]\tvalid_0's l1: 0.225241\tvalid_0's l2: 0.0787932\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.231392\tvalid_0's l2: 0.0747636\n",
      "[1]\tvalid_0's l1: 0.266668\tvalid_0's l2: 0.0964121\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.258736\tvalid_0's l2: 0.0908876\n",
      "[3]\tvalid_0's l1: 0.250653\tvalid_0's l2: 0.0856505\n",
      "[4]\tvalid_0's l1: 0.245345\tvalid_0's l2: 0.0821112\n",
      "[5]\tvalid_0's l1: 0.241173\tvalid_0's l2: 0.0793737\n",
      "[6]\tvalid_0's l1: 0.237941\tvalid_0's l2: 0.0773911\n",
      "[7]\tvalid_0's l1: 0.235459\tvalid_0's l2: 0.0762538\n",
      "[8]\tvalid_0's l1: 0.233468\tvalid_0's l2: 0.0756837\n",
      "[9]\tvalid_0's l1: 0.231888\tvalid_0's l2: 0.0755804\n",
      "[10]\tvalid_0's l1: 0.229877\tvalid_0's l2: 0.0753915\n",
      "[11]\tvalid_0's l1: 0.229218\tvalid_0's l2: 0.0761659\n",
      "[12]\tvalid_0's l1: 0.228618\tvalid_0's l2: 0.0772564\n",
      "[13]\tvalid_0's l1: 0.227394\tvalid_0's l2: 0.0779415\n",
      "[14]\tvalid_0's l1: 0.226409\tvalid_0's l2: 0.0788124\n",
      "[15]\tvalid_0's l1: 0.22637\tvalid_0's l2: 0.080555\n",
      "[16]\tvalid_0's l1: 0.226088\tvalid_0's l2: 0.0821363\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l1: 0.229877\tvalid_0's l2: 0.0753915\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_dist = df_test_dist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        x_train_withoutCD = df_train_dist.iloc[:, (13 + j): 22]\n",
    "        x_train_withCD = df_train_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        x_test_withoutCD = df_test_dist.iloc[:, (13 + j): 22]\n",
    "        x_test_withCD = df_test_dist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # y: response (target) variable DFma_1 [col 12]\n",
    "        y_train = df_train_dist.iloc[:, [12]]\n",
    "        y_test = df_test_dist.iloc[:, [12]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_dist['DFma_1'])\n",
    "        y_test_true = np.array(df_test_dist['DFma_1'])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                                  + str(i) + '_horizon_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' \n",
    "                                               + str(i) + '_horizon_' + str(j + 1) + '_withCD_' + str(num_leaves) + '.csv', \n",
    "                                               encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_dist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        dist_code = df_train_dist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in dist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "            mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "            smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "            r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "            # Append\n",
    "            dist_array = np.append(dist_array, [[k, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                                mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                                smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                                r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_ByDistrict_MA' + str(i) + '_horizon_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_dist_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.31428\tvalid_0's l2: 0.139405\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305192\tvalid_0's l2: 0.132154\n",
      "[3]\tvalid_0's l1: 0.296936\tvalid_0's l2: 0.125953\n",
      "[4]\tvalid_0's l1: 0.289451\tvalid_0's l2: 0.120464\n",
      "[5]\tvalid_0's l1: 0.28261\tvalid_0's l2: 0.115405\n",
      "[6]\tvalid_0's l1: 0.27608\tvalid_0's l2: 0.11089\n",
      "[7]\tvalid_0's l1: 0.270015\tvalid_0's l2: 0.106922\n",
      "[8]\tvalid_0's l1: 0.264622\tvalid_0's l2: 0.10356\n",
      "[9]\tvalid_0's l1: 0.259604\tvalid_0's l2: 0.100467\n",
      "[10]\tvalid_0's l1: 0.255125\tvalid_0's l2: 0.0978501\n",
      "[11]\tvalid_0's l1: 0.250901\tvalid_0's l2: 0.0954956\n",
      "[12]\tvalid_0's l1: 0.247003\tvalid_0's l2: 0.0933007\n",
      "[13]\tvalid_0's l1: 0.243492\tvalid_0's l2: 0.0914733\n",
      "[14]\tvalid_0's l1: 0.240292\tvalid_0's l2: 0.0900979\n",
      "[15]\tvalid_0's l1: 0.23739\tvalid_0's l2: 0.088925\n",
      "[16]\tvalid_0's l1: 0.234363\tvalid_0's l2: 0.0876695\n",
      "[17]\tvalid_0's l1: 0.231615\tvalid_0's l2: 0.0866116\n",
      "[18]\tvalid_0's l1: 0.22914\tvalid_0's l2: 0.0857226\n",
      "[19]\tvalid_0's l1: 0.226897\tvalid_0's l2: 0.085056\n",
      "[20]\tvalid_0's l1: 0.224723\tvalid_0's l2: 0.0842725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.224723\tvalid_0's l2: 0.0842725\n",
      "[1]\tvalid_0's l1: 0.314277\tvalid_0's l2: 0.139376\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305203\tvalid_0's l2: 0.132354\n",
      "[3]\tvalid_0's l1: 0.296513\tvalid_0's l2: 0.125655\n",
      "[4]\tvalid_0's l1: 0.288742\tvalid_0's l2: 0.119879\n",
      "[5]\tvalid_0's l1: 0.281714\tvalid_0's l2: 0.114889\n",
      "[6]\tvalid_0's l1: 0.275331\tvalid_0's l2: 0.110459\n",
      "[7]\tvalid_0's l1: 0.269399\tvalid_0's l2: 0.1065\n",
      "[8]\tvalid_0's l1: 0.264279\tvalid_0's l2: 0.103314\n",
      "[9]\tvalid_0's l1: 0.259273\tvalid_0's l2: 0.100275\n",
      "[10]\tvalid_0's l1: 0.254718\tvalid_0's l2: 0.0976891\n",
      "[11]\tvalid_0's l1: 0.250253\tvalid_0's l2: 0.0952033\n",
      "[12]\tvalid_0's l1: 0.246339\tvalid_0's l2: 0.0931495\n",
      "[13]\tvalid_0's l1: 0.242923\tvalid_0's l2: 0.091546\n",
      "[14]\tvalid_0's l1: 0.239564\tvalid_0's l2: 0.090005\n",
      "[15]\tvalid_0's l1: 0.236373\tvalid_0's l2: 0.088325\n",
      "[16]\tvalid_0's l1: 0.233488\tvalid_0's l2: 0.0870592\n",
      "[17]\tvalid_0's l1: 0.23083\tvalid_0's l2: 0.0860515\n",
      "[18]\tvalid_0's l1: 0.228396\tvalid_0's l2: 0.0851366\n",
      "[19]\tvalid_0's l1: 0.226037\tvalid_0's l2: 0.0843895\n",
      "[20]\tvalid_0's l1: 0.223967\tvalid_0's l2: 0.0837217\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.223967\tvalid_0's l2: 0.0837217\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.314619\tvalid_0's l2: 0.139536\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306053\tvalid_0's l2: 0.132621\n",
      "[3]\tvalid_0's l1: 0.29795\tvalid_0's l2: 0.126341\n",
      "[4]\tvalid_0's l1: 0.290721\tvalid_0's l2: 0.120911\n",
      "[5]\tvalid_0's l1: 0.28422\tvalid_0's l2: 0.116329\n",
      "[6]\tvalid_0's l1: 0.27818\tvalid_0's l2: 0.111959\n",
      "[7]\tvalid_0's l1: 0.27294\tvalid_0's l2: 0.108376\n",
      "[8]\tvalid_0's l1: 0.267988\tvalid_0's l2: 0.105236\n",
      "[9]\tvalid_0's l1: 0.263329\tvalid_0's l2: 0.102319\n",
      "[10]\tvalid_0's l1: 0.259285\tvalid_0's l2: 0.100018\n",
      "[11]\tvalid_0's l1: 0.255285\tvalid_0's l2: 0.0978365\n",
      "[12]\tvalid_0's l1: 0.251511\tvalid_0's l2: 0.0958526\n",
      "[13]\tvalid_0's l1: 0.2486\tvalid_0's l2: 0.0944785\n",
      "[14]\tvalid_0's l1: 0.245994\tvalid_0's l2: 0.0935231\n",
      "[15]\tvalid_0's l1: 0.243116\tvalid_0's l2: 0.0923157\n",
      "[16]\tvalid_0's l1: 0.241176\tvalid_0's l2: 0.0917436\n",
      "[17]\tvalid_0's l1: 0.238985\tvalid_0's l2: 0.0911063\n",
      "[18]\tvalid_0's l1: 0.237123\tvalid_0's l2: 0.0906322\n",
      "[19]\tvalid_0's l1: 0.235635\tvalid_0's l2: 0.0905163\n",
      "[20]\tvalid_0's l1: 0.234195\tvalid_0's l2: 0.0905119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.234195\tvalid_0's l2: 0.0905119\n",
      "[1]\tvalid_0's l1: 0.314769\tvalid_0's l2: 0.139599\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305849\tvalid_0's l2: 0.132527\n",
      "[3]\tvalid_0's l1: 0.297561\tvalid_0's l2: 0.126104\n",
      "[4]\tvalid_0's l1: 0.290349\tvalid_0's l2: 0.120549\n",
      "[5]\tvalid_0's l1: 0.283912\tvalid_0's l2: 0.115851\n",
      "[6]\tvalid_0's l1: 0.278022\tvalid_0's l2: 0.111749\n",
      "[7]\tvalid_0's l1: 0.272621\tvalid_0's l2: 0.108155\n",
      "[8]\tvalid_0's l1: 0.26777\tvalid_0's l2: 0.105106\n",
      "[9]\tvalid_0's l1: 0.263082\tvalid_0's l2: 0.102348\n",
      "[10]\tvalid_0's l1: 0.258728\tvalid_0's l2: 0.0999836\n",
      "[11]\tvalid_0's l1: 0.255033\tvalid_0's l2: 0.0979059\n",
      "[12]\tvalid_0's l1: 0.25142\tvalid_0's l2: 0.0960754\n",
      "[13]\tvalid_0's l1: 0.247959\tvalid_0's l2: 0.0944118\n",
      "[14]\tvalid_0's l1: 0.245185\tvalid_0's l2: 0.0933554\n",
      "[15]\tvalid_0's l1: 0.242649\tvalid_0's l2: 0.0924237\n",
      "[16]\tvalid_0's l1: 0.240395\tvalid_0's l2: 0.0916185\n",
      "[17]\tvalid_0's l1: 0.238371\tvalid_0's l2: 0.0908761\n",
      "[18]\tvalid_0's l1: 0.236709\tvalid_0's l2: 0.0904585\n",
      "[19]\tvalid_0's l1: 0.235072\tvalid_0's l2: 0.089955\n",
      "[20]\tvalid_0's l1: 0.233578\tvalid_0's l2: 0.0895386\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.233578\tvalid_0's l2: 0.0895386\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.31451\tvalid_0's l2: 0.139618\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.305823\tvalid_0's l2: 0.132834\n",
      "[3]\tvalid_0's l1: 0.298706\tvalid_0's l2: 0.127435\n",
      "[4]\tvalid_0's l1: 0.292604\tvalid_0's l2: 0.122812\n",
      "[5]\tvalid_0's l1: 0.287279\tvalid_0's l2: 0.119115\n",
      "[6]\tvalid_0's l1: 0.28179\tvalid_0's l2: 0.115382\n",
      "[7]\tvalid_0's l1: 0.276682\tvalid_0's l2: 0.112055\n",
      "[8]\tvalid_0's l1: 0.272774\tvalid_0's l2: 0.109803\n",
      "[9]\tvalid_0's l1: 0.26871\tvalid_0's l2: 0.107537\n",
      "[10]\tvalid_0's l1: 0.265132\tvalid_0's l2: 0.10571\n",
      "[11]\tvalid_0's l1: 0.261904\tvalid_0's l2: 0.104255\n",
      "[12]\tvalid_0's l1: 0.259059\tvalid_0's l2: 0.103197\n",
      "[13]\tvalid_0's l1: 0.256536\tvalid_0's l2: 0.102499\n",
      "[14]\tvalid_0's l1: 0.254569\tvalid_0's l2: 0.102234\n",
      "[15]\tvalid_0's l1: 0.252967\tvalid_0's l2: 0.102291\n",
      "[16]\tvalid_0's l1: 0.25126\tvalid_0's l2: 0.102174\n",
      "[17]\tvalid_0's l1: 0.249588\tvalid_0's l2: 0.102126\n",
      "[18]\tvalid_0's l1: 0.248447\tvalid_0's l2: 0.102519\n",
      "[19]\tvalid_0's l1: 0.247482\tvalid_0's l2: 0.103082\n",
      "[20]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.103696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.24657\tvalid_0's l2: 0.103696\n",
      "[1]\tvalid_0's l1: 0.314646\tvalid_0's l2: 0.139746\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.306513\tvalid_0's l2: 0.133088\n",
      "[3]\tvalid_0's l1: 0.299426\tvalid_0's l2: 0.127697\n",
      "[4]\tvalid_0's l1: 0.292538\tvalid_0's l2: 0.122478\n",
      "[5]\tvalid_0's l1: 0.286485\tvalid_0's l2: 0.118271\n",
      "[6]\tvalid_0's l1: 0.281263\tvalid_0's l2: 0.114779\n",
      "[7]\tvalid_0's l1: 0.276711\tvalid_0's l2: 0.111874\n",
      "[8]\tvalid_0's l1: 0.272225\tvalid_0's l2: 0.109177\n",
      "[9]\tvalid_0's l1: 0.2686\tvalid_0's l2: 0.107285\n",
      "[10]\tvalid_0's l1: 0.26528\tvalid_0's l2: 0.105655\n",
      "[11]\tvalid_0's l1: 0.262228\tvalid_0's l2: 0.104422\n",
      "[12]\tvalid_0's l1: 0.259501\tvalid_0's l2: 0.103408\n",
      "[13]\tvalid_0's l1: 0.257053\tvalid_0's l2: 0.102734\n",
      "[14]\tvalid_0's l1: 0.255136\tvalid_0's l2: 0.10251\n",
      "[15]\tvalid_0's l1: 0.253288\tvalid_0's l2: 0.102407\n",
      "[16]\tvalid_0's l1: 0.251697\tvalid_0's l2: 0.102399\n",
      "[17]\tvalid_0's l1: 0.2502\tvalid_0's l2: 0.102469\n",
      "[18]\tvalid_0's l1: 0.248972\tvalid_0's l2: 0.102547\n",
      "[19]\tvalid_0's l1: 0.247705\tvalid_0's l2: 0.102702\n",
      "[20]\tvalid_0's l1: 0.246626\tvalid_0's l2: 0.102989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.246626\tvalid_0's l2: 0.102989\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315081\tvalid_0's l2: 0.14009\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.307523\tvalid_0's l2: 0.134156\n",
      "[3]\tvalid_0's l1: 0.300575\tvalid_0's l2: 0.128597\n",
      "[4]\tvalid_0's l1: 0.294792\tvalid_0's l2: 0.12428\n",
      "[5]\tvalid_0's l1: 0.289206\tvalid_0's l2: 0.120216\n",
      "[6]\tvalid_0's l1: 0.284573\tvalid_0's l2: 0.117054\n",
      "[7]\tvalid_0's l1: 0.280893\tvalid_0's l2: 0.114553\n",
      "[8]\tvalid_0's l1: 0.277019\tvalid_0's l2: 0.112283\n",
      "[9]\tvalid_0's l1: 0.273924\tvalid_0's l2: 0.110793\n",
      "[10]\tvalid_0's l1: 0.270768\tvalid_0's l2: 0.109342\n",
      "[11]\tvalid_0's l1: 0.268323\tvalid_0's l2: 0.108317\n",
      "[12]\tvalid_0's l1: 0.266179\tvalid_0's l2: 0.107735\n",
      "[13]\tvalid_0's l1: 0.264109\tvalid_0's l2: 0.10727\n",
      "[14]\tvalid_0's l1: 0.26269\tvalid_0's l2: 0.107406\n",
      "[15]\tvalid_0's l1: 0.260956\tvalid_0's l2: 0.107218\n",
      "[16]\tvalid_0's l1: 0.259286\tvalid_0's l2: 0.107293\n",
      "[17]\tvalid_0's l1: 0.258548\tvalid_0's l2: 0.108174\n",
      "[18]\tvalid_0's l1: 0.257256\tvalid_0's l2: 0.108531\n",
      "[19]\tvalid_0's l1: 0.256128\tvalid_0's l2: 0.109069\n",
      "[20]\tvalid_0's l1: 0.255228\tvalid_0's l2: 0.109802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.255228\tvalid_0's l2: 0.109802\n",
      "[1]\tvalid_0's l1: 0.315185\tvalid_0's l2: 0.140207\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.30772\tvalid_0's l2: 0.133939\n",
      "[3]\tvalid_0's l1: 0.300734\tvalid_0's l2: 0.128416\n",
      "[4]\tvalid_0's l1: 0.294632\tvalid_0's l2: 0.123772\n",
      "[5]\tvalid_0's l1: 0.289516\tvalid_0's l2: 0.120279\n",
      "[6]\tvalid_0's l1: 0.285005\tvalid_0's l2: 0.117184\n",
      "[7]\tvalid_0's l1: 0.281337\tvalid_0's l2: 0.115073\n",
      "[8]\tvalid_0's l1: 0.277829\tvalid_0's l2: 0.113222\n",
      "[9]\tvalid_0's l1: 0.275045\tvalid_0's l2: 0.111871\n",
      "[10]\tvalid_0's l1: 0.272438\tvalid_0's l2: 0.111006\n",
      "[11]\tvalid_0's l1: 0.270206\tvalid_0's l2: 0.110227\n",
      "[12]\tvalid_0's l1: 0.268012\tvalid_0's l2: 0.109814\n",
      "[13]\tvalid_0's l1: 0.266573\tvalid_0's l2: 0.109849\n",
      "[14]\tvalid_0's l1: 0.265129\tvalid_0's l2: 0.110213\n",
      "[15]\tvalid_0's l1: 0.264458\tvalid_0's l2: 0.110855\n",
      "[16]\tvalid_0's l1: 0.263537\tvalid_0's l2: 0.111683\n",
      "[17]\tvalid_0's l1: 0.262475\tvalid_0's l2: 0.112408\n",
      "[18]\tvalid_0's l1: 0.261596\tvalid_0's l2: 0.113471\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.268012\tvalid_0's l2: 0.109814\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.315479\tvalid_0's l2: 0.140282\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308749\tvalid_0's l2: 0.134484\n",
      "[3]\tvalid_0's l1: 0.302685\tvalid_0's l2: 0.129557\n",
      "[4]\tvalid_0's l1: 0.297787\tvalid_0's l2: 0.125835\n",
      "[5]\tvalid_0's l1: 0.293558\tvalid_0's l2: 0.12276\n",
      "[6]\tvalid_0's l1: 0.289579\tvalid_0's l2: 0.119919\n",
      "[7]\tvalid_0's l1: 0.286596\tvalid_0's l2: 0.118055\n",
      "[8]\tvalid_0's l1: 0.284009\tvalid_0's l2: 0.116676\n",
      "[9]\tvalid_0's l1: 0.281736\tvalid_0's l2: 0.115773\n",
      "[10]\tvalid_0's l1: 0.27965\tvalid_0's l2: 0.115259\n",
      "[11]\tvalid_0's l1: 0.278097\tvalid_0's l2: 0.114976\n",
      "[12]\tvalid_0's l1: 0.276321\tvalid_0's l2: 0.114741\n",
      "[13]\tvalid_0's l1: 0.275249\tvalid_0's l2: 0.115117\n",
      "[14]\tvalid_0's l1: 0.274344\tvalid_0's l2: 0.11579\n",
      "[15]\tvalid_0's l1: 0.273604\tvalid_0's l2: 0.116738\n",
      "[16]\tvalid_0's l1: 0.273224\tvalid_0's l2: 0.118049\n",
      "[17]\tvalid_0's l1: 0.272328\tvalid_0's l2: 0.119011\n",
      "[18]\tvalid_0's l1: 0.271665\tvalid_0's l2: 0.120289\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.276321\tvalid_0's l2: 0.114741\n",
      "[1]\tvalid_0's l1: 0.315387\tvalid_0's l2: 0.14024\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.308232\tvalid_0's l2: 0.134461\n",
      "[3]\tvalid_0's l1: 0.303186\tvalid_0's l2: 0.130276\n",
      "[4]\tvalid_0's l1: 0.298322\tvalid_0's l2: 0.126285\n",
      "[5]\tvalid_0's l1: 0.294517\tvalid_0's l2: 0.123373\n",
      "[6]\tvalid_0's l1: 0.290901\tvalid_0's l2: 0.121014\n",
      "[7]\tvalid_0's l1: 0.288147\tvalid_0's l2: 0.119188\n",
      "[8]\tvalid_0's l1: 0.285892\tvalid_0's l2: 0.118191\n",
      "[9]\tvalid_0's l1: 0.284021\tvalid_0's l2: 0.117576\n",
      "[10]\tvalid_0's l1: 0.281948\tvalid_0's l2: 0.116879\n",
      "[11]\tvalid_0's l1: 0.280377\tvalid_0's l2: 0.116784\n",
      "[12]\tvalid_0's l1: 0.279575\tvalid_0's l2: 0.117709\n",
      "[13]\tvalid_0's l1: 0.278318\tvalid_0's l2: 0.118198\n",
      "[14]\tvalid_0's l1: 0.277382\tvalid_0's l2: 0.119047\n",
      "[15]\tvalid_0's l1: 0.276425\tvalid_0's l2: 0.119994\n",
      "[16]\tvalid_0's l1: 0.276047\tvalid_0's l2: 0.1214\n",
      "[17]\tvalid_0's l1: 0.275584\tvalid_0's l2: 0.122972\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's l1: 0.280377\tvalid_0's l2: 0.116784\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.316786\tvalid_0's l2: 0.141243\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.310552\tvalid_0's l2: 0.136147\n",
      "[3]\tvalid_0's l1: 0.30561\tvalid_0's l2: 0.13227\n",
      "[4]\tvalid_0's l1: 0.301393\tvalid_0's l2: 0.128907\n",
      "[5]\tvalid_0's l1: 0.298188\tvalid_0's l2: 0.126527\n",
      "[6]\tvalid_0's l1: 0.295356\tvalid_0's l2: 0.124603\n",
      "[7]\tvalid_0's l1: 0.293223\tvalid_0's l2: 0.123624\n",
      "[8]\tvalid_0's l1: 0.29129\tvalid_0's l2: 0.122936\n",
      "[9]\tvalid_0's l1: 0.290065\tvalid_0's l2: 0.122995\n",
      "[10]\tvalid_0's l1: 0.289312\tvalid_0's l2: 0.123713\n",
      "[11]\tvalid_0's l1: 0.288403\tvalid_0's l2: 0.124434\n",
      "[12]\tvalid_0's l1: 0.286723\tvalid_0's l2: 0.124697\n",
      "[13]\tvalid_0's l1: 0.285757\tvalid_0's l2: 0.125602\n",
      "[14]\tvalid_0's l1: 0.285086\tvalid_0's l2: 0.126752\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's l1: 0.29129\tvalid_0's l2: 0.122936\n",
      "[1]\tvalid_0's l1: 0.31672\tvalid_0's l2: 0.141301\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.311546\tvalid_0's l2: 0.137163\n",
      "[3]\tvalid_0's l1: 0.306062\tvalid_0's l2: 0.132742\n",
      "[4]\tvalid_0's l1: 0.302342\tvalid_0's l2: 0.130097\n",
      "[5]\tvalid_0's l1: 0.299339\tvalid_0's l2: 0.128004\n",
      "[6]\tvalid_0's l1: 0.296659\tvalid_0's l2: 0.126551\n",
      "[7]\tvalid_0's l1: 0.294564\tvalid_0's l2: 0.125834\n",
      "[8]\tvalid_0's l1: 0.29284\tvalid_0's l2: 0.125769\n",
      "[9]\tvalid_0's l1: 0.291004\tvalid_0's l2: 0.125249\n",
      "[10]\tvalid_0's l1: 0.289485\tvalid_0's l2: 0.12534\n",
      "[11]\tvalid_0's l1: 0.288356\tvalid_0's l2: 0.126181\n",
      "[12]\tvalid_0's l1: 0.287669\tvalid_0's l2: 0.127459\n",
      "[13]\tvalid_0's l1: 0.286796\tvalid_0's l2: 0.128856\n",
      "[14]\tvalid_0's l1: 0.285794\tvalid_0's l2: 0.129942\n",
      "[15]\tvalid_0's l1: 0.285057\tvalid_0's l2: 0.131337\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's l1: 0.291004\tvalid_0's l2: 0.125249\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_dist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_dist_cd_mavg2.csv'\n",
    "\n",
    "df_train_dist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_dist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_dist = df_test_dist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_dist_DFinfo = df_train_dist.iloc[:, (5 + i):12]\n",
    "    df_train_dist_withoutCD = df_train_dist.iloc[:, [20, 21]]\n",
    "    df_train_dist_withCD = df_train_dist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_dist_DFinfo = df_test_dist.iloc[:, (5 + i):12]\n",
    "    df_test_dist_withoutCD = df_test_dist.iloc[:, [20, 21]]\n",
    "    df_test_dist_withCD = df_test_dist.iloc[:, 20: 31]\n",
    "        \n",
    "    x_train_withoutCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withoutCD], axis = 1)\n",
    "    x_train_withCD = pd.concat([df_train_dist_DFinfo, df_train_dist_withCD], axis = 1)\n",
    "    \n",
    "    x_test_withoutCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withoutCD], axis = 1)\n",
    "    x_test_withCD = pd.concat([df_test_dist_DFinfo, df_test_dist_withCD], axis = 1)\n",
    "    \n",
    "    # y: response (target) variable DF_1 (col 4)\n",
    "    y_train = df_train_dist.iloc[:, [4]]\n",
    "    y_test = df_test_dist.iloc[:, [4]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_dist['DF_1'])\n",
    "    y_test_true = np.array(df_test_dist['DF_1'])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_dist_withoutCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                              + str(i + 1) + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_dist_withCD = pd.concat([df_test_addrcode_week_year_dist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_dist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_dist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                           + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' \n",
    "                                           + str(i + 1) + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_dist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "    dist_code = df_train_dist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in dist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_dist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_dist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_dist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_dist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_dist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_dist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_dist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_dist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_dist = (rmse_withoutCD_dist - rmse_withCD_dist) / rmse_withoutCD_dist\n",
    "        mae_percent_improved_dist = (mae_withoutCD_dist - mae_withCD_dist) / mae_withoutCD_dist\n",
    "        smape_percent_improved_dist = (smape_withoutCD_dist - smape_withCD_dist) / smape_withoutCD_dist\n",
    "        r2_percent_improved_dist = (r2_withoutCD_dist - r2_withCD_dist) / r2_withoutCD_dist\n",
    "            \n",
    "        # Append\n",
    "        dist_array = np.append(dist_array, [[j, rmse_withoutCD_dist, rmse_withCD_dist, rmse_percent_improved_dist,\n",
    "                                            mae_withoutCD_dist, mae_withCD_dist, mae_percent_improved_dist,\n",
    "                                            smape_withoutCD_dist, smape_withCD_dist, smape_percent_improved_dist,\n",
    "                                            r2_withoutCD_dist, r2_withCD_dist, r2_percent_improved_dist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(dist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_ByDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    dist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_dist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sub-district level</h1>\n",
    "For MAs (adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.37839\tvalid_0's l2: 0.240277\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.365864\tvalid_0's l2: 0.225832\n",
      "[3]\tvalid_0's l1: 0.354928\tvalid_0's l2: 0.21403\n",
      "[4]\tvalid_0's l1: 0.344881\tvalid_0's l2: 0.203476\n",
      "[5]\tvalid_0's l1: 0.33397\tvalid_0's l2: 0.192215\n",
      "[6]\tvalid_0's l1: 0.323954\tvalid_0's l2: 0.182453\n",
      "[7]\tvalid_0's l1: 0.31425\tvalid_0's l2: 0.1726\n",
      "[8]\tvalid_0's l1: 0.305548\tvalid_0's l2: 0.164498\n",
      "[9]\tvalid_0's l1: 0.298172\tvalid_0's l2: 0.15829\n",
      "[10]\tvalid_0's l1: 0.290282\tvalid_0's l2: 0.151115\n",
      "[11]\tvalid_0's l1: 0.282991\tvalid_0's l2: 0.14505\n",
      "[12]\tvalid_0's l1: 0.276325\tvalid_0's l2: 0.139541\n",
      "[13]\tvalid_0's l1: 0.269913\tvalid_0's l2: 0.134164\n",
      "[14]\tvalid_0's l1: 0.264186\tvalid_0's l2: 0.129643\n",
      "[15]\tvalid_0's l1: 0.259404\tvalid_0's l2: 0.126366\n",
      "[16]\tvalid_0's l1: 0.254246\tvalid_0's l2: 0.122412\n",
      "[17]\tvalid_0's l1: 0.249552\tvalid_0's l2: 0.119163\n",
      "[18]\tvalid_0's l1: 0.245002\tvalid_0's l2: 0.116025\n",
      "[19]\tvalid_0's l1: 0.24098\tvalid_0's l2: 0.113448\n",
      "[20]\tvalid_0's l1: 0.238483\tvalid_0's l2: 0.112075\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238483\tvalid_0's l2: 0.112075\n",
      "[1]\tvalid_0's l1: 0.378428\tvalid_0's l2: 0.24034\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3667\tvalid_0's l2: 0.227104\n",
      "[3]\tvalid_0's l1: 0.354474\tvalid_0's l2: 0.213576\n",
      "[4]\tvalid_0's l1: 0.343087\tvalid_0's l2: 0.201227\n",
      "[5]\tvalid_0's l1: 0.333399\tvalid_0's l2: 0.191406\n",
      "[6]\tvalid_0's l1: 0.323257\tvalid_0's l2: 0.181344\n",
      "[7]\tvalid_0's l1: 0.313904\tvalid_0's l2: 0.172209\n",
      "[8]\tvalid_0's l1: 0.306026\tvalid_0's l2: 0.165209\n",
      "[9]\tvalid_0's l1: 0.297827\tvalid_0's l2: 0.157745\n",
      "[10]\tvalid_0's l1: 0.289911\tvalid_0's l2: 0.151006\n",
      "[11]\tvalid_0's l1: 0.282704\tvalid_0's l2: 0.144795\n",
      "[12]\tvalid_0's l1: 0.276151\tvalid_0's l2: 0.139345\n",
      "[13]\tvalid_0's l1: 0.270553\tvalid_0's l2: 0.134977\n",
      "[14]\tvalid_0's l1: 0.264735\tvalid_0's l2: 0.130443\n",
      "[15]\tvalid_0's l1: 0.261491\tvalid_0's l2: 0.128481\n",
      "[16]\tvalid_0's l1: 0.258439\tvalid_0's l2: 0.126747\n",
      "[17]\tvalid_0's l1: 0.253482\tvalid_0's l2: 0.123127\n",
      "[18]\tvalid_0's l1: 0.250732\tvalid_0's l2: 0.121602\n",
      "[19]\tvalid_0's l1: 0.246075\tvalid_0's l2: 0.118232\n",
      "[20]\tvalid_0's l1: 0.241565\tvalid_0's l2: 0.114965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.241565\tvalid_0's l2: 0.114965\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.382501\tvalid_0's l2: 0.246336\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.374944\tvalid_0's l2: 0.238955\n",
      "[3]\tvalid_0's l1: 0.367862\tvalid_0's l2: 0.232227\n",
      "[4]\tvalid_0's l1: 0.36139\tvalid_0's l2: 0.226415\n",
      "[5]\tvalid_0's l1: 0.355396\tvalid_0's l2: 0.221062\n",
      "[6]\tvalid_0's l1: 0.349427\tvalid_0's l2: 0.215234\n",
      "[7]\tvalid_0's l1: 0.343933\tvalid_0's l2: 0.210644\n",
      "[8]\tvalid_0's l1: 0.339037\tvalid_0's l2: 0.206821\n",
      "[9]\tvalid_0's l1: 0.334645\tvalid_0's l2: 0.203738\n",
      "[10]\tvalid_0's l1: 0.330535\tvalid_0's l2: 0.200843\n",
      "[11]\tvalid_0's l1: 0.326576\tvalid_0's l2: 0.198005\n",
      "[12]\tvalid_0's l1: 0.322736\tvalid_0's l2: 0.194939\n",
      "[13]\tvalid_0's l1: 0.319347\tvalid_0's l2: 0.192737\n",
      "[14]\tvalid_0's l1: 0.316422\tvalid_0's l2: 0.19091\n",
      "[15]\tvalid_0's l1: 0.313543\tvalid_0's l2: 0.189138\n",
      "[16]\tvalid_0's l1: 0.310931\tvalid_0's l2: 0.187542\n",
      "[17]\tvalid_0's l1: 0.308416\tvalid_0's l2: 0.185718\n",
      "[18]\tvalid_0's l1: 0.306188\tvalid_0's l2: 0.184279\n",
      "[19]\tvalid_0's l1: 0.304092\tvalid_0's l2: 0.183144\n",
      "[20]\tvalid_0's l1: 0.302156\tvalid_0's l2: 0.182036\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.302156\tvalid_0's l2: 0.182036\n",
      "[1]\tvalid_0's l1: 0.382491\tvalid_0's l2: 0.246271\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375475\tvalid_0's l2: 0.239426\n",
      "[3]\tvalid_0's l1: 0.367769\tvalid_0's l2: 0.231152\n",
      "[4]\tvalid_0's l1: 0.361354\tvalid_0's l2: 0.225445\n",
      "[5]\tvalid_0's l1: 0.355427\tvalid_0's l2: 0.22027\n",
      "[6]\tvalid_0's l1: 0.349575\tvalid_0's l2: 0.215288\n",
      "[7]\tvalid_0's l1: 0.344482\tvalid_0's l2: 0.211145\n",
      "[8]\tvalid_0's l1: 0.339304\tvalid_0's l2: 0.207146\n",
      "[9]\tvalid_0's l1: 0.334562\tvalid_0's l2: 0.203381\n",
      "[10]\tvalid_0's l1: 0.330398\tvalid_0's l2: 0.200384\n",
      "[11]\tvalid_0's l1: 0.326501\tvalid_0's l2: 0.197489\n",
      "[12]\tvalid_0's l1: 0.32279\tvalid_0's l2: 0.194903\n",
      "[13]\tvalid_0's l1: 0.319351\tvalid_0's l2: 0.192669\n",
      "[14]\tvalid_0's l1: 0.316182\tvalid_0's l2: 0.190355\n",
      "[15]\tvalid_0's l1: 0.313364\tvalid_0's l2: 0.188665\n",
      "[16]\tvalid_0's l1: 0.31099\tvalid_0's l2: 0.187375\n",
      "[17]\tvalid_0's l1: 0.308728\tvalid_0's l2: 0.185663\n",
      "[18]\tvalid_0's l1: 0.306512\tvalid_0's l2: 0.184443\n",
      "[19]\tvalid_0's l1: 0.30463\tvalid_0's l2: 0.183358\n",
      "[20]\tvalid_0's l1: 0.302811\tvalid_0's l2: 0.182451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.302811\tvalid_0's l2: 0.182451\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.382647\tvalid_0's l2: 0.246724\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375292\tvalid_0's l2: 0.239653\n",
      "[3]\tvalid_0's l1: 0.368701\tvalid_0's l2: 0.233249\n",
      "[4]\tvalid_0's l1: 0.362643\tvalid_0's l2: 0.22758\n",
      "[5]\tvalid_0's l1: 0.357354\tvalid_0's l2: 0.222797\n",
      "[6]\tvalid_0's l1: 0.351623\tvalid_0's l2: 0.217992\n",
      "[7]\tvalid_0's l1: 0.346399\tvalid_0's l2: 0.212896\n",
      "[8]\tvalid_0's l1: 0.342116\tvalid_0's l2: 0.20966\n",
      "[9]\tvalid_0's l1: 0.337767\tvalid_0's l2: 0.205834\n",
      "[10]\tvalid_0's l1: 0.333832\tvalid_0's l2: 0.202967\n",
      "[11]\tvalid_0's l1: 0.33027\tvalid_0's l2: 0.200442\n",
      "[12]\tvalid_0's l1: 0.327008\tvalid_0's l2: 0.198274\n",
      "[13]\tvalid_0's l1: 0.323926\tvalid_0's l2: 0.196384\n",
      "[14]\tvalid_0's l1: 0.321179\tvalid_0's l2: 0.194818\n",
      "[15]\tvalid_0's l1: 0.318475\tvalid_0's l2: 0.193352\n",
      "[16]\tvalid_0's l1: 0.316139\tvalid_0's l2: 0.192037\n",
      "[17]\tvalid_0's l1: 0.313819\tvalid_0's l2: 0.190616\n",
      "[18]\tvalid_0's l1: 0.311763\tvalid_0's l2: 0.189458\n",
      "[19]\tvalid_0's l1: 0.309708\tvalid_0's l2: 0.188361\n",
      "[20]\tvalid_0's l1: 0.30801\tvalid_0's l2: 0.187622\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.30801\tvalid_0's l2: 0.187622\n",
      "[1]\tvalid_0's l1: 0.382947\tvalid_0's l2: 0.246928\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375506\tvalid_0's l2: 0.238527\n",
      "[3]\tvalid_0's l1: 0.368829\tvalid_0's l2: 0.232211\n",
      "[4]\tvalid_0's l1: 0.362342\tvalid_0's l2: 0.226322\n",
      "[5]\tvalid_0's l1: 0.3567\tvalid_0's l2: 0.221165\n",
      "[6]\tvalid_0's l1: 0.351056\tvalid_0's l2: 0.216607\n",
      "[7]\tvalid_0's l1: 0.346346\tvalid_0's l2: 0.212706\n",
      "[8]\tvalid_0's l1: 0.34178\tvalid_0's l2: 0.208849\n",
      "[9]\tvalid_0's l1: 0.337568\tvalid_0's l2: 0.206019\n",
      "[10]\tvalid_0's l1: 0.333486\tvalid_0's l2: 0.203033\n",
      "[11]\tvalid_0's l1: 0.329879\tvalid_0's l2: 0.200375\n",
      "[12]\tvalid_0's l1: 0.326647\tvalid_0's l2: 0.198268\n",
      "[13]\tvalid_0's l1: 0.323507\tvalid_0's l2: 0.196117\n",
      "[14]\tvalid_0's l1: 0.320715\tvalid_0's l2: 0.19428\n",
      "[15]\tvalid_0's l1: 0.318079\tvalid_0's l2: 0.192578\n",
      "[16]\tvalid_0's l1: 0.315433\tvalid_0's l2: 0.190821\n",
      "[17]\tvalid_0's l1: 0.313081\tvalid_0's l2: 0.189507\n",
      "[18]\tvalid_0's l1: 0.311115\tvalid_0's l2: 0.188451\n",
      "[19]\tvalid_0's l1: 0.309241\tvalid_0's l2: 0.187542\n",
      "[20]\tvalid_0's l1: 0.307499\tvalid_0's l2: 0.186805\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.307499\tvalid_0's l2: 0.186805\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.383082\tvalid_0's l2: 0.246911\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.376328\tvalid_0's l2: 0.240023\n",
      "[3]\tvalid_0's l1: 0.369725\tvalid_0's l2: 0.233808\n",
      "[4]\tvalid_0's l1: 0.363738\tvalid_0's l2: 0.228414\n",
      "[5]\tvalid_0's l1: 0.358198\tvalid_0's l2: 0.222513\n",
      "[6]\tvalid_0's l1: 0.35331\tvalid_0's l2: 0.218445\n",
      "[7]\tvalid_0's l1: 0.34884\tvalid_0's l2: 0.215094\n",
      "[8]\tvalid_0's l1: 0.34454\tvalid_0's l2: 0.211076\n",
      "[9]\tvalid_0's l1: 0.340887\tvalid_0's l2: 0.208334\n",
      "[10]\tvalid_0's l1: 0.337445\tvalid_0's l2: 0.20548\n",
      "[11]\tvalid_0's l1: 0.334236\tvalid_0's l2: 0.203534\n",
      "[12]\tvalid_0's l1: 0.331324\tvalid_0's l2: 0.202015\n",
      "[13]\tvalid_0's l1: 0.328525\tvalid_0's l2: 0.200215\n",
      "[14]\tvalid_0's l1: 0.325818\tvalid_0's l2: 0.198611\n",
      "[15]\tvalid_0's l1: 0.323482\tvalid_0's l2: 0.197079\n",
      "[16]\tvalid_0's l1: 0.321571\tvalid_0's l2: 0.195929\n",
      "[17]\tvalid_0's l1: 0.319797\tvalid_0's l2: 0.195305\n",
      "[18]\tvalid_0's l1: 0.318017\tvalid_0's l2: 0.194655\n",
      "[19]\tvalid_0's l1: 0.316648\tvalid_0's l2: 0.194091\n",
      "[20]\tvalid_0's l1: 0.315196\tvalid_0's l2: 0.193799\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.315196\tvalid_0's l2: 0.193799\n",
      "[1]\tvalid_0's l1: 0.382961\tvalid_0's l2: 0.246749\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375789\tvalid_0's l2: 0.239532\n",
      "[3]\tvalid_0's l1: 0.369248\tvalid_0's l2: 0.233353\n",
      "[4]\tvalid_0's l1: 0.363243\tvalid_0's l2: 0.227315\n",
      "[5]\tvalid_0's l1: 0.357816\tvalid_0's l2: 0.222559\n",
      "[6]\tvalid_0's l1: 0.3527\tvalid_0's l2: 0.218303\n",
      "[7]\tvalid_0's l1: 0.348418\tvalid_0's l2: 0.215171\n",
      "[8]\tvalid_0's l1: 0.344222\tvalid_0's l2: 0.211945\n",
      "[9]\tvalid_0's l1: 0.340409\tvalid_0's l2: 0.208037\n",
      "[10]\tvalid_0's l1: 0.337051\tvalid_0's l2: 0.205692\n",
      "[11]\tvalid_0's l1: 0.333787\tvalid_0's l2: 0.203228\n",
      "[12]\tvalid_0's l1: 0.33074\tvalid_0's l2: 0.201425\n",
      "[13]\tvalid_0's l1: 0.328033\tvalid_0's l2: 0.19971\n",
      "[14]\tvalid_0's l1: 0.325421\tvalid_0's l2: 0.198169\n",
      "[15]\tvalid_0's l1: 0.323104\tvalid_0's l2: 0.196777\n",
      "[16]\tvalid_0's l1: 0.32105\tvalid_0's l2: 0.195653\n",
      "[17]\tvalid_0's l1: 0.319223\tvalid_0's l2: 0.194793\n",
      "[18]\tvalid_0's l1: 0.317399\tvalid_0's l2: 0.193912\n",
      "[19]\tvalid_0's l1: 0.315766\tvalid_0's l2: 0.193377\n",
      "[20]\tvalid_0's l1: 0.314326\tvalid_0's l2: 0.1929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.314326\tvalid_0's l2: 0.1929\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.383376\tvalid_0's l2: 0.247554\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.376883\tvalid_0's l2: 0.241456\n",
      "[3]\tvalid_0's l1: 0.370628\tvalid_0's l2: 0.235684\n",
      "[4]\tvalid_0's l1: 0.365095\tvalid_0's l2: 0.23097\n",
      "[5]\tvalid_0's l1: 0.360115\tvalid_0's l2: 0.226845\n",
      "[6]\tvalid_0's l1: 0.355393\tvalid_0's l2: 0.22218\n",
      "[7]\tvalid_0's l1: 0.351144\tvalid_0's l2: 0.218737\n",
      "[8]\tvalid_0's l1: 0.347536\tvalid_0's l2: 0.216266\n",
      "[9]\tvalid_0's l1: 0.344163\tvalid_0's l2: 0.213998\n",
      "[10]\tvalid_0's l1: 0.340966\tvalid_0's l2: 0.211918\n",
      "[11]\tvalid_0's l1: 0.337973\tvalid_0's l2: 0.209741\n",
      "[12]\tvalid_0's l1: 0.335263\tvalid_0's l2: 0.207375\n",
      "[13]\tvalid_0's l1: 0.332799\tvalid_0's l2: 0.205851\n",
      "[14]\tvalid_0's l1: 0.330517\tvalid_0's l2: 0.204575\n",
      "[15]\tvalid_0's l1: 0.328691\tvalid_0's l2: 0.203688\n",
      "[16]\tvalid_0's l1: 0.326835\tvalid_0's l2: 0.203041\n",
      "[17]\tvalid_0's l1: 0.325279\tvalid_0's l2: 0.202421\n",
      "[18]\tvalid_0's l1: 0.323872\tvalid_0's l2: 0.201908\n",
      "[19]\tvalid_0's l1: 0.322349\tvalid_0's l2: 0.201398\n",
      "[20]\tvalid_0's l1: 0.321052\tvalid_0's l2: 0.201059\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.321052\tvalid_0's l2: 0.201059\n",
      "[1]\tvalid_0's l1: 0.383222\tvalid_0's l2: 0.247417\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.376905\tvalid_0's l2: 0.24065\n",
      "[3]\tvalid_0's l1: 0.371334\tvalid_0's l2: 0.235895\n",
      "[4]\tvalid_0's l1: 0.36567\tvalid_0's l2: 0.230935\n",
      "[5]\tvalid_0's l1: 0.360686\tvalid_0's l2: 0.226767\n",
      "[6]\tvalid_0's l1: 0.356061\tvalid_0's l2: 0.222291\n",
      "[7]\tvalid_0's l1: 0.351747\tvalid_0's l2: 0.219076\n",
      "[8]\tvalid_0's l1: 0.347882\tvalid_0's l2: 0.216389\n",
      "[9]\tvalid_0's l1: 0.344184\tvalid_0's l2: 0.213724\n",
      "[10]\tvalid_0's l1: 0.341031\tvalid_0's l2: 0.2114\n",
      "[11]\tvalid_0's l1: 0.338102\tvalid_0's l2: 0.209241\n",
      "[12]\tvalid_0's l1: 0.335362\tvalid_0's l2: 0.207553\n",
      "[13]\tvalid_0's l1: 0.332771\tvalid_0's l2: 0.205719\n",
      "[14]\tvalid_0's l1: 0.330317\tvalid_0's l2: 0.204208\n",
      "[15]\tvalid_0's l1: 0.328179\tvalid_0's l2: 0.203037\n",
      "[16]\tvalid_0's l1: 0.326161\tvalid_0's l2: 0.202348\n",
      "[17]\tvalid_0's l1: 0.324243\tvalid_0's l2: 0.201497\n",
      "[18]\tvalid_0's l1: 0.322586\tvalid_0's l2: 0.201104\n",
      "[19]\tvalid_0's l1: 0.321153\tvalid_0's l2: 0.200687\n",
      "[20]\tvalid_0's l1: 0.319775\tvalid_0's l2: 0.200416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.319775\tvalid_0's l2: 0.200416\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.384384\tvalid_0's l2: 0.248702\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.379065\tvalid_0's l2: 0.243885\n",
      "[3]\tvalid_0's l1: 0.373828\tvalid_0's l2: 0.239704\n",
      "[4]\tvalid_0's l1: 0.368936\tvalid_0's l2: 0.234718\n",
      "[5]\tvalid_0's l1: 0.365025\tvalid_0's l2: 0.231666\n",
      "[6]\tvalid_0's l1: 0.360787\tvalid_0's l2: 0.22848\n",
      "[7]\tvalid_0's l1: 0.35695\tvalid_0's l2: 0.225776\n",
      "[8]\tvalid_0's l1: 0.353829\tvalid_0's l2: 0.223864\n",
      "[9]\tvalid_0's l1: 0.350903\tvalid_0's l2: 0.222149\n",
      "[10]\tvalid_0's l1: 0.348225\tvalid_0's l2: 0.220799\n",
      "[11]\tvalid_0's l1: 0.345851\tvalid_0's l2: 0.219669\n",
      "[12]\tvalid_0's l1: 0.343422\tvalid_0's l2: 0.217919\n",
      "[13]\tvalid_0's l1: 0.341053\tvalid_0's l2: 0.216518\n",
      "[14]\tvalid_0's l1: 0.339076\tvalid_0's l2: 0.215714\n",
      "[15]\tvalid_0's l1: 0.337337\tvalid_0's l2: 0.214847\n",
      "[16]\tvalid_0's l1: 0.335772\tvalid_0's l2: 0.214447\n",
      "[17]\tvalid_0's l1: 0.334285\tvalid_0's l2: 0.213897\n",
      "[18]\tvalid_0's l1: 0.332724\tvalid_0's l2: 0.213727\n",
      "[19]\tvalid_0's l1: 0.331585\tvalid_0's l2: 0.213941\n",
      "[20]\tvalid_0's l1: 0.330699\tvalid_0's l2: 0.214449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.330699\tvalid_0's l2: 0.214449\n",
      "[1]\tvalid_0's l1: 0.384337\tvalid_0's l2: 0.248754\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.378624\tvalid_0's l2: 0.24369\n",
      "[3]\tvalid_0's l1: 0.372687\tvalid_0's l2: 0.23721\n",
      "[4]\tvalid_0's l1: 0.367766\tvalid_0's l2: 0.233026\n",
      "[5]\tvalid_0's l1: 0.363255\tvalid_0's l2: 0.229401\n",
      "[6]\tvalid_0's l1: 0.358929\tvalid_0's l2: 0.226121\n",
      "[7]\tvalid_0's l1: 0.354949\tvalid_0's l2: 0.223369\n",
      "[8]\tvalid_0's l1: 0.351228\tvalid_0's l2: 0.220717\n",
      "[9]\tvalid_0's l1: 0.348155\tvalid_0's l2: 0.218993\n",
      "[10]\tvalid_0's l1: 0.345421\tvalid_0's l2: 0.216958\n",
      "[11]\tvalid_0's l1: 0.343092\tvalid_0's l2: 0.215467\n",
      "[12]\tvalid_0's l1: 0.340965\tvalid_0's l2: 0.214458\n",
      "[13]\tvalid_0's l1: 0.339017\tvalid_0's l2: 0.213173\n",
      "[14]\tvalid_0's l1: 0.337209\tvalid_0's l2: 0.212244\n",
      "[15]\tvalid_0's l1: 0.33551\tvalid_0's l2: 0.211648\n",
      "[16]\tvalid_0's l1: 0.333813\tvalid_0's l2: 0.211229\n",
      "[17]\tvalid_0's l1: 0.332287\tvalid_0's l2: 0.210855\n",
      "[18]\tvalid_0's l1: 0.331027\tvalid_0's l2: 0.210866\n",
      "[19]\tvalid_0's l1: 0.329956\tvalid_0's l2: 0.210695\n",
      "[20]\tvalid_0's l1: 0.329107\tvalid_0's l2: 0.210957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.329107\tvalid_0's l2: 0.210957\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.34549\tvalid_0's l2: 0.195412\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.331831\tvalid_0's l2: 0.181071\n",
      "[3]\tvalid_0's l1: 0.318523\tvalid_0's l2: 0.167232\n",
      "[4]\tvalid_0's l1: 0.305935\tvalid_0's l2: 0.154611\n",
      "[5]\tvalid_0's l1: 0.294171\tvalid_0's l2: 0.143584\n",
      "[6]\tvalid_0's l1: 0.282954\tvalid_0's l2: 0.133475\n",
      "[7]\tvalid_0's l1: 0.272506\tvalid_0's l2: 0.124402\n",
      "[8]\tvalid_0's l1: 0.262859\tvalid_0's l2: 0.116515\n",
      "[9]\tvalid_0's l1: 0.253868\tvalid_0's l2: 0.109476\n",
      "[10]\tvalid_0's l1: 0.245301\tvalid_0's l2: 0.102821\n",
      "[11]\tvalid_0's l1: 0.237323\tvalid_0's l2: 0.096884\n",
      "[12]\tvalid_0's l1: 0.229839\tvalid_0's l2: 0.0915452\n",
      "[13]\tvalid_0's l1: 0.222646\tvalid_0's l2: 0.0864361\n",
      "[14]\tvalid_0's l1: 0.216289\tvalid_0's l2: 0.0824277\n",
      "[15]\tvalid_0's l1: 0.210028\tvalid_0's l2: 0.0784761\n",
      "[16]\tvalid_0's l1: 0.204206\tvalid_0's l2: 0.0747635\n",
      "[17]\tvalid_0's l1: 0.198975\tvalid_0's l2: 0.0717995\n",
      "[18]\tvalid_0's l1: 0.194197\tvalid_0's l2: 0.0691961\n",
      "[19]\tvalid_0's l1: 0.189642\tvalid_0's l2: 0.0668501\n",
      "[20]\tvalid_0's l1: 0.186334\tvalid_0's l2: 0.0653302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.186334\tvalid_0's l2: 0.0653302\n",
      "[1]\tvalid_0's l1: 0.345444\tvalid_0's l2: 0.195182\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.331378\tvalid_0's l2: 0.179964\n",
      "[3]\tvalid_0's l1: 0.318158\tvalid_0's l2: 0.166398\n",
      "[4]\tvalid_0's l1: 0.305604\tvalid_0's l2: 0.153817\n",
      "[5]\tvalid_0's l1: 0.293859\tvalid_0's l2: 0.142921\n",
      "[6]\tvalid_0's l1: 0.282787\tvalid_0's l2: 0.133033\n",
      "[7]\tvalid_0's l1: 0.272515\tvalid_0's l2: 0.124335\n",
      "[8]\tvalid_0's l1: 0.26295\tvalid_0's l2: 0.116483\n",
      "[9]\tvalid_0's l1: 0.253854\tvalid_0's l2: 0.109262\n",
      "[10]\tvalid_0's l1: 0.245391\tvalid_0's l2: 0.102886\n",
      "[11]\tvalid_0's l1: 0.237412\tvalid_0's l2: 0.096949\n",
      "[12]\tvalid_0's l1: 0.229992\tvalid_0's l2: 0.091681\n",
      "[13]\tvalid_0's l1: 0.223343\tvalid_0's l2: 0.0871991\n",
      "[14]\tvalid_0's l1: 0.21681\tvalid_0's l2: 0.0828779\n",
      "[15]\tvalid_0's l1: 0.212209\tvalid_0's l2: 0.0802976\n",
      "[16]\tvalid_0's l1: 0.208159\tvalid_0's l2: 0.0781237\n",
      "[17]\tvalid_0's l1: 0.202551\tvalid_0's l2: 0.0748294\n",
      "[18]\tvalid_0's l1: 0.198873\tvalid_0's l2: 0.0729828\n",
      "[19]\tvalid_0's l1: 0.19395\tvalid_0's l2: 0.0702808\n",
      "[20]\tvalid_0's l1: 0.189357\tvalid_0's l2: 0.0678519\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189357\tvalid_0's l2: 0.0678519\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.349636\tvalid_0's l2: 0.200801\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.33905\tvalid_0's l2: 0.190396\n",
      "[3]\tvalid_0's l1: 0.33141\tvalid_0's l2: 0.183798\n",
      "[4]\tvalid_0's l1: 0.32197\tvalid_0's l2: 0.174669\n",
      "[5]\tvalid_0's l1: 0.315731\tvalid_0's l2: 0.169657\n",
      "[6]\tvalid_0's l1: 0.306687\tvalid_0's l2: 0.160908\n",
      "[7]\tvalid_0's l1: 0.299428\tvalid_0's l2: 0.155007\n",
      "[8]\tvalid_0's l1: 0.292085\tvalid_0's l2: 0.148599\n",
      "[9]\tvalid_0's l1: 0.285307\tvalid_0's l2: 0.143191\n",
      "[10]\tvalid_0's l1: 0.279435\tvalid_0's l2: 0.138828\n",
      "[11]\tvalid_0's l1: 0.273601\tvalid_0's l2: 0.134141\n",
      "[12]\tvalid_0's l1: 0.267862\tvalid_0's l2: 0.129314\n",
      "[13]\tvalid_0's l1: 0.264349\tvalid_0's l2: 0.127354\n",
      "[14]\tvalid_0's l1: 0.261172\tvalid_0's l2: 0.125628\n",
      "[15]\tvalid_0's l1: 0.256405\tvalid_0's l2: 0.122386\n",
      "[16]\tvalid_0's l1: 0.253628\tvalid_0's l2: 0.120964\n",
      "[17]\tvalid_0's l1: 0.249309\tvalid_0's l2: 0.117674\n",
      "[18]\tvalid_0's l1: 0.245247\tvalid_0's l2: 0.11473\n",
      "[19]\tvalid_0's l1: 0.241774\tvalid_0's l2: 0.112673\n",
      "[20]\tvalid_0's l1: 0.238354\tvalid_0's l2: 0.110353\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238354\tvalid_0's l2: 0.110353\n",
      "[1]\tvalid_0's l1: 0.349608\tvalid_0's l2: 0.200655\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.341622\tvalid_0's l2: 0.193413\n",
      "[3]\tvalid_0's l1: 0.330945\tvalid_0's l2: 0.182265\n",
      "[4]\tvalid_0's l1: 0.321538\tvalid_0's l2: 0.17351\n",
      "[5]\tvalid_0's l1: 0.312829\tvalid_0's l2: 0.165593\n",
      "[6]\tvalid_0's l1: 0.304763\tvalid_0's l2: 0.158707\n",
      "[7]\tvalid_0's l1: 0.297339\tvalid_0's l2: 0.15248\n",
      "[8]\tvalid_0's l1: 0.290655\tvalid_0's l2: 0.147138\n",
      "[9]\tvalid_0's l1: 0.284151\tvalid_0's l2: 0.142116\n",
      "[10]\tvalid_0's l1: 0.278057\tvalid_0's l2: 0.137282\n",
      "[11]\tvalid_0's l1: 0.272588\tvalid_0's l2: 0.133294\n",
      "[12]\tvalid_0's l1: 0.267422\tvalid_0's l2: 0.129499\n",
      "[13]\tvalid_0's l1: 0.26238\tvalid_0's l2: 0.125908\n",
      "[14]\tvalid_0's l1: 0.257753\tvalid_0's l2: 0.12256\n",
      "[15]\tvalid_0's l1: 0.253357\tvalid_0's l2: 0.119574\n",
      "[16]\tvalid_0's l1: 0.249513\tvalid_0's l2: 0.117198\n",
      "[17]\tvalid_0's l1: 0.246958\tvalid_0's l2: 0.1156\n",
      "[18]\tvalid_0's l1: 0.243516\tvalid_0's l2: 0.113483\n",
      "[19]\tvalid_0's l1: 0.241225\tvalid_0's l2: 0.112632\n",
      "[20]\tvalid_0's l1: 0.238031\tvalid_0's l2: 0.110603\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238031\tvalid_0's l2: 0.110603\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.351494\tvalid_0's l2: 0.203499\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.343667\tvalid_0's l2: 0.196299\n",
      "[3]\tvalid_0's l1: 0.336486\tvalid_0's l2: 0.189713\n",
      "[4]\tvalid_0's l1: 0.330067\tvalid_0's l2: 0.183995\n",
      "[5]\tvalid_0's l1: 0.32407\tvalid_0's l2: 0.179171\n",
      "[6]\tvalid_0's l1: 0.318435\tvalid_0's l2: 0.174659\n",
      "[7]\tvalid_0's l1: 0.312542\tvalid_0's l2: 0.169346\n",
      "[8]\tvalid_0's l1: 0.307799\tvalid_0's l2: 0.166035\n",
      "[9]\tvalid_0's l1: 0.302903\tvalid_0's l2: 0.161702\n",
      "[10]\tvalid_0's l1: 0.298741\tvalid_0's l2: 0.1588\n",
      "[11]\tvalid_0's l1: 0.294989\tvalid_0's l2: 0.156255\n",
      "[12]\tvalid_0's l1: 0.291688\tvalid_0's l2: 0.154116\n",
      "[13]\tvalid_0's l1: 0.288487\tvalid_0's l2: 0.152218\n",
      "[14]\tvalid_0's l1: 0.285636\tvalid_0's l2: 0.150651\n",
      "[15]\tvalid_0's l1: 0.282922\tvalid_0's l2: 0.149113\n",
      "[16]\tvalid_0's l1: 0.280311\tvalid_0's l2: 0.14766\n",
      "[17]\tvalid_0's l1: 0.277884\tvalid_0's l2: 0.146323\n",
      "[18]\tvalid_0's l1: 0.27561\tvalid_0's l2: 0.145219\n",
      "[19]\tvalid_0's l1: 0.273563\tvalid_0's l2: 0.144193\n",
      "[20]\tvalid_0's l1: 0.271673\tvalid_0's l2: 0.143503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.271673\tvalid_0's l2: 0.143503\n",
      "[1]\tvalid_0's l1: 0.351804\tvalid_0's l2: 0.203828\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.343393\tvalid_0's l2: 0.195206\n",
      "[3]\tvalid_0's l1: 0.33632\tvalid_0's l2: 0.188831\n",
      "[4]\tvalid_0's l1: 0.329707\tvalid_0's l2: 0.183176\n",
      "[5]\tvalid_0's l1: 0.323545\tvalid_0's l2: 0.177894\n",
      "[6]\tvalid_0's l1: 0.318034\tvalid_0's l2: 0.173645\n",
      "[7]\tvalid_0's l1: 0.312893\tvalid_0's l2: 0.169948\n",
      "[8]\tvalid_0's l1: 0.308331\tvalid_0's l2: 0.166644\n",
      "[9]\tvalid_0's l1: 0.304073\tvalid_0's l2: 0.163802\n",
      "[10]\tvalid_0's l1: 0.300057\tvalid_0's l2: 0.160941\n",
      "[11]\tvalid_0's l1: 0.29636\tvalid_0's l2: 0.158369\n",
      "[12]\tvalid_0's l1: 0.292834\tvalid_0's l2: 0.156023\n",
      "[13]\tvalid_0's l1: 0.289635\tvalid_0's l2: 0.154103\n",
      "[14]\tvalid_0's l1: 0.286648\tvalid_0's l2: 0.152316\n",
      "[15]\tvalid_0's l1: 0.283885\tvalid_0's l2: 0.150662\n",
      "[16]\tvalid_0's l1: 0.281145\tvalid_0's l2: 0.148814\n",
      "[17]\tvalid_0's l1: 0.278634\tvalid_0's l2: 0.147461\n",
      "[18]\tvalid_0's l1: 0.276593\tvalid_0's l2: 0.146632\n",
      "[19]\tvalid_0's l1: 0.274473\tvalid_0's l2: 0.145685\n",
      "[20]\tvalid_0's l1: 0.272628\tvalid_0's l2: 0.144799\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.272628\tvalid_0's l2: 0.144799\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.351963\tvalid_0's l2: 0.203895\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3444\tvalid_0's l2: 0.196871\n",
      "[3]\tvalid_0's l1: 0.3373\tvalid_0's l2: 0.190435\n",
      "[4]\tvalid_0's l1: 0.331014\tvalid_0's l2: 0.185144\n",
      "[5]\tvalid_0's l1: 0.324822\tvalid_0's l2: 0.179124\n",
      "[6]\tvalid_0's l1: 0.319248\tvalid_0's l2: 0.174776\n",
      "[7]\tvalid_0's l1: 0.314519\tvalid_0's l2: 0.171363\n",
      "[8]\tvalid_0's l1: 0.30969\tvalid_0's l2: 0.167188\n",
      "[9]\tvalid_0's l1: 0.305714\tvalid_0's l2: 0.16448\n",
      "[10]\tvalid_0's l1: 0.30182\tvalid_0's l2: 0.161332\n",
      "[11]\tvalid_0's l1: 0.298335\tvalid_0's l2: 0.159267\n",
      "[12]\tvalid_0's l1: 0.295243\tvalid_0's l2: 0.15748\n",
      "[13]\tvalid_0's l1: 0.292505\tvalid_0's l2: 0.155966\n",
      "[14]\tvalid_0's l1: 0.289873\tvalid_0's l2: 0.154418\n",
      "[15]\tvalid_0's l1: 0.287495\tvalid_0's l2: 0.152987\n",
      "[16]\tvalid_0's l1: 0.285433\tvalid_0's l2: 0.151845\n",
      "[17]\tvalid_0's l1: 0.28341\tvalid_0's l2: 0.150888\n",
      "[18]\tvalid_0's l1: 0.281549\tvalid_0's l2: 0.15039\n",
      "[19]\tvalid_0's l1: 0.280072\tvalid_0's l2: 0.149815\n",
      "[20]\tvalid_0's l1: 0.2787\tvalid_0's l2: 0.149577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.2787\tvalid_0's l2: 0.149577\n",
      "[1]\tvalid_0's l1: 0.351894\tvalid_0's l2: 0.203818\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.344392\tvalid_0's l2: 0.196686\n",
      "[3]\tvalid_0's l1: 0.337165\tvalid_0's l2: 0.190475\n",
      "[4]\tvalid_0's l1: 0.330133\tvalid_0's l2: 0.183597\n",
      "[5]\tvalid_0's l1: 0.324313\tvalid_0's l2: 0.178696\n",
      "[6]\tvalid_0's l1: 0.318823\tvalid_0's l2: 0.17466\n",
      "[7]\tvalid_0's l1: 0.313893\tvalid_0's l2: 0.171126\n",
      "[8]\tvalid_0's l1: 0.309611\tvalid_0's l2: 0.168176\n",
      "[9]\tvalid_0's l1: 0.305146\tvalid_0's l2: 0.164047\n",
      "[10]\tvalid_0's l1: 0.301594\tvalid_0's l2: 0.161958\n",
      "[11]\tvalid_0's l1: 0.298341\tvalid_0's l2: 0.159646\n",
      "[12]\tvalid_0's l1: 0.295152\tvalid_0's l2: 0.157522\n",
      "[13]\tvalid_0's l1: 0.29246\tvalid_0's l2: 0.155881\n",
      "[14]\tvalid_0's l1: 0.289701\tvalid_0's l2: 0.15419\n",
      "[15]\tvalid_0's l1: 0.287409\tvalid_0's l2: 0.153045\n",
      "[16]\tvalid_0's l1: 0.285122\tvalid_0's l2: 0.151931\n",
      "[17]\tvalid_0's l1: 0.283052\tvalid_0's l2: 0.150998\n",
      "[18]\tvalid_0's l1: 0.281197\tvalid_0's l2: 0.150459\n",
      "[19]\tvalid_0's l1: 0.279633\tvalid_0's l2: 0.149967\n",
      "[20]\tvalid_0's l1: 0.278461\tvalid_0's l2: 0.149581\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.278461\tvalid_0's l2: 0.149581\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.352585\tvalid_0's l2: 0.204817\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345325\tvalid_0's l2: 0.198061\n",
      "[3]\tvalid_0's l1: 0.338691\tvalid_0's l2: 0.192161\n",
      "[4]\tvalid_0's l1: 0.332723\tvalid_0's l2: 0.187228\n",
      "[5]\tvalid_0's l1: 0.327227\tvalid_0's l2: 0.182648\n",
      "[6]\tvalid_0's l1: 0.321966\tvalid_0's l2: 0.177884\n",
      "[7]\tvalid_0's l1: 0.317541\tvalid_0's l2: 0.174856\n",
      "[8]\tvalid_0's l1: 0.313471\tvalid_0's l2: 0.172195\n",
      "[9]\tvalid_0's l1: 0.309775\tvalid_0's l2: 0.169973\n",
      "[10]\tvalid_0's l1: 0.306515\tvalid_0's l2: 0.16799\n",
      "[11]\tvalid_0's l1: 0.303452\tvalid_0's l2: 0.165963\n",
      "[12]\tvalid_0's l1: 0.300698\tvalid_0's l2: 0.163918\n",
      "[13]\tvalid_0's l1: 0.298217\tvalid_0's l2: 0.162467\n",
      "[14]\tvalid_0's l1: 0.295993\tvalid_0's l2: 0.161484\n",
      "[15]\tvalid_0's l1: 0.293833\tvalid_0's l2: 0.160561\n",
      "[16]\tvalid_0's l1: 0.291725\tvalid_0's l2: 0.159779\n",
      "[17]\tvalid_0's l1: 0.289963\tvalid_0's l2: 0.158778\n",
      "[18]\tvalid_0's l1: 0.288423\tvalid_0's l2: 0.158065\n",
      "[19]\tvalid_0's l1: 0.286778\tvalid_0's l2: 0.157507\n",
      "[20]\tvalid_0's l1: 0.28546\tvalid_0's l2: 0.157181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.28546\tvalid_0's l2: 0.157181\n",
      "[1]\tvalid_0's l1: 0.352212\tvalid_0's l2: 0.204596\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345381\tvalid_0's l2: 0.197651\n",
      "[3]\tvalid_0's l1: 0.339205\tvalid_0's l2: 0.19254\n",
      "[4]\tvalid_0's l1: 0.333178\tvalid_0's l2: 0.187657\n",
      "[5]\tvalid_0's l1: 0.327508\tvalid_0's l2: 0.182916\n",
      "[6]\tvalid_0's l1: 0.322037\tvalid_0's l2: 0.177964\n",
      "[7]\tvalid_0's l1: 0.317351\tvalid_0's l2: 0.174715\n",
      "[8]\tvalid_0's l1: 0.313066\tvalid_0's l2: 0.172088\n",
      "[9]\tvalid_0's l1: 0.309277\tvalid_0's l2: 0.169762\n",
      "[10]\tvalid_0's l1: 0.305616\tvalid_0's l2: 0.167464\n",
      "[11]\tvalid_0's l1: 0.302607\tvalid_0's l2: 0.16549\n",
      "[12]\tvalid_0's l1: 0.299971\tvalid_0's l2: 0.16391\n",
      "[13]\tvalid_0's l1: 0.297451\tvalid_0's l2: 0.162427\n",
      "[14]\tvalid_0's l1: 0.2953\tvalid_0's l2: 0.161252\n",
      "[15]\tvalid_0's l1: 0.293191\tvalid_0's l2: 0.160272\n",
      "[16]\tvalid_0's l1: 0.291031\tvalid_0's l2: 0.159463\n",
      "[17]\tvalid_0's l1: 0.289133\tvalid_0's l2: 0.158704\n",
      "[18]\tvalid_0's l1: 0.287487\tvalid_0's l2: 0.158111\n",
      "[19]\tvalid_0's l1: 0.286096\tvalid_0's l2: 0.157771\n",
      "[20]\tvalid_0's l1: 0.28499\tvalid_0's l2: 0.157527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.28499\tvalid_0's l2: 0.157527\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.353057\tvalid_0's l2: 0.205412\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346693\tvalid_0's l2: 0.199976\n",
      "[3]\tvalid_0's l1: 0.340961\tvalid_0's l2: 0.195386\n",
      "[4]\tvalid_0's l1: 0.335083\tvalid_0's l2: 0.189505\n",
      "[5]\tvalid_0's l1: 0.330605\tvalid_0's l2: 0.186145\n",
      "[6]\tvalid_0's l1: 0.326077\tvalid_0's l2: 0.182853\n",
      "[7]\tvalid_0's l1: 0.32207\tvalid_0's l2: 0.180204\n",
      "[8]\tvalid_0's l1: 0.318562\tvalid_0's l2: 0.178101\n",
      "[9]\tvalid_0's l1: 0.3153\tvalid_0's l2: 0.176169\n",
      "[10]\tvalid_0's l1: 0.31232\tvalid_0's l2: 0.174616\n",
      "[11]\tvalid_0's l1: 0.309818\tvalid_0's l2: 0.173128\n",
      "[12]\tvalid_0's l1: 0.307015\tvalid_0's l2: 0.171041\n",
      "[13]\tvalid_0's l1: 0.304576\tvalid_0's l2: 0.169779\n",
      "[14]\tvalid_0's l1: 0.302485\tvalid_0's l2: 0.168786\n",
      "[15]\tvalid_0's l1: 0.300564\tvalid_0's l2: 0.167623\n",
      "[16]\tvalid_0's l1: 0.29876\tvalid_0's l2: 0.166999\n",
      "[17]\tvalid_0's l1: 0.297178\tvalid_0's l2: 0.166186\n",
      "[18]\tvalid_0's l1: 0.29555\tvalid_0's l2: 0.165734\n",
      "[19]\tvalid_0's l1: 0.294415\tvalid_0's l2: 0.165745\n",
      "[20]\tvalid_0's l1: 0.293389\tvalid_0's l2: 0.165755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.293389\tvalid_0's l2: 0.165755\n",
      "[1]\tvalid_0's l1: 0.352923\tvalid_0's l2: 0.205335\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346381\tvalid_0's l2: 0.200044\n",
      "[3]\tvalid_0's l1: 0.339896\tvalid_0's l2: 0.193495\n",
      "[4]\tvalid_0's l1: 0.334461\tvalid_0's l2: 0.189036\n",
      "[5]\tvalid_0's l1: 0.329394\tvalid_0's l2: 0.185077\n",
      "[6]\tvalid_0's l1: 0.32504\tvalid_0's l2: 0.182057\n",
      "[7]\tvalid_0's l1: 0.321192\tvalid_0's l2: 0.179402\n",
      "[8]\tvalid_0's l1: 0.317487\tvalid_0's l2: 0.176987\n",
      "[9]\tvalid_0's l1: 0.314015\tvalid_0's l2: 0.174844\n",
      "[10]\tvalid_0's l1: 0.310857\tvalid_0's l2: 0.172565\n",
      "[11]\tvalid_0's l1: 0.3081\tvalid_0's l2: 0.171144\n",
      "[12]\tvalid_0's l1: 0.305769\tvalid_0's l2: 0.169943\n",
      "[13]\tvalid_0's l1: 0.303799\tvalid_0's l2: 0.168899\n",
      "[14]\tvalid_0's l1: 0.302\tvalid_0's l2: 0.167939\n",
      "[15]\tvalid_0's l1: 0.30003\tvalid_0's l2: 0.167274\n",
      "[16]\tvalid_0's l1: 0.298363\tvalid_0's l2: 0.166776\n",
      "[17]\tvalid_0's l1: 0.296875\tvalid_0's l2: 0.166477\n",
      "[18]\tvalid_0's l1: 0.295604\tvalid_0's l2: 0.166305\n",
      "[19]\tvalid_0's l1: 0.294392\tvalid_0's l2: 0.166258\n",
      "[20]\tvalid_0's l1: 0.293542\tvalid_0's l2: 0.166133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.293542\tvalid_0's l2: 0.166133\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.327153\tvalid_0's l2: 0.172603\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.312918\tvalid_0's l2: 0.15817\n",
      "[3]\tvalid_0's l1: 0.29938\tvalid_0's l2: 0.14506\n",
      "[4]\tvalid_0's l1: 0.286764\tvalid_0's l2: 0.133307\n",
      "[5]\tvalid_0's l1: 0.274892\tvalid_0's l2: 0.122802\n",
      "[6]\tvalid_0's l1: 0.263557\tvalid_0's l2: 0.113228\n",
      "[7]\tvalid_0's l1: 0.252829\tvalid_0's l2: 0.104484\n",
      "[8]\tvalid_0's l1: 0.243006\tvalid_0's l2: 0.096959\n",
      "[9]\tvalid_0's l1: 0.23363\tvalid_0's l2: 0.0900656\n",
      "[10]\tvalid_0's l1: 0.224702\tvalid_0's l2: 0.083571\n",
      "[11]\tvalid_0's l1: 0.21644\tvalid_0's l2: 0.0779209\n",
      "[12]\tvalid_0's l1: 0.208626\tvalid_0's l2: 0.0726958\n",
      "[13]\tvalid_0's l1: 0.201245\tvalid_0's l2: 0.067979\n",
      "[14]\tvalid_0's l1: 0.194496\tvalid_0's l2: 0.0638774\n",
      "[15]\tvalid_0's l1: 0.188056\tvalid_0's l2: 0.0601118\n",
      "[16]\tvalid_0's l1: 0.181939\tvalid_0's l2: 0.0566932\n",
      "[17]\tvalid_0's l1: 0.176368\tvalid_0's l2: 0.0537329\n",
      "[18]\tvalid_0's l1: 0.171232\tvalid_0's l2: 0.0511234\n",
      "[19]\tvalid_0's l1: 0.166384\tvalid_0's l2: 0.0487151\n",
      "[20]\tvalid_0's l1: 0.162677\tvalid_0's l2: 0.0469768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.162677\tvalid_0's l2: 0.0469768\n",
      "[1]\tvalid_0's l1: 0.327126\tvalid_0's l2: 0.172512\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.312848\tvalid_0's l2: 0.157928\n",
      "[3]\tvalid_0's l1: 0.299225\tvalid_0's l2: 0.144669\n",
      "[4]\tvalid_0's l1: 0.286563\tvalid_0's l2: 0.132874\n",
      "[5]\tvalid_0's l1: 0.274529\tvalid_0's l2: 0.122223\n",
      "[6]\tvalid_0's l1: 0.263184\tvalid_0's l2: 0.1127\n",
      "[7]\tvalid_0's l1: 0.252599\tvalid_0's l2: 0.104388\n",
      "[8]\tvalid_0's l1: 0.242517\tvalid_0's l2: 0.0965912\n",
      "[9]\tvalid_0's l1: 0.233127\tvalid_0's l2: 0.0894957\n",
      "[10]\tvalid_0's l1: 0.224246\tvalid_0's l2: 0.0830023\n",
      "[11]\tvalid_0's l1: 0.21602\tvalid_0's l2: 0.0774288\n",
      "[12]\tvalid_0's l1: 0.208277\tvalid_0's l2: 0.0723319\n",
      "[13]\tvalid_0's l1: 0.201026\tvalid_0's l2: 0.0676836\n",
      "[14]\tvalid_0's l1: 0.194184\tvalid_0's l2: 0.0635826\n",
      "[15]\tvalid_0's l1: 0.188721\tvalid_0's l2: 0.060506\n",
      "[16]\tvalid_0's l1: 0.183767\tvalid_0's l2: 0.0578294\n",
      "[17]\tvalid_0's l1: 0.178019\tvalid_0's l2: 0.0547714\n",
      "[18]\tvalid_0's l1: 0.173784\tvalid_0's l2: 0.052699\n",
      "[19]\tvalid_0's l1: 0.168732\tvalid_0's l2: 0.0500922\n",
      "[20]\tvalid_0's l1: 0.164112\tvalid_0's l2: 0.0478403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.164112\tvalid_0's l2: 0.0478403\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.329631\tvalid_0's l2: 0.175751\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.317727\tvalid_0's l2: 0.163842\n",
      "[3]\tvalid_0's l1: 0.308483\tvalid_0's l2: 0.155532\n",
      "[4]\tvalid_0's l1: 0.297943\tvalid_0's l2: 0.145874\n",
      "[5]\tvalid_0's l1: 0.290032\tvalid_0's l2: 0.139455\n",
      "[6]\tvalid_0's l1: 0.280186\tvalid_0's l2: 0.130342\n",
      "[7]\tvalid_0's l1: 0.271355\tvalid_0's l2: 0.123202\n",
      "[8]\tvalid_0's l1: 0.263052\tvalid_0's l2: 0.116556\n",
      "[9]\tvalid_0's l1: 0.255266\tvalid_0's l2: 0.110819\n",
      "[10]\tvalid_0's l1: 0.24802\tvalid_0's l2: 0.105463\n",
      "[11]\tvalid_0's l1: 0.241143\tvalid_0's l2: 0.100578\n",
      "[12]\tvalid_0's l1: 0.234671\tvalid_0's l2: 0.0957938\n",
      "[13]\tvalid_0's l1: 0.230364\tvalid_0's l2: 0.0931493\n",
      "[14]\tvalid_0's l1: 0.226328\tvalid_0's l2: 0.0906978\n",
      "[15]\tvalid_0's l1: 0.221133\tvalid_0's l2: 0.0872387\n",
      "[16]\tvalid_0's l1: 0.21751\tvalid_0's l2: 0.0853356\n",
      "[17]\tvalid_0's l1: 0.212726\tvalid_0's l2: 0.0821081\n",
      "[18]\tvalid_0's l1: 0.208443\tvalid_0's l2: 0.0792396\n",
      "[19]\tvalid_0's l1: 0.204726\tvalid_0's l2: 0.0770637\n",
      "[20]\tvalid_0's l1: 0.201012\tvalid_0's l2: 0.0747086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.201012\tvalid_0's l2: 0.0747086\n",
      "[1]\tvalid_0's l1: 0.329674\tvalid_0's l2: 0.175819\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.319859\tvalid_0's l2: 0.166693\n",
      "[3]\tvalid_0's l1: 0.30788\tvalid_0's l2: 0.154624\n",
      "[4]\tvalid_0's l1: 0.297391\tvalid_0's l2: 0.145018\n",
      "[5]\tvalid_0's l1: 0.287559\tvalid_0's l2: 0.136416\n",
      "[6]\tvalid_0's l1: 0.278168\tvalid_0's l2: 0.128462\n",
      "[7]\tvalid_0's l1: 0.269758\tvalid_0's l2: 0.121777\n",
      "[8]\tvalid_0's l1: 0.261562\tvalid_0's l2: 0.115386\n",
      "[9]\tvalid_0's l1: 0.253967\tvalid_0's l2: 0.109669\n",
      "[10]\tvalid_0's l1: 0.247016\tvalid_0's l2: 0.104456\n",
      "[11]\tvalid_0's l1: 0.240729\tvalid_0's l2: 0.0999749\n",
      "[12]\tvalid_0's l1: 0.234625\tvalid_0's l2: 0.0956191\n",
      "[13]\tvalid_0's l1: 0.229022\tvalid_0's l2: 0.0917959\n",
      "[14]\tvalid_0's l1: 0.223518\tvalid_0's l2: 0.0882687\n",
      "[15]\tvalid_0's l1: 0.218734\tvalid_0's l2: 0.0852015\n",
      "[16]\tvalid_0's l1: 0.214306\tvalid_0's l2: 0.0824891\n",
      "[17]\tvalid_0's l1: 0.210756\tvalid_0's l2: 0.0802561\n",
      "[18]\tvalid_0's l1: 0.206881\tvalid_0's l2: 0.0780165\n",
      "[19]\tvalid_0's l1: 0.204155\tvalid_0's l2: 0.076597\n",
      "[20]\tvalid_0's l1: 0.200835\tvalid_0's l2: 0.0748258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.200835\tvalid_0's l2: 0.0748258\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.33224\tvalid_0's l2: 0.179115\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32253\tvalid_0's l2: 0.169943\n",
      "[3]\tvalid_0's l1: 0.3152\tvalid_0's l2: 0.16363\n",
      "[4]\tvalid_0's l1: 0.308291\tvalid_0's l2: 0.157971\n",
      "[5]\tvalid_0's l1: 0.301999\tvalid_0's l2: 0.152962\n",
      "[6]\tvalid_0's l1: 0.294848\tvalid_0's l2: 0.147057\n",
      "[7]\tvalid_0's l1: 0.287007\tvalid_0's l2: 0.139743\n",
      "[8]\tvalid_0's l1: 0.282359\tvalid_0's l2: 0.136572\n",
      "[9]\tvalid_0's l1: 0.275515\tvalid_0's l2: 0.130538\n",
      "[10]\tvalid_0's l1: 0.269764\tvalid_0's l2: 0.126636\n",
      "[11]\tvalid_0's l1: 0.264458\tvalid_0's l2: 0.122772\n",
      "[12]\tvalid_0's l1: 0.25956\tvalid_0's l2: 0.11927\n",
      "[13]\tvalid_0's l1: 0.254816\tvalid_0's l2: 0.115957\n",
      "[14]\tvalid_0's l1: 0.250516\tvalid_0's l2: 0.113025\n",
      "[15]\tvalid_0's l1: 0.246555\tvalid_0's l2: 0.110649\n",
      "[16]\tvalid_0's l1: 0.242771\tvalid_0's l2: 0.108377\n",
      "[17]\tvalid_0's l1: 0.239472\tvalid_0's l2: 0.106443\n",
      "[18]\tvalid_0's l1: 0.236842\tvalid_0's l2: 0.105106\n",
      "[19]\tvalid_0's l1: 0.234359\tvalid_0's l2: 0.103898\n",
      "[20]\tvalid_0's l1: 0.231981\tvalid_0's l2: 0.102652\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.231981\tvalid_0's l2: 0.102652\n",
      "[1]\tvalid_0's l1: 0.332258\tvalid_0's l2: 0.17914\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.323614\tvalid_0's l2: 0.170563\n",
      "[3]\tvalid_0's l1: 0.31659\tvalid_0's l2: 0.164903\n",
      "[4]\tvalid_0's l1: 0.308375\tvalid_0's l2: 0.157841\n",
      "[5]\tvalid_0's l1: 0.300321\tvalid_0's l2: 0.150842\n",
      "[6]\tvalid_0's l1: 0.292955\tvalid_0's l2: 0.144697\n",
      "[7]\tvalid_0's l1: 0.287625\tvalid_0's l2: 0.140977\n",
      "[8]\tvalid_0's l1: 0.280952\tvalid_0's l2: 0.135733\n",
      "[9]\tvalid_0's l1: 0.274971\tvalid_0's l2: 0.131426\n",
      "[10]\tvalid_0's l1: 0.269539\tvalid_0's l2: 0.127611\n",
      "[11]\tvalid_0's l1: 0.264284\tvalid_0's l2: 0.123649\n",
      "[12]\tvalid_0's l1: 0.259355\tvalid_0's l2: 0.120181\n",
      "[13]\tvalid_0's l1: 0.254616\tvalid_0's l2: 0.116782\n",
      "[14]\tvalid_0's l1: 0.250514\tvalid_0's l2: 0.114005\n",
      "[15]\tvalid_0's l1: 0.246664\tvalid_0's l2: 0.111527\n",
      "[16]\tvalid_0's l1: 0.243048\tvalid_0's l2: 0.109363\n",
      "[17]\tvalid_0's l1: 0.239977\tvalid_0's l2: 0.107594\n",
      "[18]\tvalid_0's l1: 0.23787\tvalid_0's l2: 0.106714\n",
      "[19]\tvalid_0's l1: 0.235111\tvalid_0's l2: 0.105101\n",
      "[20]\tvalid_0's l1: 0.232659\tvalid_0's l2: 0.103689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.232659\tvalid_0's l2: 0.103689\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.333724\tvalid_0's l2: 0.180871\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32596\tvalid_0's l2: 0.17389\n",
      "[3]\tvalid_0's l1: 0.318707\tvalid_0's l2: 0.167647\n",
      "[4]\tvalid_0's l1: 0.311975\tvalid_0's l2: 0.162061\n",
      "[5]\tvalid_0's l1: 0.305323\tvalid_0's l2: 0.156126\n",
      "[6]\tvalid_0's l1: 0.299977\tvalid_0's l2: 0.151949\n",
      "[7]\tvalid_0's l1: 0.295139\tvalid_0's l2: 0.148508\n",
      "[8]\tvalid_0's l1: 0.290225\tvalid_0's l2: 0.144445\n",
      "[9]\tvalid_0's l1: 0.285916\tvalid_0's l2: 0.141787\n",
      "[10]\tvalid_0's l1: 0.281876\tvalid_0's l2: 0.138722\n",
      "[11]\tvalid_0's l1: 0.278159\tvalid_0's l2: 0.136487\n",
      "[12]\tvalid_0's l1: 0.274749\tvalid_0's l2: 0.134573\n",
      "[13]\tvalid_0's l1: 0.271903\tvalid_0's l2: 0.133076\n",
      "[14]\tvalid_0's l1: 0.269291\tvalid_0's l2: 0.131702\n",
      "[15]\tvalid_0's l1: 0.266761\tvalid_0's l2: 0.130156\n",
      "[16]\tvalid_0's l1: 0.264524\tvalid_0's l2: 0.128775\n",
      "[17]\tvalid_0's l1: 0.262546\tvalid_0's l2: 0.128187\n",
      "[18]\tvalid_0's l1: 0.260675\tvalid_0's l2: 0.127493\n",
      "[19]\tvalid_0's l1: 0.259281\tvalid_0's l2: 0.126846\n",
      "[20]\tvalid_0's l1: 0.257774\tvalid_0's l2: 0.126438\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.257774\tvalid_0's l2: 0.126438\n",
      "[1]\tvalid_0's l1: 0.333847\tvalid_0's l2: 0.181268\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326188\tvalid_0's l2: 0.174545\n",
      "[3]\tvalid_0's l1: 0.318794\tvalid_0's l2: 0.168305\n",
      "[4]\tvalid_0's l1: 0.311527\tvalid_0's l2: 0.161642\n",
      "[5]\tvalid_0's l1: 0.305598\tvalid_0's l2: 0.156755\n",
      "[6]\tvalid_0's l1: 0.299939\tvalid_0's l2: 0.152319\n",
      "[7]\tvalid_0's l1: 0.294914\tvalid_0's l2: 0.148784\n",
      "[8]\tvalid_0's l1: 0.29023\tvalid_0's l2: 0.145322\n",
      "[9]\tvalid_0's l1: 0.285741\tvalid_0's l2: 0.141691\n",
      "[10]\tvalid_0's l1: 0.281694\tvalid_0's l2: 0.139059\n",
      "[11]\tvalid_0's l1: 0.278132\tvalid_0's l2: 0.136931\n",
      "[12]\tvalid_0's l1: 0.274815\tvalid_0's l2: 0.134987\n",
      "[13]\tvalid_0's l1: 0.272025\tvalid_0's l2: 0.133408\n",
      "[14]\tvalid_0's l1: 0.269481\tvalid_0's l2: 0.132106\n",
      "[15]\tvalid_0's l1: 0.267052\tvalid_0's l2: 0.131101\n",
      "[16]\tvalid_0's l1: 0.264599\tvalid_0's l2: 0.1298\n",
      "[17]\tvalid_0's l1: 0.262548\tvalid_0's l2: 0.128802\n",
      "[18]\tvalid_0's l1: 0.260922\tvalid_0's l2: 0.128143\n",
      "[19]\tvalid_0's l1: 0.259275\tvalid_0's l2: 0.127691\n",
      "[20]\tvalid_0's l1: 0.257613\tvalid_0's l2: 0.126925\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.257613\tvalid_0's l2: 0.126925\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334155\tvalid_0's l2: 0.181215\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326583\tvalid_0's l2: 0.17426\n",
      "[3]\tvalid_0's l1: 0.319686\tvalid_0's l2: 0.168424\n",
      "[4]\tvalid_0's l1: 0.313272\tvalid_0's l2: 0.163224\n",
      "[5]\tvalid_0's l1: 0.307278\tvalid_0's l2: 0.158577\n",
      "[6]\tvalid_0's l1: 0.301653\tvalid_0's l2: 0.153875\n",
      "[7]\tvalid_0's l1: 0.296909\tvalid_0's l2: 0.150536\n",
      "[8]\tvalid_0's l1: 0.292521\tvalid_0's l2: 0.147661\n",
      "[9]\tvalid_0's l1: 0.288715\tvalid_0's l2: 0.145501\n",
      "[10]\tvalid_0's l1: 0.285247\tvalid_0's l2: 0.143461\n",
      "[11]\tvalid_0's l1: 0.282055\tvalid_0's l2: 0.141512\n",
      "[12]\tvalid_0's l1: 0.279035\tvalid_0's l2: 0.139583\n",
      "[13]\tvalid_0's l1: 0.276466\tvalid_0's l2: 0.138272\n",
      "[14]\tvalid_0's l1: 0.274074\tvalid_0's l2: 0.137225\n",
      "[15]\tvalid_0's l1: 0.271953\tvalid_0's l2: 0.136185\n",
      "[16]\tvalid_0's l1: 0.269958\tvalid_0's l2: 0.135321\n",
      "[17]\tvalid_0's l1: 0.268157\tvalid_0's l2: 0.134457\n",
      "[18]\tvalid_0's l1: 0.266638\tvalid_0's l2: 0.133816\n",
      "[19]\tvalid_0's l1: 0.265029\tvalid_0's l2: 0.133441\n",
      "[20]\tvalid_0's l1: 0.263892\tvalid_0's l2: 0.133278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.263892\tvalid_0's l2: 0.133278\n",
      "[1]\tvalid_0's l1: 0.333721\tvalid_0's l2: 0.18067\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.325697\tvalid_0's l2: 0.172181\n",
      "[3]\tvalid_0's l1: 0.319171\tvalid_0's l2: 0.16707\n",
      "[4]\tvalid_0's l1: 0.312423\tvalid_0's l2: 0.161502\n",
      "[5]\tvalid_0's l1: 0.306341\tvalid_0's l2: 0.156721\n",
      "[6]\tvalid_0's l1: 0.300942\tvalid_0's l2: 0.151954\n",
      "[7]\tvalid_0's l1: 0.296116\tvalid_0's l2: 0.148661\n",
      "[8]\tvalid_0's l1: 0.291754\tvalid_0's l2: 0.145918\n",
      "[9]\tvalid_0's l1: 0.288102\tvalid_0's l2: 0.143713\n",
      "[10]\tvalid_0's l1: 0.284316\tvalid_0's l2: 0.141188\n",
      "[11]\tvalid_0's l1: 0.281058\tvalid_0's l2: 0.13912\n",
      "[12]\tvalid_0's l1: 0.278294\tvalid_0's l2: 0.137701\n",
      "[13]\tvalid_0's l1: 0.275787\tvalid_0's l2: 0.136235\n",
      "[14]\tvalid_0's l1: 0.273517\tvalid_0's l2: 0.135124\n",
      "[15]\tvalid_0's l1: 0.271335\tvalid_0's l2: 0.134063\n",
      "[16]\tvalid_0's l1: 0.269459\tvalid_0's l2: 0.133426\n",
      "[17]\tvalid_0's l1: 0.26787\tvalid_0's l2: 0.133121\n",
      "[18]\tvalid_0's l1: 0.266347\tvalid_0's l2: 0.132776\n",
      "[19]\tvalid_0's l1: 0.265082\tvalid_0's l2: 0.132698\n",
      "[20]\tvalid_0's l1: 0.26381\tvalid_0's l2: 0.132708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.26381\tvalid_0's l2: 0.132708\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334587\tvalid_0's l2: 0.181708\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327962\tvalid_0's l2: 0.176094\n",
      "[3]\tvalid_0's l1: 0.321765\tvalid_0's l2: 0.17127\n",
      "[4]\tvalid_0's l1: 0.315262\tvalid_0's l2: 0.165242\n",
      "[5]\tvalid_0's l1: 0.310152\tvalid_0's l2: 0.161539\n",
      "[6]\tvalid_0's l1: 0.305085\tvalid_0's l2: 0.158066\n",
      "[7]\tvalid_0's l1: 0.300564\tvalid_0's l2: 0.155043\n",
      "[8]\tvalid_0's l1: 0.296826\tvalid_0's l2: 0.152756\n",
      "[9]\tvalid_0's l1: 0.293365\tvalid_0's l2: 0.150824\n",
      "[10]\tvalid_0's l1: 0.290326\tvalid_0's l2: 0.149301\n",
      "[11]\tvalid_0's l1: 0.287726\tvalid_0's l2: 0.147981\n",
      "[12]\tvalid_0's l1: 0.284785\tvalid_0's l2: 0.146064\n",
      "[13]\tvalid_0's l1: 0.282229\tvalid_0's l2: 0.144966\n",
      "[14]\tvalid_0's l1: 0.27997\tvalid_0's l2: 0.144007\n",
      "[15]\tvalid_0's l1: 0.277948\tvalid_0's l2: 0.143047\n",
      "[16]\tvalid_0's l1: 0.27621\tvalid_0's l2: 0.142621\n",
      "[17]\tvalid_0's l1: 0.27484\tvalid_0's l2: 0.142078\n",
      "[18]\tvalid_0's l1: 0.27321\tvalid_0's l2: 0.141684\n",
      "[19]\tvalid_0's l1: 0.272128\tvalid_0's l2: 0.141803\n",
      "[20]\tvalid_0's l1: 0.271199\tvalid_0's l2: 0.141942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.271199\tvalid_0's l2: 0.141942\n",
      "[1]\tvalid_0's l1: 0.334486\tvalid_0's l2: 0.181731\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327466\tvalid_0's l2: 0.176003\n",
      "[3]\tvalid_0's l1: 0.320009\tvalid_0's l2: 0.168267\n",
      "[4]\tvalid_0's l1: 0.314079\tvalid_0's l2: 0.163762\n",
      "[5]\tvalid_0's l1: 0.308628\tvalid_0's l2: 0.159906\n",
      "[6]\tvalid_0's l1: 0.303673\tvalid_0's l2: 0.156567\n",
      "[7]\tvalid_0's l1: 0.299207\tvalid_0's l2: 0.153731\n",
      "[8]\tvalid_0's l1: 0.295179\tvalid_0's l2: 0.151118\n",
      "[9]\tvalid_0's l1: 0.291719\tvalid_0's l2: 0.149114\n",
      "[10]\tvalid_0's l1: 0.288317\tvalid_0's l2: 0.146821\n",
      "[11]\tvalid_0's l1: 0.285286\tvalid_0's l2: 0.145385\n",
      "[12]\tvalid_0's l1: 0.282585\tvalid_0's l2: 0.14392\n",
      "[13]\tvalid_0's l1: 0.280461\tvalid_0's l2: 0.142905\n",
      "[14]\tvalid_0's l1: 0.278516\tvalid_0's l2: 0.141986\n",
      "[15]\tvalid_0's l1: 0.2769\tvalid_0's l2: 0.14162\n",
      "[16]\tvalid_0's l1: 0.275439\tvalid_0's l2: 0.141299\n",
      "[17]\tvalid_0's l1: 0.274089\tvalid_0's l2: 0.141068\n",
      "[18]\tvalid_0's l1: 0.272894\tvalid_0's l2: 0.140999\n",
      "[19]\tvalid_0's l1: 0.271616\tvalid_0's l2: 0.140815\n",
      "[20]\tvalid_0's l1: 0.270821\tvalid_0's l2: 0.14111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.270821\tvalid_0's l2: 0.14111\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_total_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        x_train_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        x_train_withCD = df_train_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        x_test_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        x_test_withCD = df_test_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # y: response (target) variable DFma_1 [col 12]\n",
    "        y_train = df_train_subdist.iloc[:, [12]]\n",
    "        y_test = df_test_subdist.iloc[:, [12]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_subdist['DFma_1'])\n",
    "        y_test_true = np.array(df_test_subdist['DFma_1'])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' \n",
    "                                                  + str(i) + '_horizon_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' \n",
    "                                               + str(i) + '_horizon_' + str(j + 1) + '_withCD_' + str(num_leaves) + '.csv', \n",
    "                                               encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_BySubDistrict_MA' + str(i) + '_horizon_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_subdist_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, adjusted CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.449625\tvalid_0's l2: 0.367072\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.442645\tvalid_0's l2: 0.359194\n",
      "[3]\tvalid_0's l1: 0.436086\tvalid_0's l2: 0.352044\n",
      "[4]\tvalid_0's l1: 0.430176\tvalid_0's l2: 0.345791\n",
      "[5]\tvalid_0's l1: 0.424605\tvalid_0's l2: 0.34018\n",
      "[6]\tvalid_0's l1: 0.419093\tvalid_0's l2: 0.335408\n",
      "[7]\tvalid_0's l1: 0.41378\tvalid_0's l2: 0.329977\n",
      "[8]\tvalid_0's l1: 0.408962\tvalid_0's l2: 0.325856\n",
      "[9]\tvalid_0's l1: 0.404733\tvalid_0's l2: 0.3226\n",
      "[10]\tvalid_0's l1: 0.400382\tvalid_0's l2: 0.318656\n",
      "[11]\tvalid_0's l1: 0.396557\tvalid_0's l2: 0.315551\n",
      "[12]\tvalid_0's l1: 0.392996\tvalid_0's l2: 0.313066\n",
      "[13]\tvalid_0's l1: 0.38963\tvalid_0's l2: 0.310503\n",
      "[14]\tvalid_0's l1: 0.386476\tvalid_0's l2: 0.308327\n",
      "[15]\tvalid_0's l1: 0.383571\tvalid_0's l2: 0.306385\n",
      "[16]\tvalid_0's l1: 0.380883\tvalid_0's l2: 0.304371\n",
      "[17]\tvalid_0's l1: 0.378166\tvalid_0's l2: 0.302887\n",
      "[18]\tvalid_0's l1: 0.375897\tvalid_0's l2: 0.30183\n",
      "[19]\tvalid_0's l1: 0.373708\tvalid_0's l2: 0.301119\n",
      "[20]\tvalid_0's l1: 0.371435\tvalid_0's l2: 0.299773\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.371435\tvalid_0's l2: 0.299773\n",
      "[1]\tvalid_0's l1: 0.449616\tvalid_0's l2: 0.367128\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.442637\tvalid_0's l2: 0.359136\n",
      "[3]\tvalid_0's l1: 0.436193\tvalid_0's l2: 0.352119\n",
      "[4]\tvalid_0's l1: 0.430033\tvalid_0's l2: 0.346032\n",
      "[5]\tvalid_0's l1: 0.424328\tvalid_0's l2: 0.340468\n",
      "[6]\tvalid_0's l1: 0.419003\tvalid_0's l2: 0.335705\n",
      "[7]\tvalid_0's l1: 0.413824\tvalid_0's l2: 0.331241\n",
      "[8]\tvalid_0's l1: 0.409117\tvalid_0's l2: 0.327373\n",
      "[9]\tvalid_0's l1: 0.404634\tvalid_0's l2: 0.323654\n",
      "[10]\tvalid_0's l1: 0.400494\tvalid_0's l2: 0.320485\n",
      "[11]\tvalid_0's l1: 0.396747\tvalid_0's l2: 0.317588\n",
      "[12]\tvalid_0's l1: 0.393253\tvalid_0's l2: 0.314968\n",
      "[13]\tvalid_0's l1: 0.390083\tvalid_0's l2: 0.312303\n",
      "[14]\tvalid_0's l1: 0.386852\tvalid_0's l2: 0.310022\n",
      "[15]\tvalid_0's l1: 0.384017\tvalid_0's l2: 0.308106\n",
      "[16]\tvalid_0's l1: 0.381319\tvalid_0's l2: 0.306244\n",
      "[17]\tvalid_0's l1: 0.378854\tvalid_0's l2: 0.30463\n",
      "[18]\tvalid_0's l1: 0.37637\tvalid_0's l2: 0.303189\n",
      "[19]\tvalid_0's l1: 0.37418\tvalid_0's l2: 0.301733\n",
      "[20]\tvalid_0's l1: 0.372046\tvalid_0's l2: 0.300638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.372046\tvalid_0's l2: 0.300638\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45032\tvalid_0's l2: 0.368633\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444011\tvalid_0's l2: 0.362207\n",
      "[3]\tvalid_0's l1: 0.438039\tvalid_0's l2: 0.355996\n",
      "[4]\tvalid_0's l1: 0.432437\tvalid_0's l2: 0.350367\n",
      "[5]\tvalid_0's l1: 0.427649\tvalid_0's l2: 0.346089\n",
      "[6]\tvalid_0's l1: 0.42255\tvalid_0's l2: 0.34065\n",
      "[7]\tvalid_0's l1: 0.418029\tvalid_0's l2: 0.336699\n",
      "[8]\tvalid_0's l1: 0.4138\tvalid_0's l2: 0.333159\n",
      "[9]\tvalid_0's l1: 0.40977\tvalid_0's l2: 0.329987\n",
      "[10]\tvalid_0's l1: 0.405933\tvalid_0's l2: 0.327236\n",
      "[11]\tvalid_0's l1: 0.402465\tvalid_0's l2: 0.324637\n",
      "[12]\tvalid_0's l1: 0.399438\tvalid_0's l2: 0.32157\n",
      "[13]\tvalid_0's l1: 0.396388\tvalid_0's l2: 0.319382\n",
      "[14]\tvalid_0's l1: 0.393638\tvalid_0's l2: 0.317174\n",
      "[15]\tvalid_0's l1: 0.391099\tvalid_0's l2: 0.315642\n",
      "[16]\tvalid_0's l1: 0.388552\tvalid_0's l2: 0.314283\n",
      "[17]\tvalid_0's l1: 0.386312\tvalid_0's l2: 0.312405\n",
      "[18]\tvalid_0's l1: 0.384189\tvalid_0's l2: 0.310925\n",
      "[19]\tvalid_0's l1: 0.382168\tvalid_0's l2: 0.309903\n",
      "[20]\tvalid_0's l1: 0.380424\tvalid_0's l2: 0.309123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.380424\tvalid_0's l2: 0.309123\n",
      "[1]\tvalid_0's l1: 0.450455\tvalid_0's l2: 0.369094\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444402\tvalid_0's l2: 0.363055\n",
      "[3]\tvalid_0's l1: 0.438197\tvalid_0's l2: 0.355354\n",
      "[4]\tvalid_0's l1: 0.43262\tvalid_0's l2: 0.350041\n",
      "[5]\tvalid_0's l1: 0.427279\tvalid_0's l2: 0.344951\n",
      "[6]\tvalid_0's l1: 0.422433\tvalid_0's l2: 0.340599\n",
      "[7]\tvalid_0's l1: 0.417739\tvalid_0's l2: 0.336573\n",
      "[8]\tvalid_0's l1: 0.413735\tvalid_0's l2: 0.33337\n",
      "[9]\tvalid_0's l1: 0.409836\tvalid_0's l2: 0.33049\n",
      "[10]\tvalid_0's l1: 0.406202\tvalid_0's l2: 0.327973\n",
      "[11]\tvalid_0's l1: 0.402781\tvalid_0's l2: 0.325568\n",
      "[12]\tvalid_0's l1: 0.39941\tvalid_0's l2: 0.323136\n",
      "[13]\tvalid_0's l1: 0.396234\tvalid_0's l2: 0.320959\n",
      "[14]\tvalid_0's l1: 0.393391\tvalid_0's l2: 0.318921\n",
      "[15]\tvalid_0's l1: 0.390751\tvalid_0's l2: 0.317229\n",
      "[16]\tvalid_0's l1: 0.388216\tvalid_0's l2: 0.315519\n",
      "[17]\tvalid_0's l1: 0.386031\tvalid_0's l2: 0.313814\n",
      "[18]\tvalid_0's l1: 0.383738\tvalid_0's l2: 0.312281\n",
      "[19]\tvalid_0's l1: 0.381706\tvalid_0's l2: 0.311717\n",
      "[20]\tvalid_0's l1: 0.379617\tvalid_0's l2: 0.310375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.379617\tvalid_0's l2: 0.310375\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.450251\tvalid_0's l2: 0.368617\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.443955\tvalid_0's l2: 0.36224\n",
      "[3]\tvalid_0's l1: 0.438345\tvalid_0's l2: 0.35677\n",
      "[4]\tvalid_0's l1: 0.43299\tvalid_0's l2: 0.351986\n",
      "[5]\tvalid_0's l1: 0.42831\tvalid_0's l2: 0.347742\n",
      "[6]\tvalid_0's l1: 0.423332\tvalid_0's l2: 0.343586\n",
      "[7]\tvalid_0's l1: 0.418735\tvalid_0's l2: 0.338873\n",
      "[8]\tvalid_0's l1: 0.41448\tvalid_0's l2: 0.3357\n",
      "[9]\tvalid_0's l1: 0.4106\tvalid_0's l2: 0.331793\n",
      "[10]\tvalid_0's l1: 0.406997\tvalid_0's l2: 0.329611\n",
      "[11]\tvalid_0's l1: 0.40389\tvalid_0's l2: 0.327389\n",
      "[12]\tvalid_0's l1: 0.400826\tvalid_0's l2: 0.325171\n",
      "[13]\tvalid_0's l1: 0.397873\tvalid_0's l2: 0.323164\n",
      "[14]\tvalid_0's l1: 0.395317\tvalid_0's l2: 0.32158\n",
      "[15]\tvalid_0's l1: 0.39264\tvalid_0's l2: 0.319691\n",
      "[16]\tvalid_0's l1: 0.390334\tvalid_0's l2: 0.318371\n",
      "[17]\tvalid_0's l1: 0.388104\tvalid_0's l2: 0.317391\n",
      "[18]\tvalid_0's l1: 0.385859\tvalid_0's l2: 0.316471\n",
      "[19]\tvalid_0's l1: 0.38352\tvalid_0's l2: 0.315519\n",
      "[20]\tvalid_0's l1: 0.381868\tvalid_0's l2: 0.314834\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.381868\tvalid_0's l2: 0.314834\n",
      "[1]\tvalid_0's l1: 0.450289\tvalid_0's l2: 0.368893\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444259\tvalid_0's l2: 0.361418\n",
      "[3]\tvalid_0's l1: 0.438963\tvalid_0's l2: 0.356627\n",
      "[4]\tvalid_0's l1: 0.433514\tvalid_0's l2: 0.351658\n",
      "[5]\tvalid_0's l1: 0.428439\tvalid_0's l2: 0.347422\n",
      "[6]\tvalid_0's l1: 0.423335\tvalid_0's l2: 0.34316\n",
      "[7]\tvalid_0's l1: 0.41861\tvalid_0's l2: 0.339233\n",
      "[8]\tvalid_0's l1: 0.414316\tvalid_0's l2: 0.336073\n",
      "[9]\tvalid_0's l1: 0.410423\tvalid_0's l2: 0.333426\n",
      "[10]\tvalid_0's l1: 0.40698\tvalid_0's l2: 0.331348\n",
      "[11]\tvalid_0's l1: 0.403822\tvalid_0's l2: 0.328945\n",
      "[12]\tvalid_0's l1: 0.401027\tvalid_0's l2: 0.32702\n",
      "[13]\tvalid_0's l1: 0.398217\tvalid_0's l2: 0.324954\n",
      "[14]\tvalid_0's l1: 0.395762\tvalid_0's l2: 0.323569\n",
      "[15]\tvalid_0's l1: 0.393377\tvalid_0's l2: 0.321941\n",
      "[16]\tvalid_0's l1: 0.390944\tvalid_0's l2: 0.32055\n",
      "[17]\tvalid_0's l1: 0.388761\tvalid_0's l2: 0.319388\n",
      "[18]\tvalid_0's l1: 0.38678\tvalid_0's l2: 0.318549\n",
      "[19]\tvalid_0's l1: 0.385045\tvalid_0's l2: 0.317778\n",
      "[20]\tvalid_0's l1: 0.383503\tvalid_0's l2: 0.317275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.383503\tvalid_0's l2: 0.317275\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.450812\tvalid_0's l2: 0.36954\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445132\tvalid_0's l2: 0.364018\n",
      "[3]\tvalid_0's l1: 0.439441\tvalid_0's l2: 0.35859\n",
      "[4]\tvalid_0's l1: 0.434749\tvalid_0's l2: 0.35447\n",
      "[5]\tvalid_0's l1: 0.430019\tvalid_0's l2: 0.348672\n",
      "[6]\tvalid_0's l1: 0.425211\tvalid_0's l2: 0.344771\n",
      "[7]\tvalid_0's l1: 0.420855\tvalid_0's l2: 0.341476\n",
      "[8]\tvalid_0's l1: 0.417042\tvalid_0's l2: 0.33709\n",
      "[9]\tvalid_0's l1: 0.413314\tvalid_0's l2: 0.33464\n",
      "[10]\tvalid_0's l1: 0.410043\tvalid_0's l2: 0.331213\n",
      "[11]\tvalid_0's l1: 0.406998\tvalid_0's l2: 0.329088\n",
      "[12]\tvalid_0's l1: 0.404175\tvalid_0's l2: 0.327276\n",
      "[13]\tvalid_0's l1: 0.401693\tvalid_0's l2: 0.326053\n",
      "[14]\tvalid_0's l1: 0.399307\tvalid_0's l2: 0.324401\n",
      "[15]\tvalid_0's l1: 0.396967\tvalid_0's l2: 0.32266\n",
      "[16]\tvalid_0's l1: 0.394864\tvalid_0's l2: 0.32112\n",
      "[17]\tvalid_0's l1: 0.392823\tvalid_0's l2: 0.320193\n",
      "[18]\tvalid_0's l1: 0.390709\tvalid_0's l2: 0.319222\n",
      "[19]\tvalid_0's l1: 0.389059\tvalid_0's l2: 0.318255\n",
      "[20]\tvalid_0's l1: 0.387266\tvalid_0's l2: 0.317452\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.387266\tvalid_0's l2: 0.317452\n",
      "[1]\tvalid_0's l1: 0.451026\tvalid_0's l2: 0.369838\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445711\tvalid_0's l2: 0.365042\n",
      "[3]\tvalid_0's l1: 0.440335\tvalid_0's l2: 0.360352\n",
      "[4]\tvalid_0's l1: 0.435269\tvalid_0's l2: 0.35426\n",
      "[5]\tvalid_0's l1: 0.430504\tvalid_0's l2: 0.350286\n",
      "[6]\tvalid_0's l1: 0.425561\tvalid_0's l2: 0.34607\n",
      "[7]\tvalid_0's l1: 0.421236\tvalid_0's l2: 0.343115\n",
      "[8]\tvalid_0's l1: 0.417393\tvalid_0's l2: 0.339964\n",
      "[9]\tvalid_0's l1: 0.4143\tvalid_0's l2: 0.336744\n",
      "[10]\tvalid_0's l1: 0.411041\tvalid_0's l2: 0.334181\n",
      "[11]\tvalid_0's l1: 0.408211\tvalid_0's l2: 0.332393\n",
      "[12]\tvalid_0's l1: 0.405691\tvalid_0's l2: 0.33104\n",
      "[13]\tvalid_0's l1: 0.403132\tvalid_0's l2: 0.329675\n",
      "[14]\tvalid_0's l1: 0.400736\tvalid_0's l2: 0.32848\n",
      "[15]\tvalid_0's l1: 0.398577\tvalid_0's l2: 0.327219\n",
      "[16]\tvalid_0's l1: 0.39628\tvalid_0's l2: 0.3257\n",
      "[17]\tvalid_0's l1: 0.394123\tvalid_0's l2: 0.324338\n",
      "[18]\tvalid_0's l1: 0.392195\tvalid_0's l2: 0.323296\n",
      "[19]\tvalid_0's l1: 0.390329\tvalid_0's l2: 0.322575\n",
      "[20]\tvalid_0's l1: 0.388799\tvalid_0's l2: 0.321923\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.388799\tvalid_0's l2: 0.321923\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45101\tvalid_0's l2: 0.369932\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445455\tvalid_0's l2: 0.364613\n",
      "[3]\tvalid_0's l1: 0.440183\tvalid_0's l2: 0.360025\n",
      "[4]\tvalid_0's l1: 0.435265\tvalid_0's l2: 0.35576\n",
      "[5]\tvalid_0's l1: 0.430862\tvalid_0's l2: 0.352298\n",
      "[6]\tvalid_0's l1: 0.426884\tvalid_0's l2: 0.347885\n",
      "[7]\tvalid_0's l1: 0.422948\tvalid_0's l2: 0.344929\n",
      "[8]\tvalid_0's l1: 0.419197\tvalid_0's l2: 0.342197\n",
      "[9]\tvalid_0's l1: 0.416078\tvalid_0's l2: 0.340121\n",
      "[10]\tvalid_0's l1: 0.412905\tvalid_0's l2: 0.338285\n",
      "[11]\tvalid_0's l1: 0.410211\tvalid_0's l2: 0.336813\n",
      "[12]\tvalid_0's l1: 0.407508\tvalid_0's l2: 0.334721\n",
      "[13]\tvalid_0's l1: 0.40511\tvalid_0's l2: 0.333409\n",
      "[14]\tvalid_0's l1: 0.402822\tvalid_0's l2: 0.332436\n",
      "[15]\tvalid_0's l1: 0.400737\tvalid_0's l2: 0.331206\n",
      "[16]\tvalid_0's l1: 0.398657\tvalid_0's l2: 0.330421\n",
      "[17]\tvalid_0's l1: 0.397095\tvalid_0's l2: 0.329786\n",
      "[18]\tvalid_0's l1: 0.395739\tvalid_0's l2: 0.329351\n",
      "[19]\tvalid_0's l1: 0.394095\tvalid_0's l2: 0.328949\n",
      "[20]\tvalid_0's l1: 0.392692\tvalid_0's l2: 0.328397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.392692\tvalid_0's l2: 0.328397\n",
      "[1]\tvalid_0's l1: 0.45101\tvalid_0's l2: 0.369675\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.446407\tvalid_0's l2: 0.364285\n",
      "[3]\tvalid_0's l1: 0.441774\tvalid_0's l2: 0.359879\n",
      "[4]\tvalid_0's l1: 0.43658\tvalid_0's l2: 0.355333\n",
      "[5]\tvalid_0's l1: 0.431752\tvalid_0's l2: 0.351258\n",
      "[6]\tvalid_0's l1: 0.427904\tvalid_0's l2: 0.34702\n",
      "[7]\tvalid_0's l1: 0.423693\tvalid_0's l2: 0.343836\n",
      "[8]\tvalid_0's l1: 0.41989\tvalid_0's l2: 0.341217\n",
      "[9]\tvalid_0's l1: 0.416399\tvalid_0's l2: 0.33918\n",
      "[10]\tvalid_0's l1: 0.413162\tvalid_0's l2: 0.337246\n",
      "[11]\tvalid_0's l1: 0.410527\tvalid_0's l2: 0.335645\n",
      "[12]\tvalid_0's l1: 0.408317\tvalid_0's l2: 0.33425\n",
      "[13]\tvalid_0's l1: 0.406307\tvalid_0's l2: 0.333142\n",
      "[14]\tvalid_0's l1: 0.404106\tvalid_0's l2: 0.332095\n",
      "[15]\tvalid_0's l1: 0.402122\tvalid_0's l2: 0.331467\n",
      "[16]\tvalid_0's l1: 0.400056\tvalid_0's l2: 0.330349\n",
      "[17]\tvalid_0's l1: 0.398191\tvalid_0's l2: 0.329799\n",
      "[18]\tvalid_0's l1: 0.396383\tvalid_0's l2: 0.329197\n",
      "[19]\tvalid_0's l1: 0.394902\tvalid_0's l2: 0.328657\n",
      "[20]\tvalid_0's l1: 0.393329\tvalid_0's l2: 0.32838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.393329\tvalid_0's l2: 0.32838\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.452355\tvalid_0's l2: 0.371747\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448013\tvalid_0's l2: 0.367953\n",
      "[3]\tvalid_0's l1: 0.443339\tvalid_0's l2: 0.36409\n",
      "[4]\tvalid_0's l1: 0.439201\tvalid_0's l2: 0.359651\n",
      "[5]\tvalid_0's l1: 0.43571\tvalid_0's l2: 0.357326\n",
      "[6]\tvalid_0's l1: 0.432138\tvalid_0's l2: 0.355018\n",
      "[7]\tvalid_0's l1: 0.428719\tvalid_0's l2: 0.353035\n",
      "[8]\tvalid_0's l1: 0.425691\tvalid_0's l2: 0.351235\n",
      "[9]\tvalid_0's l1: 0.422858\tvalid_0's l2: 0.349975\n",
      "[10]\tvalid_0's l1: 0.420606\tvalid_0's l2: 0.348698\n",
      "[11]\tvalid_0's l1: 0.418497\tvalid_0's l2: 0.347702\n",
      "[12]\tvalid_0's l1: 0.416359\tvalid_0's l2: 0.346022\n",
      "[13]\tvalid_0's l1: 0.414117\tvalid_0's l2: 0.344942\n",
      "[14]\tvalid_0's l1: 0.411865\tvalid_0's l2: 0.343844\n",
      "[15]\tvalid_0's l1: 0.410174\tvalid_0's l2: 0.343001\n",
      "[16]\tvalid_0's l1: 0.408408\tvalid_0's l2: 0.342725\n",
      "[17]\tvalid_0's l1: 0.406762\tvalid_0's l2: 0.341809\n",
      "[18]\tvalid_0's l1: 0.404954\tvalid_0's l2: 0.341362\n",
      "[19]\tvalid_0's l1: 0.40373\tvalid_0's l2: 0.341504\n",
      "[20]\tvalid_0's l1: 0.402503\tvalid_0's l2: 0.341661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.402503\tvalid_0's l2: 0.341661\n",
      "[1]\tvalid_0's l1: 0.452144\tvalid_0's l2: 0.371024\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.447455\tvalid_0's l2: 0.366622\n",
      "[3]\tvalid_0's l1: 0.443093\tvalid_0's l2: 0.361759\n",
      "[4]\tvalid_0's l1: 0.439255\tvalid_0's l2: 0.358666\n",
      "[5]\tvalid_0's l1: 0.434905\tvalid_0's l2: 0.354856\n",
      "[6]\tvalid_0's l1: 0.430844\tvalid_0's l2: 0.352039\n",
      "[7]\tvalid_0's l1: 0.427299\tvalid_0's l2: 0.349784\n",
      "[8]\tvalid_0's l1: 0.423963\tvalid_0's l2: 0.34774\n",
      "[9]\tvalid_0's l1: 0.421292\tvalid_0's l2: 0.346251\n",
      "[10]\tvalid_0's l1: 0.419129\tvalid_0's l2: 0.344421\n",
      "[11]\tvalid_0's l1: 0.416565\tvalid_0's l2: 0.342987\n",
      "[12]\tvalid_0's l1: 0.414153\tvalid_0's l2: 0.341747\n",
      "[13]\tvalid_0's l1: 0.412504\tvalid_0's l2: 0.34085\n",
      "[14]\tvalid_0's l1: 0.411076\tvalid_0's l2: 0.340004\n",
      "[15]\tvalid_0's l1: 0.409262\tvalid_0's l2: 0.339636\n",
      "[16]\tvalid_0's l1: 0.407648\tvalid_0's l2: 0.33934\n",
      "[17]\tvalid_0's l1: 0.405948\tvalid_0's l2: 0.339126\n",
      "[18]\tvalid_0's l1: 0.404354\tvalid_0's l2: 0.338803\n",
      "[19]\tvalid_0's l1: 0.403105\tvalid_0's l2: 0.3391\n",
      "[20]\tvalid_0's l1: 0.402024\tvalid_0's l2: 0.339174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.402024\tvalid_0's l2: 0.339174\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_total_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_total_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 31]\n",
    "        \n",
    "    x_train_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    x_train_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    x_test_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    x_test_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # y: response (target) variable DF_1 (col 4)\n",
    "    y_train = df_train_subdist.iloc[:, [4]]\n",
    "    y_test = df_test_subdist.iloc[:, [4]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_subdist['DF_1'])\n",
    "    y_test_true = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' \n",
    "                                              + str(i + 1) + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' \n",
    "                                           + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' \n",
    "                                           + str(i + 1) + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_BySubDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Adjusted CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_subdist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MAs (normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.37839\tvalid_0's l2: 0.240277\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.365864\tvalid_0's l2: 0.225832\n",
      "[3]\tvalid_0's l1: 0.354928\tvalid_0's l2: 0.21403\n",
      "[4]\tvalid_0's l1: 0.344881\tvalid_0's l2: 0.203476\n",
      "[5]\tvalid_0's l1: 0.33397\tvalid_0's l2: 0.192215\n",
      "[6]\tvalid_0's l1: 0.323954\tvalid_0's l2: 0.182453\n",
      "[7]\tvalid_0's l1: 0.31425\tvalid_0's l2: 0.1726\n",
      "[8]\tvalid_0's l1: 0.305548\tvalid_0's l2: 0.164498\n",
      "[9]\tvalid_0's l1: 0.298172\tvalid_0's l2: 0.15829\n",
      "[10]\tvalid_0's l1: 0.290282\tvalid_0's l2: 0.151115\n",
      "[11]\tvalid_0's l1: 0.282991\tvalid_0's l2: 0.14505\n",
      "[12]\tvalid_0's l1: 0.276325\tvalid_0's l2: 0.139541\n",
      "[13]\tvalid_0's l1: 0.269913\tvalid_0's l2: 0.134164\n",
      "[14]\tvalid_0's l1: 0.264186\tvalid_0's l2: 0.129643\n",
      "[15]\tvalid_0's l1: 0.259404\tvalid_0's l2: 0.126366\n",
      "[16]\tvalid_0's l1: 0.254246\tvalid_0's l2: 0.122412\n",
      "[17]\tvalid_0's l1: 0.249552\tvalid_0's l2: 0.119163\n",
      "[18]\tvalid_0's l1: 0.245002\tvalid_0's l2: 0.116025\n",
      "[19]\tvalid_0's l1: 0.24098\tvalid_0's l2: 0.113448\n",
      "[20]\tvalid_0's l1: 0.238483\tvalid_0's l2: 0.112075\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238483\tvalid_0's l2: 0.112075\n",
      "[1]\tvalid_0's l1: 0.378363\tvalid_0's l2: 0.240322\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.36665\tvalid_0's l2: 0.227154\n",
      "[3]\tvalid_0's l1: 0.354411\tvalid_0's l2: 0.213674\n",
      "[4]\tvalid_0's l1: 0.343022\tvalid_0's l2: 0.201369\n",
      "[5]\tvalid_0's l1: 0.333398\tvalid_0's l2: 0.19172\n",
      "[6]\tvalid_0's l1: 0.323351\tvalid_0's l2: 0.181849\n",
      "[7]\tvalid_0's l1: 0.314044\tvalid_0's l2: 0.172941\n",
      "[8]\tvalid_0's l1: 0.306148\tvalid_0's l2: 0.165926\n",
      "[9]\tvalid_0's l1: 0.297997\tvalid_0's l2: 0.158615\n",
      "[10]\tvalid_0's l1: 0.290015\tvalid_0's l2: 0.151727\n",
      "[11]\tvalid_0's l1: 0.282822\tvalid_0's l2: 0.145521\n",
      "[12]\tvalid_0's l1: 0.276257\tvalid_0's l2: 0.140133\n",
      "[13]\tvalid_0's l1: 0.270744\tvalid_0's l2: 0.135884\n",
      "[14]\tvalid_0's l1: 0.264987\tvalid_0's l2: 0.131439\n",
      "[15]\tvalid_0's l1: 0.261692\tvalid_0's l2: 0.129398\n",
      "[16]\tvalid_0's l1: 0.258656\tvalid_0's l2: 0.127659\n",
      "[17]\tvalid_0's l1: 0.253356\tvalid_0's l2: 0.123716\n",
      "[18]\tvalid_0's l1: 0.250612\tvalid_0's l2: 0.122137\n",
      "[19]\tvalid_0's l1: 0.245943\tvalid_0's l2: 0.11864\n",
      "[20]\tvalid_0's l1: 0.241799\tvalid_0's l2: 0.115789\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.241799\tvalid_0's l2: 0.115789\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.382501\tvalid_0's l2: 0.246336\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.374944\tvalid_0's l2: 0.238955\n",
      "[3]\tvalid_0's l1: 0.367862\tvalid_0's l2: 0.232227\n",
      "[4]\tvalid_0's l1: 0.36139\tvalid_0's l2: 0.226415\n",
      "[5]\tvalid_0's l1: 0.355396\tvalid_0's l2: 0.221062\n",
      "[6]\tvalid_0's l1: 0.349427\tvalid_0's l2: 0.215234\n",
      "[7]\tvalid_0's l1: 0.343933\tvalid_0's l2: 0.210644\n",
      "[8]\tvalid_0's l1: 0.339037\tvalid_0's l2: 0.206821\n",
      "[9]\tvalid_0's l1: 0.334645\tvalid_0's l2: 0.203738\n",
      "[10]\tvalid_0's l1: 0.330535\tvalid_0's l2: 0.200843\n",
      "[11]\tvalid_0's l1: 0.326576\tvalid_0's l2: 0.198005\n",
      "[12]\tvalid_0's l1: 0.322736\tvalid_0's l2: 0.194939\n",
      "[13]\tvalid_0's l1: 0.319347\tvalid_0's l2: 0.192737\n",
      "[14]\tvalid_0's l1: 0.316422\tvalid_0's l2: 0.19091\n",
      "[15]\tvalid_0's l1: 0.313543\tvalid_0's l2: 0.189138\n",
      "[16]\tvalid_0's l1: 0.310931\tvalid_0's l2: 0.187542\n",
      "[17]\tvalid_0's l1: 0.308416\tvalid_0's l2: 0.185718\n",
      "[18]\tvalid_0's l1: 0.306188\tvalid_0's l2: 0.184279\n",
      "[19]\tvalid_0's l1: 0.304092\tvalid_0's l2: 0.183144\n",
      "[20]\tvalid_0's l1: 0.302156\tvalid_0's l2: 0.182036\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.302156\tvalid_0's l2: 0.182036\n",
      "[1]\tvalid_0's l1: 0.382527\tvalid_0's l2: 0.246455\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3754\tvalid_0's l2: 0.239411\n",
      "[3]\tvalid_0's l1: 0.367798\tvalid_0's l2: 0.231378\n",
      "[4]\tvalid_0's l1: 0.361399\tvalid_0's l2: 0.225792\n",
      "[5]\tvalid_0's l1: 0.355437\tvalid_0's l2: 0.220573\n",
      "[6]\tvalid_0's l1: 0.349704\tvalid_0's l2: 0.215658\n",
      "[7]\tvalid_0's l1: 0.34466\tvalid_0's l2: 0.211517\n",
      "[8]\tvalid_0's l1: 0.339734\tvalid_0's l2: 0.207675\n",
      "[9]\tvalid_0's l1: 0.335264\tvalid_0's l2: 0.204412\n",
      "[10]\tvalid_0's l1: 0.331059\tvalid_0's l2: 0.201449\n",
      "[11]\tvalid_0's l1: 0.327291\tvalid_0's l2: 0.19858\n",
      "[12]\tvalid_0's l1: 0.323584\tvalid_0's l2: 0.196047\n",
      "[13]\tvalid_0's l1: 0.320231\tvalid_0's l2: 0.193748\n",
      "[14]\tvalid_0's l1: 0.317269\tvalid_0's l2: 0.191917\n",
      "[15]\tvalid_0's l1: 0.314435\tvalid_0's l2: 0.190072\n",
      "[16]\tvalid_0's l1: 0.311751\tvalid_0's l2: 0.188452\n",
      "[17]\tvalid_0's l1: 0.309422\tvalid_0's l2: 0.186926\n",
      "[18]\tvalid_0's l1: 0.30735\tvalid_0's l2: 0.185944\n",
      "[19]\tvalid_0's l1: 0.30527\tvalid_0's l2: 0.184845\n",
      "[20]\tvalid_0's l1: 0.303494\tvalid_0's l2: 0.183912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.303494\tvalid_0's l2: 0.183912\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.382647\tvalid_0's l2: 0.246724\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375292\tvalid_0's l2: 0.239653\n",
      "[3]\tvalid_0's l1: 0.368701\tvalid_0's l2: 0.233249\n",
      "[4]\tvalid_0's l1: 0.362643\tvalid_0's l2: 0.22758\n",
      "[5]\tvalid_0's l1: 0.357354\tvalid_0's l2: 0.222797\n",
      "[6]\tvalid_0's l1: 0.351623\tvalid_0's l2: 0.217992\n",
      "[7]\tvalid_0's l1: 0.346399\tvalid_0's l2: 0.212896\n",
      "[8]\tvalid_0's l1: 0.342116\tvalid_0's l2: 0.20966\n",
      "[9]\tvalid_0's l1: 0.337767\tvalid_0's l2: 0.205834\n",
      "[10]\tvalid_0's l1: 0.333832\tvalid_0's l2: 0.202967\n",
      "[11]\tvalid_0's l1: 0.33027\tvalid_0's l2: 0.200442\n",
      "[12]\tvalid_0's l1: 0.327008\tvalid_0's l2: 0.198274\n",
      "[13]\tvalid_0's l1: 0.323926\tvalid_0's l2: 0.196384\n",
      "[14]\tvalid_0's l1: 0.321179\tvalid_0's l2: 0.194818\n",
      "[15]\tvalid_0's l1: 0.318475\tvalid_0's l2: 0.193352\n",
      "[16]\tvalid_0's l1: 0.316139\tvalid_0's l2: 0.192037\n",
      "[17]\tvalid_0's l1: 0.313819\tvalid_0's l2: 0.190616\n",
      "[18]\tvalid_0's l1: 0.311763\tvalid_0's l2: 0.189458\n",
      "[19]\tvalid_0's l1: 0.309708\tvalid_0's l2: 0.188361\n",
      "[20]\tvalid_0's l1: 0.30801\tvalid_0's l2: 0.187622\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.30801\tvalid_0's l2: 0.187622\n",
      "[1]\tvalid_0's l1: 0.382948\tvalid_0's l2: 0.246897\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375254\tvalid_0's l2: 0.236688\n",
      "[3]\tvalid_0's l1: 0.368606\tvalid_0's l2: 0.230477\n",
      "[4]\tvalid_0's l1: 0.362202\tvalid_0's l2: 0.224528\n",
      "[5]\tvalid_0's l1: 0.356517\tvalid_0's l2: 0.219654\n",
      "[6]\tvalid_0's l1: 0.350966\tvalid_0's l2: 0.215073\n",
      "[7]\tvalid_0's l1: 0.346223\tvalid_0's l2: 0.211573\n",
      "[8]\tvalid_0's l1: 0.341684\tvalid_0's l2: 0.208031\n",
      "[9]\tvalid_0's l1: 0.337464\tvalid_0's l2: 0.205217\n",
      "[10]\tvalid_0's l1: 0.333559\tvalid_0's l2: 0.202524\n",
      "[11]\tvalid_0's l1: 0.330034\tvalid_0's l2: 0.199878\n",
      "[12]\tvalid_0's l1: 0.326702\tvalid_0's l2: 0.197591\n",
      "[13]\tvalid_0's l1: 0.323634\tvalid_0's l2: 0.195538\n",
      "[14]\tvalid_0's l1: 0.320764\tvalid_0's l2: 0.193426\n",
      "[15]\tvalid_0's l1: 0.318217\tvalid_0's l2: 0.191872\n",
      "[16]\tvalid_0's l1: 0.315728\tvalid_0's l2: 0.190424\n",
      "[17]\tvalid_0's l1: 0.313344\tvalid_0's l2: 0.188921\n",
      "[18]\tvalid_0's l1: 0.31131\tvalid_0's l2: 0.188021\n",
      "[19]\tvalid_0's l1: 0.309357\tvalid_0's l2: 0.187174\n",
      "[20]\tvalid_0's l1: 0.307652\tvalid_0's l2: 0.186228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.307652\tvalid_0's l2: 0.186228\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.383082\tvalid_0's l2: 0.246911\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.376328\tvalid_0's l2: 0.240023\n",
      "[3]\tvalid_0's l1: 0.369725\tvalid_0's l2: 0.233808\n",
      "[4]\tvalid_0's l1: 0.363738\tvalid_0's l2: 0.228414\n",
      "[5]\tvalid_0's l1: 0.358198\tvalid_0's l2: 0.222513\n",
      "[6]\tvalid_0's l1: 0.35331\tvalid_0's l2: 0.218445\n",
      "[7]\tvalid_0's l1: 0.34884\tvalid_0's l2: 0.215094\n",
      "[8]\tvalid_0's l1: 0.34454\tvalid_0's l2: 0.211076\n",
      "[9]\tvalid_0's l1: 0.340887\tvalid_0's l2: 0.208334\n",
      "[10]\tvalid_0's l1: 0.337445\tvalid_0's l2: 0.20548\n",
      "[11]\tvalid_0's l1: 0.334236\tvalid_0's l2: 0.203534\n",
      "[12]\tvalid_0's l1: 0.331324\tvalid_0's l2: 0.202015\n",
      "[13]\tvalid_0's l1: 0.328525\tvalid_0's l2: 0.200215\n",
      "[14]\tvalid_0's l1: 0.325818\tvalid_0's l2: 0.198611\n",
      "[15]\tvalid_0's l1: 0.323482\tvalid_0's l2: 0.197079\n",
      "[16]\tvalid_0's l1: 0.321571\tvalid_0's l2: 0.195929\n",
      "[17]\tvalid_0's l1: 0.319797\tvalid_0's l2: 0.195305\n",
      "[18]\tvalid_0's l1: 0.318017\tvalid_0's l2: 0.194655\n",
      "[19]\tvalid_0's l1: 0.316648\tvalid_0's l2: 0.194091\n",
      "[20]\tvalid_0's l1: 0.315196\tvalid_0's l2: 0.193799\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.315196\tvalid_0's l2: 0.193799\n",
      "[1]\tvalid_0's l1: 0.383043\tvalid_0's l2: 0.246835\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.375922\tvalid_0's l2: 0.239789\n",
      "[3]\tvalid_0's l1: 0.369396\tvalid_0's l2: 0.233698\n",
      "[4]\tvalid_0's l1: 0.362919\tvalid_0's l2: 0.225395\n",
      "[5]\tvalid_0's l1: 0.357737\tvalid_0's l2: 0.220897\n",
      "[6]\tvalid_0's l1: 0.352693\tvalid_0's l2: 0.217\n",
      "[7]\tvalid_0's l1: 0.348054\tvalid_0's l2: 0.213466\n",
      "[8]\tvalid_0's l1: 0.343966\tvalid_0's l2: 0.210233\n",
      "[9]\tvalid_0's l1: 0.340345\tvalid_0's l2: 0.206834\n",
      "[10]\tvalid_0's l1: 0.337007\tvalid_0's l2: 0.20452\n",
      "[11]\tvalid_0's l1: 0.333815\tvalid_0's l2: 0.202473\n",
      "[12]\tvalid_0's l1: 0.330927\tvalid_0's l2: 0.200773\n",
      "[13]\tvalid_0's l1: 0.328189\tvalid_0's l2: 0.199337\n",
      "[14]\tvalid_0's l1: 0.325721\tvalid_0's l2: 0.198158\n",
      "[15]\tvalid_0's l1: 0.323576\tvalid_0's l2: 0.197169\n",
      "[16]\tvalid_0's l1: 0.321437\tvalid_0's l2: 0.195641\n",
      "[17]\tvalid_0's l1: 0.319566\tvalid_0's l2: 0.194764\n",
      "[18]\tvalid_0's l1: 0.317989\tvalid_0's l2: 0.194331\n",
      "[19]\tvalid_0's l1: 0.316268\tvalid_0's l2: 0.193586\n",
      "[20]\tvalid_0's l1: 0.315006\tvalid_0's l2: 0.193357\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.315006\tvalid_0's l2: 0.193357\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.383376\tvalid_0's l2: 0.247554\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.376883\tvalid_0's l2: 0.241456\n",
      "[3]\tvalid_0's l1: 0.370628\tvalid_0's l2: 0.235684\n",
      "[4]\tvalid_0's l1: 0.365095\tvalid_0's l2: 0.23097\n",
      "[5]\tvalid_0's l1: 0.360115\tvalid_0's l2: 0.226845\n",
      "[6]\tvalid_0's l1: 0.355393\tvalid_0's l2: 0.22218\n",
      "[7]\tvalid_0's l1: 0.351144\tvalid_0's l2: 0.218737\n",
      "[8]\tvalid_0's l1: 0.347536\tvalid_0's l2: 0.216266\n",
      "[9]\tvalid_0's l1: 0.344163\tvalid_0's l2: 0.213998\n",
      "[10]\tvalid_0's l1: 0.340966\tvalid_0's l2: 0.211918\n",
      "[11]\tvalid_0's l1: 0.337973\tvalid_0's l2: 0.209741\n",
      "[12]\tvalid_0's l1: 0.335263\tvalid_0's l2: 0.207375\n",
      "[13]\tvalid_0's l1: 0.332799\tvalid_0's l2: 0.205851\n",
      "[14]\tvalid_0's l1: 0.330517\tvalid_0's l2: 0.204575\n",
      "[15]\tvalid_0's l1: 0.328691\tvalid_0's l2: 0.203688\n",
      "[16]\tvalid_0's l1: 0.326835\tvalid_0's l2: 0.203041\n",
      "[17]\tvalid_0's l1: 0.325279\tvalid_0's l2: 0.202421\n",
      "[18]\tvalid_0's l1: 0.323872\tvalid_0's l2: 0.201908\n",
      "[19]\tvalid_0's l1: 0.322349\tvalid_0's l2: 0.201398\n",
      "[20]\tvalid_0's l1: 0.321052\tvalid_0's l2: 0.201059\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.321052\tvalid_0's l2: 0.201059\n",
      "[1]\tvalid_0's l1: 0.383283\tvalid_0's l2: 0.247515\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.37712\tvalid_0's l2: 0.240975\n",
      "[3]\tvalid_0's l1: 0.371464\tvalid_0's l2: 0.236158\n",
      "[4]\tvalid_0's l1: 0.365736\tvalid_0's l2: 0.231176\n",
      "[5]\tvalid_0's l1: 0.360608\tvalid_0's l2: 0.22664\n",
      "[6]\tvalid_0's l1: 0.355839\tvalid_0's l2: 0.221881\n",
      "[7]\tvalid_0's l1: 0.351545\tvalid_0's l2: 0.218714\n",
      "[8]\tvalid_0's l1: 0.347617\tvalid_0's l2: 0.215635\n",
      "[9]\tvalid_0's l1: 0.344063\tvalid_0's l2: 0.213219\n",
      "[10]\tvalid_0's l1: 0.341015\tvalid_0's l2: 0.211254\n",
      "[11]\tvalid_0's l1: 0.338189\tvalid_0's l2: 0.209295\n",
      "[12]\tvalid_0's l1: 0.335611\tvalid_0's l2: 0.207855\n",
      "[13]\tvalid_0's l1: 0.333097\tvalid_0's l2: 0.206067\n",
      "[14]\tvalid_0's l1: 0.330956\tvalid_0's l2: 0.204855\n",
      "[15]\tvalid_0's l1: 0.328742\tvalid_0's l2: 0.203781\n",
      "[16]\tvalid_0's l1: 0.32676\tvalid_0's l2: 0.202898\n",
      "[17]\tvalid_0's l1: 0.324902\tvalid_0's l2: 0.202188\n",
      "[18]\tvalid_0's l1: 0.323339\tvalid_0's l2: 0.201953\n",
      "[19]\tvalid_0's l1: 0.322007\tvalid_0's l2: 0.201873\n",
      "[20]\tvalid_0's l1: 0.320593\tvalid_0's l2: 0.201666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.320593\tvalid_0's l2: 0.201666\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.384384\tvalid_0's l2: 0.248702\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.379065\tvalid_0's l2: 0.243885\n",
      "[3]\tvalid_0's l1: 0.373828\tvalid_0's l2: 0.239704\n",
      "[4]\tvalid_0's l1: 0.368936\tvalid_0's l2: 0.234718\n",
      "[5]\tvalid_0's l1: 0.365025\tvalid_0's l2: 0.231666\n",
      "[6]\tvalid_0's l1: 0.360787\tvalid_0's l2: 0.22848\n",
      "[7]\tvalid_0's l1: 0.35695\tvalid_0's l2: 0.225776\n",
      "[8]\tvalid_0's l1: 0.353829\tvalid_0's l2: 0.223864\n",
      "[9]\tvalid_0's l1: 0.350903\tvalid_0's l2: 0.222149\n",
      "[10]\tvalid_0's l1: 0.348225\tvalid_0's l2: 0.220799\n",
      "[11]\tvalid_0's l1: 0.345851\tvalid_0's l2: 0.219669\n",
      "[12]\tvalid_0's l1: 0.343422\tvalid_0's l2: 0.217919\n",
      "[13]\tvalid_0's l1: 0.341053\tvalid_0's l2: 0.216518\n",
      "[14]\tvalid_0's l1: 0.339076\tvalid_0's l2: 0.215714\n",
      "[15]\tvalid_0's l1: 0.337337\tvalid_0's l2: 0.214847\n",
      "[16]\tvalid_0's l1: 0.335772\tvalid_0's l2: 0.214447\n",
      "[17]\tvalid_0's l1: 0.334285\tvalid_0's l2: 0.213897\n",
      "[18]\tvalid_0's l1: 0.332724\tvalid_0's l2: 0.213727\n",
      "[19]\tvalid_0's l1: 0.331585\tvalid_0's l2: 0.213941\n",
      "[20]\tvalid_0's l1: 0.330699\tvalid_0's l2: 0.214449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.330699\tvalid_0's l2: 0.214449\n",
      "[1]\tvalid_0's l1: 0.384167\tvalid_0's l2: 0.2483\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.378455\tvalid_0's l2: 0.243081\n",
      "[3]\tvalid_0's l1: 0.372845\tvalid_0's l2: 0.237264\n",
      "[4]\tvalid_0's l1: 0.368059\tvalid_0's l2: 0.23326\n",
      "[5]\tvalid_0's l1: 0.363489\tvalid_0's l2: 0.229692\n",
      "[6]\tvalid_0's l1: 0.359084\tvalid_0's l2: 0.226208\n",
      "[7]\tvalid_0's l1: 0.355194\tvalid_0's l2: 0.223283\n",
      "[8]\tvalid_0's l1: 0.351582\tvalid_0's l2: 0.220939\n",
      "[9]\tvalid_0's l1: 0.348414\tvalid_0's l2: 0.219218\n",
      "[10]\tvalid_0's l1: 0.345404\tvalid_0's l2: 0.217075\n",
      "[11]\tvalid_0's l1: 0.343029\tvalid_0's l2: 0.215708\n",
      "[12]\tvalid_0's l1: 0.340943\tvalid_0's l2: 0.214782\n",
      "[13]\tvalid_0's l1: 0.338839\tvalid_0's l2: 0.213499\n",
      "[14]\tvalid_0's l1: 0.33696\tvalid_0's l2: 0.212791\n",
      "[15]\tvalid_0's l1: 0.335047\tvalid_0's l2: 0.211939\n",
      "[16]\tvalid_0's l1: 0.333443\tvalid_0's l2: 0.211682\n",
      "[17]\tvalid_0's l1: 0.332099\tvalid_0's l2: 0.211694\n",
      "[18]\tvalid_0's l1: 0.331001\tvalid_0's l2: 0.211829\n",
      "[19]\tvalid_0's l1: 0.330029\tvalid_0's l2: 0.211914\n",
      "[20]\tvalid_0's l1: 0.329141\tvalid_0's l2: 0.212194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.329141\tvalid_0's l2: 0.212194\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.34549\tvalid_0's l2: 0.195412\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.331831\tvalid_0's l2: 0.181071\n",
      "[3]\tvalid_0's l1: 0.318523\tvalid_0's l2: 0.167232\n",
      "[4]\tvalid_0's l1: 0.305935\tvalid_0's l2: 0.154611\n",
      "[5]\tvalid_0's l1: 0.294171\tvalid_0's l2: 0.143584\n",
      "[6]\tvalid_0's l1: 0.282954\tvalid_0's l2: 0.133475\n",
      "[7]\tvalid_0's l1: 0.272506\tvalid_0's l2: 0.124402\n",
      "[8]\tvalid_0's l1: 0.262859\tvalid_0's l2: 0.116515\n",
      "[9]\tvalid_0's l1: 0.253868\tvalid_0's l2: 0.109476\n",
      "[10]\tvalid_0's l1: 0.245301\tvalid_0's l2: 0.102821\n",
      "[11]\tvalid_0's l1: 0.237323\tvalid_0's l2: 0.096884\n",
      "[12]\tvalid_0's l1: 0.229839\tvalid_0's l2: 0.0915452\n",
      "[13]\tvalid_0's l1: 0.222646\tvalid_0's l2: 0.0864361\n",
      "[14]\tvalid_0's l1: 0.216289\tvalid_0's l2: 0.0824277\n",
      "[15]\tvalid_0's l1: 0.210028\tvalid_0's l2: 0.0784761\n",
      "[16]\tvalid_0's l1: 0.204206\tvalid_0's l2: 0.0747635\n",
      "[17]\tvalid_0's l1: 0.198975\tvalid_0's l2: 0.0717995\n",
      "[18]\tvalid_0's l1: 0.194197\tvalid_0's l2: 0.0691961\n",
      "[19]\tvalid_0's l1: 0.189642\tvalid_0's l2: 0.0668501\n",
      "[20]\tvalid_0's l1: 0.186334\tvalid_0's l2: 0.0653302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.186334\tvalid_0's l2: 0.0653302\n",
      "[1]\tvalid_0's l1: 0.345396\tvalid_0's l2: 0.195124\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.331284\tvalid_0's l2: 0.17986\n",
      "[3]\tvalid_0's l1: 0.317963\tvalid_0's l2: 0.165996\n",
      "[4]\tvalid_0's l1: 0.305553\tvalid_0's l2: 0.153878\n",
      "[5]\tvalid_0's l1: 0.293853\tvalid_0's l2: 0.143109\n",
      "[6]\tvalid_0's l1: 0.282666\tvalid_0's l2: 0.132967\n",
      "[7]\tvalid_0's l1: 0.272415\tvalid_0's l2: 0.124395\n",
      "[8]\tvalid_0's l1: 0.262815\tvalid_0's l2: 0.11654\n",
      "[9]\tvalid_0's l1: 0.253873\tvalid_0's l2: 0.109529\n",
      "[10]\tvalid_0's l1: 0.245597\tvalid_0's l2: 0.103211\n",
      "[11]\tvalid_0's l1: 0.237577\tvalid_0's l2: 0.0972583\n",
      "[12]\tvalid_0's l1: 0.23008\tvalid_0's l2: 0.091917\n",
      "[13]\tvalid_0's l1: 0.223456\tvalid_0's l2: 0.087489\n",
      "[14]\tvalid_0's l1: 0.216885\tvalid_0's l2: 0.0831851\n",
      "[15]\tvalid_0's l1: 0.212292\tvalid_0's l2: 0.0805911\n",
      "[16]\tvalid_0's l1: 0.208299\tvalid_0's l2: 0.0784876\n",
      "[17]\tvalid_0's l1: 0.202495\tvalid_0's l2: 0.0748882\n",
      "[18]\tvalid_0's l1: 0.198768\tvalid_0's l2: 0.072944\n",
      "[19]\tvalid_0's l1: 0.193736\tvalid_0's l2: 0.0700251\n",
      "[20]\tvalid_0's l1: 0.189016\tvalid_0's l2: 0.0674757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.189016\tvalid_0's l2: 0.0674757\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.349636\tvalid_0's l2: 0.200801\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.33905\tvalid_0's l2: 0.190396\n",
      "[3]\tvalid_0's l1: 0.33141\tvalid_0's l2: 0.183798\n",
      "[4]\tvalid_0's l1: 0.32197\tvalid_0's l2: 0.174669\n",
      "[5]\tvalid_0's l1: 0.315731\tvalid_0's l2: 0.169657\n",
      "[6]\tvalid_0's l1: 0.306687\tvalid_0's l2: 0.160908\n",
      "[7]\tvalid_0's l1: 0.299428\tvalid_0's l2: 0.155007\n",
      "[8]\tvalid_0's l1: 0.292085\tvalid_0's l2: 0.148599\n",
      "[9]\tvalid_0's l1: 0.285307\tvalid_0's l2: 0.143191\n",
      "[10]\tvalid_0's l1: 0.279435\tvalid_0's l2: 0.138828\n",
      "[11]\tvalid_0's l1: 0.273601\tvalid_0's l2: 0.134141\n",
      "[12]\tvalid_0's l1: 0.267862\tvalid_0's l2: 0.129314\n",
      "[13]\tvalid_0's l1: 0.264349\tvalid_0's l2: 0.127354\n",
      "[14]\tvalid_0's l1: 0.261172\tvalid_0's l2: 0.125628\n",
      "[15]\tvalid_0's l1: 0.256405\tvalid_0's l2: 0.122386\n",
      "[16]\tvalid_0's l1: 0.253628\tvalid_0's l2: 0.120964\n",
      "[17]\tvalid_0's l1: 0.249309\tvalid_0's l2: 0.117674\n",
      "[18]\tvalid_0's l1: 0.245247\tvalid_0's l2: 0.11473\n",
      "[19]\tvalid_0's l1: 0.241774\tvalid_0's l2: 0.112673\n",
      "[20]\tvalid_0's l1: 0.238354\tvalid_0's l2: 0.110353\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238354\tvalid_0's l2: 0.110353\n",
      "[1]\tvalid_0's l1: 0.349637\tvalid_0's l2: 0.200777\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3417\tvalid_0's l2: 0.193637\n",
      "[3]\tvalid_0's l1: 0.330882\tvalid_0's l2: 0.182092\n",
      "[4]\tvalid_0's l1: 0.321725\tvalid_0's l2: 0.173643\n",
      "[5]\tvalid_0's l1: 0.313001\tvalid_0's l2: 0.165587\n",
      "[6]\tvalid_0's l1: 0.304942\tvalid_0's l2: 0.15877\n",
      "[7]\tvalid_0's l1: 0.297476\tvalid_0's l2: 0.152663\n",
      "[8]\tvalid_0's l1: 0.290722\tvalid_0's l2: 0.147303\n",
      "[9]\tvalid_0's l1: 0.28416\tvalid_0's l2: 0.142161\n",
      "[10]\tvalid_0's l1: 0.278166\tvalid_0's l2: 0.137372\n",
      "[11]\tvalid_0's l1: 0.272994\tvalid_0's l2: 0.133531\n",
      "[12]\tvalid_0's l1: 0.267707\tvalid_0's l2: 0.129615\n",
      "[13]\tvalid_0's l1: 0.263068\tvalid_0's l2: 0.126431\n",
      "[14]\tvalid_0's l1: 0.258418\tvalid_0's l2: 0.12323\n",
      "[15]\tvalid_0's l1: 0.254053\tvalid_0's l2: 0.120227\n",
      "[16]\tvalid_0's l1: 0.250138\tvalid_0's l2: 0.117761\n",
      "[17]\tvalid_0's l1: 0.247551\tvalid_0's l2: 0.116164\n",
      "[18]\tvalid_0's l1: 0.244051\tvalid_0's l2: 0.114038\n",
      "[19]\tvalid_0's l1: 0.241743\tvalid_0's l2: 0.11306\n",
      "[20]\tvalid_0's l1: 0.238595\tvalid_0's l2: 0.111191\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.238595\tvalid_0's l2: 0.111191\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.351494\tvalid_0's l2: 0.203499\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.343667\tvalid_0's l2: 0.196299\n",
      "[3]\tvalid_0's l1: 0.336486\tvalid_0's l2: 0.189713\n",
      "[4]\tvalid_0's l1: 0.330067\tvalid_0's l2: 0.183995\n",
      "[5]\tvalid_0's l1: 0.32407\tvalid_0's l2: 0.179171\n",
      "[6]\tvalid_0's l1: 0.318435\tvalid_0's l2: 0.174659\n",
      "[7]\tvalid_0's l1: 0.312542\tvalid_0's l2: 0.169346\n",
      "[8]\tvalid_0's l1: 0.307799\tvalid_0's l2: 0.166035\n",
      "[9]\tvalid_0's l1: 0.302903\tvalid_0's l2: 0.161702\n",
      "[10]\tvalid_0's l1: 0.298741\tvalid_0's l2: 0.1588\n",
      "[11]\tvalid_0's l1: 0.294989\tvalid_0's l2: 0.156255\n",
      "[12]\tvalid_0's l1: 0.291688\tvalid_0's l2: 0.154116\n",
      "[13]\tvalid_0's l1: 0.288487\tvalid_0's l2: 0.152218\n",
      "[14]\tvalid_0's l1: 0.285636\tvalid_0's l2: 0.150651\n",
      "[15]\tvalid_0's l1: 0.282922\tvalid_0's l2: 0.149113\n",
      "[16]\tvalid_0's l1: 0.280311\tvalid_0's l2: 0.14766\n",
      "[17]\tvalid_0's l1: 0.277884\tvalid_0's l2: 0.146323\n",
      "[18]\tvalid_0's l1: 0.27561\tvalid_0's l2: 0.145219\n",
      "[19]\tvalid_0's l1: 0.273563\tvalid_0's l2: 0.144193\n",
      "[20]\tvalid_0's l1: 0.271673\tvalid_0's l2: 0.143503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.271673\tvalid_0's l2: 0.143503\n",
      "[1]\tvalid_0's l1: 0.351805\tvalid_0's l2: 0.203907\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.34349\tvalid_0's l2: 0.194843\n",
      "[3]\tvalid_0's l1: 0.336342\tvalid_0's l2: 0.188518\n",
      "[4]\tvalid_0's l1: 0.32976\tvalid_0's l2: 0.183047\n",
      "[5]\tvalid_0's l1: 0.323722\tvalid_0's l2: 0.178129\n",
      "[6]\tvalid_0's l1: 0.318249\tvalid_0's l2: 0.17375\n",
      "[7]\tvalid_0's l1: 0.313002\tvalid_0's l2: 0.169812\n",
      "[8]\tvalid_0's l1: 0.308222\tvalid_0's l2: 0.166119\n",
      "[9]\tvalid_0's l1: 0.303856\tvalid_0's l2: 0.163078\n",
      "[10]\tvalid_0's l1: 0.299921\tvalid_0's l2: 0.160476\n",
      "[11]\tvalid_0's l1: 0.296276\tvalid_0's l2: 0.158117\n",
      "[12]\tvalid_0's l1: 0.292834\tvalid_0's l2: 0.155739\n",
      "[13]\tvalid_0's l1: 0.289796\tvalid_0's l2: 0.153835\n",
      "[14]\tvalid_0's l1: 0.287004\tvalid_0's l2: 0.152106\n",
      "[15]\tvalid_0's l1: 0.284389\tvalid_0's l2: 0.150621\n",
      "[16]\tvalid_0's l1: 0.281717\tvalid_0's l2: 0.149206\n",
      "[17]\tvalid_0's l1: 0.279272\tvalid_0's l2: 0.148053\n",
      "[18]\tvalid_0's l1: 0.277252\tvalid_0's l2: 0.147184\n",
      "[19]\tvalid_0's l1: 0.275231\tvalid_0's l2: 0.145988\n",
      "[20]\tvalid_0's l1: 0.273387\tvalid_0's l2: 0.145116\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.273387\tvalid_0's l2: 0.145116\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.351963\tvalid_0's l2: 0.203895\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.3444\tvalid_0's l2: 0.196871\n",
      "[3]\tvalid_0's l1: 0.3373\tvalid_0's l2: 0.190435\n",
      "[4]\tvalid_0's l1: 0.331014\tvalid_0's l2: 0.185144\n",
      "[5]\tvalid_0's l1: 0.324822\tvalid_0's l2: 0.179124\n",
      "[6]\tvalid_0's l1: 0.319248\tvalid_0's l2: 0.174776\n",
      "[7]\tvalid_0's l1: 0.314519\tvalid_0's l2: 0.171363\n",
      "[8]\tvalid_0's l1: 0.30969\tvalid_0's l2: 0.167188\n",
      "[9]\tvalid_0's l1: 0.305714\tvalid_0's l2: 0.16448\n",
      "[10]\tvalid_0's l1: 0.30182\tvalid_0's l2: 0.161332\n",
      "[11]\tvalid_0's l1: 0.298335\tvalid_0's l2: 0.159267\n",
      "[12]\tvalid_0's l1: 0.295243\tvalid_0's l2: 0.15748\n",
      "[13]\tvalid_0's l1: 0.292505\tvalid_0's l2: 0.155966\n",
      "[14]\tvalid_0's l1: 0.289873\tvalid_0's l2: 0.154418\n",
      "[15]\tvalid_0's l1: 0.287495\tvalid_0's l2: 0.152987\n",
      "[16]\tvalid_0's l1: 0.285433\tvalid_0's l2: 0.151845\n",
      "[17]\tvalid_0's l1: 0.28341\tvalid_0's l2: 0.150888\n",
      "[18]\tvalid_0's l1: 0.281549\tvalid_0's l2: 0.15039\n",
      "[19]\tvalid_0's l1: 0.280072\tvalid_0's l2: 0.149815\n",
      "[20]\tvalid_0's l1: 0.2787\tvalid_0's l2: 0.149577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.2787\tvalid_0's l2: 0.149577\n",
      "[1]\tvalid_0's l1: 0.351871\tvalid_0's l2: 0.203809\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.34434\tvalid_0's l2: 0.196736\n",
      "[3]\tvalid_0's l1: 0.337149\tvalid_0's l2: 0.190188\n",
      "[4]\tvalid_0's l1: 0.330331\tvalid_0's l2: 0.183356\n",
      "[5]\tvalid_0's l1: 0.324786\tvalid_0's l2: 0.178802\n",
      "[6]\tvalid_0's l1: 0.319267\tvalid_0's l2: 0.174836\n",
      "[7]\tvalid_0's l1: 0.314332\tvalid_0's l2: 0.171448\n",
      "[8]\tvalid_0's l1: 0.309916\tvalid_0's l2: 0.168403\n",
      "[9]\tvalid_0's l1: 0.305749\tvalid_0's l2: 0.164884\n",
      "[10]\tvalid_0's l1: 0.302165\tvalid_0's l2: 0.162458\n",
      "[11]\tvalid_0's l1: 0.298768\tvalid_0's l2: 0.160108\n",
      "[12]\tvalid_0's l1: 0.295655\tvalid_0's l2: 0.158361\n",
      "[13]\tvalid_0's l1: 0.292807\tvalid_0's l2: 0.156895\n",
      "[14]\tvalid_0's l1: 0.290484\tvalid_0's l2: 0.155798\n",
      "[15]\tvalid_0's l1: 0.288041\tvalid_0's l2: 0.154648\n",
      "[16]\tvalid_0's l1: 0.285796\tvalid_0's l2: 0.153812\n",
      "[17]\tvalid_0's l1: 0.283714\tvalid_0's l2: 0.152738\n",
      "[18]\tvalid_0's l1: 0.281957\tvalid_0's l2: 0.152209\n",
      "[19]\tvalid_0's l1: 0.280477\tvalid_0's l2: 0.151701\n",
      "[20]\tvalid_0's l1: 0.279185\tvalid_0's l2: 0.151615\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.279185\tvalid_0's l2: 0.151615\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.352585\tvalid_0's l2: 0.204817\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.345325\tvalid_0's l2: 0.198061\n",
      "[3]\tvalid_0's l1: 0.338691\tvalid_0's l2: 0.192161\n",
      "[4]\tvalid_0's l1: 0.332723\tvalid_0's l2: 0.187228\n",
      "[5]\tvalid_0's l1: 0.327227\tvalid_0's l2: 0.182648\n",
      "[6]\tvalid_0's l1: 0.321966\tvalid_0's l2: 0.177884\n",
      "[7]\tvalid_0's l1: 0.317541\tvalid_0's l2: 0.174856\n",
      "[8]\tvalid_0's l1: 0.313471\tvalid_0's l2: 0.172195\n",
      "[9]\tvalid_0's l1: 0.309775\tvalid_0's l2: 0.169973\n",
      "[10]\tvalid_0's l1: 0.306515\tvalid_0's l2: 0.16799\n",
      "[11]\tvalid_0's l1: 0.303452\tvalid_0's l2: 0.165963\n",
      "[12]\tvalid_0's l1: 0.300698\tvalid_0's l2: 0.163918\n",
      "[13]\tvalid_0's l1: 0.298217\tvalid_0's l2: 0.162467\n",
      "[14]\tvalid_0's l1: 0.295993\tvalid_0's l2: 0.161484\n",
      "[15]\tvalid_0's l1: 0.293833\tvalid_0's l2: 0.160561\n",
      "[16]\tvalid_0's l1: 0.291725\tvalid_0's l2: 0.159779\n",
      "[17]\tvalid_0's l1: 0.289963\tvalid_0's l2: 0.158778\n",
      "[18]\tvalid_0's l1: 0.288423\tvalid_0's l2: 0.158065\n",
      "[19]\tvalid_0's l1: 0.286778\tvalid_0's l2: 0.157507\n",
      "[20]\tvalid_0's l1: 0.28546\tvalid_0's l2: 0.157181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.28546\tvalid_0's l2: 0.157181\n",
      "[1]\tvalid_0's l1: 0.352409\tvalid_0's l2: 0.204732\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.34521\tvalid_0's l2: 0.197456\n",
      "[3]\tvalid_0's l1: 0.339127\tvalid_0's l2: 0.192517\n",
      "[4]\tvalid_0's l1: 0.332829\tvalid_0's l2: 0.187528\n",
      "[5]\tvalid_0's l1: 0.327175\tvalid_0's l2: 0.182824\n",
      "[6]\tvalid_0's l1: 0.32204\tvalid_0's l2: 0.178234\n",
      "[7]\tvalid_0's l1: 0.31754\tvalid_0's l2: 0.175333\n",
      "[8]\tvalid_0's l1: 0.313393\tvalid_0's l2: 0.172727\n",
      "[9]\tvalid_0's l1: 0.309477\tvalid_0's l2: 0.170143\n",
      "[10]\tvalid_0's l1: 0.306139\tvalid_0's l2: 0.16829\n",
      "[11]\tvalid_0's l1: 0.303218\tvalid_0's l2: 0.166709\n",
      "[12]\tvalid_0's l1: 0.300632\tvalid_0's l2: 0.16527\n",
      "[13]\tvalid_0's l1: 0.298196\tvalid_0's l2: 0.163673\n",
      "[14]\tvalid_0's l1: 0.296111\tvalid_0's l2: 0.162883\n",
      "[15]\tvalid_0's l1: 0.29406\tvalid_0's l2: 0.162157\n",
      "[16]\tvalid_0's l1: 0.292212\tvalid_0's l2: 0.161588\n",
      "[17]\tvalid_0's l1: 0.290522\tvalid_0's l2: 0.160765\n",
      "[18]\tvalid_0's l1: 0.288652\tvalid_0's l2: 0.160081\n",
      "[19]\tvalid_0's l1: 0.287339\tvalid_0's l2: 0.159952\n",
      "[20]\tvalid_0's l1: 0.285839\tvalid_0's l2: 0.159543\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.285839\tvalid_0's l2: 0.159543\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.353057\tvalid_0's l2: 0.205412\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346693\tvalid_0's l2: 0.199976\n",
      "[3]\tvalid_0's l1: 0.340961\tvalid_0's l2: 0.195386\n",
      "[4]\tvalid_0's l1: 0.335083\tvalid_0's l2: 0.189505\n",
      "[5]\tvalid_0's l1: 0.330605\tvalid_0's l2: 0.186145\n",
      "[6]\tvalid_0's l1: 0.326077\tvalid_0's l2: 0.182853\n",
      "[7]\tvalid_0's l1: 0.32207\tvalid_0's l2: 0.180204\n",
      "[8]\tvalid_0's l1: 0.318562\tvalid_0's l2: 0.178101\n",
      "[9]\tvalid_0's l1: 0.3153\tvalid_0's l2: 0.176169\n",
      "[10]\tvalid_0's l1: 0.31232\tvalid_0's l2: 0.174616\n",
      "[11]\tvalid_0's l1: 0.309818\tvalid_0's l2: 0.173128\n",
      "[12]\tvalid_0's l1: 0.307015\tvalid_0's l2: 0.171041\n",
      "[13]\tvalid_0's l1: 0.304576\tvalid_0's l2: 0.169779\n",
      "[14]\tvalid_0's l1: 0.302485\tvalid_0's l2: 0.168786\n",
      "[15]\tvalid_0's l1: 0.300564\tvalid_0's l2: 0.167623\n",
      "[16]\tvalid_0's l1: 0.29876\tvalid_0's l2: 0.166999\n",
      "[17]\tvalid_0's l1: 0.297178\tvalid_0's l2: 0.166186\n",
      "[18]\tvalid_0's l1: 0.29555\tvalid_0's l2: 0.165734\n",
      "[19]\tvalid_0's l1: 0.294415\tvalid_0's l2: 0.165745\n",
      "[20]\tvalid_0's l1: 0.293389\tvalid_0's l2: 0.165755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.293389\tvalid_0's l2: 0.165755\n",
      "[1]\tvalid_0's l1: 0.352942\tvalid_0's l2: 0.205481\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.346415\tvalid_0's l2: 0.19995\n",
      "[3]\tvalid_0's l1: 0.339924\tvalid_0's l2: 0.193303\n",
      "[4]\tvalid_0's l1: 0.334545\tvalid_0's l2: 0.1892\n",
      "[5]\tvalid_0's l1: 0.329753\tvalid_0's l2: 0.185511\n",
      "[6]\tvalid_0's l1: 0.325158\tvalid_0's l2: 0.182221\n",
      "[7]\tvalid_0's l1: 0.320918\tvalid_0's l2: 0.179451\n",
      "[8]\tvalid_0's l1: 0.317136\tvalid_0's l2: 0.177067\n",
      "[9]\tvalid_0's l1: 0.3137\tvalid_0's l2: 0.174834\n",
      "[10]\tvalid_0's l1: 0.31064\tvalid_0's l2: 0.172566\n",
      "[11]\tvalid_0's l1: 0.308084\tvalid_0's l2: 0.171199\n",
      "[12]\tvalid_0's l1: 0.305887\tvalid_0's l2: 0.170085\n",
      "[13]\tvalid_0's l1: 0.303761\tvalid_0's l2: 0.168757\n",
      "[14]\tvalid_0's l1: 0.301975\tvalid_0's l2: 0.167836\n",
      "[15]\tvalid_0's l1: 0.300297\tvalid_0's l2: 0.167281\n",
      "[16]\tvalid_0's l1: 0.298723\tvalid_0's l2: 0.166951\n",
      "[17]\tvalid_0's l1: 0.297145\tvalid_0's l2: 0.166643\n",
      "[18]\tvalid_0's l1: 0.29578\tvalid_0's l2: 0.166443\n",
      "[19]\tvalid_0's l1: 0.294604\tvalid_0's l2: 0.166407\n",
      "[20]\tvalid_0's l1: 0.293654\tvalid_0's l2: 0.166385\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.293654\tvalid_0's l2: 0.166385\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.327153\tvalid_0's l2: 0.172603\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.312918\tvalid_0's l2: 0.15817\n",
      "[3]\tvalid_0's l1: 0.29938\tvalid_0's l2: 0.14506\n",
      "[4]\tvalid_0's l1: 0.286764\tvalid_0's l2: 0.133307\n",
      "[5]\tvalid_0's l1: 0.274892\tvalid_0's l2: 0.122802\n",
      "[6]\tvalid_0's l1: 0.263557\tvalid_0's l2: 0.113228\n",
      "[7]\tvalid_0's l1: 0.252829\tvalid_0's l2: 0.104484\n",
      "[8]\tvalid_0's l1: 0.243006\tvalid_0's l2: 0.096959\n",
      "[9]\tvalid_0's l1: 0.23363\tvalid_0's l2: 0.0900656\n",
      "[10]\tvalid_0's l1: 0.224702\tvalid_0's l2: 0.083571\n",
      "[11]\tvalid_0's l1: 0.21644\tvalid_0's l2: 0.0779209\n",
      "[12]\tvalid_0's l1: 0.208626\tvalid_0's l2: 0.0726958\n",
      "[13]\tvalid_0's l1: 0.201245\tvalid_0's l2: 0.067979\n",
      "[14]\tvalid_0's l1: 0.194496\tvalid_0's l2: 0.0638774\n",
      "[15]\tvalid_0's l1: 0.188056\tvalid_0's l2: 0.0601118\n",
      "[16]\tvalid_0's l1: 0.181939\tvalid_0's l2: 0.0566932\n",
      "[17]\tvalid_0's l1: 0.176368\tvalid_0's l2: 0.0537329\n",
      "[18]\tvalid_0's l1: 0.171232\tvalid_0's l2: 0.0511234\n",
      "[19]\tvalid_0's l1: 0.166384\tvalid_0's l2: 0.0487151\n",
      "[20]\tvalid_0's l1: 0.162677\tvalid_0's l2: 0.0469768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.162677\tvalid_0's l2: 0.0469768\n",
      "[1]\tvalid_0's l1: 0.327144\tvalid_0's l2: 0.172589\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.312873\tvalid_0's l2: 0.158056\n",
      "[3]\tvalid_0's l1: 0.299307\tvalid_0's l2: 0.14493\n",
      "[4]\tvalid_0's l1: 0.286698\tvalid_0's l2: 0.133215\n",
      "[5]\tvalid_0's l1: 0.274676\tvalid_0's l2: 0.122579\n",
      "[6]\tvalid_0's l1: 0.263305\tvalid_0's l2: 0.112992\n",
      "[7]\tvalid_0's l1: 0.252708\tvalid_0's l2: 0.104595\n",
      "[8]\tvalid_0's l1: 0.242808\tvalid_0's l2: 0.096921\n",
      "[9]\tvalid_0's l1: 0.233492\tvalid_0's l2: 0.0899508\n",
      "[10]\tvalid_0's l1: 0.224698\tvalid_0's l2: 0.0836939\n",
      "[11]\tvalid_0's l1: 0.216447\tvalid_0's l2: 0.077975\n",
      "[12]\tvalid_0's l1: 0.208724\tvalid_0's l2: 0.0728619\n",
      "[13]\tvalid_0's l1: 0.201512\tvalid_0's l2: 0.0683383\n",
      "[14]\tvalid_0's l1: 0.194564\tvalid_0's l2: 0.0641404\n",
      "[15]\tvalid_0's l1: 0.189208\tvalid_0's l2: 0.0611263\n",
      "[16]\tvalid_0's l1: 0.184274\tvalid_0's l2: 0.0584334\n",
      "[17]\tvalid_0's l1: 0.178555\tvalid_0's l2: 0.0552401\n",
      "[18]\tvalid_0's l1: 0.174243\tvalid_0's l2: 0.0530249\n",
      "[19]\tvalid_0's l1: 0.16927\tvalid_0's l2: 0.0504774\n",
      "[20]\tvalid_0's l1: 0.164626\tvalid_0's l2: 0.0482125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.164626\tvalid_0's l2: 0.0482125\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.329631\tvalid_0's l2: 0.175751\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.317727\tvalid_0's l2: 0.163842\n",
      "[3]\tvalid_0's l1: 0.308483\tvalid_0's l2: 0.155532\n",
      "[4]\tvalid_0's l1: 0.297943\tvalid_0's l2: 0.145874\n",
      "[5]\tvalid_0's l1: 0.290032\tvalid_0's l2: 0.139455\n",
      "[6]\tvalid_0's l1: 0.280186\tvalid_0's l2: 0.130342\n",
      "[7]\tvalid_0's l1: 0.271355\tvalid_0's l2: 0.123202\n",
      "[8]\tvalid_0's l1: 0.263052\tvalid_0's l2: 0.116556\n",
      "[9]\tvalid_0's l1: 0.255266\tvalid_0's l2: 0.110819\n",
      "[10]\tvalid_0's l1: 0.24802\tvalid_0's l2: 0.105463\n",
      "[11]\tvalid_0's l1: 0.241143\tvalid_0's l2: 0.100578\n",
      "[12]\tvalid_0's l1: 0.234671\tvalid_0's l2: 0.0957938\n",
      "[13]\tvalid_0's l1: 0.230364\tvalid_0's l2: 0.0931493\n",
      "[14]\tvalid_0's l1: 0.226328\tvalid_0's l2: 0.0906978\n",
      "[15]\tvalid_0's l1: 0.221133\tvalid_0's l2: 0.0872387\n",
      "[16]\tvalid_0's l1: 0.21751\tvalid_0's l2: 0.0853356\n",
      "[17]\tvalid_0's l1: 0.212726\tvalid_0's l2: 0.0821081\n",
      "[18]\tvalid_0's l1: 0.208443\tvalid_0's l2: 0.0792396\n",
      "[19]\tvalid_0's l1: 0.204726\tvalid_0's l2: 0.0770637\n",
      "[20]\tvalid_0's l1: 0.201012\tvalid_0's l2: 0.0747086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.201012\tvalid_0's l2: 0.0747086\n",
      "[1]\tvalid_0's l1: 0.329646\tvalid_0's l2: 0.175755\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.319843\tvalid_0's l2: 0.166625\n",
      "[3]\tvalid_0's l1: 0.307862\tvalid_0's l2: 0.15459\n",
      "[4]\tvalid_0's l1: 0.297318\tvalid_0's l2: 0.144926\n",
      "[5]\tvalid_0's l1: 0.287492\tvalid_0's l2: 0.136391\n",
      "[6]\tvalid_0's l1: 0.278216\tvalid_0's l2: 0.128582\n",
      "[7]\tvalid_0's l1: 0.269836\tvalid_0's l2: 0.12201\n",
      "[8]\tvalid_0's l1: 0.26164\tvalid_0's l2: 0.115599\n",
      "[9]\tvalid_0's l1: 0.254086\tvalid_0's l2: 0.109904\n",
      "[10]\tvalid_0's l1: 0.247108\tvalid_0's l2: 0.1048\n",
      "[11]\tvalid_0's l1: 0.240908\tvalid_0's l2: 0.100483\n",
      "[12]\tvalid_0's l1: 0.234885\tvalid_0's l2: 0.0961748\n",
      "[13]\tvalid_0's l1: 0.229227\tvalid_0's l2: 0.0922915\n",
      "[14]\tvalid_0's l1: 0.223693\tvalid_0's l2: 0.0885818\n",
      "[15]\tvalid_0's l1: 0.218909\tvalid_0's l2: 0.0855607\n",
      "[16]\tvalid_0's l1: 0.214514\tvalid_0's l2: 0.0829534\n",
      "[17]\tvalid_0's l1: 0.211042\tvalid_0's l2: 0.080893\n",
      "[18]\tvalid_0's l1: 0.207231\tvalid_0's l2: 0.0786999\n",
      "[19]\tvalid_0's l1: 0.204505\tvalid_0's l2: 0.0774617\n",
      "[20]\tvalid_0's l1: 0.201273\tvalid_0's l2: 0.0757271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.201273\tvalid_0's l2: 0.0757271\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.33224\tvalid_0's l2: 0.179115\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32253\tvalid_0's l2: 0.169943\n",
      "[3]\tvalid_0's l1: 0.3152\tvalid_0's l2: 0.16363\n",
      "[4]\tvalid_0's l1: 0.308291\tvalid_0's l2: 0.157971\n",
      "[5]\tvalid_0's l1: 0.301999\tvalid_0's l2: 0.152962\n",
      "[6]\tvalid_0's l1: 0.294848\tvalid_0's l2: 0.147057\n",
      "[7]\tvalid_0's l1: 0.287007\tvalid_0's l2: 0.139743\n",
      "[8]\tvalid_0's l1: 0.282359\tvalid_0's l2: 0.136572\n",
      "[9]\tvalid_0's l1: 0.275515\tvalid_0's l2: 0.130538\n",
      "[10]\tvalid_0's l1: 0.269764\tvalid_0's l2: 0.126636\n",
      "[11]\tvalid_0's l1: 0.264458\tvalid_0's l2: 0.122772\n",
      "[12]\tvalid_0's l1: 0.25956\tvalid_0's l2: 0.11927\n",
      "[13]\tvalid_0's l1: 0.254816\tvalid_0's l2: 0.115957\n",
      "[14]\tvalid_0's l1: 0.250516\tvalid_0's l2: 0.113025\n",
      "[15]\tvalid_0's l1: 0.246555\tvalid_0's l2: 0.110649\n",
      "[16]\tvalid_0's l1: 0.242771\tvalid_0's l2: 0.108377\n",
      "[17]\tvalid_0's l1: 0.239472\tvalid_0's l2: 0.106443\n",
      "[18]\tvalid_0's l1: 0.236842\tvalid_0's l2: 0.105106\n",
      "[19]\tvalid_0's l1: 0.234359\tvalid_0's l2: 0.103898\n",
      "[20]\tvalid_0's l1: 0.231981\tvalid_0's l2: 0.102652\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.231981\tvalid_0's l2: 0.102652\n",
      "[1]\tvalid_0's l1: 0.332335\tvalid_0's l2: 0.179224\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.323757\tvalid_0's l2: 0.170766\n",
      "[3]\tvalid_0's l1: 0.316523\tvalid_0's l2: 0.164848\n",
      "[4]\tvalid_0's l1: 0.3084\tvalid_0's l2: 0.157889\n",
      "[5]\tvalid_0's l1: 0.300441\tvalid_0's l2: 0.151101\n",
      "[6]\tvalid_0's l1: 0.293236\tvalid_0's l2: 0.145271\n",
      "[7]\tvalid_0's l1: 0.287935\tvalid_0's l2: 0.141555\n",
      "[8]\tvalid_0's l1: 0.281358\tvalid_0's l2: 0.136407\n",
      "[9]\tvalid_0's l1: 0.275298\tvalid_0's l2: 0.132074\n",
      "[10]\tvalid_0's l1: 0.26968\tvalid_0's l2: 0.128051\n",
      "[11]\tvalid_0's l1: 0.264367\tvalid_0's l2: 0.124018\n",
      "[12]\tvalid_0's l1: 0.259649\tvalid_0's l2: 0.120685\n",
      "[13]\tvalid_0's l1: 0.255008\tvalid_0's l2: 0.117493\n",
      "[14]\tvalid_0's l1: 0.250929\tvalid_0's l2: 0.114716\n",
      "[15]\tvalid_0's l1: 0.247039\tvalid_0's l2: 0.112194\n",
      "[16]\tvalid_0's l1: 0.243393\tvalid_0's l2: 0.109994\n",
      "[17]\tvalid_0's l1: 0.240278\tvalid_0's l2: 0.108184\n",
      "[18]\tvalid_0's l1: 0.238152\tvalid_0's l2: 0.107385\n",
      "[19]\tvalid_0's l1: 0.235343\tvalid_0's l2: 0.105624\n",
      "[20]\tvalid_0's l1: 0.232802\tvalid_0's l2: 0.104314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.232802\tvalid_0's l2: 0.104314\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.333724\tvalid_0's l2: 0.180871\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.32596\tvalid_0's l2: 0.17389\n",
      "[3]\tvalid_0's l1: 0.318707\tvalid_0's l2: 0.167647\n",
      "[4]\tvalid_0's l1: 0.311975\tvalid_0's l2: 0.162061\n",
      "[5]\tvalid_0's l1: 0.305323\tvalid_0's l2: 0.156126\n",
      "[6]\tvalid_0's l1: 0.299977\tvalid_0's l2: 0.151949\n",
      "[7]\tvalid_0's l1: 0.295139\tvalid_0's l2: 0.148508\n",
      "[8]\tvalid_0's l1: 0.290225\tvalid_0's l2: 0.144445\n",
      "[9]\tvalid_0's l1: 0.285916\tvalid_0's l2: 0.141787\n",
      "[10]\tvalid_0's l1: 0.281876\tvalid_0's l2: 0.138722\n",
      "[11]\tvalid_0's l1: 0.278159\tvalid_0's l2: 0.136487\n",
      "[12]\tvalid_0's l1: 0.274749\tvalid_0's l2: 0.134573\n",
      "[13]\tvalid_0's l1: 0.271903\tvalid_0's l2: 0.133076\n",
      "[14]\tvalid_0's l1: 0.269291\tvalid_0's l2: 0.131702\n",
      "[15]\tvalid_0's l1: 0.266761\tvalid_0's l2: 0.130156\n",
      "[16]\tvalid_0's l1: 0.264524\tvalid_0's l2: 0.128775\n",
      "[17]\tvalid_0's l1: 0.262546\tvalid_0's l2: 0.128187\n",
      "[18]\tvalid_0's l1: 0.260675\tvalid_0's l2: 0.127493\n",
      "[19]\tvalid_0's l1: 0.259281\tvalid_0's l2: 0.126846\n",
      "[20]\tvalid_0's l1: 0.257774\tvalid_0's l2: 0.126438\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.257774\tvalid_0's l2: 0.126438\n",
      "[1]\tvalid_0's l1: 0.33377\tvalid_0's l2: 0.181018\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326045\tvalid_0's l2: 0.174205\n",
      "[3]\tvalid_0's l1: 0.318606\tvalid_0's l2: 0.16804\n",
      "[4]\tvalid_0's l1: 0.311402\tvalid_0's l2: 0.161458\n",
      "[5]\tvalid_0's l1: 0.305331\tvalid_0's l2: 0.156827\n",
      "[6]\tvalid_0's l1: 0.29988\tvalid_0's l2: 0.152808\n",
      "[7]\tvalid_0's l1: 0.294644\tvalid_0's l2: 0.149255\n",
      "[8]\tvalid_0's l1: 0.289971\tvalid_0's l2: 0.145831\n",
      "[9]\tvalid_0's l1: 0.28573\tvalid_0's l2: 0.142681\n",
      "[10]\tvalid_0's l1: 0.281995\tvalid_0's l2: 0.140451\n",
      "[11]\tvalid_0's l1: 0.27841\tvalid_0's l2: 0.138267\n",
      "[12]\tvalid_0's l1: 0.274947\tvalid_0's l2: 0.135657\n",
      "[13]\tvalid_0's l1: 0.272034\tvalid_0's l2: 0.133871\n",
      "[14]\tvalid_0's l1: 0.269445\tvalid_0's l2: 0.132351\n",
      "[15]\tvalid_0's l1: 0.267051\tvalid_0's l2: 0.131023\n",
      "[16]\tvalid_0's l1: 0.264752\tvalid_0's l2: 0.1296\n",
      "[17]\tvalid_0's l1: 0.262936\tvalid_0's l2: 0.128811\n",
      "[18]\tvalid_0's l1: 0.261073\tvalid_0's l2: 0.128141\n",
      "[19]\tvalid_0's l1: 0.25965\tvalid_0's l2: 0.127889\n",
      "[20]\tvalid_0's l1: 0.258199\tvalid_0's l2: 0.12747\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.258199\tvalid_0's l2: 0.12747\n",
      "Starting predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334155\tvalid_0's l2: 0.181215\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326583\tvalid_0's l2: 0.17426\n",
      "[3]\tvalid_0's l1: 0.319686\tvalid_0's l2: 0.168424\n",
      "[4]\tvalid_0's l1: 0.313272\tvalid_0's l2: 0.163224\n",
      "[5]\tvalid_0's l1: 0.307278\tvalid_0's l2: 0.158577\n",
      "[6]\tvalid_0's l1: 0.301653\tvalid_0's l2: 0.153875\n",
      "[7]\tvalid_0's l1: 0.296909\tvalid_0's l2: 0.150536\n",
      "[8]\tvalid_0's l1: 0.292521\tvalid_0's l2: 0.147661\n",
      "[9]\tvalid_0's l1: 0.288715\tvalid_0's l2: 0.145501\n",
      "[10]\tvalid_0's l1: 0.285247\tvalid_0's l2: 0.143461\n",
      "[11]\tvalid_0's l1: 0.282055\tvalid_0's l2: 0.141512\n",
      "[12]\tvalid_0's l1: 0.279035\tvalid_0's l2: 0.139583\n",
      "[13]\tvalid_0's l1: 0.276466\tvalid_0's l2: 0.138272\n",
      "[14]\tvalid_0's l1: 0.274074\tvalid_0's l2: 0.137225\n",
      "[15]\tvalid_0's l1: 0.271953\tvalid_0's l2: 0.136185\n",
      "[16]\tvalid_0's l1: 0.269958\tvalid_0's l2: 0.135321\n",
      "[17]\tvalid_0's l1: 0.268157\tvalid_0's l2: 0.134457\n",
      "[18]\tvalid_0's l1: 0.266638\tvalid_0's l2: 0.133816\n",
      "[19]\tvalid_0's l1: 0.265029\tvalid_0's l2: 0.133441\n",
      "[20]\tvalid_0's l1: 0.263892\tvalid_0's l2: 0.133278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.263892\tvalid_0's l2: 0.133278\n",
      "[1]\tvalid_0's l1: 0.334191\tvalid_0's l2: 0.181701\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.326257\tvalid_0's l2: 0.173432\n",
      "[3]\tvalid_0's l1: 0.319646\tvalid_0's l2: 0.168327\n",
      "[4]\tvalid_0's l1: 0.313105\tvalid_0's l2: 0.162923\n",
      "[5]\tvalid_0's l1: 0.307018\tvalid_0's l2: 0.157753\n",
      "[6]\tvalid_0's l1: 0.301605\tvalid_0's l2: 0.153303\n",
      "[7]\tvalid_0's l1: 0.296765\tvalid_0's l2: 0.150095\n",
      "[8]\tvalid_0's l1: 0.292539\tvalid_0's l2: 0.147436\n",
      "[9]\tvalid_0's l1: 0.288776\tvalid_0's l2: 0.145288\n",
      "[10]\tvalid_0's l1: 0.285111\tvalid_0's l2: 0.143224\n",
      "[11]\tvalid_0's l1: 0.281868\tvalid_0's l2: 0.141446\n",
      "[12]\tvalid_0's l1: 0.279075\tvalid_0's l2: 0.139959\n",
      "[13]\tvalid_0's l1: 0.276471\tvalid_0's l2: 0.138098\n",
      "[14]\tvalid_0's l1: 0.274257\tvalid_0's l2: 0.137191\n",
      "[15]\tvalid_0's l1: 0.272184\tvalid_0's l2: 0.136329\n",
      "[16]\tvalid_0's l1: 0.270402\tvalid_0's l2: 0.135628\n",
      "[17]\tvalid_0's l1: 0.268799\tvalid_0's l2: 0.135131\n",
      "[18]\tvalid_0's l1: 0.26722\tvalid_0's l2: 0.134624\n",
      "[19]\tvalid_0's l1: 0.265956\tvalid_0's l2: 0.134597\n",
      "[20]\tvalid_0's l1: 0.264627\tvalid_0's l2: 0.134212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.264627\tvalid_0's l2: 0.134212\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.334587\tvalid_0's l2: 0.181708\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327962\tvalid_0's l2: 0.176094\n",
      "[3]\tvalid_0's l1: 0.321765\tvalid_0's l2: 0.17127\n",
      "[4]\tvalid_0's l1: 0.315262\tvalid_0's l2: 0.165242\n",
      "[5]\tvalid_0's l1: 0.310152\tvalid_0's l2: 0.161539\n",
      "[6]\tvalid_0's l1: 0.305085\tvalid_0's l2: 0.158066\n",
      "[7]\tvalid_0's l1: 0.300564\tvalid_0's l2: 0.155043\n",
      "[8]\tvalid_0's l1: 0.296826\tvalid_0's l2: 0.152756\n",
      "[9]\tvalid_0's l1: 0.293365\tvalid_0's l2: 0.150824\n",
      "[10]\tvalid_0's l1: 0.290326\tvalid_0's l2: 0.149301\n",
      "[11]\tvalid_0's l1: 0.287726\tvalid_0's l2: 0.147981\n",
      "[12]\tvalid_0's l1: 0.284785\tvalid_0's l2: 0.146064\n",
      "[13]\tvalid_0's l1: 0.282229\tvalid_0's l2: 0.144966\n",
      "[14]\tvalid_0's l1: 0.27997\tvalid_0's l2: 0.144007\n",
      "[15]\tvalid_0's l1: 0.277948\tvalid_0's l2: 0.143047\n",
      "[16]\tvalid_0's l1: 0.27621\tvalid_0's l2: 0.142621\n",
      "[17]\tvalid_0's l1: 0.27484\tvalid_0's l2: 0.142078\n",
      "[18]\tvalid_0's l1: 0.27321\tvalid_0's l2: 0.141684\n",
      "[19]\tvalid_0's l1: 0.272128\tvalid_0's l2: 0.141803\n",
      "[20]\tvalid_0's l1: 0.271199\tvalid_0's l2: 0.141942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.271199\tvalid_0's l2: 0.141942\n",
      "[1]\tvalid_0's l1: 0.334394\tvalid_0's l2: 0.181852\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.327506\tvalid_0's l2: 0.176401\n",
      "[3]\tvalid_0's l1: 0.320381\tvalid_0's l2: 0.169336\n",
      "[4]\tvalid_0's l1: 0.314411\tvalid_0's l2: 0.164847\n",
      "[5]\tvalid_0's l1: 0.309184\tvalid_0's l2: 0.161163\n",
      "[6]\tvalid_0's l1: 0.304311\tvalid_0's l2: 0.157847\n",
      "[7]\tvalid_0's l1: 0.29982\tvalid_0's l2: 0.154948\n",
      "[8]\tvalid_0's l1: 0.29584\tvalid_0's l2: 0.152469\n",
      "[9]\tvalid_0's l1: 0.292527\tvalid_0's l2: 0.150681\n",
      "[10]\tvalid_0's l1: 0.28932\tvalid_0's l2: 0.148601\n",
      "[11]\tvalid_0's l1: 0.286632\tvalid_0's l2: 0.147477\n",
      "[12]\tvalid_0's l1: 0.283906\tvalid_0's l2: 0.146009\n",
      "[13]\tvalid_0's l1: 0.281855\tvalid_0's l2: 0.145084\n",
      "[14]\tvalid_0's l1: 0.280166\tvalid_0's l2: 0.144363\n",
      "[15]\tvalid_0's l1: 0.278557\tvalid_0's l2: 0.144078\n",
      "[16]\tvalid_0's l1: 0.277031\tvalid_0's l2: 0.143907\n",
      "[17]\tvalid_0's l1: 0.275611\tvalid_0's l2: 0.143621\n",
      "[18]\tvalid_0's l1: 0.274632\tvalid_0's l2: 0.143807\n",
      "[19]\tvalid_0's l1: 0.273978\tvalid_0's l2: 0.144149\n",
      "[20]\tvalid_0's l1: 0.273001\tvalid_0's l2: 0.144334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.273001\tvalid_0's l2: 0.144334\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DFma_1), \n",
    "# MAE (DFma_1), \n",
    "# SMAPE (DFma_1), \n",
    "# R-squared (DFma_1)\n",
    "\n",
    "# col: head,\n",
    "# MA2 (without CD, with CD, % improved),\n",
    "# MA3 (without CD, with CD, % improved),\n",
    "# MA4 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'MA2 without CD', 'MA2 with CD', 'MA2 % improved', \n",
    "                         'MA3 without CD', 'MA3 with CD', 'MA3 % improved', \n",
    "                         'MA4 without CD', 'MA4 with CD', 'MA4 % improved']])\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "# Starting from MA2 to MA4\n",
    "for i in range(2, 5):\n",
    "    # Get the input variables from CSV file\n",
    "    # Change files directory here\n",
    "    train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_cd_mavg' + str(i) + '.csv'\n",
    "    \n",
    "    df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "    df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "    # Continue on DFma_1 to DFma_6\n",
    "    for j in range(6):\n",
    "        # Allocate the column of addrcode, week, year and actual values first\n",
    "        df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:, [1, 2, 3, 12]]\n",
    "        \n",
    "        ## Without CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # and LST_wm4 [col 21]\n",
    "        \n",
    "        ## With CD ##\n",
    "    \n",
    "        # Import the dataset\n",
    "        # x: independent variables\n",
    "        # DFma_0 [col 13],\n",
    "        # DFma_wm1 [col 14],\n",
    "        # DFma_wm2 [col 15],\n",
    "        # DFma_wm3 [col 16],\n",
    "        # DFma_wm4 [col 17],\n",
    "        # DFma_wm5 [col 18],\n",
    "        # DFma_wm6 [col 19],\n",
    "        # RF_wm6 [col 20],\n",
    "        # LST_wm4 [col 21]\n",
    "        # bin [col 22],\n",
    "        # bowl [col 23],\n",
    "        # bucket [col 24],\n",
    "        # misc_short [col 25],\n",
    "        # jar [col 26],\n",
    "        # pottedplant [col 27],\n",
    "        # tire [col 28],\n",
    "        # misc_tall [col 29],\n",
    "        # and total [col 30]\n",
    "        \n",
    "        x_train_withoutCD = df_train_subdist.iloc[:, (13 + j): 22]\n",
    "        x_train_withCD = df_train_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        x_test_withoutCD = df_test_subdist.iloc[:, (13 + j): 22]\n",
    "        x_test_withCD = df_test_subdist.iloc[:, (13 + j): 31]\n",
    "        \n",
    "        # y: response (target) variable DFma_1 [col 12]\n",
    "        y_train = df_train_subdist.iloc[:, [12]]\n",
    "        y_test = df_test_subdist.iloc[:, [12]]\n",
    "        \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        y_train_true = np.array(df_train_subdist['DFma_1'])\n",
    "        y_test_true = np.array(df_test_subdist['DFma_1'])\n",
    "        \n",
    "        # Pass the dataset of both independent and response variables to Light GBM\n",
    "        lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "        lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "        lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "        lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        print('Starting training...')\n",
    "        gbm_withoutCD = lgb.train(params,\n",
    "                    lgb_train_withoutCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withoutCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withoutCD.save_model('model.txt')\n",
    "        \n",
    "        gbm_withCD = lgb.train(params,\n",
    "                    lgb_train_withCD,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets = lgb_eval_withCD,\n",
    "                    early_stopping_rounds = 6)\n",
    "        #print('Saving model...')\n",
    "        # Save model to file\n",
    "        #gbm_withCD.save_model('model.txt')\n",
    "\n",
    "        # Predict out by using test data\n",
    "        print('Starting predicting...')\n",
    "        y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "        y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "        df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "        df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "        # Store all of the predicted values to the CSV files\n",
    "        df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                                  + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' \n",
    "                                                  + str(i) + '_horizon_' + str(j + 1) + '_withoutCD_' + str(num_leaves) \n",
    "                                                  + '.csv', encoding = 'utf-8')\n",
    "\n",
    "        df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "        df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "        df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                               + str(num_leaves) + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' \n",
    "                                               + str(i) + '_horizon_' + str(j + 1) + '_withCD_' + str(num_leaves) + '.csv', \n",
    "                                               encoding = 'utf-8')\n",
    "        \n",
    "        # Evaluation\n",
    "        rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "        r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "        smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "        #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "        #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "        #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "        #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "        rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "        mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "        r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "        smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "        #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "        #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "        #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "        #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "        rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "        mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "        smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "        r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "        #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        #print(eval_array)\n",
    "        \n",
    "        rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "        mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "        smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "        r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "        df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                   + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                   + '_withoutCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/MA' + str(i) + '/LGBM_' + province2 + '_subdist_MA' + str(i) + '_horizon_' + str(j + 1) \n",
    "                                + '_withCD_' + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "        subdist_code = df_train_subdist['addrcode'].unique()\n",
    "        \n",
    "        # For each district\n",
    "        for k in subdist_code:\n",
    "            \n",
    "            # Get the subset of actual and predicted values according to the district code\n",
    "            subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == k]\n",
    "            subset_withCD = df_withCD.loc[df_withCD['addrcode'] == k]\n",
    "            \n",
    "            # Pass the response values to the array for evaluation calculation\n",
    "            array_true = np.array(subset_withoutCD['actual'])\n",
    "            array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "            array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "            # Calculate the evaluation values\n",
    "            rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "            mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "            smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "            r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "            rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "            mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "            smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "            r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "            rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "            mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "            smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "            r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "            # Append\n",
    "            subdist_array = np.append(subdist_array, [[k, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                                mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                                smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                                r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "        #print(dist_array)\n",
    "        pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                        + '/MA' + str(i) + '/LGBM_' + province2 + '_BySubDistrict_MA' + str(i) + '_horizon_' \n",
    "                                        + str(j + 1) + '_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                        encoding = 'utf-8')\n",
    "        \n",
    "        # Clear the old memory to store a new one\n",
    "        subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DFma_1 to R squared DFma_6\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/LGBM_' + province2 + '_subdist_eval_' + str(num_leaves) + '.csv', header = False, \n",
    "                                encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For original DF_0 (without smoothing, normal CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.449625\tvalid_0's l2: 0.367072\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.442645\tvalid_0's l2: 0.359194\n",
      "[3]\tvalid_0's l1: 0.436086\tvalid_0's l2: 0.352044\n",
      "[4]\tvalid_0's l1: 0.430176\tvalid_0's l2: 0.345791\n",
      "[5]\tvalid_0's l1: 0.424605\tvalid_0's l2: 0.34018\n",
      "[6]\tvalid_0's l1: 0.419093\tvalid_0's l2: 0.335408\n",
      "[7]\tvalid_0's l1: 0.41378\tvalid_0's l2: 0.329977\n",
      "[8]\tvalid_0's l1: 0.408962\tvalid_0's l2: 0.325856\n",
      "[9]\tvalid_0's l1: 0.404733\tvalid_0's l2: 0.3226\n",
      "[10]\tvalid_0's l1: 0.400382\tvalid_0's l2: 0.318656\n",
      "[11]\tvalid_0's l1: 0.396557\tvalid_0's l2: 0.315551\n",
      "[12]\tvalid_0's l1: 0.392996\tvalid_0's l2: 0.313066\n",
      "[13]\tvalid_0's l1: 0.38963\tvalid_0's l2: 0.310503\n",
      "[14]\tvalid_0's l1: 0.386476\tvalid_0's l2: 0.308327\n",
      "[15]\tvalid_0's l1: 0.383571\tvalid_0's l2: 0.306385\n",
      "[16]\tvalid_0's l1: 0.380883\tvalid_0's l2: 0.304371\n",
      "[17]\tvalid_0's l1: 0.378166\tvalid_0's l2: 0.302887\n",
      "[18]\tvalid_0's l1: 0.375897\tvalid_0's l2: 0.30183\n",
      "[19]\tvalid_0's l1: 0.373708\tvalid_0's l2: 0.301119\n",
      "[20]\tvalid_0's l1: 0.371435\tvalid_0's l2: 0.299773\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.371435\tvalid_0's l2: 0.299773\n",
      "[1]\tvalid_0's l1: 0.449639\tvalid_0's l2: 0.367377\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.442801\tvalid_0's l2: 0.359789\n",
      "[3]\tvalid_0's l1: 0.436306\tvalid_0's l2: 0.35278\n",
      "[4]\tvalid_0's l1: 0.430038\tvalid_0's l2: 0.346406\n",
      "[5]\tvalid_0's l1: 0.424504\tvalid_0's l2: 0.340832\n",
      "[6]\tvalid_0's l1: 0.419276\tvalid_0's l2: 0.336304\n",
      "[7]\tvalid_0's l1: 0.414098\tvalid_0's l2: 0.331726\n",
      "[8]\tvalid_0's l1: 0.409316\tvalid_0's l2: 0.32787\n",
      "[9]\tvalid_0's l1: 0.40484\tvalid_0's l2: 0.324189\n",
      "[10]\tvalid_0's l1: 0.400905\tvalid_0's l2: 0.321297\n",
      "[11]\tvalid_0's l1: 0.397069\tvalid_0's l2: 0.318335\n",
      "[12]\tvalid_0's l1: 0.393637\tvalid_0's l2: 0.315778\n",
      "[13]\tvalid_0's l1: 0.390471\tvalid_0's l2: 0.313309\n",
      "[14]\tvalid_0's l1: 0.3874\tvalid_0's l2: 0.311033\n",
      "[15]\tvalid_0's l1: 0.384667\tvalid_0's l2: 0.309326\n",
      "[16]\tvalid_0's l1: 0.382062\tvalid_0's l2: 0.307328\n",
      "[17]\tvalid_0's l1: 0.379681\tvalid_0's l2: 0.306054\n",
      "[18]\tvalid_0's l1: 0.377149\tvalid_0's l2: 0.304323\n",
      "[19]\tvalid_0's l1: 0.374916\tvalid_0's l2: 0.30315\n",
      "[20]\tvalid_0's l1: 0.372845\tvalid_0's l2: 0.302143\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.372845\tvalid_0's l2: 0.302143\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45032\tvalid_0's l2: 0.368633\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444011\tvalid_0's l2: 0.362207\n",
      "[3]\tvalid_0's l1: 0.438039\tvalid_0's l2: 0.355996\n",
      "[4]\tvalid_0's l1: 0.432437\tvalid_0's l2: 0.350367\n",
      "[5]\tvalid_0's l1: 0.427649\tvalid_0's l2: 0.346089\n",
      "[6]\tvalid_0's l1: 0.42255\tvalid_0's l2: 0.34065\n",
      "[7]\tvalid_0's l1: 0.418029\tvalid_0's l2: 0.336699\n",
      "[8]\tvalid_0's l1: 0.4138\tvalid_0's l2: 0.333159\n",
      "[9]\tvalid_0's l1: 0.40977\tvalid_0's l2: 0.329987\n",
      "[10]\tvalid_0's l1: 0.405933\tvalid_0's l2: 0.327236\n",
      "[11]\tvalid_0's l1: 0.402465\tvalid_0's l2: 0.324637\n",
      "[12]\tvalid_0's l1: 0.399438\tvalid_0's l2: 0.32157\n",
      "[13]\tvalid_0's l1: 0.396388\tvalid_0's l2: 0.319382\n",
      "[14]\tvalid_0's l1: 0.393638\tvalid_0's l2: 0.317174\n",
      "[15]\tvalid_0's l1: 0.391099\tvalid_0's l2: 0.315642\n",
      "[16]\tvalid_0's l1: 0.388552\tvalid_0's l2: 0.314283\n",
      "[17]\tvalid_0's l1: 0.386312\tvalid_0's l2: 0.312405\n",
      "[18]\tvalid_0's l1: 0.384189\tvalid_0's l2: 0.310925\n",
      "[19]\tvalid_0's l1: 0.382168\tvalid_0's l2: 0.309903\n",
      "[20]\tvalid_0's l1: 0.380424\tvalid_0's l2: 0.309123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.380424\tvalid_0's l2: 0.309123\n",
      "[1]\tvalid_0's l1: 0.450303\tvalid_0's l2: 0.368934\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444313\tvalid_0's l2: 0.362917\n",
      "[3]\tvalid_0's l1: 0.438322\tvalid_0's l2: 0.355579\n",
      "[4]\tvalid_0's l1: 0.43279\tvalid_0's l2: 0.350141\n",
      "[5]\tvalid_0's l1: 0.427753\tvalid_0's l2: 0.345677\n",
      "[6]\tvalid_0's l1: 0.423006\tvalid_0's l2: 0.341606\n",
      "[7]\tvalid_0's l1: 0.418429\tvalid_0's l2: 0.3378\n",
      "[8]\tvalid_0's l1: 0.41405\tvalid_0's l2: 0.334332\n",
      "[9]\tvalid_0's l1: 0.409967\tvalid_0's l2: 0.331312\n",
      "[10]\tvalid_0's l1: 0.406305\tvalid_0's l2: 0.328404\n",
      "[11]\tvalid_0's l1: 0.403039\tvalid_0's l2: 0.326245\n",
      "[12]\tvalid_0's l1: 0.399732\tvalid_0's l2: 0.323653\n",
      "[13]\tvalid_0's l1: 0.396969\tvalid_0's l2: 0.321692\n",
      "[14]\tvalid_0's l1: 0.394297\tvalid_0's l2: 0.320004\n",
      "[15]\tvalid_0's l1: 0.391575\tvalid_0's l2: 0.318172\n",
      "[16]\tvalid_0's l1: 0.389092\tvalid_0's l2: 0.316628\n",
      "[17]\tvalid_0's l1: 0.386733\tvalid_0's l2: 0.31464\n",
      "[18]\tvalid_0's l1: 0.384443\tvalid_0's l2: 0.313156\n",
      "[19]\tvalid_0's l1: 0.382352\tvalid_0's l2: 0.312358\n",
      "[20]\tvalid_0's l1: 0.38032\tvalid_0's l2: 0.310991\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.38032\tvalid_0's l2: 0.310991\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.450251\tvalid_0's l2: 0.368617\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.443955\tvalid_0's l2: 0.36224\n",
      "[3]\tvalid_0's l1: 0.438345\tvalid_0's l2: 0.35677\n",
      "[4]\tvalid_0's l1: 0.43299\tvalid_0's l2: 0.351986\n",
      "[5]\tvalid_0's l1: 0.42831\tvalid_0's l2: 0.347742\n",
      "[6]\tvalid_0's l1: 0.423332\tvalid_0's l2: 0.343586\n",
      "[7]\tvalid_0's l1: 0.418735\tvalid_0's l2: 0.338873\n",
      "[8]\tvalid_0's l1: 0.41448\tvalid_0's l2: 0.3357\n",
      "[9]\tvalid_0's l1: 0.4106\tvalid_0's l2: 0.331793\n",
      "[10]\tvalid_0's l1: 0.406997\tvalid_0's l2: 0.329611\n",
      "[11]\tvalid_0's l1: 0.40389\tvalid_0's l2: 0.327389\n",
      "[12]\tvalid_0's l1: 0.400826\tvalid_0's l2: 0.325171\n",
      "[13]\tvalid_0's l1: 0.397873\tvalid_0's l2: 0.323164\n",
      "[14]\tvalid_0's l1: 0.395317\tvalid_0's l2: 0.32158\n",
      "[15]\tvalid_0's l1: 0.39264\tvalid_0's l2: 0.319691\n",
      "[16]\tvalid_0's l1: 0.390334\tvalid_0's l2: 0.318371\n",
      "[17]\tvalid_0's l1: 0.388104\tvalid_0's l2: 0.317391\n",
      "[18]\tvalid_0's l1: 0.385859\tvalid_0's l2: 0.316471\n",
      "[19]\tvalid_0's l1: 0.38352\tvalid_0's l2: 0.315519\n",
      "[20]\tvalid_0's l1: 0.381868\tvalid_0's l2: 0.314834\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.381868\tvalid_0's l2: 0.314834\n",
      "[1]\tvalid_0's l1: 0.450588\tvalid_0's l2: 0.369575\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.444605\tvalid_0's l2: 0.361835\n",
      "[3]\tvalid_0's l1: 0.439188\tvalid_0's l2: 0.356932\n",
      "[4]\tvalid_0's l1: 0.433933\tvalid_0's l2: 0.352399\n",
      "[5]\tvalid_0's l1: 0.42867\tvalid_0's l2: 0.347618\n",
      "[6]\tvalid_0's l1: 0.423673\tvalid_0's l2: 0.343838\n",
      "[7]\tvalid_0's l1: 0.419266\tvalid_0's l2: 0.340469\n",
      "[8]\tvalid_0's l1: 0.415046\tvalid_0's l2: 0.337257\n",
      "[9]\tvalid_0's l1: 0.411165\tvalid_0's l2: 0.33466\n",
      "[10]\tvalid_0's l1: 0.407578\tvalid_0's l2: 0.33241\n",
      "[11]\tvalid_0's l1: 0.404264\tvalid_0's l2: 0.329966\n",
      "[12]\tvalid_0's l1: 0.401228\tvalid_0's l2: 0.327666\n",
      "[13]\tvalid_0's l1: 0.398389\tvalid_0's l2: 0.325937\n",
      "[14]\tvalid_0's l1: 0.395722\tvalid_0's l2: 0.324243\n",
      "[15]\tvalid_0's l1: 0.393239\tvalid_0's l2: 0.322547\n",
      "[16]\tvalid_0's l1: 0.390824\tvalid_0's l2: 0.321153\n",
      "[17]\tvalid_0's l1: 0.388746\tvalid_0's l2: 0.319976\n",
      "[18]\tvalid_0's l1: 0.386619\tvalid_0's l2: 0.319047\n",
      "[19]\tvalid_0's l1: 0.384546\tvalid_0's l2: 0.318176\n",
      "[20]\tvalid_0's l1: 0.382915\tvalid_0's l2: 0.317368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.382915\tvalid_0's l2: 0.317368\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.450812\tvalid_0's l2: 0.36954\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445132\tvalid_0's l2: 0.364018\n",
      "[3]\tvalid_0's l1: 0.439441\tvalid_0's l2: 0.35859\n",
      "[4]\tvalid_0's l1: 0.434749\tvalid_0's l2: 0.35447\n",
      "[5]\tvalid_0's l1: 0.430019\tvalid_0's l2: 0.348672\n",
      "[6]\tvalid_0's l1: 0.425211\tvalid_0's l2: 0.344771\n",
      "[7]\tvalid_0's l1: 0.420855\tvalid_0's l2: 0.341476\n",
      "[8]\tvalid_0's l1: 0.417042\tvalid_0's l2: 0.33709\n",
      "[9]\tvalid_0's l1: 0.413314\tvalid_0's l2: 0.33464\n",
      "[10]\tvalid_0's l1: 0.410043\tvalid_0's l2: 0.331213\n",
      "[11]\tvalid_0's l1: 0.406998\tvalid_0's l2: 0.329088\n",
      "[12]\tvalid_0's l1: 0.404175\tvalid_0's l2: 0.327276\n",
      "[13]\tvalid_0's l1: 0.401693\tvalid_0's l2: 0.326053\n",
      "[14]\tvalid_0's l1: 0.399307\tvalid_0's l2: 0.324401\n",
      "[15]\tvalid_0's l1: 0.396967\tvalid_0's l2: 0.32266\n",
      "[16]\tvalid_0's l1: 0.394864\tvalid_0's l2: 0.32112\n",
      "[17]\tvalid_0's l1: 0.392823\tvalid_0's l2: 0.320193\n",
      "[18]\tvalid_0's l1: 0.390709\tvalid_0's l2: 0.319222\n",
      "[19]\tvalid_0's l1: 0.389059\tvalid_0's l2: 0.318255\n",
      "[20]\tvalid_0's l1: 0.387266\tvalid_0's l2: 0.317452\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.387266\tvalid_0's l2: 0.317452\n",
      "[1]\tvalid_0's l1: 0.450932\tvalid_0's l2: 0.369814\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445602\tvalid_0's l2: 0.365024\n",
      "[3]\tvalid_0's l1: 0.439916\tvalid_0's l2: 0.359698\n",
      "[4]\tvalid_0's l1: 0.434919\tvalid_0's l2: 0.353604\n",
      "[5]\tvalid_0's l1: 0.430336\tvalid_0's l2: 0.349873\n",
      "[6]\tvalid_0's l1: 0.425361\tvalid_0's l2: 0.345707\n",
      "[7]\tvalid_0's l1: 0.421193\tvalid_0's l2: 0.342726\n",
      "[8]\tvalid_0's l1: 0.417149\tvalid_0's l2: 0.339675\n",
      "[9]\tvalid_0's l1: 0.413803\tvalid_0's l2: 0.3361\n",
      "[10]\tvalid_0's l1: 0.410541\tvalid_0's l2: 0.333832\n",
      "[11]\tvalid_0's l1: 0.407562\tvalid_0's l2: 0.331768\n",
      "[12]\tvalid_0's l1: 0.404957\tvalid_0's l2: 0.330177\n",
      "[13]\tvalid_0's l1: 0.402617\tvalid_0's l2: 0.328616\n",
      "[14]\tvalid_0's l1: 0.400297\tvalid_0's l2: 0.327493\n",
      "[15]\tvalid_0's l1: 0.398204\tvalid_0's l2: 0.32661\n",
      "[16]\tvalid_0's l1: 0.395917\tvalid_0's l2: 0.325272\n",
      "[17]\tvalid_0's l1: 0.393797\tvalid_0's l2: 0.324063\n",
      "[18]\tvalid_0's l1: 0.391786\tvalid_0's l2: 0.32299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalid_0's l1: 0.389917\tvalid_0's l2: 0.322409\n",
      "[20]\tvalid_0's l1: 0.388662\tvalid_0's l2: 0.321862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.388662\tvalid_0's l2: 0.321862\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.45101\tvalid_0's l2: 0.369932\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.445455\tvalid_0's l2: 0.364613\n",
      "[3]\tvalid_0's l1: 0.440183\tvalid_0's l2: 0.360025\n",
      "[4]\tvalid_0's l1: 0.435265\tvalid_0's l2: 0.35576\n",
      "[5]\tvalid_0's l1: 0.430862\tvalid_0's l2: 0.352298\n",
      "[6]\tvalid_0's l1: 0.426884\tvalid_0's l2: 0.347885\n",
      "[7]\tvalid_0's l1: 0.422948\tvalid_0's l2: 0.344929\n",
      "[8]\tvalid_0's l1: 0.419197\tvalid_0's l2: 0.342197\n",
      "[9]\tvalid_0's l1: 0.416078\tvalid_0's l2: 0.340121\n",
      "[10]\tvalid_0's l1: 0.412905\tvalid_0's l2: 0.338285\n",
      "[11]\tvalid_0's l1: 0.410211\tvalid_0's l2: 0.336813\n",
      "[12]\tvalid_0's l1: 0.407508\tvalid_0's l2: 0.334721\n",
      "[13]\tvalid_0's l1: 0.40511\tvalid_0's l2: 0.333409\n",
      "[14]\tvalid_0's l1: 0.402822\tvalid_0's l2: 0.332436\n",
      "[15]\tvalid_0's l1: 0.400737\tvalid_0's l2: 0.331206\n",
      "[16]\tvalid_0's l1: 0.398657\tvalid_0's l2: 0.330421\n",
      "[17]\tvalid_0's l1: 0.397095\tvalid_0's l2: 0.329786\n",
      "[18]\tvalid_0's l1: 0.395739\tvalid_0's l2: 0.329351\n",
      "[19]\tvalid_0's l1: 0.394095\tvalid_0's l2: 0.328949\n",
      "[20]\tvalid_0's l1: 0.392692\tvalid_0's l2: 0.328397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.392692\tvalid_0's l2: 0.328397\n",
      "[1]\tvalid_0's l1: 0.450885\tvalid_0's l2: 0.369605\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.446182\tvalid_0's l2: 0.364028\n",
      "[3]\tvalid_0's l1: 0.441337\tvalid_0's l2: 0.359567\n",
      "[4]\tvalid_0's l1: 0.436145\tvalid_0's l2: 0.355101\n",
      "[5]\tvalid_0's l1: 0.431493\tvalid_0's l2: 0.351426\n",
      "[6]\tvalid_0's l1: 0.427753\tvalid_0's l2: 0.34741\n",
      "[7]\tvalid_0's l1: 0.423604\tvalid_0's l2: 0.344116\n",
      "[8]\tvalid_0's l1: 0.419855\tvalid_0's l2: 0.3415\n",
      "[9]\tvalid_0's l1: 0.416406\tvalid_0's l2: 0.339427\n",
      "[10]\tvalid_0's l1: 0.413201\tvalid_0's l2: 0.337468\n",
      "[11]\tvalid_0's l1: 0.41048\tvalid_0's l2: 0.336025\n",
      "[12]\tvalid_0's l1: 0.408073\tvalid_0's l2: 0.334498\n",
      "[13]\tvalid_0's l1: 0.406139\tvalid_0's l2: 0.3331\n",
      "[14]\tvalid_0's l1: 0.404164\tvalid_0's l2: 0.332176\n",
      "[15]\tvalid_0's l1: 0.402204\tvalid_0's l2: 0.331215\n",
      "[16]\tvalid_0's l1: 0.400059\tvalid_0's l2: 0.330267\n",
      "[17]\tvalid_0's l1: 0.398189\tvalid_0's l2: 0.329289\n",
      "[18]\tvalid_0's l1: 0.396317\tvalid_0's l2: 0.328711\n",
      "[19]\tvalid_0's l1: 0.394727\tvalid_0's l2: 0.328209\n",
      "[20]\tvalid_0's l1: 0.393114\tvalid_0's l2: 0.327698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.393114\tvalid_0's l2: 0.327698\n",
      "Starting predicting...\n",
      "Starting training...\n",
      "[1]\tvalid_0's l1: 0.452355\tvalid_0's l2: 0.371747\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.448013\tvalid_0's l2: 0.367953\n",
      "[3]\tvalid_0's l1: 0.443339\tvalid_0's l2: 0.36409\n",
      "[4]\tvalid_0's l1: 0.439201\tvalid_0's l2: 0.359651\n",
      "[5]\tvalid_0's l1: 0.43571\tvalid_0's l2: 0.357326\n",
      "[6]\tvalid_0's l1: 0.432138\tvalid_0's l2: 0.355018\n",
      "[7]\tvalid_0's l1: 0.428719\tvalid_0's l2: 0.353035\n",
      "[8]\tvalid_0's l1: 0.425691\tvalid_0's l2: 0.351235\n",
      "[9]\tvalid_0's l1: 0.422858\tvalid_0's l2: 0.349975\n",
      "[10]\tvalid_0's l1: 0.420606\tvalid_0's l2: 0.348698\n",
      "[11]\tvalid_0's l1: 0.418497\tvalid_0's l2: 0.347702\n",
      "[12]\tvalid_0's l1: 0.416359\tvalid_0's l2: 0.346022\n",
      "[13]\tvalid_0's l1: 0.414117\tvalid_0's l2: 0.344942\n",
      "[14]\tvalid_0's l1: 0.411865\tvalid_0's l2: 0.343844\n",
      "[15]\tvalid_0's l1: 0.410174\tvalid_0's l2: 0.343001\n",
      "[16]\tvalid_0's l1: 0.408408\tvalid_0's l2: 0.342725\n",
      "[17]\tvalid_0's l1: 0.406762\tvalid_0's l2: 0.341809\n",
      "[18]\tvalid_0's l1: 0.404954\tvalid_0's l2: 0.341362\n",
      "[19]\tvalid_0's l1: 0.40373\tvalid_0's l2: 0.341504\n",
      "[20]\tvalid_0's l1: 0.402503\tvalid_0's l2: 0.341661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.402503\tvalid_0's l2: 0.341661\n",
      "[1]\tvalid_0's l1: 0.452236\tvalid_0's l2: 0.371243\n",
      "Training until validation scores don't improve for 6 rounds.\n",
      "[2]\tvalid_0's l1: 0.447419\tvalid_0's l2: 0.367252\n",
      "[3]\tvalid_0's l1: 0.443063\tvalid_0's l2: 0.362118\n",
      "[4]\tvalid_0's l1: 0.439277\tvalid_0's l2: 0.359125\n",
      "[5]\tvalid_0's l1: 0.434981\tvalid_0's l2: 0.35562\n",
      "[6]\tvalid_0's l1: 0.430945\tvalid_0's l2: 0.352773\n",
      "[7]\tvalid_0's l1: 0.427126\tvalid_0's l2: 0.350221\n",
      "[8]\tvalid_0's l1: 0.423582\tvalid_0's l2: 0.348185\n",
      "[9]\tvalid_0's l1: 0.420589\tvalid_0's l2: 0.346411\n",
      "[10]\tvalid_0's l1: 0.418131\tvalid_0's l2: 0.344211\n",
      "[11]\tvalid_0's l1: 0.415547\tvalid_0's l2: 0.342328\n",
      "[12]\tvalid_0's l1: 0.413239\tvalid_0's l2: 0.340974\n",
      "[13]\tvalid_0's l1: 0.411629\tvalid_0's l2: 0.340138\n",
      "[14]\tvalid_0's l1: 0.410353\tvalid_0's l2: 0.339705\n",
      "[15]\tvalid_0's l1: 0.408485\tvalid_0's l2: 0.339032\n",
      "[16]\tvalid_0's l1: 0.406655\tvalid_0's l2: 0.338513\n",
      "[17]\tvalid_0's l1: 0.404973\tvalid_0's l2: 0.338043\n",
      "[18]\tvalid_0's l1: 0.403482\tvalid_0's l2: 0.337822\n",
      "[19]\tvalid_0's l1: 0.40215\tvalid_0's l2: 0.337616\n",
      "[20]\tvalid_0's l1: 0.40105\tvalid_0's l2: 0.337825\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 0.40105\tvalid_0's l2: 0.337825\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "# Arrays of all evaluation values\n",
    "# row: head,\n",
    "# RMSE (DF_1 - DF_6), \n",
    "# MAE (DF_1 - DF_6), \n",
    "# SMAPE (DF_1 - DF_6), \n",
    "# R-squared (DF_1 - DF_6)\n",
    "\n",
    "# col: head,\n",
    "# DF_0 (without CD, with CD, % improved)\n",
    "\n",
    "eval_array = np.asarray([['Evaluation', 'Without CD', 'With CD', '% improved']])\n",
    "\n",
    "rmse = np.zeros(1)\n",
    "mae = np.zeros(1)\n",
    "smape = np.zeros(1)\n",
    "r2 = np.zeros(1)\n",
    "\n",
    "subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                         'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                         'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                         'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "\n",
    "train_file_dir = 'Data/' + province1 + '/Modified Lags/train_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "test_file_dir = 'Data/' + province1 + '/Modified Lags/test_' + province2 + '_subdist_cd_mavg2.csv'\n",
    "\n",
    "df_train_subdist =  pd.read_csv(train_file_dir, header = 0, skiprows = 0)\n",
    "df_test_subdist = pd.read_csv(test_file_dir, header = 0, skiprows = 0)\n",
    "\n",
    "# From DF_1 to DF_6\n",
    "for i in range(6):\n",
    "    # Allocate the column of addrcode, week, year and actual values first\n",
    "    df_test_addrcode_week_year_subdist = df_test_subdist.iloc[:,[1, 2, 3, 4]]\n",
    "    \n",
    "    ## Without CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # and LST_wm4 [col 21]\n",
    "        \n",
    "    ## With CD ##\n",
    "    \n",
    "    # Import the dataset\n",
    "    # x: independent variables\n",
    "    # DF_0 [col 5],\n",
    "    # DF_wm1 [col 6], \n",
    "    # DF_wm2 [col 7],\n",
    "    # DF_wm3 [col 8],\n",
    "    # DF_wm4 [col 9], \n",
    "    # DF_wm5 [col 10],\n",
    "    # DF_wm6 [col 11],\n",
    "    # RF_wm6 [col 20],\n",
    "    # LST_wm4 [col 21],\n",
    "    # bin_pop9s [col 22],\n",
    "    # bowl_pop9s [col 23],\n",
    "    # bucket_pop9s [col 24],\n",
    "    # misc_short_pop9s [col 25],\n",
    "    # jar_pop9s [col 26],\n",
    "    # pottedplant_pop9s [col 27],\n",
    "    # tire_pop9s [col 28],\n",
    "    # misc_tall_pop9s [col 29],\n",
    "    # and total_pop9s [col 30]\n",
    "    \n",
    "    df_train_subdist_DFinfo = df_train_subdist.iloc[:, (5 + i):12]\n",
    "    df_train_subdist_withoutCD = df_train_subdist.iloc[:, [20, 21]]\n",
    "    df_train_subdist_withCD = df_train_subdist.iloc[:, 20: 31]\n",
    "    \n",
    "    df_test_subdist_DFinfo = df_test_subdist.iloc[:, (5 + i):12]\n",
    "    df_test_subdist_withoutCD = df_test_subdist.iloc[:, [20, 21]]\n",
    "    df_test_subdist_withCD = df_test_subdist.iloc[:, 20: 31]\n",
    "        \n",
    "    x_train_withoutCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withoutCD], axis = 1)\n",
    "    x_train_withCD = pd.concat([df_train_subdist_DFinfo, df_train_subdist_withCD], axis = 1)\n",
    "    \n",
    "    x_test_withoutCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withoutCD], axis = 1)\n",
    "    x_test_withCD = pd.concat([df_test_subdist_DFinfo, df_test_subdist_withCD], axis = 1)\n",
    "    \n",
    "    # y: response (target) variable DF_1 (col 4)\n",
    "    y_train = df_train_subdist.iloc[:, [4]]\n",
    "    y_test = df_test_subdist.iloc[:, [4]]\n",
    "    \n",
    "    # Pass the response values to the array for evaluation calculation\n",
    "    y_train_true = np.array(df_train_subdist['DF_1'])\n",
    "    y_test_true = np.array(df_test_subdist['DF_1'])\n",
    "    \n",
    "    # Pass the dataset of both independent and response variables to Light GBM\n",
    "    lgb_train_withoutCD = lgb.Dataset(x_train_withoutCD, y_train)\n",
    "    lgb_eval_withoutCD = lgb.Dataset(x_test_withoutCD, y_test, reference = lgb_train_withoutCD)\n",
    "        \n",
    "    lgb_train_withCD = lgb.Dataset(x_train_withCD, y_train)\n",
    "    lgb_eval_withCD = lgb.Dataset(x_test_withCD, y_test, reference = lgb_train_withCD)\n",
    "\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    print('Starting training...')\n",
    "    gbm_withoutCD = lgb.train(params,\n",
    "                lgb_train_withoutCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withoutCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withoutCD.save_model('model.txt')\n",
    "    \n",
    "    gbm_withCD = lgb.train(params,\n",
    "                lgb_train_withCD,\n",
    "                num_boost_round = 20,\n",
    "                valid_sets = lgb_eval_withCD,\n",
    "                early_stopping_rounds = 6)\n",
    "    #print('Saving model...')\n",
    "    # Save model to file\n",
    "    #gbm_withCD.save_model('model.txt')\n",
    "    \n",
    "    # Predict out by using test data\n",
    "    print('Starting predicting...')\n",
    "    y_pred_withoutCD = gbm_withoutCD.predict(x_test_withoutCD, num_iteration = gbm_withoutCD.best_iteration)\n",
    "    y_pred_withCD = gbm_withCD.predict(x_test_withCD, num_iteration = gbm_withCD.best_iteration)\n",
    "\n",
    "    df_y_pred_withoutCD = pd.DataFrame(y_pred_withoutCD, columns = ['predicted'])\n",
    "    df_y_pred_withCD = pd.DataFrame(y_pred_withCD, columns = ['predicted'])\n",
    "        \n",
    "    # Store all of the predicted values to the CSV files\n",
    "    df_compare_addrcode_subdist_withoutCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withoutCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withoutCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withoutCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                              + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' \n",
    "                                              + str(i + 1) + '_withoutCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "\n",
    "    df_compare_addrcode_subdist_withCD = pd.concat([df_test_addrcode_week_year_subdist, df_y_pred_withCD], axis = 1)\n",
    "    df_compare_addrcode_subdist_withCD.columns = [['addrcode', 'Week', 'Year', 'actual', 'predicted']]\n",
    "    df_compare_addrcode_subdist_withCD.to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' \n",
    "                                           + str(num_leaves) + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' \n",
    "                                           + str(i + 1) + '_withCD_' + str(num_leaves) + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_withoutCD = mean_squared_error(y_test_true, y_pred_withoutCD) ** 0.5\n",
    "    mae_withoutCD = mean_absolute_error(y_test_true, y_pred_withoutCD)\n",
    "    r2_withoutCD = r2_score(y_test_true, y_pred_withoutCD)\n",
    "    smape_withoutCD = smape_fast(y_test_true, y_pred_withoutCD)\n",
    "    #print('RMSE of the prediction without CD is:', rmse_withoutCD)\n",
    "    #print('MAE of the prediction without CD is:', mae_withoutCD)\n",
    "    #print('R-squared of the prediction without CD is:', r2_withoutCD)\n",
    "    #print('SMAPE of the prediction without CD is:', smape_withoutCD)\n",
    "        \n",
    "    rmse_withCD = mean_squared_error(y_test_true, y_pred_withCD) ** 0.5\n",
    "    mae_withCD = mean_absolute_error(y_test_true, y_pred_withCD)\n",
    "    r2_withCD = r2_score(y_test_true, y_pred_withCD)\n",
    "    smape_withCD = smape_fast(y_test_true, y_pred_withCD)\n",
    "    #print('RMSE of the prediction with CD is:', rmse_withCD)\n",
    "    #print('MAE of the prediction with CD is:', mae_withCD)\n",
    "    #print('R-squared of the prediction with CD is:', r2_withCD)\n",
    "    #print('SMAPE of the prediction with CD is:', smape_withCD)\n",
    "        \n",
    "    rmse_percent_improved = (rmse_withoutCD - rmse_withCD) / rmse_withoutCD\n",
    "    mae_percent_improved = (mae_withoutCD - mae_withCD) / mae_withoutCD\n",
    "    smape_percent_improved = (smape_withoutCD - smape_withCD) / smape_withoutCD\n",
    "    r2_percent_improved = (r2_withoutCD - r2_withCD) / r2_withoutCD\n",
    "    #eval_array = np.append(eval_array, ['RMSE', rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    #print(eval_array)\n",
    "        \n",
    "    rmse = np.append(rmse, [rmse_withoutCD, rmse_withCD, rmse_percent_improved])\n",
    "    mae = np.append(mae, [mae_withoutCD, mae_withCD, mae_percent_improved])\n",
    "    smape = np.append(smape, [smape_withoutCD, smape_withCD, smape_percent_improved])\n",
    "    r2 = np.append(r2, [r2_withoutCD, r2_withCD, r2_percent_improved])\n",
    "        \n",
    "    #df_withoutCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withoutCD.csv', header = 0)\n",
    "    #df_withCD = pd.read_csv('LGBM/Original/LGBM_dist_DF_' + str(j + 1) + '_withCD.csv', header = 0)\n",
    "    \n",
    "    df_withoutCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                               + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) + '_withoutCD_' \n",
    "                               + str(num_leaves) + '.csv', header = 0)\n",
    "    df_withCD = pd.read_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                            + '/Original DF_0/LGBM_' + province2 + '_subdist_original_DF_' + str(i + 1) + '_withCD_' \n",
    "                            + str(num_leaves) + '.csv', header = 0)\n",
    "        \n",
    "    subdist_code = df_train_subdist['addrcode'].unique()\n",
    "    \n",
    "    # For each district\n",
    "    for j in subdist_code:\n",
    "            \n",
    "        # Get the subset of actual and predicted values according to the district code\n",
    "        subset_withoutCD = df_withoutCD.loc[df_withoutCD['addrcode'] == j]\n",
    "        subset_withCD = df_withCD.loc[df_withCD['addrcode'] == j]\n",
    "            \n",
    "        # Pass the response values to the array for evaluation calculation\n",
    "        array_true = np.array(subset_withoutCD['actual'])\n",
    "        array_pred_withoutCD = np.array(subset_withoutCD['predicted'])\n",
    "        array_pred_withCD = np.array(subset_withCD['predicted'])\n",
    "            \n",
    "        # Calculate the evaluation values\n",
    "        rmse_withoutCD_subdist = mean_squared_error(array_true, array_pred_withoutCD) ** 0.5\n",
    "        mae_withoutCD_subdist = mean_absolute_error(array_true, array_pred_withoutCD)\n",
    "        smape_withoutCD_subdist = smape_fast(array_true, array_pred_withoutCD)\n",
    "        r2_withoutCD_subdist = r2_score(array_true, array_pred_withoutCD)\n",
    "            \n",
    "        rmse_withCD_subdist = mean_squared_error(array_true, array_pred_withCD) ** 0.5\n",
    "        mae_withCD_subdist = mean_absolute_error(array_true, array_pred_withCD)\n",
    "        smape_withCD_subdist = smape_fast(array_true, array_pred_withCD)\n",
    "        r2_withCD_subdist = r2_score(array_true, array_pred_withCD)\n",
    "            \n",
    "        rmse_percent_improved_subdist = (rmse_withoutCD_subdist - rmse_withCD_subdist) / rmse_withoutCD_subdist\n",
    "        mae_percent_improved_subdist = (mae_withoutCD_subdist - mae_withCD_subdist) / mae_withoutCD_subdist\n",
    "        smape_percent_improved_subdist = (smape_withoutCD_subdist - smape_withCD_subdist) / smape_withoutCD_subdist\n",
    "        r2_percent_improved_subdist = (r2_withoutCD_subdist - r2_withCD_subdist) / r2_withoutCD_subdist\n",
    "            \n",
    "        # Append\n",
    "        subdist_array = np.append(subdist_array, [[j, rmse_withoutCD_subdist, rmse_withCD_subdist, rmse_percent_improved_subdist,\n",
    "                                            mae_withoutCD_subdist, mae_withCD_subdist, mae_percent_improved_subdist,\n",
    "                                            smape_withoutCD_subdist, smape_withCD_subdist, smape_percent_improved_subdist,\n",
    "                                            r2_withoutCD_subdist, r2_withCD_subdist, r2_percent_improved_subdist]], axis = 0)\n",
    "\n",
    "    #print(dist_array)\n",
    "    pd.DataFrame(subdist_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                    + '/Original DF_0/LGBM_' + province2 + '_BySubDistrict_Original_DF_' + str(i + 1) \n",
    "                                    + '_eval_' + str(num_leaves) + '.csv', header = False, encoding = 'utf-8')\n",
    "        \n",
    "    # Clear the old memory to store a new one\n",
    "    subdist_array = np.asarray([['addrcode', 'RMSE without CD', 'RMSE with CD', '% improved RMSE', \n",
    "                              'MAE without CD', 'MAE with CD', '% improved MAE', \n",
    "                              'SMAPE without CD', 'SMAPE with CD', '% improved SMAPE', \n",
    "                              'R squared without CD', 'R squared with CD', '% improved R squared']])\n",
    "    \n",
    "# Evaluation file storing\n",
    "# From RMSE DF_1 to R squared DF_6\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'RMSE', rmse)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'MAE', mae)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'SMAPE', smape)\n",
    "eval_array = evaluation_print_modified_lag_original(eval_array, 'R squared', r2)\n",
    "\n",
    "#print(eval_array)\n",
    "\n",
    "# Store all of the evaluation values into a CSV file\n",
    "pd.DataFrame(eval_array).to_csv('LGBM/' + province1 + '/Modified Lags/Normal CD/num_leaves = ' + str(num_leaves) \n",
    "                                + '/Original DF_0/LGBM_' + province2 + '_subdist_original_eval_' + str(num_leaves) \n",
    "                                + '.csv', header = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
